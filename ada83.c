/* ═══════════════════════════════════════════════════════════════════════════
 * Ada83 - An Ada 1983 (ANSI/MIL-STD-1815A) compiler targeting LLVM IR
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * §0    Setup              - SIMD instruction and fat pointer
 * §1    Type_Metrics       - Representation details
 * §2    Memory_Arena       - Bump allocation for AST nodes
 * §3    String_Slice       - Non-owning string views
 * §4    Source_Location    - Diagnostic anchors
 * §5    Error_Handling     - Accumulating error reports
 * §6    Big_Integer        - Arbitrary precision for literals
 * §7    Lexer              - Character stream to tokens
 * §8    Abstract_Syntax    - Parse tree representation
 * §9    Parser             - Recursive descent
 * §10   Type_System        - Ada type semantics
 * §11   Symbol_Table       - Scoped name resolution
 * §12   Semantic_Pass      - Type checking and resolution
 * §15   ALI_Writer         - GNAT-compatible library info
 * §15.7 Elaboration_Model  - GNAT LLVM-style dependency ordering (NEW)
 * §14   Include_Path       - Package loading & search paths
 * §16   Generic_Expansion  - Macro-style instantiation
 * §13   Code_Generator     - LLVM IR emission
 * §17   Main_Driver        - Command-line entry point
 */

#define _POSIX_C_SOURCE 200809L

#include <ctype.h>
#include <dirent.h>
#include <errno.h>
#include <fcntl.h>
#include <iso646.h>
#include <limits.h>
#include <math.h>
#include <stdarg.h>
#include <stdbool.h>
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <strings.h>
#include <pthread.h>
#include <sys/stat.h>
#include <sys/wait.h>
#include <unistd.h>

/* ═══════════════════════════════════════════════════════════════════════════
 * §0. SIMD Optimizations and Fat Pointers
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * Architectures:
 *  x86-64  - AVX-512BW (64B), AVX2 (32B), SSE4.2 (16B)                  
 *  ARM64   - NEON/ASIMD (16B), SVE (128-2048b, runtime detected)        
 *  Generic - Scalar fallback with loop unrolling      
 *
 * NOTE: Every SIMD path has an equivalent scalar fallback
 *
 * At runtime the primary path derives the bound type from the type system
 * via Array_Bound_Llvm_Type() > Type_To_Llvm(index_type).  These macros
 * exist ONLY as a compile-time backstop for the RTS preamble (emitted
 * before the type system is consulted) and for safety-net fallbacks
 * where the type is genuinely unavailable.
 *
 * The values MUST match Type_To_Llvm(Standard.INTEGER).  With 8-byte
 * INTEGER (64-bit), the bound type is i64.  To switch to 32-bit
 * INTEGER, change type_integer->size to 4 AND these four macros.
 *
 * Array types whose index type is NOT INTEGER derive their bound type
 * dynamically via Array_Bound_Llvm_Type().
 * ═══════════════════════════════════════════════════════════════════════════
 */

/* Bounds live behind the second pointer as a { bt, bt } struct where
 * bt = the native index type (i32 for STRING, i8 for CHARACTER, etc.).
 * See gnatllvm-arrays-create.adb:684-707. */
#define FAT_PTR_TYPE "{ ptr, ptr }"

/* Fat pointer size in bytes: ptr(8) + ptr(8) = 16 always. */
#define FAT_PTR_ALLOC_SIZE  16

#define STRING_BOUND_TYPE   "i32"            /* LLVM IR type for STRING bounds  */
#define STRING_BOUND_WIDTH  32               /* Width in bits                    */
#define STRING_BOUNDS_STRUCT "{ i32, i32 }"  /* Bounds struct for STRING        */
#define STRING_BOUNDS_ALLOC 8                /* sizeof(STRING bounds struct)     */

/* Check if an LLVM type string represents a thin pointer ("ptr"). */
static inline bool Llvm_Type_Is_Pointer(const char *ty) {
    return ty and ty[0] == 'p' and ty[1] == 't' and ty[2] == 'r' and ty[3] == '\0';
}

/* Check if an LLVM type string represents a fat pointer type.
 * With the uniform { ptr, ptr } layout, this is an exact match. */
static inline bool Llvm_Type_Is_Fat_Pointer(const char *ty) {
    return ty and strcmp(ty, "{ ptr, ptr }") == 0;
}

/* Detect architecture at compile time */
#if defined(__x86_64__) || defined(_M_X64)
    #define SIMD_X86_64 1
#elif defined(__aarch64__) || defined(_M_ARM64)
    #define SIMD_ARM64 1
#else
    #define SIMD_GENERIC 1
#endif

/* Runtime CPU feature detection for x86-64
 * Note: AVX-512 code only compiles with -mavx512bw; without it we use AVX2/scalar */
#ifdef SIMD_X86_64
#ifdef __AVX512BW__
static int Simd_Has_Avx512 = -1;  /* -1 = unchecked, 0 = no, 1 = yes */
#else
__attribute__((unused))
static int Simd_Has_Avx512 = 0;   /* Disabled: not compiled with AVX-512 support */
#endif
static int Simd_Has_Avx2 = -1;

static void Simd_Detect_Features(void) {
    if (Simd_Has_Avx2 >= 0) return;  /* Already detected */

    uint32_t eax, ebx, ecx, edx;

    /* Check for AVX2: CPUID.07H:EBX.AVX2[bit 5] */
    __asm__ volatile (
        "mov $7, %%eax\n\t"
        "xor %%ecx, %%ecx\n\t"
        "cpuid\n\t"
        : "=a" (eax), "=b" (ebx), "=c" (ecx), "=d" (edx)
        :
        : "memory"
    );
    Simd_Has_Avx2 = (ebx >> 5) & 1;

#ifdef __AVX512BW__
    /* Check for AVX-512F and AVX-512BW at runtime (only if compiled with support) */
    Simd_Has_Avx512 = ((ebx >> 16) & 1) and ((ebx >> 30) & 1);
#endif
}
#endif

/* ═══════════════════════════════════════════════════════════════════════════
 * §1. TYPE METRICS — Representation details
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * We centralize all size and alignment computations. All sizes flow through
 * To_Bits/To_Bytes morphisms.
 *
 * INVARIANT: Sizes in Type_Info are stored in BYTES (not bits).
 * This matches LLVM's DataLayout model and simplifies record layout.
 */

/* Safe ctype: C library requires unsigned char to avoid UB on signed char */
static inline int  Is_Alpha(char c)   { return isalpha((unsigned char)c); }
static inline int  Is_Digit(char c)   { return isdigit((unsigned char)c); }
static inline int  Is_Xdigit(char c)  { return isxdigit((unsigned char)c); }
static inline int  Is_Space(char c)   { return isspace((unsigned char)c); }
static inline char To_Lower(char c)   { return (char)tolower((unsigned char)c); }

/* Fast identifier character lookup table per Ada LRM
 * ASCII: [A-Za-z0-9_]
 * Latin-1 letters: 0xC0-0xD6 (À-Ö), 0xD8-0xF6 (Ø-ö), 0xF8-0xFF (ø-ÿ)
 * Excludes: 0xD7 (×) and 0xF7 (÷) which are operators, not letters
 */
static const uint8_t Id_Char_Table[256] = {
    /* ASCII letters */
    ['A']=1,['B']=1,['C']=1,['D']=1,['E']=1,['F']=1,['G']=1,['H']=1,
    ['I']=1,['J']=1,['K']=1,['L']=1,['M']=1,['N']=1,['O']=1,['P']=1,
    ['Q']=1,['R']=1,['S']=1,['T']=1,['U']=1,['V']=1,['W']=1,['X']=1,
    ['Y']=1,['Z']=1,
    ['a']=1,['b']=1,['c']=1,['d']=1,['e']=1,['f']=1,['g']=1,['h']=1,
    ['i']=1,['j']=1,['k']=1,['l']=1,['m']=1,['n']=1,['o']=1,['p']=1,
    ['q']=1,['r']=1,['s']=1,['t']=1,['u']=1,['v']=1,['w']=1,['x']=1,
    ['y']=1,['z']=1,
    /* Digits and underscore */
    ['0']=1,['1']=1,['2']=1,['3']=1,['4']=1,['5']=1,['6']=1,['7']=1,
    ['8']=1,['9']=1,['_']=1,
    /* Latin-1 uppercase letters: À Á Â Ã Ä Å Æ Ç È É Ê Ë Ì Í Î Ï Ð Ñ Ò Ó Ô Õ Ö */
    [0xC0]=1,[0xC1]=1,[0xC2]=1,[0xC3]=1,[0xC4]=1,[0xC5]=1,[0xC6]=1,[0xC7]=1,
    [0xC8]=1,[0xC9]=1,[0xCA]=1,[0xCB]=1,[0xCC]=1,[0xCD]=1,[0xCE]=1,[0xCF]=1,
    [0xD0]=1,[0xD1]=1,[0xD2]=1,[0xD3]=1,[0xD4]=1,[0xD5]=1,[0xD6]=1,
    /* 0xD7 = × (multiplication sign) - NOT a letter */
    /* Latin-1 more letters: Ø Ù Ú Û Ü Ý Þ ß */
    [0xD8]=1,[0xD9]=1,[0xDA]=1,[0xDB]=1,[0xDC]=1,[0xDD]=1,[0xDE]=1,[0xDF]=1,
    /* Latin-1 lowercase letters: à á â ã ä å æ ç è é ê ë ì í î ï ð ñ ò ó ô õ ö */
    [0xE0]=1,[0xE1]=1,[0xE2]=1,[0xE3]=1,[0xE4]=1,[0xE5]=1,[0xE6]=1,[0xE7]=1,
    [0xE8]=1,[0xE9]=1,[0xEA]=1,[0xEB]=1,[0xEC]=1,[0xED]=1,[0xEE]=1,[0xEF]=1,
    [0xF0]=1,[0xF1]=1,[0xF2]=1,[0xF3]=1,[0xF4]=1,[0xF5]=1,[0xF6]=1,
    /* 0xF7 = ÷ (division sign) - NOT a letter */
    /* Latin-1 remaining lowercase: ø ù ú û ü ý þ ÿ */
    [0xF8]=1,[0xF9]=1,[0xFA]=1,[0xFB]=1,[0xFC]=1,[0xFD]=1,[0xFE]=1,[0xFF]=1
};
#define Is_Id_Char(c) (Id_Char_Table[(uint8_t)(c)])

/* 128-bit integer typedefs — GCC/Clang extension, used for i128/u128 support.
 * Ada modular types (mod 2**128) and Long_Long_Long_Integer require these. */
typedef __int128          int128_t;
typedef unsigned __int128 uint128_t;

/* Universally 8 on modern targets */
enum { Bits_Per_Unit = 8 };

/* LLVM integer widths in bits */
typedef enum {
    Width_1   = 1,    Width_8   = 8,    Width_16  = 16,
    Width_32  = 32,   Width_64  = 64,   Width_128 = 128,
    Width_Ptr = 64,   Width_Float = 32, Width_Double = 64
} Bit_Width;

/* Ada standard integer widths per RM §3.5.4.
 * Long_Long_Long_Integer (128-bit) is an Ada 2022 extension,
 * included here to prepare for i128/u128 support. */
typedef enum {
    Ada_Short_Short_Integer_Bits      = Width_8,
    Ada_Short_Integer_Bits            = Width_16,
    Ada_Integer_Bits                  = Width_32,
    Ada_Long_Integer_Bits             = Width_64,
    Ada_Long_Long_Integer_Bits        = Width_64,
    Ada_Long_Long_Long_Integer_Bits   = Width_128   /* Ada 2022: 128-bit */
} Ada_Integer_Width;

/* Default metrics when type is unspecified — uses Integer'Size (32 bits) */
enum {
    Default_Size_Bits   = Ada_Integer_Bits,
    Default_Size_Bytes  = Ada_Integer_Bits / Bits_Per_Unit,
    Default_Align_Bytes = Default_Size_Bytes
};

/* ─────────────────────────────────────────────────────────────────────────
 * §1.1 Bit/Byte Conversions — Size morphisms
 *
 * To_Bits:  bytes > bits  (multiplicative, total)
 * To_Bytes: bits > bytes  (ceiling division, rounds up)
 * ───────────────────────────────────────────────────────────────────────── */

static inline uint64_t To_Bits(uint64_t bytes)  { return bytes * Bits_Per_Unit; }
static inline uint64_t To_Bytes(uint64_t bits)  { return (bits + Bits_Per_Unit - 1) / Bits_Per_Unit; }
static inline uint64_t Byte_Align(uint64_t bits){ return To_Bits(To_Bytes(bits)); }

/* Align size up to power-of-2 alignment boundary */
static inline size_t Align_To(size_t size, size_t align) {
    return align ? ((size + align - 1) & ~(align - 1)) : size;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §1.2 LLVM Type Selection — Width to type morphisms
 *
 * Maps bit width to smallest containing LLVM integer type.
 * ───────────────────────────────────────────────────────────────────────── */

static inline const char *Llvm_Int_Type(uint32_t bits) {
    return bits <= 1   ? "i1"   : bits <= 8   ? "i8"  : bits <= 16  ? "i16" :
           bits <= 32  ? "i32"  : bits <= 64  ? "i64" : "i128";
}

static inline const char *Llvm_Float_Type(uint32_t bits) {
    return bits <= Width_Float ? "float" : "double";
}


/* ─────────────────────────────────────────────────────────────────────────
 * §1.3 Range Predicates — Determining Representation Width
 *
 * Compute minimum bits needed for a range [lo, hi].
 * ───────────────────────────────────────────────────────────────────────── */

static inline bool Fits_In_Signed(int128_t lo, int128_t hi, uint32_t bits) {
    if (bits >= 128) return true;
    if (bits >= 64) {
        return lo >= (int128_t)INT64_MIN and hi <= (int128_t)INT64_MAX;
    }
    int128_t min = -((int128_t)1 << (bits - 1));
    int128_t max = ((int128_t)1 << (bits - 1)) - 1;
    return lo >= min and hi <= max;
}

static inline bool Fits_In_Unsigned(int128_t lo, int128_t hi, uint32_t bits) {
    if (lo < 0) return false;
    if (bits >= 128) return true;
    if (bits >= 64) return (uint128_t)hi <= UINT64_MAX;
    return (uint128_t)hi < ((uint128_t)1 << bits);
}

/* Determine minimum LLVM integer width for a range [lo, hi].
 * Returns Width_8, Width_16, Width_32, Width_64, or Width_128.
 * Unsigned ranges (lo >= 0) use unsigned analysis.
 * Bounds are int128_t so the full range of i128/u128 types is covered. */
static inline uint32_t Bits_For_Range(int128_t lo, int128_t hi) {
    if (lo >= 0) {
        uint128_t uhi = (uint128_t)hi;
        return uhi < 256               ? Width_8   :
               uhi < 65536             ? Width_16  :
               uhi < (uint128_t)1 << 32 ? Width_32  :
               uhi <= UINT64_MAX       ? Width_64  : Width_128;
    }
    return Fits_In_Signed(lo, hi, 8)  ? Width_8  :
           Fits_In_Signed(lo, hi, 16) ? Width_16 :
           Fits_In_Signed(lo, hi, 32) ? Width_32 :
           Fits_In_Signed(lo, hi, 64) ? Width_64 : Width_128;
}

/* Determine minimum LLVM integer width for a modular type with given modulus.
 * Modular types need enough bits to represent values 0 .. modulus-1.
 * For power-of-2 moduli (the common case), this is exactly log2(modulus) bits.
 * For non-power-of-2 moduli, we round up to the next standard LLVM width.
 * Ada RM 3.5.4(9): the range of a modular type is 0 .. modulus-1.
 *
 * Modulus is uint128_t so mod 2**64 and mod 2**128 are represented directly
 * without sentinel values.
 *
 * Examples:
 *   mod 256     -> 8 bits  (i8)     — u8
 *   mod 65536   -> 16 bits (i16)    — u16
 *   mod 2**32   -> 32 bits (i32)    — u32
 *   mod 2**64   -> 64 bits (i64)    — u64
 *   mod 2**128  -> 128 bits (i128)  — u128
 *   mod 100     -> 8 bits  (i8)     — fits in 7 bits, rounds to i8 */
static inline uint32_t Bits_For_Modulus(uint128_t modulus) {
    if (modulus == 0) return 0;  /* Invalid: modulus must be > 0 */
    uint128_t max_val = modulus - 1;
    return max_val < 256               ? Width_8  :
           max_val < 65536             ? Width_16 :
           max_val < (uint128_t)1 << 32 ? Width_32 :
           max_val <= UINT64_MAX       ? Width_64 : Width_128;
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §2. MEMORY ARENA — Bump Allocation for the Compilation Session
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * Bump allocator for AST nodes and strings. All memory persists for the
 * compilation session — we trade fragmentation for simplicity.
 *
 * Avoiding malloc(32) is not important for performance.
 */

typedef struct Arena_Chunk Arena_Chunk;
struct Arena_Chunk {
    Arena_Chunk *previous;
    char        *base;
    char        *current;
    char        *end;
};

typedef struct {
    Arena_Chunk *head;
    size_t       chunk_size;
} Memory_Arena;

static Memory_Arena Global_Arena = {0};
enum { Default_Chunk_Size = 1 << 24 };  /* 16 MiB chunks */

static void *Arena_Allocate(size_t size) {
    size = Align_To(size, 16);

    if (not Global_Arena.head or Global_Arena.head->current + size > Global_Arena.head->end) {
        size_t chunk_size = Default_Chunk_Size;
        if (size > chunk_size) chunk_size = size + sizeof(Arena_Chunk);

        Arena_Chunk *chunk = malloc(sizeof(Arena_Chunk) + chunk_size);
        if (not chunk) { fprintf(stderr, "Out of memory\n"); exit(1); }

        chunk->previous = Global_Arena.head;
        char *raw = (char*)(chunk + 1);
        char *aligned = (char*)(((uintptr_t)raw + 15) & ~(uintptr_t)15);
        chunk->base = chunk->current = aligned;
        chunk->end = raw + chunk_size;
        Global_Arena.head = chunk;
    }

    void *result = Global_Arena.head->current;
    Global_Arena.head->current += size;
    return memset(result, 0, size);
}

static void Arena_Free_All(void) {
    Arena_Chunk *chunk = Global_Arena.head;
    while (chunk) {
        Arena_Chunk *prev = chunk->previous;
        free(chunk);
        chunk = prev;
    }
    Global_Arena.head = NULL;
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §3. STRING SLICE — Non-Owning String Views
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * A slice is a pointer + length, borrowed from source or arena.
 * This avoids strlen() calls and enables substring views without allocation.
 */

typedef struct {
    const char *data;
    uint32_t    length;
} String_Slice;

#define S(literal) ((String_Slice){literal, sizeof(literal) - 1})
static const String_Slice Empty_Slice = {NULL, 0};

static inline String_Slice Slice_From_Cstring(const char *s) {
    return (String_Slice){s, s ? (uint32_t)strlen(s) : 0};
}

static String_Slice Slice_Duplicate(String_Slice s) {
    if (not s.length) return Empty_Slice;
    char *copy = Arena_Allocate(s.length + 1);
    memcpy(copy, s.data, s.length);
    return (String_Slice){copy, s.length};
}

static bool Slice_Equal(String_Slice a, String_Slice b) {
    if (a.length != b.length) return false;
    return memcmp(a.data, b.data, a.length) == 0;
}

static bool Slice_Equal_Ignore_Case(String_Slice a, String_Slice b) {
    if (a.length != b.length) return false;
    for (uint32_t i = 0; i < a.length; i++)
        if (To_Lower(a.data[i]) != To_Lower(b.data[i])) return false;
    return true;
}

/* FNV-1a hash with case folding for case-insensitive symbol lookup.
 * The constants are prime; their provenance is empirical, not divine. */
static uint64_t Slice_Hash(String_Slice s) {
    uint64_t h = 14695981039346656037ULL;
    for (uint32_t i = 0; i < s.length; i++)
        h = (h ^ (uint8_t)To_Lower(s.data[i])) * 1099511628211ULL;
    return h;
}

/* Levenshtein distance for "did you mean?" suggestions.
 * O(nm) is acceptable; identifiers are short, and errors are infrequent. */
__attribute__((unused))
static int Edit_Distance(String_Slice a, String_Slice b) {
    if (a.length > 20 or b.length > 20) return 100;
    int d[21][21];
    for (uint32_t i = 0; i <= a.length; i++) d[i][0] = (int)i;
    for (uint32_t j = 0; j <= b.length; j++) d[0][j] = (int)j;
    for (uint32_t i = 1; i <= a.length; i++)
        for (uint32_t j = 1; j <= b.length; j++) {
            int cost = To_Lower(a.data[i-1]) != To_Lower(b.data[j-1]);
            int del = d[i-1][j] + 1, ins = d[i][j-1] + 1, sub = d[i-1][j-1] + cost;
            d[i][j] = del < ins ? (del < sub ? del : sub) : (ins < sub ? ins : sub);
        }
    return d[a.length][b.length];
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §4. SOURCE LOCATION — Diagnostics to Source
 * ═══════════════════════════════════════════════════════════════════════════
 */

typedef struct {
    const char *filename;
    uint32_t    line;
    uint32_t    column;
} Source_Location;

static const Source_Location No_Location = {NULL, 0, 0};

/* ═══════════════════════════════════════════════════════════════════════════
 * §5. ERROR HANDLING — Diagnostic and message collection
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * Errors accumulate rather than immediately aborting, allowing the compiler
 * to report multiple issues in a single pass.
 */

static int Error_Count = 0;

static void Report_Error(Source_Location loc, const char *format, ...) {
    va_list args;
    va_start(args, format);
    fprintf(stderr, "%s:%u:%u: error: ",
            loc.filename ? loc.filename : "<unknown>", loc.line, loc.column);
    vfprintf(stderr, format, args);
    fputc('\n', stderr);
    va_end(args);
    Error_Count++;
}

__attribute__((unused, noreturn))
static void Fatal_Error(Source_Location loc, const char *format, ...) {
    va_list args;
    va_start(args, format);
    fprintf(stderr, "%s:%u:%u: INTERNAL ERROR: ",
            loc.filename ? loc.filename : "<unknown>", loc.line, loc.column);
    vfprintf(stderr, format, args);
    fputc('\n', stderr);
    va_end(args);
    exit(1);
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §6. BIG INTEGER — Arbitrary Precision for Literal Values
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * Ada literals can exceed 64-bit range. We represent magnitudes as arrays
 * of 64-bit limbs (little-endian). For literal parsing, we only need:
 *   - Construction from decimal string
 *   - Multiply by small constant (base)
 *   - Add small constant (digit)
 *   - Comparison and extraction
 */

typedef struct {
    uint64_t *limbs;
    uint32_t  count;
    uint32_t  capacity;
    bool      is_negative;
} Big_Integer;

static Big_Integer *Big_Integer_New(uint32_t capacity) {
    Big_Integer *bi = Arena_Allocate(sizeof(Big_Integer));
    bi->limbs = Arena_Allocate(capacity * sizeof(uint64_t));
    bi->capacity = capacity;
    return bi;
}

static void Big_Integer_Ensure_Capacity(Big_Integer *bi, uint32_t needed) {
    if (needed <= bi->capacity) return;
    uint32_t new_cap = bi->capacity * 2;
    if (new_cap < needed) new_cap = needed;
    uint64_t *new_limbs = Arena_Allocate(new_cap * sizeof(uint64_t));
    memcpy(new_limbs, bi->limbs, bi->count * sizeof(uint64_t));
    bi->limbs = new_limbs;
    bi->capacity = new_cap;
}

/* Normalize: remove leading zero limbs, ensure zero is non-negative */
static void Big_Integer_Normalize(Big_Integer *bi) {
    while (bi->count > 0 and bi->limbs[bi->count - 1] == 0) bi->count--;
    if (bi->count == 0) bi->is_negative = false;
}

/* Multiply in-place by small factor and add small addend */
static void Big_Integer_Mul_Add_Small(Big_Integer *bi, uint64_t factor, uint64_t addend) {
    __uint128_t carry = addend;
    for (uint32_t i = 0; i < bi->count; i++) {
        carry += (__uint128_t)bi->limbs[i] * factor;
        bi->limbs[i] = (uint64_t)carry;
        carry >>= 64;
    }
    if (carry) {
        Big_Integer_Ensure_Capacity(bi, bi->count + 1);
        bi->limbs[bi->count++] = (uint64_t)carry;
    }
}

/* Check if value fits in int64_t and extract if so */
static bool Big_Integer_Fits_Int64(const Big_Integer *bi, int64_t *out) {
    if (bi->count == 0) { *out = 0; return true; }
    if (bi->count > 1) return false;
    uint64_t v = bi->limbs[0];
    if (bi->is_negative) {
        if (v > (uint64_t)INT64_MAX + 1) return false;
        *out = -(int64_t)v;
    } else {
        if (v > (uint64_t)INT64_MAX) return false;
        *out = (int64_t)v;
    }
    return true;
}

/* Extract a Big_Integer as unsigned 128-bit value.  Returns true if the
 * value fits in uint128_t (0 .. 2^128-1).  Handles 0, 1, or 2 limbs. */
static bool Big_Integer_To_Uint128(const Big_Integer *bi, uint128_t *out) {
    if (bi->is_negative) return false;
    if (bi->count == 0) { *out = 0; return true; }
    if (bi->count == 1) { *out = (uint128_t)bi->limbs[0]; return true; }
    if (bi->count == 2) {
        *out = ((uint128_t)bi->limbs[1] << 64) | (uint128_t)bi->limbs[0];
        return true;
    }
    return false;  /* > 128 bits */
}

/* Extract a Big_Integer as signed 128-bit value.  Returns true if the
 * value fits in int128_t (-2^127 .. 2^127-1). */
static bool Big_Integer_To_Int128(const Big_Integer *bi, int128_t *out) {
    uint128_t uval;
    if (bi->count == 0) { *out = 0; return true; }
    if (bi->count > 2) return false;
    if (bi->count == 1) uval = (uint128_t)bi->limbs[0];
    else uval = ((uint128_t)bi->limbs[1] << 64) | (uint128_t)bi->limbs[0];

    if (bi->is_negative) {
        /* -(2^127) is the min value; uval must be <= 2^127 */
        if (uval > ((uint128_t)1 << 127)) return false;
        *out = -(int128_t)uval;
    } else {
        if (uval > (((uint128_t)1 << 127) - 1)) return false;
        *out = (int128_t)uval;
    }
    return true;
}

/* Compare two Big_Integer magnitudes (unsigned): returns -1, 0, or 1.
 * Sign-aware: negative < positive, then magnitude comparison. */
static int Big_Integer_Compare(const Big_Integer *a, const Big_Integer *b) {
    bool a_neg = a->is_negative and a->count > 0;
    bool b_neg = b->is_negative and b->count > 0;
    bool a_zero = a->count == 0, b_zero = b->count == 0;
    if (a_zero and b_zero) return 0;
    if (a_zero) return b_neg ? 1 : -1;
    if (b_zero) return a_neg ? -1 : 1;
    if (a_neg != b_neg) return a_neg ? -1 : 1;
    /* Same sign: compare magnitudes */
    int mag;
    if (a->count != b->count)
        mag = a->count > b->count ? 1 : -1;
    else {
        mag = 0;
        for (int i = (int)a->count - 1; i >= 0; i--) {
            if (a->limbs[i] != b->limbs[i]) {
                mag = a->limbs[i] > b->limbs[i] ? 1 : -1;
                break;
            }
        }
    }
    return a_neg ? -mag : mag;
}

/* Add two Big_Integer values with sign handling.
 * Returns a + b (sign-aware arbitrary precision). */
static Big_Integer *Big_Integer_Add(const Big_Integer *a, const Big_Integer *b) {
    /* Determine operation based on signs */
    uint32_t max_count = (a->count > b->count ? a->count : b->count) + 1;
    Big_Integer *result = Big_Integer_New(max_count);

    if (a->is_negative == b->is_negative) {
        /* Same sign: add magnitudes, keep sign */
        result->is_negative = a->is_negative;
        __uint128_t carry = 0;
        for (uint32_t i = 0; i < max_count; i++) {
            __uint128_t sum = carry;
            if (i < a->count) sum += a->limbs[i];
            if (i < b->count) sum += b->limbs[i];
            result->limbs[i] = (uint64_t)sum;
            carry = sum >> 64;
        }
        result->count = max_count;
        Big_Integer_Normalize(result);
    } else {
        /* Different signs: subtract smaller magnitude from larger */
        const Big_Integer *larger = a, *smaller = b;
        /* Compare magnitudes only */
        int cmp = 0;
        if (a->count != b->count)
            cmp = a->count > b->count ? 1 : -1;
        else {
            for (int i = (int)a->count - 1; i >= 0; i--) {
                if (a->limbs[i] != b->limbs[i]) {
                    cmp = a->limbs[i] > b->limbs[i] ? 1 : -1;
                    break;
                }
            }
        }
        if (cmp < 0) { larger = b; smaller = a; }
        result->is_negative = larger->is_negative;
        int64_t borrow = 0;
        for (uint32_t i = 0; i < larger->count; i++) {
            int64_t diff = (int64_t)larger->limbs[i] - borrow;
            if (i < smaller->count) diff -= (int64_t)smaller->limbs[i];
            if (diff < 0) { borrow = 1; }  /* cast to uint64_t handles wrap */
            else borrow = 0;
            result->limbs[i] = (uint64_t)diff;
        }
        result->count = larger->count;
        Big_Integer_Normalize(result);
    }
    return result;
}

/* ─────────────────────────────────────────────────────────────────────────────
 * §6.1 SIMD Big Integer Acceleration
 *
 * SIMD optimization for bigint operations, primarily targeting decimal parsing.
 * Instead of processing one digit at a time (mul by 10, add digit), we batch
 * process 8 digits at once (mul by 10^8, add 8-digit value).
 *
 * For example, eight ASCII digits can be converted to a 32-bit integer using:
 *   vpmaddubsw: Multiply adjacent bytes by weights, sum to words
 *   vpmaddwd:   Multiply adjacent words by weights, sum to dwords
 *   vphaddd:    Horizontal add for final reduction
 *
 * This turns O(n) multiply-add operations into O(n/8) for large literals.
 * ───────────────────────────────────────────────────────────────────────────── */

#ifdef SIMD_X86_64
/* Parse exactly 8 ASCII digits into a 32-bit integer using SIMD
 * Input: pointer to 8 ASCII digit characters ('0'-'9')
 * Output: 32-bit value in range [0, 99999999]
 *
 * Algorithm:
 *   1. Load 8 bytes, subtract '0' to get digit values 0-9
 *   2. vpmaddubsw with weights [10,1,10,1,10,1,10,1] gives 4 words:
 *      [d0*10+d1, d2*10+d3, d4*10+d5, d6*10+d7]
 *   3. vpmaddwd with weights [100,1,100,1] gives 2 dwords:
 *      [w0*100+w1, w2*100+w3]
 *   4. Final combine: dw0 * 10000 + dw1
 */
static inline uint32_t simd_parse_8_digits_avx2(const char *p) {
    uint32_t result;
    __asm__ volatile (

        /* Load 8 bytes into low portion of xmm0 */
        "vmovq (%[src]), %%xmm0\n\t"

        /* Broadcast '0' and subtract to get digit values */
        "vmovd %[zero], %%xmm1\n\t"
        "vpbroadcastb %%xmm1, %%xmm1\n\t"
        "vpsubb %%xmm1, %%xmm0, %%xmm0\n\t"

        /* Multiply-add bytes to words: weights [10,1,10,1,10,1,10,1] */
        "vmovq %[w1], %%xmm2\n\t"
        "vpmaddubsw %%xmm2, %%xmm0, %%xmm0\n\t"

        /* Multiply-add words to dwords: weights [100,1,100,1] */
        "vmovq %[w2], %%xmm2\n\t"
        "vpmaddwd %%xmm2, %%xmm0, %%xmm0\n\t"

        /* Extract two dwords and combine: dw0 * 10000 + dw1 */
        "vmovd %%xmm0, %%eax\n\t"
        "vpextrd $1, %%xmm0, %%edx\n\t"
        "imull $10000, %%eax\n\t"
        "addl %%edx, %%eax\n\t"

        : "=a" (result)
        : [src] "r" (p),
          [zero] "r" ((uint32_t)'0'),
          [w1] "r" (0x010A010A010A010AULL),  /* [10,1,10,1,10,1,10,1] as bytes (0x0A=10) */
          [w2] "r" (0x0001006400010064ULL)   /* [100,1,100,1] as words */
        : "xmm0", "xmm1", "xmm2", "edx", "memory"
    );
    return result;
}

/* Parse up to 16 ASCII digits using AVX2 (two 8-digit chunks)
 * Returns the number of digits parsed and the 64-bit value
 * Validates that all bytes are ASCII digits first
 */
static inline int simd_parse_digits_avx2(const char *p, const char *end, uint64_t *out) {
    int len = (end - p > 16) ? 16 : (int)(end - p);
    if (len < 8) {

        /* Fall back to scalar for small counts */
        uint64_t v = 0;
        int i = 0;
        while (i < len and p[i] >= '0' and p[i] <= '9') {
            v = v * 10 + (p[i] - '0');
            i++;
        }
        *out = v;
        return i;
    }

    /* Validate first eight are all digits using SIMD comparison */
    uint32_t valid_mask;
    __asm__ volatile (
        "vmovq (%[src]), %%xmm0\n\t"
        "vmovd %[lo], %%xmm1\n\t"
        "vpbroadcastb %%xmm1, %%xmm1\n\t"
        "vmovd %[hi], %%xmm2\n\t"
        "vpbroadcastb %%xmm2, %%xmm2\n\t"
        "vpcmpgtb %%xmm1, %%xmm0, %%xmm3\n\t"   /* c > '0'-1 */
        "vpcmpgtb %%xmm0, %%xmm2, %%xmm4\n\t"   /* '9'+1 > c */
        "vpand %%xmm3, %%xmm4, %%xmm0\n\t"
        "vpmovmskb %%xmm0, %[mask]\n\t"
        : [mask] "=r" (valid_mask)
        : [src] "r" (p), [lo] "r" ((uint32_t)('0' - 1)), [hi] "r" ((uint32_t)('9' + 1))
        : "xmm0", "xmm1", "xmm2", "xmm3", "xmm4", "memory"
    );

    /* Check if first 8 bytes are all digits */
    if ((valid_mask & 0xFF) != 0xFF) {
        /* Not all 8 are digits, fall back to scalar */
        uint64_t v = 0;
        int i = 0;
        while (i < len and p[i] >= '0' and p[i] <= '9') {
            v = v * 10 + (p[i] - '0');
            i++;
        }
        *out = v;
        return i;
    }

    uint32_t hi = simd_parse_8_digits_avx2(p);

    /* Try for 16 digits if we have enough input */
    if (len >= 16) {
        /* Validate next 8 */
        __asm__ volatile (
            "vmovq 8(%[src]), %%xmm0\n\t"
            "vmovd %[lo], %%xmm1\n\t"
            "vpbroadcastb %%xmm1, %%xmm1\n\t"
            "vmovd %[hi], %%xmm2\n\t"
            "vpbroadcastb %%xmm2, %%xmm2\n\t"
            "vpcmpgtb %%xmm1, %%xmm0, %%xmm3\n\t"
            "vpcmpgtb %%xmm0, %%xmm2, %%xmm4\n\t"
            "vpand %%xmm3, %%xmm4, %%xmm0\n\t"
            "vpmovmskb %%xmm0, %[mask]\n\t"
            : [mask] "=r" (valid_mask)
            : [src] "r" (p), [lo] "r" ((uint32_t)('0' - 1)), [hi] "r" ((uint32_t)('9' + 1))
            : "xmm0", "xmm1", "xmm2", "xmm3", "xmm4", "memory"
        );
        if ((valid_mask & 0xFF) == 0xFF) {
            uint32_t lo = simd_parse_8_digits_avx2(p + 8);
            *out = (uint64_t)hi * 100000000ULL + lo;
            return 16;
        }
    }

    /* Only 8 digits valid */
    *out = hi;
    return 8;
}
#endif /* SIMD_X86_64 */

/* SIMD-accelerated decimal to big integer conversion
 * Processes 8 digits at a time when possible for large numbers
 */
static Big_Integer *Big_Integer_From_Decimal_SIMD(const char *str) {
    Big_Integer *bi = Big_Integer_New(4);
    bi->is_negative = (*str == '-');
    if (*str == '-' or *str == '+') str++;

    /* Skip leading zeros */
    while (*str == '0') str++;
    if (*str == '\0' or (*str < '0' or *str > '9')) {
        bi->limbs[0] = 0;
        bi->count = 1;
        Big_Integer_Normalize(bi);
        return bi;
    }

    /* Find end of digit string */
    const char *end = str;
    while (*end >= '0' and *end <= '9') end++;

#ifdef SIMD_X86_64
    Simd_Detect_Features();
    if (Simd_Has_Avx2) {
        /* Initialize bigint with first chunk */
        bi->limbs[0] = 0;
        bi->count = 1;

        const char *p = str;
        while (p < end) {
            int remaining = (int)(end - p);
            if (remaining >= 8) {
                /* Process 8 or 16 digits at once */
                uint64_t chunk;
                int parsed = simd_parse_digits_avx2(p, end, &chunk);
                if (parsed == 16) {
                    /* Multiply by 10^16 and add 16-digit value */
                    Big_Integer_Mul_Add_Small(bi, 10000000000000000ULL, chunk);
                    p += 16;
                } else if (parsed == 8) {
                    /* Multiply by 10^8 and add 8-digit value */
                    Big_Integer_Mul_Add_Small(bi, 100000000ULL, chunk);
                    p += 8;
                } else {
                    /* Partial - process one digit */
                    Big_Integer_Mul_Add_Small(bi, 10, (uint64_t)(*p - '0'));
                    p++;
                }
            } else {
                /* Remaining digits one at a time */
                Big_Integer_Mul_Add_Small(bi, 10, (uint64_t)(*p - '0'));
                p++;
            }
        }
        Big_Integer_Normalize(bi);
        return bi;
    }
#endif

    /* Scalar fallback */
    bi->limbs[0] = 0;
    bi->count = 1;
    while (str < end) {
        Big_Integer_Mul_Add_Small(bi, 10, (uint64_t)(*str - '0'));
        str++;
    }
    Big_Integer_Normalize(bi);
    return bi;
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §6.2 BIG_REAL — Arbitrary Precision Real Numbers
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * Represents real literals with arbitrary precision per Ada LRM §2.4.1.
 * Structure: significand × 10^exponent
 *
 * Example: 3.14159_26535_89793 is stored as:
 *   significand = 314159265358979 (Big_Integer)
 *   exponent = -14 (decimal point position)
 *
 * This allows exact representation of literals like Pi to any precision.
 * The rounding error is in the conversion, not the representation.
 */

typedef struct {
    Big_Integer *significand;  /* All digits without decimal point */
    int32_t      exponent;     /* Power of 10 (negative for fractional) */
} Big_Real;

static Big_Real *Big_Real_New(void) {
    Big_Real *br = Arena_Allocate(sizeof(Big_Real));
    br->significand = Big_Integer_New(4);
    br->exponent = 0;
    return br;
}

/* Parse a real literal into arbitrary precision Big_Real
 * Handles: 3.14, 3.14E-10, 3.14159_26535_89793_23846_26433_83279
 */
static Big_Real *Big_Real_From_String(const char *str) {
    Big_Real *br = Big_Real_New();
    br->significand->is_negative = (*str == '-');
    if (*str == '-' or *str == '+') str++;

    /* Collect all digits (ignoring decimal point and underscores) */
    char clean[512];
    int clean_len = 0;
    int decimal_pos = -1;  /* Position of decimal point in digit sequence */
    int digit_count = 0;

    while (*str and *str != 'E' and *str != 'e') {
        if (*str == '.') {
            decimal_pos = digit_count;
        } else if (*str >= '0' and *str <= '9') {
            if (clean_len < (int)sizeof(clean) - 1) {
                clean[clean_len++] = *str;
            }
            digit_count++;
        }
        /* Skip underscores */
        str++;
    }
    clean[clean_len] = '\0';

    /* Parse exponent if present */
    int exp = 0;
    if (*str == 'E' or *str == 'e') {
        str++;
        int exp_sign = 1;
        if (*str == '-') { exp_sign = -1; str++; }
        else if (*str == '+') str++;
        while (*str >= '0' and *str <= '9') {
            exp = exp * 10 + (*str - '0');
            str++;
        }
        exp *= exp_sign;
    }

    /* Calculate final exponent:
     *
     * If decimal at position 3 in "314159" (for 3.14159), exponent = 3 - 6 = -3
     * Then add any explicit exponent
     */
    if (decimal_pos >= 0) {
        br->exponent = exp + (decimal_pos - digit_count);
    } else {
        br->exponent = exp;
    }

    /* Parse significand digits using existing Big_Integer parsing */
    br->significand = Big_Integer_From_Decimal_SIMD(clean);
    return br;
}

/* Convert Big_Real to double (for compatibility with existing code) */
static double Big_Real_To_Double(const Big_Real *br) {
    if (br->significand->count == 0) return 0.0;

    /* Extract significand as double */
    double sig = 0.0;
    for (int i = (int)br->significand->count - 1; i >= 0; i--) {
        sig = sig * 18446744073709551616.0 + (double)br->significand->limbs[i];
    }
    if (br->significand->is_negative) sig = -sig;

    /* Apply exponent */
    if (br->exponent > 0) {
        for (int i = 0; i < br->exponent; i++) sig *= 10.0;
    } else if (br->exponent < 0) {
        for (int i = 0; i < -br->exponent; i++) sig /= 10.0;
    }
    return sig;
}

/* Check if Big_Real fits in a double without precision loss
 * Returns true if the significand has <= 15 significant digits
 */
__attribute__((unused))
static bool Big_Real_Fits_Double(const Big_Real *br) {
    if (br->significand->count == 0) return true;
    if (br->significand->count > 1) return false;
    /* 15 decimal digits fit in a double's 53-bit mantissa */
    return br->significand->limbs[0] < 1000000000000000ULL;
}

/* Convert Big_Real to hexadecimal float format for precise LLVM IR emission
 * LLVM accepts: 0xHHHHHHHHHHHHHHHH (IEEE 754 double hex encoding)
 * This preserves full precision unlike %f format
 */
__attribute__((unused))
static void Big_Real_To_Hex(const Big_Real *br, char *buf, size_t bufsize) {
    if (not br or br->significand->count == 0) {
        snprintf(buf, bufsize, "0.0");
        return;
    }
    /* Convert to double and extract IEEE 754 bits */
    double d = Big_Real_To_Double(br);
    uint64_t bits;
    memcpy(&bits, &d, sizeof(bits));
    snprintf(buf, bufsize, "0x%016llX", (unsigned long long)bits);
}

/* Clone a Big_Integer */
static Big_Integer *Big_Integer_Clone(const Big_Integer *src) {
    Big_Integer *dst = Big_Integer_New(src->count > 0 ? src->count : 1);
    dst->count = src->count;
    dst->is_negative = src->is_negative;
    if (src->count > 0)
        memcpy(dst->limbs, src->limbs, src->count * sizeof(uint64_t));
    return dst;
}

/* Compare two Big_Real values exactly: returns -1, 0, or 1.
 * Normalizes to same exponent by multiplying the one with larger exponent
 * by 10^(diff), then compares significands. */
__attribute__((unused))
static int Big_Real_Compare(const Big_Real *a, const Big_Real *b) {
    if (not a or not b) return 0;

    /* Handle signs first */
    bool a_neg = a->significand->is_negative and a->significand->count > 0;
    bool b_neg = b->significand->is_negative and b->significand->count > 0;
    bool a_zero = a->significand->count == 0;
    bool b_zero = b->significand->count == 0;
    if (a_zero and b_zero) return 0;
    if (a_zero) return b_neg ? 1 : -1;
    if (b_zero) return a_neg ? -1 : 1;
    if (a_neg and not b_neg) return -1;
    if (not a_neg and b_neg) return 1;

    /* Same sign — normalize to common exponent (min), multiply the other */
    int32_t exp_diff = a->exponent - b->exponent;
    Big_Integer *sa, *sb;
    if (exp_diff == 0) {
        sa = Big_Integer_Clone(a->significand);
        sb = Big_Integer_Clone(b->significand);
    } else if (exp_diff > 0) {
        sa = Big_Integer_Clone(a->significand);
        for (int32_t i = 0; i < exp_diff; i++)
            Big_Integer_Mul_Add_Small(sa, 10, 0);
        sb = Big_Integer_Clone(b->significand);
    } else {
        sa = Big_Integer_Clone(a->significand);
        sb = Big_Integer_Clone(b->significand);
        for (int32_t i = 0; i < -exp_diff; i++)
            Big_Integer_Mul_Add_Small(sb, 10, 0);
    }
    /* Compare magnitudes, then adjust for sign */
    int cmp = Big_Integer_Compare(sa, sb);
    return a_neg ? -cmp : cmp;
}

/* Add/subtract Big_Real values (exact). op_sub: 0=add, 1=subtract.
 * Result = a ± b via normalizing to common exponent. */
__attribute__((unused))
static Big_Real *Big_Real_Add_Sub(const Big_Real *a, const Big_Real *b, bool op_sub) {
    if (not a) return (Big_Real *)(uintptr_t)b;
    if (not b) return (Big_Real *)(uintptr_t)a;
    Big_Real *result = Big_Real_New();

    int32_t min_exp = a->exponent < b->exponent ? a->exponent : b->exponent;

    /* Normalize both to min_exp by multiplying significands by 10^(exp - min_exp) */
    Big_Integer *sa = Big_Integer_Clone(a->significand);
    for (int32_t i = 0; i < a->exponent - min_exp; i++)
        Big_Integer_Mul_Add_Small(sa, 10, 0);

    Big_Integer *sb = Big_Integer_Clone(b->significand);
    for (int32_t i = 0; i < b->exponent - min_exp; i++)
        Big_Integer_Mul_Add_Small(sb, 10, 0);

    /* Flip sign for subtraction */
    if (op_sub) sb->is_negative = not sb->is_negative;

    /* Add: if same sign, add magnitudes. If different sign, subtract. */
    result->significand = Big_Integer_Add(sa, sb);
    result->exponent = min_exp;
    return result;
}

/* Multiply Big_Real by power of 10 (for exponent adjustment) */
__attribute__((unused))
static Big_Real *Big_Real_Scale(const Big_Real *br, int32_t scale) {
    if (not br) return NULL;
    Big_Real *result = Big_Real_New();
    result->significand = Big_Integer_New(br->significand->capacity);
    result->significand->count = br->significand->count;
    result->significand->is_negative = br->significand->is_negative;
    memcpy(result->significand->limbs, br->significand->limbs,
           br->significand->count * sizeof(uint64_t));
    result->exponent = br->exponent + scale;
    return result;
}

/* Divide Big_Real by integer (for fixed-point SMALL calculation)
 * Returns result = a / divisor
 * Uses arbitrary precision for intermediate calculation
 */
__attribute__((unused))
static Big_Real *Big_Real_Divide_Int(const Big_Real *a, int64_t divisor) {
    if (not a or divisor == 0) return NULL;
    /* For exact division: multiply significand precision and divide */
    /* Result = (significand * 10^precision) / divisor × 10^(exponent-precision) */
    int precision = 30;  /* Extra decimal places for precision */

    Big_Real *result = Big_Real_New();
    result->significand = Big_Integer_New(a->significand->capacity + 4);

    /* Copy significand and multiply by 10^precision */
    result->significand->count = a->significand->count;
    result->significand->is_negative = a->significand->is_negative ^ (divisor < 0);
    memcpy(result->significand->limbs, a->significand->limbs,
           a->significand->count * sizeof(uint64_t));

    for (int i = 0; i < precision; i++) {
        Big_Integer_Mul_Add_Small(result->significand, 10, 0);
    }

    /* Divide by absolute value of divisor */
    uint64_t d = divisor < 0 ? -divisor : divisor;
    uint64_t remainder = 0;
    for (int i = (int)result->significand->count - 1; i >= 0; i--) {
        __uint128_t val = ((__uint128_t)remainder << 64) | result->significand->limbs[i];
        result->significand->limbs[i] = (uint64_t)(val / d);
        remainder = (uint64_t)(val % d);
    }
    Big_Integer_Normalize(result->significand);

    result->exponent = a->exponent - precision;
    return result;
}

/* Multiply two Big_Real values
 * Result = a × b with full precision
 */
__attribute__((unused))
static Big_Real *Big_Real_Multiply(const Big_Real *a, const Big_Real *b) {
    if (not a or not b) return NULL;

    Big_Real *result = Big_Real_New();
    uint32_t new_count = a->significand->count + b->significand->count;
    result->significand = Big_Integer_New(new_count + 1);
    result->significand->count = new_count;
    result->significand->is_negative =
        a->significand->is_negative ^ b->significand->is_negative;
    memset(result->significand->limbs, 0, new_count * sizeof(uint64_t));

    /* Textbook multiplication */
    for (uint32_t i = 0; i < a->significand->count; i++) {
        __uint128_t carry = 0;
        for (uint32_t j = 0; j < b->significand->count; j++) {
            __uint128_t prod = (__uint128_t)a->significand->limbs[i] *
                               b->significand->limbs[j] +
                               result->significand->limbs[i + j] + carry;
            result->significand->limbs[i + j] = (uint64_t)prod;
            carry = prod >> 64;
        }
        if (carry and i + b->significand->count < new_count) {
            result->significand->limbs[i + b->significand->count] = (uint64_t)carry;
        }
    }
    Big_Integer_Normalize(result->significand);

    result->exponent = a->exponent + b->exponent;
    return result;
}

/* ─────────────────────────────────────────────────────────────────────────────
 * §6.3 Exact Rational Arithmetic for Universal Reals (RM 4.10)
 *
 * Ada requires that static universal_real expressions be evaluated exactly
 * during compilation.  IEEE double cannot represent fractions like 1/3, so
 * we carry numerator/denominator as Big_Integer pairs, reduced by GCD.
 * ───────────────────────────────────────────────────────────────────────── */

/* Full-precision Big_Integer multiply: returns a * b. */
static Big_Integer *Big_Integer_Multiply(const Big_Integer *a, const Big_Integer *b) {
    if (a->count == 0 or b->count == 0) {
        Big_Integer *z = Big_Integer_New(1); z->count = 0; return z;
    }
    uint32_t nc = a->count + b->count;
    Big_Integer *r = Big_Integer_New(nc + 1);
    r->count = nc;
    r->is_negative = a->is_negative ^ b->is_negative;
    memset(r->limbs, 0, nc * sizeof(uint64_t));
    for (uint32_t i = 0; i < a->count; i++) {
        __uint128_t carry = 0;
        for (uint32_t j = 0; j < b->count; j++) {
            __uint128_t prod = (__uint128_t)a->limbs[i] * b->limbs[j]
                             + r->limbs[i + j] + carry;
            r->limbs[i + j] = (uint64_t)prod;
            carry = prod >> 64;
        }
        if (carry) r->limbs[i + b->count] += (uint64_t)carry;
    }
    Big_Integer_Normalize(r);
    return r;
}

/* Big_Integer_Div_Rem: q = |a| / |b|, rem = |a| % |b| (unsigned).
 * Uses schoolbook long division on 64-bit limbs.  Signs ignored. */
static void Big_Integer_Div_Rem(const Big_Integer *a, const Big_Integer *b,
                                Big_Integer **q_out, Big_Integer **r_out) {
    if (b->count == 0) { *q_out = *r_out = Big_Integer_New(1); return; }
    if (a->count == 0 or Big_Integer_Compare(a, b) == 0
        ? false : (a->count < b->count)) {
        /* |a| < |b| > q=0, r=a */
        *q_out = Big_Integer_New(1); (*q_out)->count = 0;
        *r_out = Big_Integer_Clone(a); (*r_out)->is_negative = false;
        return;
    }
    /* Single-limb divisor fast path */
    if (b->count == 1) {
        uint64_t d = b->limbs[0];
        Big_Integer *q = Big_Integer_New(a->count);
        q->count = a->count;
        __uint128_t rem = 0;
        for (int i = (int)a->count - 1; i >= 0; i--) {
            __uint128_t val = (rem << 64) | a->limbs[i];
            q->limbs[i] = (uint64_t)(val / d);
            rem = val % d;
        }
        Big_Integer_Normalize(q);
        Big_Integer *r = Big_Integer_New(1);
        if (rem) { r->limbs[0] = (uint64_t)rem; r->count = 1; }
        else r->count = 0;
        *q_out = q; *r_out = r;
        return;
    }
    /* Multi-limb: Knuth Algorithm D (simplified) */
    uint32_t m = a->count, n = b->count;
    /* Normalize: shift so top bit of divisor's MSL is set */
    int shift = __builtin_clzll(b->limbs[n - 1]);
    Big_Integer *u = Big_Integer_New(m + 1);
    u->count = m + 1;
    if (shift > 0) {
        u->limbs[m] = 0;
        for (uint32_t i = m; i > 0; i--)
            u->limbs[i] = (a->limbs[i-1] >> (64 - shift))
                         | (i < m ? (a->limbs[i] << shift) : 0);
        u->limbs[0] = a->limbs[0] << shift;
        /* Re-check top */
        if (m > 0) u->limbs[m] |= (a->limbs[m-1] >> (64 - shift));
    } else {
        memcpy(u->limbs, a->limbs, m * sizeof(uint64_t));
        u->limbs[m] = 0;
    }
    /* Actually, let's do it cleanly */
    /* Re-do: create shifted copies */
    Big_Integer *v = Big_Integer_New(n);
    v->count = n;
    if (shift > 0) {
        uint64_t carry = 0;
        for (uint32_t i = 0; i < n; i++) {
            v->limbs[i] = (b->limbs[i] << shift) | carry;
            carry = b->limbs[i] >> (64 - shift);
        }
        carry = 0;
        u->count = m + 1;
        for (uint32_t i = 0; i < m; i++) {
            u->limbs[i] = (a->limbs[i] << shift) | carry;
            carry = a->limbs[i] >> (64 - shift);
        }
        u->limbs[m] = carry;
    } else {
        memcpy(u->limbs, a->limbs, m * sizeof(uint64_t));
        u->limbs[m] = 0;
        memcpy(v->limbs, b->limbs, n * sizeof(uint64_t));
    }
    Big_Integer *q = Big_Integer_New(m - n + 1);
    q->count = m - n + 1;
    memset(q->limbs, 0, q->count * sizeof(uint64_t));
    for (int j = (int)(m - n); j >= 0; j--) {
        /* Estimate q_hat = (u[j+n]*2^64 + u[j+n-1]) / v[n-1] */
        __uint128_t num = ((__uint128_t)u->limbs[j + n] << 64) | u->limbs[j + n - 1];
        __uint128_t q_hat = num / v->limbs[n - 1];
        __uint128_t r_hat = num % v->limbs[n - 1];
        /* Refine */
        while (q_hat >= ((__uint128_t)1 << 64) or
               (n >= 2 and q_hat * v->limbs[n - 2] >
                (r_hat << 64) + u->limbs[j + n - 2])) {
            q_hat--;
            r_hat += v->limbs[n - 1];
            if (r_hat >= ((__uint128_t)1 << 64)) break;
        }
        /* Multiply and subtract: u[j..j+n] -= q_hat * v[0..n-1] */
        __int128_t borrow = 0;
        for (uint32_t i = 0; i < n; i++) {
            __uint128_t prod = q_hat * v->limbs[i];
            __int128_t diff = (__int128_t)u->limbs[j + i] - (uint64_t)prod - borrow;
            u->limbs[j + i] = (uint64_t)diff;
            borrow = (int64_t)(prod >> 64) - (int64_t)(diff >> 64);
        }
        __int128_t diff = (__int128_t)u->limbs[j + n] - borrow;
        u->limbs[j + n] = (uint64_t)diff;
        q->limbs[j] = (uint64_t)q_hat;
        if (diff < 0) {
            /* Add back */
            q->limbs[j]--;
            __uint128_t carry = 0;
            for (uint32_t i = 0; i < n; i++) {
                carry += (__uint128_t)u->limbs[j + i] + v->limbs[i];
                u->limbs[j + i] = (uint64_t)carry;
                carry >>= 64;
            }
            u->limbs[j + n] += (uint64_t)carry;
        }
    }
    Big_Integer_Normalize(q);
    /* Remainder = u >> shift */
    Big_Integer *rem = Big_Integer_New(n);
    rem->count = n;
    if (shift > 0) {
        for (uint32_t i = 0; i < n; i++) {
            rem->limbs[i] = (u->limbs[i] >> shift)
                          | (i + 1 < u->count ? u->limbs[i + 1] << (64 - shift) : 0);
        }
    } else {
        memcpy(rem->limbs, u->limbs, n * sizeof(uint64_t));
    }
    Big_Integer_Normalize(rem);
    *q_out = q; *r_out = rem;
}

/* GCD via Euclidean algorithm on Big_Integer (magnitude only). */
static Big_Integer *Big_Integer_GCD(const Big_Integer *a, const Big_Integer *b) {
    Big_Integer *x = Big_Integer_Clone(a); x->is_negative = false;
    Big_Integer *y = Big_Integer_Clone(b); y->is_negative = false;
    while (y->count > 0) {
        Big_Integer *q, *r;
        Big_Integer_Div_Rem(x, y, &q, &r);
        x = y; y = r;
    }
    return x;
}

/* Rational number: exact num/den with den > 0, reduced by GCD. */
typedef struct { Big_Integer *num, *den; } Rational;

static Big_Integer *Big_Integer_One(void) {
    Big_Integer *r = Big_Integer_New(1);
    r->limbs[0] = 1; r->count = 1; r->is_negative = false;
    return r;
}

static Rational Rational_Reduce(Big_Integer *n, Big_Integer *d) {
    /* Ensure denominator is positive */
    if (d->is_negative) { n->is_negative = !n->is_negative; d->is_negative = false; }
    if (n->count == 0) return (Rational){n, Big_Integer_One()};
    Big_Integer *g = Big_Integer_GCD(n, d);
    if (g->count == 1 and g->limbs[0] == 1)
        return (Rational){n, d};
    Big_Integer *qn, *rn, *qd, *rd;
    Big_Integer_Div_Rem(n, g, &qn, &rn);
    Big_Integer_Div_Rem(d, g, &qd, &rd);
    qn->is_negative = n->is_negative;
    return (Rational){qn, qd};
}

static Rational Rational_From_Big_Real(const Big_Real *br) {
    if (!br || br->significand->count == 0)
        return (Rational){Big_Integer_New(1), Big_Integer_One()};
    Big_Integer *num = Big_Integer_Clone(br->significand);
    Big_Integer *den = Big_Integer_One();
    if (br->exponent > 0) {
        for (int32_t i = 0; i < br->exponent; i++)
            Big_Integer_Mul_Add_Small(num, 10, 0);
    } else if (br->exponent < 0) {
        for (int32_t i = 0; i < -br->exponent; i++)
            Big_Integer_Mul_Add_Small(den, 10, 0);
    }
    return Rational_Reduce(num, den);
}

static Rational Rational_From_Int(int64_t v) {
    Big_Integer *n = Big_Integer_New(1);
    n->limbs[0] = v < 0 ? (uint64_t)(-v) : (uint64_t)v;
    n->count = v != 0 ? 1 : 0;
    n->is_negative = v < 0;
    return (Rational){n, Big_Integer_One()};
}

static Rational Rational_Add(Rational a, Rational b) {
    /* a.num/a.den + b.num/b.den = (a.num*b.den + b.num*a.den) / (a.den*b.den) */
    Big_Integer *n1 = Big_Integer_Multiply(a.num, b.den);
    Big_Integer *n2 = Big_Integer_Multiply(b.num, a.den);
    Big_Integer *num = Big_Integer_Add(n1, n2);
    Big_Integer *den = Big_Integer_Multiply(a.den, b.den);
    return Rational_Reduce(num, den);
}

static Rational Rational_Sub(Rational a, Rational b) {
    Big_Integer *neg_b_num = Big_Integer_Clone(b.num);
    neg_b_num->is_negative = !neg_b_num->is_negative;
    Rational neg_b = {neg_b_num, b.den};
    return Rational_Add(a, neg_b);
}

static Rational Rational_Mul(Rational a, Rational b) {
    Big_Integer *num = Big_Integer_Multiply(a.num, b.num);
    Big_Integer *den = Big_Integer_Multiply(a.den, b.den);
    return Rational_Reduce(num, den);
}

static Rational Rational_Div(Rational a, Rational b) {
    /* a / b = a.num*b.den / (a.den*b.num) */
    Big_Integer *num = Big_Integer_Multiply(a.num, b.den);
    Big_Integer *den = Big_Integer_Multiply(a.den, b.num);
    return Rational_Reduce(num, den);
}

static Rational Rational_Pow(Rational base, int exp) {
    if (exp == 0) return Rational_From_Int(1);
    bool neg_exp = exp < 0;
    if (neg_exp) exp = -exp;
    Rational result = Rational_From_Int(1);
    Rational b = base;
    while (exp > 0) {
        if (exp & 1) result = Rational_Mul(result, b);
        b = Rational_Mul(b, b);
        exp >>= 1;
    }
    if (neg_exp) {
        /* Invert: swap num and den */
        Big_Integer *tmp = result.num;
        result.num = result.den;
        result.den = tmp;
        if (result.den->is_negative) {
            result.num->is_negative = !result.num->is_negative;
            result.den->is_negative = false;
        }
    }
    return result;
}

static int Rational_Compare(Rational a, Rational b) {
    /* a/b vs c/d: compare a*d vs c*b (respecting signs) */
    Big_Integer *lhs = Big_Integer_Multiply(a.num, b.den);
    Big_Integer *rhs = Big_Integer_Multiply(b.num, a.den);
    return Big_Integer_Compare(lhs, rhs);
}

__attribute__((unused))
static double Rational_To_Double(Rational r) {
    /* Convert to double by computing num/den as double.
     * For best precision, convert both to double and divide. */
    double n = 0.0, d = 0.0;
    for (int i = (int)r.num->count - 1; i >= 0; i--)
        n = n * 18446744073709551616.0 + (double)r.num->limbs[i];
    if (r.num->is_negative) n = -n;
    for (int i = (int)r.den->count - 1; i >= 0; i--)
        d = d * 18446744073709551616.0 + (double)r.den->limbs[i];
    return n / d;
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §7. LEXER — Transform Characters into Tokens
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * The lexer maintains a cursor over the source buffer and produces tokens
 * on demand. Ada lexical rules from RM §2.
 */

/* ─────────────────────────────────────────────────────────────────────────
 * §7.1 Token Kinds — Ada lexicon
 * ───────────────────────────────────────────────────────────────────────── */

typedef enum {
    /* Sentinel & error */
    TK_EOF = 0, TK_ERROR,

    /* Literals */
    TK_IDENTIFIER, TK_INTEGER, TK_REAL, TK_CHARACTER, TK_STRING,

    /* Delimiters */
    TK_LPAREN, TK_RPAREN, TK_LBRACKET, TK_RBRACKET,
    TK_COMMA, TK_DOT, TK_SEMICOLON, TK_COLON, TK_TICK,

    /* Compound delimiters */
    TK_ASSIGN, TK_ARROW, TK_DOTDOT, TK_LSHIFT, TK_RSHIFT, TK_BOX, TK_BAR,

    /* Operators */
    TK_EQ, TK_NE, TK_LT, TK_LE, TK_GT, TK_GE,
    TK_PLUS, TK_MINUS, TK_STAR, TK_SLASH, TK_AMPERSAND, TK_EXPON,

    /* Reserved words (Ada 83) */
    TK_ABORT, TK_ABS, TK_ACCEPT, TK_ACCESS, TK_ALL, TK_AND, TK_AND_THEN,
    TK_ARRAY, TK_AT, TK_BEGIN, TK_BODY, TK_CASE, TK_CONSTANT, TK_DECLARE,
    TK_DELAY, TK_DELTA, TK_DIGITS, TK_DO, TK_ELSE, TK_ELSIF, TK_END,
    TK_ENTRY, TK_EXCEPTION, TK_EXIT, TK_FOR, TK_FUNCTION, TK_GENERIC,
    TK_GOTO, TK_IF, TK_IN, TK_IS, TK_LIMITED, TK_LOOP, TK_MOD, TK_NEW,
    TK_NOT, TK_NULL, TK_OF, TK_OR, TK_OR_ELSE, TK_OTHERS, TK_OUT,
    TK_PACKAGE, TK_PRAGMA, TK_PRIVATE, TK_PROCEDURE, TK_RAISE, TK_RANGE,
    TK_RECORD, TK_REM, TK_RENAMES, TK_RETURN, TK_REVERSE, TK_SELECT,
    TK_SEPARATE, TK_SUBTYPE, TK_TASK, TK_TERMINATE, TK_THEN, TK_TYPE,
    TK_USE, TK_WHEN, TK_WHILE, TK_WITH, TK_XOR,

    TK_COUNT
} Token_Kind;

/* Token kind names for diagnostics */
static const char *Token_Name[TK_COUNT] = {
    [TK_EOF]="<eof>", [TK_ERROR]="<error>", [TK_IDENTIFIER]="identifier",
    [TK_INTEGER]="integer", [TK_REAL]="real", [TK_CHARACTER]="character",
    [TK_STRING]="string", [TK_LPAREN]="(", [TK_RPAREN]=")", [TK_LBRACKET]="[",
    [TK_RBRACKET]="]", [TK_COMMA]=",", [TK_DOT]=".", [TK_SEMICOLON]=";",
    [TK_COLON]=":", [TK_TICK]="'", [TK_ASSIGN]=":=", [TK_ARROW]="=>",
    [TK_DOTDOT]="..", [TK_LSHIFT]="<<", [TK_RSHIFT]=">>", [TK_BOX]="<>",
    [TK_BAR]="|", [TK_EQ]="=", [TK_NE]="/=", [TK_LT]="<", [TK_LE]="<=",
    [TK_GT]=">", [TK_GE]=">=", [TK_PLUS]="+", [TK_MINUS]="-", [TK_STAR]="*",
    [TK_SLASH]="/", [TK_AMPERSAND]="&", [TK_EXPON]="**",
    [TK_ABORT]="ABORT", [TK_ABS]="ABS", [TK_ACCEPT]="ACCEPT",
    [TK_ACCESS]="ACCESS", [TK_ALL]="ALL", [TK_AND]="AND",
    [TK_AND_THEN]="AND THEN", [TK_ARRAY]="ARRAY", [TK_AT]="AT",
    [TK_BEGIN]="BEGIN", [TK_BODY]="BODY", [TK_CASE]="CASE",
    [TK_CONSTANT]="CONSTANT", [TK_DECLARE]="DECLARE", [TK_DELAY]="DELAY",
    [TK_DELTA]="DELTA", [TK_DIGITS]="DIGITS", [TK_DO]="DO", [TK_ELSE]="ELSE",
    [TK_ELSIF]="ELSIF", [TK_END]="END", [TK_ENTRY]="ENTRY",
    [TK_EXCEPTION]="EXCEPTION", [TK_EXIT]="EXIT", [TK_FOR]="FOR",
    [TK_FUNCTION]="FUNCTION", [TK_GENERIC]="GENERIC", [TK_GOTO]="GOTO",
    [TK_IF]="IF", [TK_IN]="IN", [TK_IS]="IS", [TK_LIMITED]="LIMITED",
    [TK_LOOP]="LOOP", [TK_MOD]="MOD", [TK_NEW]="NEW", [TK_NOT]="NOT",
    [TK_NULL]="NULL", [TK_OF]="OF", [TK_OR]="OR", [TK_OR_ELSE]="OR ELSE",
    [TK_OTHERS]="OTHERS", [TK_OUT]="OUT", [TK_PACKAGE]="PACKAGE",
    [TK_PRAGMA]="PRAGMA", [TK_PRIVATE]="PRIVATE", [TK_PROCEDURE]="PROCEDURE",
    [TK_RAISE]="RAISE", [TK_RANGE]="RANGE", [TK_RECORD]="RECORD",
    [TK_REM]="REM", [TK_RENAMES]="RENAMES", [TK_RETURN]="RETURN",
    [TK_REVERSE]="REVERSE", [TK_SELECT]="SELECT", [TK_SEPARATE]="SEPARATE",
    [TK_SUBTYPE]="SUBTYPE", [TK_TASK]="TASK", [TK_TERMINATE]="TERMINATE",
    [TK_THEN]="THEN", [TK_TYPE]="TYPE", [TK_USE]="USE", [TK_WHEN]="WHEN",
    [TK_WHILE]="WHILE", [TK_WITH]="WITH", [TK_XOR]="XOR"
};

/* Keyword lookup table — sorted for potential binary search, but linear is fine for 63 keywords */
static struct { String_Slice name; Token_Kind kind; } Keywords[] = {
    {S("abort"),TK_ABORT},{S("abs"),TK_ABS},{S("accept"),TK_ACCEPT},{S("access"),TK_ACCESS},
    {S("all"),TK_ALL},{S("and"),TK_AND},{S("array"),TK_ARRAY},{S("at"),TK_AT},
    {S("begin"),TK_BEGIN},{S("body"),TK_BODY},{S("case"),TK_CASE},{S("constant"),TK_CONSTANT},
    {S("declare"),TK_DECLARE},{S("delay"),TK_DELAY},{S("delta"),TK_DELTA},{S("digits"),TK_DIGITS},
    {S("do"),TK_DO},{S("else"),TK_ELSE},{S("elsif"),TK_ELSIF},{S("end"),TK_END},
    {S("entry"),TK_ENTRY},{S("exception"),TK_EXCEPTION},{S("exit"),TK_EXIT},{S("for"),TK_FOR},
    {S("function"),TK_FUNCTION},{S("generic"),TK_GENERIC},{S("goto"),TK_GOTO},{S("if"),TK_IF},
    {S("in"),TK_IN},{S("is"),TK_IS},{S("limited"),TK_LIMITED},{S("loop"),TK_LOOP},
    {S("mod"),TK_MOD},{S("new"),TK_NEW},{S("not"),TK_NOT},{S("null"),TK_NULL},
    {S("of"),TK_OF},{S("or"),TK_OR},{S("others"),TK_OTHERS},{S("out"),TK_OUT},
    {S("package"),TK_PACKAGE},{S("pragma"),TK_PRAGMA},{S("private"),TK_PRIVATE},
    {S("procedure"),TK_PROCEDURE},{S("raise"),TK_RAISE},{S("range"),TK_RANGE},
    {S("record"),TK_RECORD},{S("rem"),TK_REM},{S("renames"),TK_RENAMES},{S("return"),TK_RETURN},
    {S("reverse"),TK_REVERSE},{S("select"),TK_SELECT},{S("separate"),TK_SEPARATE},
    {S("subtype"),TK_SUBTYPE},{S("task"),TK_TASK},{S("terminate"),TK_TERMINATE},
    {S("then"),TK_THEN},{S("type"),TK_TYPE},{S("use"),TK_USE},{S("when"),TK_WHEN},
    {S("while"),TK_WHILE},{S("with"),TK_WITH},{S("xor"),TK_XOR},
    {Empty_Slice, TK_EOF}  /* Sentinel */
};

static Token_Kind Lookup_Keyword(String_Slice name) {
    for (int i = 0; Keywords[i].name.data; i++)
        if (Slice_Equal_Ignore_Case(name, Keywords[i].name))
            return Keywords[i].kind;
    return TK_IDENTIFIER;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §7.2 Token Structure
 * ───────────────────────────────────────────────────────────────────────── */

typedef struct {
    Token_Kind      kind;
    Source_Location location;
    String_Slice    text;

    /* Semantic value (valid based on kind) */
    union {
        int64_t      integer_value;
        double       float_value;
    };
    union {
        Big_Integer *big_integer;
        Big_Real    *big_real;     /* Arbitrary precision real literal */
    };
} Token;

/* ─────────────────────────────────────────────────────────────────────────
 * §7.3 Lexer State
 * ───────────────────────────────────────────────────────────────────────── */

typedef struct {
    const char *source_start;
    const char *current;
    const char *source_end;
    const char *filename;
    uint32_t    line;
    uint32_t    column;
    Token_Kind  prev_token_kind;  /* Track previous token for context-sensitive lexing */
} Lexer;

static Lexer Lexer_New(const char *source, size_t length, const char *filename) {
    return (Lexer){source, source, source + length, filename, 1, 1, TK_EOF};
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §7.3.1 SIMD-Accelerated Scanning Functions
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * Four ??? paths: x86-64 (AVX2/SSE4.2), ARM64 (NEON), RISC ???, and
 * scalar fallback.
 * These functions find interesting bytes without character-by-character loops.
 */

#ifdef SIMD_X86_64
/* ─────────────────────────────────────────────────────────────────────────────
 * x86-64 AVX-512/AVX2 SIMD Lexer Acceleration
 *
 * Features:
 *   - AVX-512BW: 64-byte processing with k-mask registers
 *   - AVX2: 32-byte processing with optimized instruction scheduling
 *   - Software prefetching (prefetcht0) for memory-bound operations
 *   - Loop unrolling for better instruction-level parallelism
 *   - BMI2 TZCNT for fast trailing zero count (find first non-match)
 *
 * Architecture:
 *   - Simd_Skip_Whitespace: Skip space (0x20) and C0 controls (0x09-0x0D)
 *   - Simd_Find_Char_X86: Generic single-character search (newline, quotes)
 *   - Simd_Scan_Identifier: Match [a-zA-Z0-9_] character class
 *   - Simd_Scan_Digits: Match [0-9_] for numeric literals
 * ───────────────────────────────────────────────────────────────────────────── */

/* Raw assembly bit-scan helpers - BMI2 TZCNT instruction */
static inline uint32_t Tzcnt32(uint32_t v) {
    uint32_t r;
    __asm__ ("tzcntl %1, %0" : "=r" (r) : "r" (v));
    return r;
}

static inline uint64_t Tzcnt64(uint64_t v) {
    uint64_t r;
    __asm__ ("tzcntq %1, %0" : "=r" (r) : "r" (v));
    return r;
}

/* ─────────────────────────────────────────────────────────────────────────────
 * AVX-512 Whitespace Skip
 *
 * Processes 64 bytes at a time using k-mask registers.
 * Matches: space (0x20) OR range 0x09-0x0D (tab, LF, VT, FF, CR)
 * Only compiled when targeting AVX-512 capable CPUs.
 * ───────────────────────────────────────────────────────────────────────────── */
#ifdef __AVX512BW__
static inline const char *Simd_Skip_Whitespace_Avx512(const char *p, const char *end) {
    while (p + 64 <= end) {
        uint64_t mask;
        __asm__ volatile (
            "prefetcht0 128(%[src])\n\t"           /* Prefetch next cache line */
            "vmovdqu8 (%[src]), %%zmm0\n\t"        /* Load 64 bytes */
            "vpbroadcastb %[space], %%zmm1\n\t"   /* Broadcast space char */
            "vpcmpeqb %%zmm1, %%zmm0, %%k1\n\t"   /* k1 = (c == ' ') */
            "vpbroadcastb %[lo], %%zmm2\n\t"      /* Broadcast 0x08 */
            "vpbroadcastb %[hi], %%zmm3\n\t"      /* Broadcast 0x0E */
            "vpcmpgtb %%zmm2, %%zmm0, %%k2\n\t"   /* k2 = (c > 0x08) */
            "vpcmpgtb %%zmm0, %%zmm3, %%k3\n\t"   /* k3 = (0x0E > c) */
            "kandd %%k2, %%k3, %%k2\n\t"          /* k2 = in range [0x09,0x0D] */
            "kord %%k1, %%k2, %%k0\n\t"           /* k0 = whitespace mask */
            "kmovq %%k0, %[mask]\n\t"             /* Extract to GPR */
            : [mask] "=r" (mask)
            : [src] "r" (p), [space] "r" ((uint32_t)' '),
              [lo] "r" ((uint32_t)0x08), [hi] "r" ((uint32_t)0x0E)
            : "zmm0", "zmm1", "zmm2", "zmm3", "k0", "k1", "k2", "k3", "memory"
        );
        /* If any non-whitespace found, return its position */
        if (~mask) {
            uint64_t inv = ~mask;
            __asm__ volatile ("tzcntq %1, %0" : "=r" (inv) : "r" (inv));
            return p + inv;
        }
        p += 64;
    }
    return p;
}
#endif /* __AVX512BW__ */

/* ─────────────────────────────────────────────────────────────────────────────
 * AVX2 Whitespace Skip with 2x Unrolling
 *
 * Processes 64 bytes (2x32) per iteration for better throughput.
 * Falls back to single 32-byte chunks for remaining data.
 * ───────────────────────────────────────────────────────────────────────────── */
static inline const char *Simd_Skip_Whitespace_Avx2(const char *p, const char *end) {

    /* 2x unrolled: process 64 bytes per iteration */
    while (p + 64 <= end) {
        uint32_t m0, m1;
        __asm__ volatile (
            "prefetcht0 128(%[src])\n\t"
            /* Load two 32-byte chunks in parallel */
            "vmovdqu (%[src]), %%ymm0\n\t"
            "vmovdqu 32(%[src]), %%ymm8\n\t"
            /* Broadcast constants once, reuse for both chunks */
            "vmovd %[space], %%xmm1\n\t"
            "vpbroadcastb %%xmm1, %%ymm1\n\t"
            "vmovd %[lo], %%xmm2\n\t"
            "vpbroadcastb %%xmm2, %%ymm2\n\t"
            "vmovd %[hi], %%xmm3\n\t"
            "vpbroadcastb %%xmm3, %%ymm3\n\t"
            /* First chunk comparison */
            "vpcmpeqb %%ymm1, %%ymm0, %%ymm5\n\t"   /* space match */
            "vpcmpgtb %%ymm2, %%ymm0, %%ymm6\n\t"   /* > 0x08 */
            "vpcmpgtb %%ymm0, %%ymm3, %%ymm7\n\t"   /* < 0x0E */
            /* Second chunk comparison (parallel with first) */
            "vpcmpeqb %%ymm1, %%ymm8, %%ymm9\n\t"
            "vpcmpgtb %%ymm2, %%ymm8, %%ymm10\n\t"
            "vpcmpgtb %%ymm8, %%ymm3, %%ymm11\n\t"
            /* Combine results */
            "vpand %%ymm6, %%ymm7, %%ymm6\n\t"
            "vpor %%ymm5, %%ymm6, %%ymm0\n\t"
            "vpand %%ymm10, %%ymm11, %%ymm10\n\t"
            "vpor %%ymm9, %%ymm10, %%ymm8\n\t"
            /* Extract masks */
            "vpmovmskb %%ymm0, %[m0]\n\t"
            "vpmovmskb %%ymm8, %[m1]\n\t"
            "vzeroupper\n\t"
            : [m0] "=r" (m0), [m1] "=r" (m1)
            : [src] "r" (p), [space] "r" ((uint32_t)' '),
              [lo] "r" ((uint32_t)0x08), [hi] "r" ((uint32_t)0x0E)
            : "ymm0", "ymm1", "ymm2", "ymm3", "ymm5", "ymm6", "ymm7",
              "ymm8", "ymm9", "ymm10", "ymm11", "memory"
        );
        if (m0 != 0xFFFFFFFF) return p + Tzcnt32(~m0);
        if (m1 != 0xFFFFFFFF) return p + 32 + Tzcnt32(~m1);
        p += 64;
    }

    /* Handle remaining 32-byte chunk */
    while (p + 32 <= end) {
        uint32_t mask;
        __asm__ volatile (
            "vmovdqu (%[src]), %%ymm0\n\t"
            "vmovd %[space], %%xmm1\n\t"
            "vpbroadcastb %%xmm1, %%ymm1\n\t"
            "vmovd %[lo], %%xmm2\n\t"
            "vpbroadcastb %%xmm2, %%ymm2\n\t"
            "vmovd %[hi], %%xmm3\n\t"
            "vpbroadcastb %%xmm3, %%ymm3\n\t"
            "vpcmpeqb %%ymm1, %%ymm0, %%ymm5\n\t"
            "vpcmpgtb %%ymm2, %%ymm0, %%ymm6\n\t"
            "vpcmpgtb %%ymm0, %%ymm3, %%ymm7\n\t"
            "vpand %%ymm6, %%ymm7, %%ymm6\n\t"
            "vpor %%ymm5, %%ymm6, %%ymm0\n\t"
            "vpmovmskb %%ymm0, %[mask]\n\t"
            "vzeroupper\n\t"
            : [mask] "=r" (mask)
            : [src] "r" (p), [space] "r" ((uint32_t)' '),
              [lo] "r" ((uint32_t)0x08), [hi] "r" ((uint32_t)0x0E)
            : "ymm0", "ymm1", "ymm2", "ymm3", "ymm5", "ymm6", "ymm7", "memory"
        );
        if (mask != 0xFFFFFFFF) return p + Tzcnt32(~mask);
        p += 32;
    }
    return p;
}

/* ─────────────────────────────────────────────────────────────────────────────
 * Whitespace Skip Dispatcher
 *
 * Selects best SIMD path at runtime based on CPU features.
 * Falls through to scalar loop for remaining bytes.
 * ───────────────────────────────────────────────────────────────────────────── */
static inline const char *Simd_Skip_Whitespace(const char *p, const char *end) {
    Simd_Detect_Features();
#ifdef __AVX512BW__
    if (Simd_Has_Avx512 and (end - p) >= 64) {
        p = Simd_Skip_Whitespace_Avx512(p, end);
    }
#endif
    if (Simd_Has_Avx2 and (end - p) >= 32) {
        p = Simd_Skip_Whitespace_Avx2(p, end);
    }
    /* Scalar tail for remaining bytes */
    while (p < end) {
        unsigned char c = (unsigned char)*p;
        if (c != ' ' and (c < 0x09 or c > 0x0D)) break;
        p++;
    }
    return p;
}

/* ─────────────────────────────────────────────────────────────────────────────
 * Generic Single-Character Search
 *
 * Searches for a specific character (newline, quote, etc.).
 * Used as building block for Simd_Find_Newline, Simd_Find_Quote, etc.
 * ───────────────────────────────────────────────────────────────────────────── */
static inline const char *Simd_Find_Char_X86(const char *p, const char *end, char ch) {

    /* Fast path: scalar check for first 16 bytes (covers most short comments/strings) */
    for (int i = 0; i < 16 and p + i < end; i++) {
        if (p[i] == ch) return p + i;
    }
    if (p + 16 >= end) {
        /* Short remaining buffer - finish with scalar */
        p += 16;
        while (p < end and *p != ch) p++;
        return p;
    }
    p += 16;  /* Fast path didn't find it, continue with SIMD */

    Simd_Detect_Features();
#ifdef __AVX512BW__
    /* AVX-512: 64 bytes at a time */
    if (Simd_Has_Avx512) {
        while (p + 64 <= end) {
            uint64_t mask;
            __asm__ volatile (
                "vmovdqu8 (%[src]), %%zmm0\n\t"
                "vpbroadcastb %[c], %%zmm1\n\t"
                "vpcmpeqb %%zmm1, %%zmm0, %%k0\n\t"
                "kmovq %%k0, %[mask]\n\t"
                : [mask] "=r" (mask)
                : [src] "r" (p), [c] "r" ((uint32_t)ch)
                : "zmm0", "zmm1", "k0", "memory"
            );
            if (mask) {
                __asm__ volatile ("tzcntq %1, %0" : "=r" (mask) : "r" (mask));
                return p + mask;
            }
            p += 64;
        }
    }
#endif
    /* AVX2: 32 bytes at a time */
    while (p + 32 <= end) {
        uint32_t mask;
        __asm__ volatile (
            "vmovdqu (%[src]), %%ymm0\n\t"
            "vmovd %[c], %%xmm1\n\t"
            "vpbroadcastb %%xmm1, %%ymm1\n\t"
            "vpcmpeqb %%ymm1, %%ymm0, %%ymm0\n\t"
            "vpmovmskb %%ymm0, %[mask]\n\t"
            "vzeroupper\n\t"
            : [mask] "=r" (mask)
            : [src] "r" (p), [c] "r" ((uint32_t)ch)
            : "ymm0", "ymm1", "memory"
        );
        if (mask) return p + Tzcnt32(mask);
        p += 32;
    }
    /* Scalar tail */
    while (p < end and *p != ch) p++;
    return p;
}

/* Convenience wrappers for common character searches */
static inline const char *Simd_Find_Newline(const char *p, const char *end) {
    return Simd_Find_Char_X86(p, end, '\n');
}

static inline const char *Simd_Find_Quote(const char *p, const char *end) {
    return Simd_Find_Char_X86(p, end, '\'');
}

static inline const char *Simd_Find_Double_Quote(const char *p, const char *end) {
    return Simd_Find_Char_X86(p, end, '"');
}

/* ─────────────────────────────────────────────────────────────────────────────
 * Identifier Character Class Scanner
 *
 * Uses fast table lookup for first 8 chars (covers most identifiers),
 * then SIMD only for long identifiers. Benchmarked 50% faster than pure SIMD ???
 * ───────────────────────────────────────────────────────────────────────────── */
static inline const char *Simd_Scan_Identifier(const char *p, const char *end) {
    /* Fast path: unrolled table lookup for first 8 chars (covers most identifiers) */
    if (p >= end or not Is_Id_Char(*p)) return p;
    if (p + 1 >= end or not Is_Id_Char(p[1])) return p + 1;
    if (p + 2 >= end or not Is_Id_Char(p[2])) return p + 2;
    if (p + 3 >= end or not Is_Id_Char(p[3])) return p + 3;
    if (p + 4 >= end or not Is_Id_Char(p[4])) return p + 4;
    if (p + 5 >= end or not Is_Id_Char(p[5])) return p + 5;
    if (p + 6 >= end or not Is_Id_Char(p[6])) return p + 6;
    if (p + 7 >= end or not Is_Id_Char(p[7])) return p + 7;

    /* Long identifier (> 8 chars) - continue with table lookup */
    p += 8;
    while (p < end and Is_Id_Char(*p)) p++;
    return p;
}

/* ─────────────────────────────────────────────────────────────────────────────
 * Digit Scanner for Numeric Literals
 *
 * Matches [0-9_] - digits with optional underscores (Ada numeric syntax).
 * Returns pointer to first non-digit character.
 * ───────────────────────────────────────────────────────────────────────────── */
static inline const char *Simd_Scan_Digits(const char *p, const char *end) {
    Simd_Detect_Features();
#ifdef __AVX512BW__
    /* AVX-512 path */
    if (Simd_Has_Avx512) {
        while (p + 64 <= end) {
            uint64_t mask;
            __asm__ volatile (
                "vmovdqu8 (%[src]), %%zmm0\n\t"
                "vpbroadcastb %[lo], %%zmm1\n\t"
                "vpbroadcastb %[hi], %%zmm2\n\t"
                "vpbroadcastb %[u], %%zmm3\n\t"
                "vpcmpgtb %%zmm1, %%zmm0, %%k1\n\t"     /* c > '0'-1 */
                "vpcmpgtb %%zmm0, %%zmm2, %%k2\n\t"     /* '9'+1 > c */
                "kandd %%k1, %%k2, %%k3\n\t"            /* digit */
                "vpcmpeqb %%zmm3, %%zmm0, %%k4\n\t"     /* underscore */
                "kord %%k3, %%k4, %%k0\n\t"             /* combine */
                "kmovq %%k0, %[mask]\n\t"
                : [mask] "=r" (mask)
                : [src] "r" (p),
                  [lo] "r" ((uint32_t)('0'-1)),
                  [hi] "r" ((uint32_t)('9'+1)),
                  [u] "r" ((uint32_t)'_')
                : "zmm0", "zmm1", "zmm2", "zmm3", "k0", "k1", "k2", "k3", "k4", "memory"
            );
            if (~mask) {
                __asm__ volatile ("tzcntq %1, %0" : "=r" (mask) : "r" (~mask));
                return p + mask;
            }
            p += 64;
        }
    }
#endif
    /* AVX2 path */
    while (p + 32 <= end) {
        uint32_t mask;
        __asm__ volatile (
            "vmovdqu (%[src]), %%ymm0\n\t"
            "vmovd %[lo], %%xmm1\n\t"
            "vpbroadcastb %%xmm1, %%ymm1\n\t"
            "vmovd %[hi], %%xmm2\n\t"
            "vpbroadcastb %%xmm2, %%ymm2\n\t"
            "vpcmpgtb %%ymm1, %%ymm0, %%ymm3\n\t"
            "vpcmpgtb %%ymm0, %%ymm2, %%ymm4\n\t"
            "vpand %%ymm3, %%ymm4, %%ymm5\n\t"
            "vmovd %[u], %%xmm1\n\t"
            "vpbroadcastb %%xmm1, %%ymm1\n\t"
            "vpcmpeqb %%ymm1, %%ymm0, %%ymm1\n\t"
            "vpor %%ymm5, %%ymm1, %%ymm0\n\t"
            "vpmovmskb %%ymm0, %[mask]\n\t"
            "vzeroupper\n\t"
            : [mask] "=r" (mask)
            : [src] "r" (p),
              [lo] "r" ((uint32_t)('0'-1)),
              [hi] "r" ((uint32_t)('9'+1)),
              [u] "r" ((uint32_t)'_')
            : "ymm0", "ymm1", "ymm2", "ymm3", "ymm4", "ymm5", "memory"
        );
        if (mask != 0xFFFFFFFF) return p + Tzcnt32(~mask);
        p += 32;
    }
    /* Scalar tail */
    while (p < end and ((*p >= '0' and *p <= '9') or *p == '_')) p++;
    return p;
}

#elif defined(SIMD_ARM64)
/* ─────────────────────────────────────────────────────────────────────────
 * ARM64 NEON Implementation (raw inline assembly)
 * ───────────────────────────────────────────────────────────────────────── */

static inline const char *Simd_Skip_Whitespace(const char *p, const char *end) {
    while (p + 16 <= end) {
        uint64_t lo, hi;
        __asm__ volatile (
            "ldr q0, [%[src]]\n\t"                /* Load 16 bytes */
            /* Check for space (0x20) */
            "movi v1.16b, #0x20\n\t"
            "cmeq v5.16b, v0.16b, v1.16b\n\t"
            /* Check range 0x09-0x0D: c > 0x08 and c < 0x0E */
            "movi v2.16b, #0x08\n\t"              /* lo-1 */
            "movi v3.16b, #0x0E\n\t"              /* hi+1 */
            "cmhi v6.16b, v0.16b, v2.16b\n\t"     /* c > 0x08 */
            "cmhi v7.16b, v3.16b, v0.16b\n\t"     /* 0x0E > c */
            "and v6.16b, v6.16b, v7.16b\n\t"      /* in range */
            /* Combine: whitespace = space OR in_range */
            "orr v0.16b, v5.16b, v6.16b\n\t"
            "mvn v0.16b, v0.16b\n\t"              /* Invert for non-whitespace */
            "mov %[lo], v0.d[0]\n\t"
            "mov %[hi], v0.d[1]\n\t"
            : [lo] "=r" (lo), [hi] "=r" (hi)
            : [src] "r" (p)
            : "v0", "v1", "v2", "v3", "v5", "v6", "v7", "memory"
        );
        if (lo) return p + (Tzcnt64(lo) >> 3);
        if (hi) return p + 8 + (Tzcnt64(hi) >> 3);
        p += 16;
    }
    /* Scalar tail: check all isspace() characters */
    while (p < end) {
        unsigned char c = (unsigned char)*p;
        if (c != ' ' and (c < 0x09 or c > 0x0D)) break;
        p++;
    }
    return p;
}

static inline const char *Simd_Find_Newline(const char *p, const char *end) {
    while (p + 16 <= end) {
        uint64_t lo, hi;
        __asm__ volatile (
            "ldr q0, [%[src]]\n\t"
            "movi v1.16b, #0x0A\n\t"
            "cmeq v0.16b, v0.16b, v1.16b\n\t"
            "mov %[lo], v0.d[0]\n\t"
            "mov %[hi], v0.d[1]\n\t"
            : [lo] "=r" (lo), [hi] "=r" (hi)
            : [src] "r" (p)
            : "v0", "v1", "memory"
        );
        if (lo) return p + (Tzcnt64(lo) >> 3);
        if (hi) return p + 8 + (Tzcnt64(hi) >> 3);
        p += 16;
    }
    while (p < end and *p != '\n') p++;
    return p;
}

static inline const char *Simd_Scan_Identifier(const char *p, const char *end) {
    while (p + 16 <= end) {
        uint64_t lo, hi;
        __asm__ volatile (
            "ldr q0, [%[src]]\n\t"
            /* Check a-z: c >= 'a' and c <= 'z' */
            "movi v1.16b, #0x60\n\t"              /* 'a' - 1 = 0x60 */
            "movi v2.16b, #0x7B\n\t"              /* 'z' + 1 = 0x7B */
            "cmhi v3.16b, v0.16b, v1.16b\n\t"     /* c > 'a'-1 */
            "cmhi v4.16b, v2.16b, v0.16b\n\t"     /* 'z'+1 > c */
            "and v5.16b, v3.16b, v4.16b\n\t"      /* lower */
            /* Check A-Z */
            "movi v1.16b, #0x40\n\t"              /* 'A' - 1 = 0x40 */
            "movi v2.16b, #0x5B\n\t"              /* 'Z' + 1 = 0x5B */
            "cmhi v3.16b, v0.16b, v1.16b\n\t"
            "cmhi v4.16b, v2.16b, v0.16b\n\t"
            "and v6.16b, v3.16b, v4.16b\n\t"      /* upper */
            /* Check 0-9 */
            "movi v1.16b, #0x2F\n\t"              /* '0' - 1 = 0x2F */
            "movi v2.16b, #0x3A\n\t"              /* '9' + 1 = 0x3A */
            "cmhi v3.16b, v0.16b, v1.16b\n\t"
            "cmhi v4.16b, v2.16b, v0.16b\n\t"
            "and v7.16b, v3.16b, v4.16b\n\t"      /* digit */
            /* Check underscore */
            "movi v1.16b, #0x5F\n\t"              /* '_' = 0x5F */
            "cmeq v16.16b, v0.16b, v1.16b\n\t"
            /* Combine: valid = lower | upper | digit | underscore */
            "orr v5.16b, v5.16b, v6.16b\n\t"
            "orr v7.16b, v7.16b, v16.16b\n\t"
            "orr v0.16b, v5.16b, v7.16b\n\t"
            "mvn v0.16b, v0.16b\n\t"              /* Invert for invalid */
            "mov %[lo], v0.d[0]\n\t"
            "mov %[hi], v0.d[1]\n\t"
            : [lo] "=r" (lo), [hi] "=r" (hi)
            : [src] "r" (p)
            : "v0", "v1", "v2", "v3", "v4", "v5", "v6", "v7", "v16", "memory"
        );
        if (lo) return p + (Tzcnt64(lo) >> 3);
        if (hi) return p + 8 + (Tzcnt64(hi) >> 3);
        p += 16;
    }
    while (p < end) {
        char c = *p;
        if (not ((c >= 'a' and c <= 'z') or (c >= 'A' and c <= 'Z') or
              (c >= '0' and c <= '9') or c == '_'))
            break;
        p++;
    }
    return p;
}

static inline const char *Simd_Find_Quote(const char *p, const char *end) {
    while (p + 16 <= end) {
        uint64_t lo, hi;
        __asm__ volatile (
            "ldr q0, [%[src]]\n\t"
            "movi v1.16b, #0x27\n\t"              /* '\'' = 0x27 */
            "cmeq v0.16b, v0.16b, v1.16b\n\t"
            "mov %[lo], v0.d[0]\n\t"
            "mov %[hi], v0.d[1]\n\t"
            : [lo] "=r" (lo), [hi] "=r" (hi)
            : [src] "r" (p)
            : "v0", "v1", "memory"
        );
        if (lo) return p + (Tzcnt64(lo) >> 3);
        if (hi) return p + 8 + (Tzcnt64(hi) >> 3);
        p += 16;
    }
    while (p < end and *p != '\'') p++;
    return p;
}

static inline const char *Simd_Find_Double_Quote(const char *p, const char *end) {
    while (p + 16 <= end) {
        uint64_t lo, hi;
        __asm__ volatile (
            "ldr q0, [%[src]]\n\t"
            "movi v1.16b, #0x22\n\t"              /* '"' = 0x22 */
            "cmeq v0.16b, v0.16b, v1.16b\n\t"
            "mov %[lo], v0.d[0]\n\t"
            "mov %[hi], v0.d[1]\n\t"
            : [lo] "=r" (lo), [hi] "=r" (hi)
            : [src] "r" (p)
            : "v0", "v1", "memory"
        );
        if (lo) return p + (Tzcnt64(lo) >> 3);
        if (hi) return p + 8 + (Tzcnt64(hi) >> 3);
        p += 16;
    }
    while (p < end and *p != '"') p++;
    return p;
}

static inline const char *Simd_Scan_Digits(const char *p, const char *end) {
    while (p + 16 <= end) {
        uint64_t lo, hi;
        __asm__ volatile (
            "ldr q0, [%[src]]\n\t"
            /* Check 0-9 */
            "movi v1.16b, #0x2F\n\t"              /* '0' - 1 */
            "movi v2.16b, #0x3A\n\t"              /* '9' + 1 */
            "cmhi v3.16b, v0.16b, v1.16b\n\t"
            "cmhi v4.16b, v2.16b, v0.16b\n\t"
            "and v5.16b, v3.16b, v4.16b\n\t"
            /* Check underscore */
            "movi v1.16b, #0x5F\n\t"
            "cmeq v6.16b, v0.16b, v1.16b\n\t"
            /* Combine and invert */
            "orr v0.16b, v5.16b, v6.16b\n\t"
            "mvn v0.16b, v0.16b\n\t"
            "mov %[lo], v0.d[0]\n\t"
            "mov %[hi], v0.d[1]\n\t"
            : [lo] "=r" (lo), [hi] "=r" (hi)
            : [src] "r" (p)
            : "v0", "v1", "v2", "v3", "v4", "v5", "v6", "memory"
        );
        if (lo) return p + (Tzcnt64(lo) >> 3);
        if (hi) return p + 8 + (Tzcnt64(hi) >> 3);
        p += 16;
    }
    while (p < end and ((*p >= '0' and *p <= '9') or *p == '_')) p++;
    return p;
}

#else
/* Generic Scalar Implementation (Portable Fallback)
 *
 * This is the reference implementation. All SIMD paths must produce identical
 * results to these scalar functions for all possible inputs.
 */

static inline const char *Simd_Skip_Whitespace(const char *p, const char *end) {
    while (p < end) {
        unsigned char c = (unsigned char)*p;
        if (c != ' ' and (c < 0x09 or c > 0x0D)) break;
        p++;
    }
    return p;
}

static inline const char *Simd_Find_Newline(const char *p, const char *end) {
    while (p < end and *p != '\n') p++;
    return p;
}

static inline const char *Simd_Scan_Identifier(const char *p, const char *end) {
    while (p < end) {
        char c = *p;
        if (not ((c >= 'a' and c <= 'z') or (c >= 'A' and c <= 'Z') or
              (c >= '0' and c <= '9') or c == '_'))
            break;
        p++;
    }
    return p;
}

static inline const char *Simd_Find_Quote(const char *p, const char *end) {
    while (p < end and *p != '\'') p++;
    return p;
}

static inline const char *Simd_Find_Double_Quote(const char *p, const char *end) {
    while (p < end and *p != '"') p++;
    return p;
}

static inline const char *Simd_Scan_Digits(const char *p, const char *end) {
    while (p < end and ((*p >= '0' and *p <= '9') or *p == '_')) p++;
    return p;
}

#endif /* SIMD architecture selection */

static inline char Lexer_Peek(const Lexer *lex, size_t offset) {
    return lex->current + offset < lex->source_end ? lex->current[offset] : '\0';
}

static inline char Lexer_Advance(Lexer *lex) {
    if (lex->current >= lex->source_end) return '\0';
    char c = *lex->current++;
    if (c == '\n') { lex->line++; lex->column = 1; }
    else lex->column++;
    return c;
}

static void Lexer_Skip_Whitespace_And_Comments(Lexer *lex) {
    for (;;) {
        /* Use SIMD to find first non-whitespace */
        const char *end_ws = Simd_Skip_Whitespace(lex->current, lex->source_end);
        /* Update line/column by scanning for newlines in skipped region */
        while (lex->current < end_ws) {
            if (*lex->current == '\n') { lex->line++; lex->column = 1; }
            else lex->column++;
            lex->current++;
        }

        /* Ada comment: -- to end of line */
        if (lex->current + 1 < lex->source_end and
            lex->current[0] == '-' and lex->current[1] == '-') {
            /* Use SIMD to find newline */
            const char *end_comment = Simd_Find_Newline(lex->current, lex->source_end);
            lex->column += (uint32_t)(end_comment - lex->current);
            lex->current = end_comment;
        } else break;
    }
}

static inline Token Make_Token(Token_Kind kind, Source_Location loc, String_Slice text) {
    return (Token){kind, loc, text, {0}, {NULL}};
}

/* ─────────────────────────────────────────────────────────────────────────
 * §7.4 Scanning Functions
 * ───────────────────────────────────────────────────────────────────────── */

static Token Scan_Identifier(Lexer *lex) {
    Source_Location loc = {lex->filename, lex->line, lex->column};
    const char *start = lex->current;

    /* Use SIMD to find end of identifier */
    const char *end_id = Simd_Scan_Identifier(lex->current, lex->source_end);
    lex->column += (uint32_t)(end_id - lex->current);
    lex->current = end_id;

    String_Slice text = {start, (uint32_t)(lex->current - start)};
    Token_Kind kind = Lookup_Keyword(text);
    return Make_Token(kind, loc, text);
}

/* Parse digit value in any base up to 16 */
static inline int Digit_Value(char c) {
    if (c >= '0' and c <= '9') return c - '0';
    if (c >= 'A' and c <= 'F') return c - 'A' + 10;
    if (c >= 'a' and c <= 'f') return c - 'a' + 10;
    return -1;
}

static Token Scan_Number(Lexer *lex) {
    Source_Location loc = {lex->filename, lex->line, lex->column};
    const char *start = lex->current;
    int base = 10;
    bool is_real = false, has_exponent = false, is_based = false;

    /* Scan integer part (possibly base specifier) */
    while (Is_Digit(Lexer_Peek(lex, 0)) or Lexer_Peek(lex, 0) == '_')
        Lexer_Advance(lex);

    /* Based literal: 16#FFFF# or 2#1010# */
    if (Lexer_Peek(lex, 0) == '#' or
        (Lexer_Peek(lex, 0) == ':' and Is_Xdigit(Lexer_Peek(lex, 1)))) {
        is_based = true;
        char delim = Lexer_Peek(lex, 0);

        /* Parse base from what we've scanned so far */
        char base_buf[16] = {0};
        int bi = 0;
        for (const char *p = start; p < lex->current and bi < 15; p++)
            if (*p != '_') base_buf[bi++] = *p;
        base = atoi(base_buf);

        Lexer_Advance(lex); /* consume # or : */

        /* Scan mantissa */
        while (Is_Xdigit(Lexer_Peek(lex, 0)) or Lexer_Peek(lex, 0) == '_')
            Lexer_Advance(lex);

        if (Lexer_Peek(lex, 0) == '.') {
            is_real = true;
            Lexer_Advance(lex);
            while (Is_Xdigit(Lexer_Peek(lex, 0)) or Lexer_Peek(lex, 0) == '_')
                Lexer_Advance(lex);
        }

        if (Lexer_Peek(lex, 0) == delim) Lexer_Advance(lex);

        if (To_Lower(Lexer_Peek(lex, 0)) == 'e') {
            has_exponent = true;
            Lexer_Advance(lex);
            if (Lexer_Peek(lex, 0) == '+' or Lexer_Peek(lex, 0) == '-')
                Lexer_Advance(lex);
            while (Is_Digit(Lexer_Peek(lex, 0)) or Lexer_Peek(lex, 0) == '_')
                Lexer_Advance(lex);
        }
    } else {
        /* Decimal literal with optional fraction and exponent */
        if (Lexer_Peek(lex, 0) == '.' and Lexer_Peek(lex, 1) != '.' and not Is_Alpha(Lexer_Peek(lex, 1))) {
            is_real = true;
            Lexer_Advance(lex);
            while (Is_Digit(Lexer_Peek(lex, 0)) or Lexer_Peek(lex, 0) == '_')
                Lexer_Advance(lex);
        }

        if (To_Lower(Lexer_Peek(lex, 0)) == 'e') {
            has_exponent = true;
            /* Note: exponent alone doesn't make it real - 12E1 is integer 120 */
            Lexer_Advance(lex);
            if (Lexer_Peek(lex, 0) == '+' or Lexer_Peek(lex, 0) == '-')
                Lexer_Advance(lex);
            while (Is_Digit(Lexer_Peek(lex, 0)) or Lexer_Peek(lex, 0) == '_')
                Lexer_Advance(lex);
        }
    }

    String_Slice text = {start, (uint32_t)(lex->current - start)};
    Token tok = Make_Token(is_real ? TK_REAL : TK_INTEGER, loc, text);

    /* Convert to value: strip underscores, parse with base */
    char clean[512];
    int ci = 0;
    for (const char *p = start; p < lex->current and ci < 510; p++)
        if (*p != '_' and *p != '#' and *p != ':') clean[ci++] = *p;
    clean[ci] = '\0';

    if (is_real) {
        if (not is_based) {
            /* Parse into Big_Real for arbitrary precision */
            tok.big_real = Big_Real_From_String(clean);
            /* Also compute double for compatibility */
            tok.float_value = Big_Real_To_Double(tok.big_real);
        } else {
            /* Based real — parse mantissa as integer, divide once for precision.
             * Accumulating frac digits individually causes ULP rounding drift. */
            long double whole = 0.0L, frac_int = 0.0L;
            int frac_digits = 0, exp = 0, state = 0;
            bool exp_neg = false;
            for (const char *p = start; p < lex->current; p++) {
                char c = *p;
                if (c == '_') continue;
                if (c == '#' or c == ':') { state++; continue; }
                if (c == '.') { state = 2; continue; }
                if (To_Lower(c) == 'e' and state > 2) { state = 3; continue; }
                int d = Digit_Value(c);
                if (state == 1 and d >= 0 and d < base)
                    whole = whole * base + d;
                else if (state == 2 and d >= 0 and d < base)
                    { frac_int = frac_int * base + d; frac_digits++; }
                else if (state == 3)
                    { if (c == '-') exp_neg = true;
                      else if (c != '+' and Is_Digit(c)) exp = exp * 10 + (c - '0'); }
            }
            /* value = whole + frac_int / base^frac_digits */
            long double divisor = 1.0L;
            for (int i = 0; i < frac_digits; i++) divisor *= base;
            long double value = whole + frac_int / divisor;
            if (exp_neg) exp = -exp;
            for (int i = 0; i < (exp > 0 ? exp : -exp); i++)
                value = exp > 0 ? value * base : value / base;
            tok.float_value = (double)value;
            tok.big_real = NULL;
        }
    } else {
        if (not is_based and not has_exponent) {
            tok.big_integer = Big_Integer_From_Decimal_SIMD(clean);
            int64_t v;
            if (Big_Integer_Fits_Int64(tok.big_integer, &v))
                tok.integer_value = v;
        } else if (not is_based and has_exponent) {
            /* Decimal integer with exponent (e.g., 12E1 = 120) */
            int64_t mantissa = 0;
            int exp = 0;
            bool in_exp = false;
            bool exp_neg = false;
            for (int i = 0; clean[i]; i++) {
                char c = clean[i];
                if (To_Lower(c) == 'e') {
                    in_exp = true;
                } else if (in_exp) {
                    if (c == '-') exp_neg = true;
                    else if (c == '+') continue;
                    else if (Is_Digit(c)) exp = exp * 10 + (c - '0');
                } else if (Is_Digit(c)) {
                    mantissa = mantissa * 10 + (c - '0');
                }
            }
            if (exp_neg) {
                /* Negative exponent in integer literal is unusual but handle it */
                for (int i = 0; i < exp; i++) mantissa /= 10;
            } else {
                for (int i = 0; i < exp; i++) mantissa *= 10;
            }
            tok.integer_value = mantissa;
        } else {
            /* Based integer: parse from original string (e.g., 16#E#E1 = 14*16 = 224) */
            /* Structure: base#mantissa#exponent or base#mantissa# */
            int64_t value = 0;
            int exp = 0;
            int state = 0; /* 0=base, 1=mantissa, 2=exponent */
            for (const char *p = start; p < lex->current; p++) {
                char c = *p;
                if (c == '_') continue;
                if (c == '#' or c == ':') {
                    state++;
                    continue;
                }
                if (state == 0) {
                    /* Skip base part - already parsed */
                } else if (state == 1) {
                    /* Mantissa in given base */
                    int d = Digit_Value(c);
                    if (d >= 0 and d < base) value = value * base + d;
                } else if (state == 2) {
                    /* Exponent (always decimal, after second delimiter) */
                    if (To_Lower(c) == 'e') continue; /* skip the 'e' marker */
                    if (c == '+') continue;
                    if (Is_Digit(c)) exp = exp * 10 + (c - '0');
                }
            }
            for (int i = 0; i < exp; i++) value *= base;
            tok.integer_value = value;
        }
    }

    return tok;
}

static Token Scan_Character_Literal(Lexer *lex) {
    Source_Location loc = {lex->filename, lex->line, lex->column};
    Lexer_Advance(lex); /* consume opening ' */

    char c = Lexer_Advance(lex);
    if (Lexer_Peek(lex, 0) != '\'') {
        Report_Error(loc, "unterminated character literal");
        return Make_Token(TK_ERROR, loc, S(""));
    }
    Lexer_Advance(lex); /* consume closing ' */

    Token tok = Make_Token(TK_CHARACTER, loc, (String_Slice){lex->current - 3, 3});
    tok.integer_value = (unsigned char)c;
    return tok;
}

static Token Scan_String_Literal(Lexer *lex) {
    Source_Location loc = {lex->filename, lex->line, lex->column};
    char delim = Lexer_Advance(lex); /* consume opening " or % */

    size_t capacity = 64, length = 0;
    char *buffer = Arena_Allocate(capacity);

    while (lex->current < lex->source_end) {
        if (*lex->current == delim) {
            if (Lexer_Peek(lex, 1) == delim) {
                /* Doubled delimiter > literal delimiter char */
                if (length >= capacity - 1) {
                    char *newbuf = Arena_Allocate(capacity * 2);
                    memcpy(newbuf, buffer, length);
                    buffer = newbuf;
                    capacity *= 2;
                }
                buffer[length++] = delim;
                Lexer_Advance(lex);
                Lexer_Advance(lex);
            } else {
                Lexer_Advance(lex); /* consume closing delimiter */
                break;
            }
        } else {
            if (length >= capacity - 1) {
                char *newbuf = Arena_Allocate(capacity * 2);
                memcpy(newbuf, buffer, length);
                buffer = newbuf;
                capacity *= 2;
            }
            buffer[length++] = Lexer_Advance(lex);
        }
    }
    buffer[length] = '\0';

    Token tok = Make_Token(TK_STRING, loc, (String_Slice){buffer, (uint32_t)length});
    return tok;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §7.5 Main Lexer Entry Point
 *
 * The lexer works as an iterator where each call advances the stream by one token.
 * ───────────────────────────────────────────────────────────────────────── */

static Token Lexer_Next_Token(Lexer *lex) {
    Lexer_Skip_Whitespace_And_Comments(lex);

    if (lex->current >= lex->source_end)
        return Make_Token(TK_EOF, (Source_Location){lex->filename, lex->line, lex->column}, S(""));

    Source_Location loc = {lex->filename, lex->line, lex->column};
    char c = Lexer_Peek(lex, 0);

    /* Identifiers and keywords */
    if (Is_Alpha(c)) return Scan_Identifier(lex);

    /* Numeric literals */
    if (Is_Digit(c)) return Scan_Number(lex);

    /* Character literal: 'X' where X is any graphic character */
    /* Need to check for printable character (not just alpha) since '1' etc. are valid */
    /* Special case: ''' is a character literal containing single quote */
    /* Context check: After identifier or RPAREN, '( could be tick+lparen (qualified expr) */
    {
        char middle = Lexer_Peek(lex, 1);
        char third = Lexer_Peek(lex, 2);
        if (c == '\'' and middle >= ' ' and third == '\'') {
            /* Check for qualified expression context: TYPE'(expr)
             * If previous token was identifier/RPAREN and middle is '(',
             * this is tick+lparen, not a character literal */
            if (middle == '(' and
                (lex->prev_token_kind == TK_IDENTIFIER or
                 lex->prev_token_kind == TK_RPAREN)) {
                /* Not a character literal - fall through to tick handling */
            } else {
                return Scan_Character_Literal(lex);
            }
        }
    }

    /* String literal — both " and % delimiters (RM 2.6, Ada 83) */
    if (c == '"' or c == '%') return Scan_String_Literal(lex);

    /* Operators and delimiters */
    Lexer_Advance(lex);
    char c2 = Lexer_Peek(lex, 0);

    switch (c) {
        case '(': return Make_Token(TK_LPAREN, loc, S("("));
        case ')': return Make_Token(TK_RPAREN, loc, S(")"));
        case '[': return Make_Token(TK_LBRACKET, loc, S("["));
        case ']': return Make_Token(TK_RBRACKET, loc, S("]"));
        case ',': return Make_Token(TK_COMMA, loc, S(","));
        case ';': return Make_Token(TK_SEMICOLON, loc, S(";"));
        case '&': return Make_Token(TK_AMPERSAND, loc, S("&"));
        case '|': return Make_Token(TK_BAR, loc, S("|"));
        case '!': return Make_Token(TK_BAR, loc, S("!"));  /* Ada 83 alternative for | */
        case '+': return Make_Token(TK_PLUS, loc, S("+"));
        case '-': return Make_Token(TK_MINUS, loc, S("-"));
        case '\'': return Make_Token(TK_TICK, loc, S("'"));

        case '.':
            if (c2 == '.') { Lexer_Advance(lex); return Make_Token(TK_DOTDOT, loc, S("..")); }
            return Make_Token(TK_DOT, loc, S("."));

        case ':':
            if (c2 == '=') { Lexer_Advance(lex); return Make_Token(TK_ASSIGN, loc, S(":=")); }
            return Make_Token(TK_COLON, loc, S(":"));

        case '*':
            if (c2 == '*') { Lexer_Advance(lex); return Make_Token(TK_EXPON, loc, S("**")); }
            return Make_Token(TK_STAR, loc, S("*"));

        case '/':
            if (c2 == '=') { Lexer_Advance(lex); return Make_Token(TK_NE, loc, S("/=")); }
            return Make_Token(TK_SLASH, loc, S("/"));

        case '=':
            if (c2 == '>') { Lexer_Advance(lex); return Make_Token(TK_ARROW, loc, S("=>")); }
            return Make_Token(TK_EQ, loc, S("="));

        case '<':
            if (c2 == '=') { Lexer_Advance(lex); return Make_Token(TK_LE, loc, S("<=")); }
            if (c2 == '<') { Lexer_Advance(lex); return Make_Token(TK_LSHIFT, loc, S("<<")); }
            if (c2 == '>') { Lexer_Advance(lex); return Make_Token(TK_BOX, loc, S("<>")); }
            return Make_Token(TK_LT, loc, S("<"));

        case '>':
            if (c2 == '=') { Lexer_Advance(lex); return Make_Token(TK_GE, loc, S(">=")); }
            if (c2 == '>') { Lexer_Advance(lex); return Make_Token(TK_RSHIFT, loc, S(">>")); }
            return Make_Token(TK_GT, loc, S(">"));

        default:
            Report_Error(loc, "unexpected character '%c'", c);
            return Make_Token(TK_ERROR, loc, S(""));
    }
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §8. ABSTRACT SYNTAX TREE — Parse Tree Representation
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * The AST uses a tagged union design. Each node kind has a specific payload.
 * The tree is a forest: one root per compilation unit, shared subtrees within.
 */

/* Forward declarations */
typedef struct Syntax_Node Syntax_Node;
typedef struct Type_Info Type_Info;
typedef struct Symbol Symbol;

/* Dynamic array of syntax nodes */
typedef struct {
    Syntax_Node **items;
    uint32_t      count;
    uint32_t      capacity;
} Node_List;

/* Doubling gives amortized O(1) append; the wasted space is the price of speed */
static void Node_List_Push(Node_List *list, Syntax_Node *node) {
    if (list->count >= list->capacity) {
        uint32_t new_cap = list->capacity ? list->capacity * 2 : 8;
        Syntax_Node **new_items = Arena_Allocate(new_cap * sizeof(Syntax_Node*));
        if (list->items) memcpy(new_items, list->items, list->count * sizeof(Syntax_Node*));
        list->items = new_items;
        list->capacity = new_cap;
    }
    list->items[list->count++] = node;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §8.1 Node Kinds
 * ───────────────────────────────────────────────────────────────────────── */

typedef enum {
    /* Literals and primaries */
    NK_INTEGER, NK_REAL, NK_STRING, NK_CHARACTER, NK_NULL, NK_OTHERS,
    NK_IDENTIFIER, NK_SELECTED, NK_ATTRIBUTE, NK_QUALIFIED,

    /* Expressions */
    NK_BINARY_OP, NK_UNARY_OP, NK_AGGREGATE, NK_ALLOCATOR,
    NK_APPLY,       /* Unified: call, index, slice — resolved later */
    NK_RANGE,       /* a .. b */
    NK_ASSOCIATION, /* name => value */

    /* Type definitions */
    NK_SUBTYPE_INDICATION, NK_RANGE_CONSTRAINT, NK_INDEX_CONSTRAINT,
    NK_DISCRIMINANT_CONSTRAINT, NK_DIGITS_CONSTRAINT, NK_DELTA_CONSTRAINT,
    NK_ARRAY_TYPE, NK_RECORD_TYPE,
    NK_ACCESS_TYPE, NK_DERIVED_TYPE, NK_ENUMERATION_TYPE,
    NK_INTEGER_TYPE, NK_REAL_TYPE, NK_COMPONENT_DECL, NK_VARIANT_PART,
    NK_VARIANT, NK_DISCRIMINANT_SPEC,

    /* Statements */
    NK_ASSIGNMENT, NK_CALL_STMT, NK_RETURN, NK_IF, NK_CASE, NK_LOOP,
    NK_BLOCK, NK_EXIT, NK_GOTO, NK_RAISE, NK_NULL_STMT, NK_LABEL,
    NK_ACCEPT, NK_SELECT, NK_DELAY, NK_ABORT, NK_CODE,

    /* Declarations */
    NK_OBJECT_DECL, NK_TYPE_DECL, NK_SUBTYPE_DECL, NK_EXCEPTION_DECL,
    NK_PROCEDURE_SPEC, NK_FUNCTION_SPEC, NK_PROCEDURE_BODY, NK_FUNCTION_BODY,
    NK_PACKAGE_SPEC, NK_PACKAGE_BODY, NK_TASK_SPEC, NK_TASK_BODY,
    NK_ENTRY_DECL, NK_SUBPROGRAM_RENAMING, NK_PACKAGE_RENAMING,
    NK_EXCEPTION_RENAMING, NK_GENERIC_DECL, NK_GENERIC_INST,
    NK_PARAM_SPEC, NK_USE_CLAUSE, NK_WITH_CLAUSE, NK_PRAGMA,
    NK_REPRESENTATION_CLAUSE, NK_EXCEPTION_HANDLER,
    NK_CONTEXT_CLAUSE, NK_COMPILATION_UNIT,

    /* Generic formals */
    NK_GENERIC_TYPE_PARAM, NK_GENERIC_OBJECT_PARAM, NK_GENERIC_SUBPROGRAM_PARAM,

    NK_COUNT
} Node_Kind;

/* ─────────────────────────────────────────────────────────────────────────
 * §8.2 Syntax Node Structure
 *
 * Each node carries its kind, location, optional type annotation (from
 * semantic analysis), and a payload specific to the kind.
 * ───────────────────────────────────────────────────────────────────────── */

struct Syntax_Node {
    Node_Kind        kind;
    Source_Location  location;
    Type_Info       *type;      /* Set during semantic analysis */
    Symbol          *symbol;    /* Set during name resolution */

    union {
        /* NK_INTEGER */
        struct { int64_t value; Big_Integer *big_value; } integer_lit;

        /* NK_REAL - arbitrary precision with double for compatibility */
        struct { double value; Big_Real *big_value; } real_lit;

        /* NK_STRING, NK_CHARACTER, NK_IDENTIFIER */
        struct { String_Slice text; } string_val;

        /* NK_SELECTED: prefix.selector */
        struct { Syntax_Node *prefix; String_Slice selector; } selected;

        /* NK_ATTRIBUTE: prefix'attribute(args) */
        struct { Syntax_Node *prefix; String_Slice name; Node_List arguments; } attribute;

        /* NK_QUALIFIED: subtype_mark'(expression) */
        struct { Syntax_Node *subtype_mark; Syntax_Node *expression; } qualified;

        /* NK_BINARY_OP, NK_UNARY_OP */
        struct { Token_Kind op; Syntax_Node *left; Syntax_Node *right; } binary;
        struct { Token_Kind op; Syntax_Node *operand; } unary;

        /* NK_AGGREGATE */
        struct { Node_List items; bool is_named; } aggregate;

        /* NK_ALLOCATOR: new subtype_mark'(expression) or new subtype_mark */
        struct { Syntax_Node *subtype_mark; Syntax_Node *expression; } allocator;

        /* NK_APPLY: prefix(arguments) — unified call/index/slice */
        struct { Syntax_Node *prefix; Node_List arguments; } apply;

        /* NK_RANGE: low .. high */
        struct { Syntax_Node *low; Syntax_Node *high; } range;

        /* NK_ASSOCIATION: choices => expression */
        struct { Node_List choices; Syntax_Node *expression; } association;

        /* NK_SUBTYPE_INDICATION: subtype_mark constraint */
        struct { Syntax_Node *subtype_mark; Syntax_Node *constraint; } subtype_ind;

        /* NK_*_CONSTRAINT */
        struct { Node_List ranges; } index_constraint;
        struct { Syntax_Node *range; } range_constraint;
        struct { Node_List associations; } discriminant_constraint;
        struct { Syntax_Node *digits_expr; Syntax_Node *range; } digits_constraint;  /* NK_DIGITS_CONSTRAINT */
        struct { Syntax_Node *delta_expr; Syntax_Node *range; } delta_constraint;    /* NK_DELTA_CONSTRAINT */

        /* NK_ARRAY_TYPE */
        struct { Node_List indices; Syntax_Node *component_type; bool is_constrained; } array_type;

        /* NK_RECORD_TYPE */
        struct {
            Node_List discriminants;
            Node_List components;
            Syntax_Node *variant_part;
            bool is_null;
        } record_type;

        /* NK_ACCESS_TYPE */
        struct { Syntax_Node *designated; bool is_constant; } access_type;

        /* NK_DERIVED_TYPE */
        struct { Syntax_Node *parent_type; Syntax_Node *constraint; } derived_type;

        /* NK_ENUMERATION_TYPE */
        struct { Node_List literals; } enum_type;

        /* NK_INTEGER_TYPE, NK_REAL_TYPE */
        struct { Syntax_Node *range; uint128_t modulus; bool is_modular; } integer_type;
        struct { Syntax_Node *precision; Syntax_Node *range; Syntax_Node *delta; } real_type;

        /* NK_COMPONENT_DECL */
        struct { Node_List names; Syntax_Node *component_type; Syntax_Node *init; } component;

        /* NK_VARIANT_PART */
        struct { String_Slice discriminant; Node_List variants; } variant_part;

        /* NK_VARIANT */
        struct { Node_List choices; Node_List components; Syntax_Node *variant_part; } variant;

        /* NK_DISCRIMINANT_SPEC */
        struct { Node_List names; Syntax_Node *disc_type; Syntax_Node *default_expr; } discriminant;

        /* NK_ASSIGNMENT */
        struct { Syntax_Node *target; Syntax_Node *value; } assignment;

        /* NK_RETURN */
        struct { Syntax_Node *expression; } return_stmt;

        /* NK_IF */
        struct {
            Syntax_Node *condition;
            Node_List then_stmts;
            Node_List elsif_parts;  /* each is another NK_IF for elsif */
            Node_List else_stmts;
        } if_stmt;

        /* NK_CASE */
        struct { Syntax_Node *expression; Node_List alternatives; } case_stmt;

        /* NK_LOOP */
        struct {
            String_Slice label;
            Symbol *label_symbol;           /* Pre-registered label for GOTO */
            Syntax_Node *iteration_scheme;  /* for/while condition */
            Node_List statements;
            bool is_reverse;
        } loop_stmt;

        /* NK_BLOCK */
        struct {
            String_Slice label;
            Symbol *label_symbol;           /* Pre-registered label for GOTO */
            Node_List declarations;
            Node_List statements;
            Node_List handlers;
        } block_stmt;

        /* NK_EXIT */
        struct { String_Slice loop_name; Syntax_Node *condition; Symbol *target; } exit_stmt;

        /* NK_GOTO */
        struct { String_Slice name; Symbol *target; } goto_stmt;

        /* NK_LABEL */
        struct { String_Slice name; Syntax_Node *statement; Symbol *symbol; } label_node;

        /* NK_RAISE */
        struct { Syntax_Node *exception_name; } raise_stmt;

        /* NK_ACCEPT */
        struct {
            String_Slice entry_name;
            Syntax_Node *index;
            Node_List parameters;
            Node_List statements;
            Symbol *entry_sym;      /* Resolved entry symbol (for entry_index) */
        } accept_stmt;

        /* NK_SELECT */
        struct { Node_List alternatives; Syntax_Node *else_part; } select_stmt;

        /* NK_DELAY */
        struct { Syntax_Node *expression; } delay_stmt;

        /* NK_ABORT */
        struct { Node_List task_names; } abort_stmt;

        /* NK_OBJECT_DECL */
        struct {
            Node_List names;
            Syntax_Node *object_type;
            Syntax_Node *init;       /* For renames, this is the renamed object */
            bool is_constant;
            bool is_aliased;
            bool is_rename;          /* True for RENAMES declarations */
        } object_decl;

        /* NK_TYPE_DECL, NK_SUBTYPE_DECL */
        struct {
            String_Slice name;
            Node_List discriminants;
            Syntax_Node *definition;
            bool is_limited;
            bool is_private;
        } type_decl;

        /* NK_EXCEPTION_DECL, NK_EXCEPTION_RENAMING */
        struct { Node_List names; Syntax_Node *renamed; } exception_decl;

        /* NK_PROCEDURE_SPEC, NK_FUNCTION_SPEC, NK_SUBPROGRAM_RENAMING */
        struct {
            String_Slice name;
            Node_List parameters;
            Syntax_Node *return_type;  /* NULL for procedures */
            Syntax_Node *renamed;      /* For NK_SUBPROGRAM_RENAMING: the renamed entity */
        } subprogram_spec;

        /* NK_PROCEDURE_BODY, NK_FUNCTION_BODY */
        struct {
            Syntax_Node *specification;
            Node_List declarations;
            Node_List statements;
            Node_List handlers;
            bool is_separate;
            bool code_generated;  /* Prevents duplicate code generation */
        } subprogram_body;

        /* NK_PACKAGE_SPEC */
        struct {
            String_Slice name;
            Node_List visible_decls;
            Node_List private_decls;
        } package_spec;

        /* NK_PACKAGE_BODY */
        struct {
            String_Slice name;
            Node_List declarations;
            Node_List statements;
            Node_List handlers;
            bool is_separate;
        } package_body;

        /* NK_PACKAGE_RENAMING */
        struct {
            String_Slice new_name;
            Syntax_Node *old_name;
        } package_renaming;

        /* NK_TASK_SPEC */
        struct {
            String_Slice name;
            Node_List entries;  /* Entry declarations */
            bool is_type;       /* true if TASK TYPE, false if single TASK */
        } task_spec;

        /* NK_TASK_BODY */
        struct {
            String_Slice name;
            Node_List declarations;
            Node_List statements;
            Node_List handlers;
            bool is_separate;
        } task_body;

        /* NK_ENTRY_DECL */
        struct {
            String_Slice name;
            Node_List parameters;  /* Parameter specs */
            Node_List index_constraints;  /* For entry families */
        } entry_decl;

        /* NK_PARAM_SPEC */
        struct {
            Node_List names;
            Syntax_Node *param_type;
            Syntax_Node *default_expr;
            enum { MODE_IN, MODE_OUT, MODE_IN_OUT } mode;
        } param_spec;

        /* NK_GENERIC_DECL */
        struct {
            Node_List formals;
            Syntax_Node *unit;  /* The procedure/function/package being made generic */
        } generic_decl;

        /* NK_GENERIC_INST */
        struct {
            Syntax_Node *generic_name;
            Node_List actuals;
            String_Slice instance_name;
            Token_Kind unit_kind;  /* TK_PROCEDURE, TK_FUNCTION, or TK_PACKAGE */
        } generic_inst;

        /* Generic type definition kinds (RM 12.1) */
        /* NK_GENERIC_TYPE_PARAM: type T is ... */
        struct {
            String_Slice name;
            enum {
                GEN_DEF_PRIVATE = 0,      /* type T is private */
                GEN_DEF_LIMITED_PRIVATE,   /* type T is limited private */
                GEN_DEF_DISCRETE,          /* type T is (<>) */
                GEN_DEF_INTEGER,           /* type T is range <> */
                GEN_DEF_FLOAT,             /* type T is digits <> */
                GEN_DEF_FIXED,             /* type T is delta <> */
                GEN_DEF_ARRAY,             /* type T is array (...) of ... */
                GEN_DEF_ACCESS,            /* type T is access ... */
                GEN_DEF_DERIVED            /* type T is new ... */
            } def_kind;
            Syntax_Node *def_detail;
        } generic_type_param;

        /* NK_GENERIC_OBJECT_PARAM: X : [mode] type [:= default] */
        struct {
            Node_List names;
            Syntax_Node *object_type;
            Syntax_Node *default_expr;
            enum {
                GEN_MODE_IN = 0,     /* in (default) */
                GEN_MODE_OUT,        /* out */
                GEN_MODE_IN_OUT      /* in out */
            } mode;
        } generic_object_param;

        /* NK_GENERIC_SUBPROGRAM_PARAM: with procedure/function spec [is name|<>] */
        struct {
            String_Slice name;
            Node_List parameters;
            Syntax_Node *return_type;  /* NULL for procedures */
            Syntax_Node *default_name;
            bool is_function;
            bool default_box;
        } generic_subprog_param;

        /* NK_WITH_CLAUSE, NK_USE_CLAUSE */
        struct { Node_List names; } use_clause;

        /* NK_PRAGMA */
        struct { String_Slice name; Node_List arguments; } pragma_node;

        /* NK_EXCEPTION_HANDLER */
        struct { Node_List exceptions; Node_List statements; } handler;

        /* NK_REPRESENTATION_CLAUSE (RM 13.1) */
        struct {
            Syntax_Node *entity_name;    /* Type or object being represented */
            String_Slice attribute;       /* 'SIZE, 'ALIGNMENT, etc. (empty if record/enum rep) */
            Syntax_Node *expression;      /* Attribute value or address expression */
            Node_List    component_clauses; /* For record representation: component positions */
            bool         is_record_rep;   /* true if FOR T USE RECORD ... */
            bool         is_enum_rep;     /* true if FOR T USE (literals...) */
        } rep_clause;

        /* NK_CONTEXT_CLAUSE */
        struct { Node_List with_clauses; Node_List use_clauses; } context;

        /* NK_COMPILATION_UNIT */
        struct {
            Syntax_Node *context;
            Syntax_Node *unit;
            Syntax_Node *separate_parent;  /* Parent name for SEPARATE subunits */
        } compilation_unit;
    };
};

/* Node constructor - zero-initializes the union to ensure all pointers start NULL */
static Syntax_Node *Node_New(Node_Kind kind, Source_Location loc) {
    Syntax_Node *node = Arena_Allocate(sizeof(Syntax_Node));
    memset(node, 0, sizeof(Syntax_Node));  /* Zero all fields including union */
    node->kind = kind;
    node->location = loc;
    return node;
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §9. PARSER — Recursive Descent with Unified Postfix Handling
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * Recursive descent mirrors the grammar, making the grammar itself the invariant.
 *
 * Key design decisions:
 *
 * 1. UNIFIED APPLY NODE: All X(...) forms parse as NK_APPLY. Semantic analysis
 *    later distinguishes calls, indexing, slicing, and type conversions.
 *
 * 2. UNIFIED ASSOCIATION PARSING: One helper handles positional, named, and
 *    choice associations used in aggregates, calls, and generic actuals.
 *
 * 3. UNIFIED POSTFIX CHAIN: One loop handles .selector, 'attribute, (args).
 */

/* ─────────────────────────────────────────────────────────────────────────
 * §9.1 Parser State
 * ───────────────────────────────────────────────────────────────────────── */

typedef struct {
    Lexer        lexer;
    Token        current_token;
    Token        previous_token;
    bool         had_error;
    bool         panic_mode;

    /* Progress tracking to detect stuck parsers */
    uint32_t     last_line;
    uint32_t     last_column;
    Token_Kind   last_kind;
} Parser;

static Parser Parser_New(const char *source, size_t length, const char *filename) {
    Parser p = {0};
    p.lexer = Lexer_New(source, length, filename);
    p.current_token = Lexer_Next_Token(&p.lexer);
    return p;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.2 Token Movement
 * ───────────────────────────────────────────────────────────────────────── */

static inline bool Parser_At(Parser *p, Token_Kind kind) {
    return p->current_token.kind == kind;
}

static inline bool Parser_At_Any(Parser *p, Token_Kind k1, Token_Kind k2) {
    return Parser_At(p, k1) or Parser_At(p, k2);
}

/* Lookahead: check if the NEXT token (after current) is of the given kind */
static bool Parser_Peek_At(Parser *p, Token_Kind kind) {
    Token saved = p->current_token;
    Lexer saved_lexer = p->lexer;

    /* Update prev_token_kind for context-sensitive lexing during lookahead */
    p->lexer.prev_token_kind = p->current_token.kind;
    p->current_token = Lexer_Next_Token(&p->lexer);
    bool result = p->current_token.kind == kind;

    p->current_token = saved;
    p->lexer = saved_lexer;
    return result;
}

static Token Parser_Advance(Parser *p) {
    p->previous_token = p->current_token;
    /* Update lexer's prev_token_kind before getting next token (for context-sensitive lexing) */
    p->lexer.prev_token_kind = p->current_token.kind;
    p->current_token = Lexer_Next_Token(&p->lexer);

    /* Handle compound keywords: AND THEN, OR ELSE */
    if (p->previous_token.kind == TK_AND and Parser_At(p, TK_THEN)) {
        p->previous_token.kind = TK_AND_THEN;
        p->lexer.prev_token_kind = TK_AND_THEN;
        p->current_token = Lexer_Next_Token(&p->lexer);
    } else if (p->previous_token.kind == TK_OR and Parser_At(p, TK_ELSE)) {
        p->previous_token.kind = TK_OR_ELSE;
        p->lexer.prev_token_kind = TK_OR_ELSE;
        p->current_token = Lexer_Next_Token(&p->lexer);
    }

    return p->previous_token;
}

static bool Parser_Match(Parser *p, Token_Kind kind) {
    if (not Parser_At(p, kind)) return false;
    Parser_Advance(p);
    return true;
}

static Source_Location Parser_Location(Parser *p) {
    return p->current_token.location;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.3 Error Recovery
 * ───────────────────────────────────────────────────────────────────────── */

static void Parser_Error(Parser *p, const char *message) {
    if (p->panic_mode) return;
    p->panic_mode = true;
    p->had_error = true;
    Report_Error(p->current_token.location, "%s", message);
}

static void Parser_Error_At_Current(Parser *p, const char *expected) {
    if (p->panic_mode) return;
    p->panic_mode = true;
    p->had_error = true;
    Report_Error(p->current_token.location, "expected %s, got %s",
                 expected, Token_Name[p->current_token.kind]);
}

/* Synchronize to a recovery point (statement/declaration boundary) */
static void Parser_Synchronize(Parser *p) {
    p->panic_mode = false;

    while (not Parser_At(p, TK_EOF)) {
        if (p->previous_token.kind == TK_SEMICOLON) return;

        switch (p->current_token.kind) {
            case TK_BEGIN: case TK_END: case TK_IF: case TK_CASE: case TK_LOOP:
            case TK_FOR: case TK_WHILE: case TK_RETURN: case TK_DECLARE:
            case TK_EXCEPTION: case TK_PROCEDURE: case TK_FUNCTION:
            case TK_PACKAGE: case TK_TASK: case TK_TYPE: case TK_SUBTYPE:
            case TK_PRAGMA: case TK_ACCEPT: case TK_SELECT:
                return;
            default:
                Parser_Advance(p);
        }
    }
}

/* Check for parser progress — detect stuck parsing loops */
static bool Parser_Check_Progress(Parser *p) {
    if (p->current_token.location.line == p->last_line and
        p->current_token.location.column == p->last_column and
        p->current_token.kind == p->last_kind) {
        Parser_Advance(p);
        return false;
    }
    p->last_line = p->current_token.location.line;
    p->last_column = p->current_token.location.column;
    p->last_kind = p->current_token.kind;
    return true;
}

/* Expect a specific token; report error and return false if not found */
static bool Parser_Expect(Parser *p, Token_Kind kind) {
    if (Parser_At(p, kind)) {
        Parser_Advance(p);
        return true;
    }
    Parser_Error_At_Current(p, Token_Name[kind]);
    return false;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.4 Identifier Parsing
 * ───────────────────────────────────────────────────────────────────────── */

static String_Slice Parser_Identifier(Parser *p) {
    if (not Parser_At(p, TK_IDENTIFIER)) {
        Parser_Error_At_Current(p, "identifier");
        return Empty_Slice;
    }
    String_Slice name = Slice_Duplicate(p->current_token.text);
    Parser_Advance(p);
    return name;
}

/* Check END identifier matches expected name (also handles operator strings) */
static void Parser_Check_End_Name(Parser *p, String_Slice expected_name) {
    if (Parser_At(p, TK_IDENTIFIER) or Parser_At(p, TK_STRING)) {
        String_Slice end_name = p->current_token.text;
        if (not Slice_Equal_Ignore_Case(end_name, expected_name)) {
            Report_Error(p->current_token.location,
                        "END name does not match (expected '%.*s', got '%.*s')",
                        expected_name.length, expected_name.data,
                        end_name.length, end_name.data);
        }
        Parser_Advance(p);
    }
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.5 Expression Parsing — Operator Precedence
 *
 * The grammar encodes precedence while recursion direction determines associativity.
 *
 * Ada precedence (highest to lowest):
 *   ** (right associative)
 *   ABS NOT (unary prefix)
 *   * / MOD REM
 *   + - & (binary) + - (unary)
 *   = /= < <= > >= IN NOT IN
 *   AND OR XOR AND THEN OR ELSE
 * ───────────────────────────────────────────────────────────────────────── */

/* Forward declarations */
static Syntax_Node *Parse_Expression(Parser *p);
static Syntax_Node *Parse_Choice(Parser *p);
static Syntax_Node *Parse_Name(Parser *p);
static Syntax_Node *Parse_Simple_Name(Parser *p);  /* identifier or dotted, no parens/ticks */
static Syntax_Node *Parse_Subtype_Indication(Parser *p);
static Syntax_Node *Parse_Array_Type(Parser *p);
static void Parse_Association_List(Parser *p, Node_List *list);
/* ═══════════════════════════════════════════════════════════════════════════
 * §9.13 Subprogram Declarations and Bodies
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * The spec declares the interface while the body provides the implementation.
 */

/* ─────────────────────────────────────────────────────────────────────────
 * §9.13.1 Parameter Specification
 *
 * IN copies in, OUT copies out, IN OUT does both. Access avoids the copy.
 * ───────────────────────────────────────────────────────────────────────── */

static void Parse_Parameter_List(Parser *p, Node_List *params) {
    if (not Parser_Match(p, TK_LPAREN)) return;

    do {
        Source_Location loc = Parser_Location(p);
        Syntax_Node *param = Node_New(NK_PARAM_SPEC, loc);

        /* Identifier list */
        do {
            Syntax_Node *id = Node_New(NK_IDENTIFIER, Parser_Location(p));
            id->string_val.text = Parser_Identifier(p);
            Node_List_Push(&param->param_spec.names, id);
        } while (Parser_Match(p, TK_COMMA));

        Parser_Expect(p, TK_COLON);

        /* Mode */
        if (Parser_Match(p, TK_IN)) {
            if (Parser_Match(p, TK_OUT)) {
                param->param_spec.mode = MODE_IN_OUT;
            } else {
                param->param_spec.mode = MODE_IN;
            }
        } else if (Parser_Match(p, TK_OUT)) {
            param->param_spec.mode = MODE_OUT;
        } else {
            param->param_spec.mode = MODE_IN;  /* Default */
        }

        param->param_spec.param_type = Parse_Subtype_Indication(p);

        /* Default expression */
        if (Parser_Match(p, TK_ASSIGN)) {
            param->param_spec.default_expr = Parse_Expression(p);
        }

        Node_List_Push(params, param);
    } while (Parser_Match(p, TK_SEMICOLON));

    Parser_Expect(p, TK_RPAREN);
}


/* Parse primary: literals, names, aggregates, allocators, parenthesized */
static Syntax_Node *Parse_Primary(Parser *p) {
    Source_Location loc = Parser_Location(p);

    /* Integer literal */
    if (Parser_At(p, TK_INTEGER)) {
        Syntax_Node *node = Node_New(NK_INTEGER, loc);
        node->integer_lit.value = p->current_token.integer_value;
        node->integer_lit.big_value = p->current_token.big_integer;
        Parser_Advance(p);
        return node;
    }

    /* Real literal - store both double and Big_Real for arbitrary precision */
    if (Parser_At(p, TK_REAL)) {
        Syntax_Node *node = Node_New(NK_REAL, loc);
        node->real_lit.value = p->current_token.float_value;
        node->real_lit.big_value = p->current_token.big_real;
        Parser_Advance(p);
        return node;
    }

    /* Character literal - store only the text (e.g., "'X'"), extract char value when needed.
     * NOTE: Do not set integer_lit.value here - it overlaps with string_val.text.data
     * in the union and would corrupt the text pointer. */
    if (Parser_At(p, TK_CHARACTER)) {
        Syntax_Node *node = Node_New(NK_CHARACTER, loc);
        node->string_val.text = Slice_Duplicate(p->current_token.text);
        Parser_Advance(p);
        return node;
    }

    /* String literal - but check for operator symbol used as function name.
     * In Ada, "+"(X, Y) is a valid function call where "+" is the operator.
     * If this looks like an operator string followed by (, let it fall through
     * to Parse_Name which handles operator names and function calls. */
    if (Parser_At(p, TK_STRING)) {
        String_Slice text = p->current_token.text;
        bool is_operator_call = (text.length <= 3) and Parser_Peek_At(p, TK_LPAREN);
        if (not is_operator_call) {
            Syntax_Node *node = Node_New(NK_STRING, loc);
            node->string_val.text = Slice_Duplicate(text);
            Parser_Advance(p);
            return node;
        }
        /* Fall through to Parse_Name for operator call like "+"(X, Y) */
    }

    /* NULL */
    if (Parser_Match(p, TK_NULL)) {
        return Node_New(NK_NULL, loc);
    }

    /* OTHERS (in aggregates) */
    if (Parser_Match(p, TK_OTHERS)) {
        return Node_New(NK_OTHERS, loc);
    }

    /* NEW allocator */
    if (Parser_Match(p, TK_NEW)) {
        Syntax_Node *node = Node_New(NK_ALLOCATOR, loc);
        Syntax_Node *subtype = Parse_Subtype_Indication(p);

        /* If Parse_Subtype_Indication returned a qualified expression,
         * extract subtype_mark and expression separately */
        if (subtype->kind == NK_QUALIFIED) {
            node->allocator.subtype_mark = subtype->qualified.subtype_mark;
            node->allocator.expression = subtype->qualified.expression;
        } else {
            node->allocator.subtype_mark = subtype;
        }
        return node;
    }

    /* Unary operators: NOT, ABS, +, - */
    if (Parser_At_Any(p, TK_NOT, TK_ABS) or
        Parser_At_Any(p, TK_PLUS, TK_MINUS)) {
        Token_Kind op = p->current_token.kind;
        Parser_Advance(p);
        Syntax_Node *node = Node_New(NK_UNARY_OP, loc);
        node->unary.op = op;
        node->unary.operand = Parse_Primary(p);
        return node;
    }

    /* Parenthesized expression or aggregate */
    if (Parser_Match(p, TK_LPAREN)) {
        Syntax_Node *expr = Parse_Expression(p);

        /* Check for aggregate indicators */
        if (Parser_At(p, TK_COMMA) or Parser_At(p, TK_ARROW) or
            Parser_At(p, TK_BAR) or Parser_At(p, TK_WITH) or
            Parser_At(p, TK_DOTDOT)) {
            /* This is an aggregate */
            Syntax_Node *node = Node_New(NK_AGGREGATE, loc);

            if (Parser_Match(p, TK_WITH)) {
                /* Extension aggregate: (ancestor with components) */
                Node_List_Push(&node->aggregate.items, expr);
                node->aggregate.is_named = true;
                Parse_Association_List(p, &node->aggregate.items);
            } else if (Parser_At(p, TK_DOTDOT)) {
                /* First element is a range: expr .. high */
                Syntax_Node *range = Node_New(NK_RANGE, loc);
                range->range.low = expr;
                Parser_Advance(p);  /* consume .. */
                range->range.high = Parse_Expression(p);

                /* Check for choice list or named association */
                if (Parser_At(p, TK_BAR) or Parser_At(p, TK_ARROW)) {
                    Syntax_Node *assoc = Node_New(NK_ASSOCIATION, loc);
                    Node_List_Push(&assoc->association.choices, range);

                    while (Parser_Match(p, TK_BAR)) {
                        Node_List_Push(&assoc->association.choices, Parse_Choice(p));
                    }
                    if (Parser_Match(p, TK_ARROW)) {
                        assoc->association.expression = Parse_Expression(p);
                    }
                    Node_List_Push(&node->aggregate.items, assoc);
                } else {
                    Node_List_Push(&node->aggregate.items, range);
                }

                if (Parser_Match(p, TK_COMMA)) {
                    Parse_Association_List(p, &node->aggregate.items);
                }
            } else if (Parser_At(p, TK_BAR) or Parser_At(p, TK_ARROW)) {
                /* First element is part of a choice list */
                Syntax_Node *assoc = Node_New(NK_ASSOCIATION, loc);
                Node_List_Push(&assoc->association.choices, expr);

                /* Collect additional choices */
                while (Parser_Match(p, TK_BAR)) {
                    Node_List_Push(&assoc->association.choices, Parse_Choice(p));
                }

                /* Named association: choices => value */
                if (Parser_Match(p, TK_ARROW)) {
                    assoc->association.expression = Parse_Expression(p);
                }

                Node_List_Push(&node->aggregate.items, assoc);

                /* Continue with remaining associations */
                if (Parser_Match(p, TK_COMMA)) {
                    Parse_Association_List(p, &node->aggregate.items);
                }
            } else {
                /* First element is positional, followed by more */
                Node_List_Push(&node->aggregate.items, expr);
                Parser_Advance(p);  /* consume the comma we know is there */
                Parse_Association_List(p, &node->aggregate.items);
            }
            Parser_Expect(p, TK_RPAREN);
            return node;
        }

        Parser_Expect(p, TK_RPAREN);
        return expr;
    }

    /* Name (identifier, selected, indexed, etc.) */
    return Parse_Name(p);
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.6 Unified Postfix Parsing
 *
 * Handles: .selector, 'attribute, (arguments) — in one loop.
 * ───────────────────────────────────────────────────────────────────────── */

static Syntax_Node *Parse_Name(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Syntax_Node *node;

    /* Base: identifier or operator symbol */
    if (Parser_At(p, TK_IDENTIFIER)) {
        node = Node_New(NK_IDENTIFIER, loc);
        node->string_val.text = Parser_Identifier(p);
    } else if (Parser_At(p, TK_STRING)) {
        /* Operator symbol as name: "+" etc */
        node = Node_New(NK_IDENTIFIER, loc);
        node->string_val.text = Slice_Duplicate(p->current_token.text);
        Parser_Advance(p);
    } else {
        Parser_Error_At_Current(p, "name");
        return Node_New(NK_IDENTIFIER, loc);
    }

    /* Postfix chain */
    for (;;) {
        Source_Location postfix_loc = Parser_Location(p);

        /* .selector or .ALL */
        if (Parser_Match(p, TK_DOT)) {
            if (Parser_Match(p, TK_ALL)) {
                /* Dereference: prefix.ALL */
                Syntax_Node *deref = Node_New(NK_UNARY_OP, postfix_loc);
                deref->unary.op = TK_ALL;
                deref->unary.operand = node;
                node = deref;
            } else if (Parser_At(p, TK_CHARACTER)) {
                /* P.'C' — character literal as enum member (RM 4.1.3) */
                Syntax_Node *sel = Node_New(NK_SELECTED, postfix_loc);
                sel->selected.prefix = node;
                sel->selected.selector = Slice_Duplicate(p->current_token.text);
                Parser_Advance(p);
                node = sel;
            } else if (Parser_At(p, TK_STRING)) {
                /* P."+" — operator symbol (RM 6.1) */
                Syntax_Node *sel = Node_New(NK_SELECTED, postfix_loc);
                sel->selected.prefix = node;
                sel->selected.selector = Slice_Duplicate(p->current_token.text);
                Parser_Advance(p);
                node = sel;
            } else {
                /* Selection: prefix.component */
                Syntax_Node *sel = Node_New(NK_SELECTED, postfix_loc);
                sel->selected.prefix = node;
                sel->selected.selector = Parser_Identifier(p);
                node = sel;
            }
            continue;
        }

        /* 'attribute or '(qualified) */
        if (Parser_Match(p, TK_TICK)) {
            if (Parser_Match(p, TK_LPAREN)) {
                /* Qualified expression: Type'(Expr or Aggregate) */
                Syntax_Node *qual = Node_New(NK_QUALIFIED, postfix_loc);
                qual->qualified.subtype_mark = node;

                /* Parse expression or aggregate */
                Syntax_Node *expr = Parse_Expression(p);
                if (Parser_At(p, TK_COMMA) or Parser_At(p, TK_ARROW) or
                    Parser_At(p, TK_BAR) or Parser_At(p, TK_DOTDOT)) {
                    /* Aggregate */
                    Syntax_Node *agg = Node_New(NK_AGGREGATE, postfix_loc);
                    if (Parser_At(p, TK_DOTDOT)) {
                        /* Range: expr .. high */
                        Syntax_Node *range = Node_New(NK_RANGE, postfix_loc);
                        range->range.low = expr;
                        Parser_Advance(p);
                        range->range.high = Parse_Expression(p);
                        if (Parser_At(p, TK_BAR) or Parser_At(p, TK_ARROW)) {
                            Syntax_Node *assoc = Node_New(NK_ASSOCIATION, postfix_loc);
                            Node_List_Push(&assoc->association.choices, range);
                            while (Parser_Match(p, TK_BAR)) {
                                Node_List_Push(&assoc->association.choices, Parse_Choice(p));
                            }
                            if (Parser_Match(p, TK_ARROW)) {
                                assoc->association.expression = Parse_Expression(p);
                            }
                            Node_List_Push(&agg->aggregate.items, assoc);
                        } else {
                            Node_List_Push(&agg->aggregate.items, range);
                        }
                        if (Parser_Match(p, TK_COMMA)) {
                            Parse_Association_List(p, &agg->aggregate.items);
                        }
                    } else if (Parser_At(p, TK_BAR) or Parser_At(p, TK_ARROW)) {
                        Syntax_Node *assoc = Node_New(NK_ASSOCIATION, postfix_loc);
                        Node_List_Push(&assoc->association.choices, expr);
                        while (Parser_Match(p, TK_BAR)) {
                            Node_List_Push(&assoc->association.choices, Parse_Choice(p));
                        }
                        if (Parser_Match(p, TK_ARROW)) {
                            assoc->association.expression = Parse_Expression(p);
                        }
                        Node_List_Push(&agg->aggregate.items, assoc);
                        if (Parser_Match(p, TK_COMMA)) {
                            Parse_Association_List(p, &agg->aggregate.items);
                        }
                    } else {
                        Node_List_Push(&agg->aggregate.items, expr);
                        Parser_Advance(p);  /* consume comma */
                        Parse_Association_List(p, &agg->aggregate.items);
                    }
                    qual->qualified.expression = agg;
                } else {
                    qual->qualified.expression = expr;
                }
                Parser_Expect(p, TK_RPAREN);
                node = qual;
            } else {
                /* Attribute: prefix'Name or prefix'Name(arg) */
                Syntax_Node *attr = Node_New(NK_ATTRIBUTE, postfix_loc);
                attr->attribute.prefix = node;

                /* Attribute name can be reserved word or identifier */
                if (Parser_At(p, TK_IDENTIFIER)) {
                    attr->attribute.name = Parser_Identifier(p);
                } else if (Parser_At(p, TK_RANGE) or Parser_At(p, TK_DIGITS) or
                           Parser_At(p, TK_DELTA) or Parser_At(p, TK_ACCESS) or
                           Parser_At(p, TK_MOD)) {
                    attr->attribute.name = Slice_Duplicate(p->current_token.text);
                    Parser_Advance(p);
                } else {
                    Parser_Error_At_Current(p, "attribute name");
                }

                /* Optional attribute arguments (one or more) */
                if (Parser_Match(p, TK_LPAREN)) {
                    Parse_Association_List(p, &attr->attribute.arguments);
                    Parser_Expect(p, TK_RPAREN);
                }
                node = attr;
            }
            continue;
        }

        /* (arguments) — call, index, slice, or type conversion */
        if (Parser_Match(p, TK_LPAREN)) {
            Syntax_Node *apply = Node_New(NK_APPLY, postfix_loc);
            apply->apply.prefix = node;
            Parse_Association_List(p, &apply->apply.arguments);
            Parser_Expect(p, TK_RPAREN);
            node = apply;
            continue;
        }

        break;
    }

    return node;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.6.1 Simple Name Parsing (no parentheses or attributes)
 *
 * Used for generic unit names in instantiations where we don't want
 * parentheses interpreted as function calls.
 * ───────────────────────────────────────────────────────────────────────── */

static Syntax_Node *Parse_Simple_Name(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Syntax_Node *node;

    /* Base: identifier */
    if (Parser_At(p, TK_IDENTIFIER)) {
        node = Node_New(NK_IDENTIFIER, loc);
        node->string_val.text = Parser_Identifier(p);
    } else {
        Parser_Error_At_Current(p, "identifier");
        return Node_New(NK_IDENTIFIER, loc);
    }

    /* Only follow dotted selections, not parentheses or ticks */
    for (;;) {
        if (Parser_Match(p, TK_DOT)) {
            Source_Location sel_loc = Parser_Location(p);
            Syntax_Node *sel = Node_New(NK_SELECTED, sel_loc);
            sel->selected.prefix = node;
            /* Accept character literal ('C') or operator string ("+") after dot */
            if (Parser_At(p, TK_CHARACTER) or Parser_At(p, TK_STRING)) {
                sel->selected.selector = Slice_Duplicate(p->current_token.text);
                Parser_Advance(p);
            } else {
                sel->selected.selector = Parser_Identifier(p);
            }
            node = sel;
            continue;
        }
        break;
    }

    return node;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.7 Unified Association Parsing
 *
 * The same syntax serves calls, aggregates, and instantiations. The parser
 * cannot tell them apart; semantic analysis can.
 * ───────────────────────────────────────────────────────────────────────── */

/* Helper to parse a choice (expression, range, or discrete_subtype_indication) */
static Syntax_Node *Parse_Choice(Parser *p) {
    Source_Location loc = Parser_Location(p);

    /* OTHERS choice */
    if (Parser_Match(p, TK_OTHERS)) {
        return Node_New(NK_OTHERS, loc);
    }

    Syntax_Node *expr = Parse_Expression(p);

    /* Check if this is a range: expr .. expr */
    if (Parser_Match(p, TK_DOTDOT)) {
        Syntax_Node *range = Node_New(NK_RANGE, loc);
        range->range.low = expr;
        range->range.high = Parse_Expression(p);
        return range;
    }

    /* Check for subtype_mark RANGE low..high (discrete_subtype_indication)
     * This handles index constraints like: INTEGER RANGE 1..10 */
    if (Parser_Match(p, TK_RANGE)) {
        Syntax_Node *ind = Node_New(NK_SUBTYPE_INDICATION, loc);
        ind->subtype_ind.subtype_mark = expr;

        Syntax_Node *constraint = Node_New(NK_RANGE_CONSTRAINT, loc);
        Syntax_Node *range_low = Parse_Expression(p);

        if (Parser_Match(p, TK_DOTDOT)) {
            Syntax_Node *range_node = Node_New(NK_RANGE, loc);
            range_node->range.low = range_low;
            range_node->range.high = Parse_Expression(p);
            constraint->range_constraint.range = range_node;
        } else {
            /* Just a range attribute or name */
            constraint->range_constraint.range = range_low;
        }

        ind->subtype_ind.constraint = constraint;
        return ind;
    }

    return expr;
}

static void Parse_Association_List(Parser *p, Node_List *list) {
    if (Parser_At(p, TK_RPAREN)) return;  /* Empty list */

    do {
        Source_Location loc = Parser_Location(p);
        Syntax_Node *first = Parse_Choice(p);

        /* Check for choice list with | or named association with => */
        if (Parser_At(p, TK_BAR) or Parser_At(p, TK_ARROW)) {
            Syntax_Node *assoc = Node_New(NK_ASSOCIATION, loc);
            Node_List_Push(&assoc->association.choices, first);

            /* Collect additional choices */
            while (Parser_Match(p, TK_BAR)) {
                Node_List_Push(&assoc->association.choices, Parse_Choice(p));
            }

            /* Named association: choices => value */
            if (Parser_Match(p, TK_ARROW)) {
                assoc->association.expression = Parse_Expression(p);
            }

            Node_List_Push(list, assoc);
        } else {
            /* Positional association */
            Node_List_Push(list, first);
        }
    } while (Parser_Match(p, TK_COMMA));
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.8 Binary Expression Parsing — Precedence Climbing
 *
 * Climbing starts at low precedence and consumes equal-or-higher before returning.
 * ───────────────────────────────────────────────────────────────────────── */

/* Precedence levels */
typedef enum {
    PREC_NONE = 0,
    PREC_LOGICAL,      /* AND, OR, XOR, AND_THEN, OR_ELSE */
    PREC_RELATIONAL,   /* = /= < <= > >= IN */
    PREC_ADDITIVE,     /* + - & */
    PREC_MULTIPLICATIVE, /* * / MOD REM */
    PREC_EXPONENTIAL,  /* ** */
    PREC_UNARY,        /* NOT ABS + - */
    PREC_PRIMARY
} Precedence;

static Precedence Get_Infix_Precedence(Token_Kind kind) {
    switch (kind) {
        case TK_AND: case TK_OR: case TK_XOR:
        case TK_AND_THEN: case TK_OR_ELSE:
            return PREC_LOGICAL;
        case TK_EQ: case TK_NE: case TK_LT: case TK_LE:
        case TK_GT: case TK_GE: case TK_IN: case TK_NOT:
            return PREC_RELATIONAL;
        case TK_PLUS: case TK_MINUS: case TK_AMPERSAND:
            return PREC_ADDITIVE;
        case TK_STAR: case TK_SLASH: case TK_MOD: case TK_REM:
            return PREC_MULTIPLICATIVE;
        case TK_EXPON:
            return PREC_EXPONENTIAL;
        default:
            return PREC_NONE;
    }
}

static bool Is_Right_Associative(Token_Kind kind) {
    return kind == TK_EXPON;
}

static Syntax_Node *Parse_Expression_Precedence(Parser *p, Precedence min_prec);

static Syntax_Node *Parse_Unary(Parser *p) {
    Source_Location loc = Parser_Location(p);

    if (Parser_At_Any(p, TK_PLUS, TK_MINUS) or
        Parser_At_Any(p, TK_NOT, TK_ABS)) {
        Token_Kind op = p->current_token.kind;
        Parser_Advance(p);
        Syntax_Node *node = Node_New(NK_UNARY_OP, loc);
        node->unary.op = op;
        node->unary.operand = Parse_Unary(p);
        return node;
    }

    return Parse_Primary(p);
}

static Syntax_Node *Parse_Expression_Precedence(Parser *p, Precedence min_prec) {
    Syntax_Node *left = Parse_Unary(p);

    for (;;) {
        Token_Kind op = p->current_token.kind;
        Precedence prec = Get_Infix_Precedence(op);

        if (prec < min_prec) break;

        Source_Location loc = Parser_Location(p);
        Parser_Advance(p);

        /* After advance, check for compound keywords (AND THEN, OR ELSE)
         * that were detected in Parser_Advance */
        if (p->previous_token.kind == TK_AND_THEN or p->previous_token.kind == TK_OR_ELSE) {
            op = p->previous_token.kind;
        }

        /* Handle NOT IN specially — mirrors IN range handling below (RM 4.4) */
        if (op == TK_NOT and Parser_At(p, TK_IN)) {
            Parser_Advance(p);
            Syntax_Node *right = Parse_Expression_Precedence(p, prec + 1);
            if (Parser_Match(p, TK_DOTDOT)) {
                Syntax_Node *range = Node_New(NK_RANGE, loc);
                range->range.low = right;
                range->range.high = Parse_Expression_Precedence(p, prec + 1);
                right = range;
            }
            Syntax_Node *node = Node_New(NK_BINARY_OP, loc);
            node->binary.op = TK_NOT;
            node->binary.left = left;
            node->binary.right = right;
            left = node;
            continue;
        }

        /* Handle IN with possible range */
        if (op == TK_IN) {
            Syntax_Node *right = Parse_Expression_Precedence(p, prec + 1);

            /* Check for range: X in A .. B */
            if (Parser_Match(p, TK_DOTDOT)) {
                Syntax_Node *range = Node_New(NK_RANGE, loc);
                range->range.low = right;
                range->range.high = Parse_Expression_Precedence(p, prec + 1);
                right = range;
            }

            Syntax_Node *node = Node_New(NK_BINARY_OP, loc);
            node->binary.op = TK_IN;
            node->binary.left = left;
            node->binary.right = right;
            left = node;
            continue;
        }

        /* Standard binary operation */
        Precedence next_prec = Is_Right_Associative(op) ? prec : prec + 1;
        Syntax_Node *right = Parse_Expression_Precedence(p, next_prec);

        Syntax_Node *node = Node_New(NK_BINARY_OP, loc);
        node->binary.op = op;
        node->binary.left = left;
        node->binary.right = right;
        left = node;
    }

    return left;
}

static Syntax_Node *Parse_Expression(Parser *p) {
    return Parse_Expression_Precedence(p, PREC_LOGICAL);
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.9 Range Parsing
 * ───────────────────────────────────────────────────────────────────────── */

static Syntax_Node *Parse_Range(Parser *p) {
    Source_Location loc = Parser_Location(p);

    /* BOX: <> for unconstrained */
    if (Parser_Match(p, TK_BOX)) {
        return Node_New(NK_RANGE, loc);  /* Empty range = unconstrained */
    }

    Syntax_Node *low = Parse_Expression(p);

    if (Parser_Match(p, TK_DOTDOT)) {
        Syntax_Node *node = Node_New(NK_RANGE, loc);
        node->range.low = low;
        node->range.high = Parse_Expression(p);
        return node;
    }

    /* Check for subtype_mark RANGE low..high (discrete subtype definition)
     * e.g., "INTEGER RANGE 1..10" or "STAT RANGE 1..5" */
    if (Parser_Match(p, TK_RANGE)) {
        Syntax_Node *ind = Node_New(NK_SUBTYPE_INDICATION, loc);
        ind->subtype_ind.subtype_mark = low;

        /* Now parse the actual range constraint */
        Syntax_Node *constraint = Node_New(NK_RANGE_CONSTRAINT, loc);
        Syntax_Node *range_low = Parse_Expression(p);

        if (Parser_Match(p, TK_DOTDOT)) {
            Syntax_Node *range_node = Node_New(NK_RANGE, loc);
            range_node->range.low = range_low;
            range_node->range.high = Parse_Expression(p);
            constraint->range_constraint.range = range_node;
        } else {
            /* Just a range attribute or name */
            constraint->range_constraint.range = range_low;
        }

        ind->subtype_ind.constraint = constraint;
        return ind;
    }

    /* Could be a subtype name used as a range */
    return low;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.10 Subtype Indication Parsing
 *
 * A subtype is a type with a constraint that narrows the range of valid values.
 * ───────────────────────────────────────────────────────────────────────── */

static Syntax_Node *Parse_Subtype_Indication(Parser *p) {
    Source_Location loc = Parser_Location(p);

    /* Parse_Name may consume (args) as NK_APPLY - we need to unwrap it for constraints */
    Syntax_Node *name_or_apply = Parse_Name(p);

    /* If Parse_Name returned NK_APPLY, the parenthesized part might be a constraint */
    if (name_or_apply->kind == NK_APPLY) {
        Syntax_Node *subtype_mark = name_or_apply->apply.prefix;
        Node_List *items = &name_or_apply->apply.arguments;

        /* Classify: if any item is a named association, it's a discriminant constraint */
        bool is_discriminant = false;
        for (uint32_t i = 0; i < items->count; i++) {
            Syntax_Node *item = items->items[i];
            if (item->kind == NK_ASSOCIATION) {
                is_discriminant = true;
                break;
            }
        }

        /* Create NK_SUBTYPE_INDICATION with appropriate constraint */
        Syntax_Node *ind = Node_New(NK_SUBTYPE_INDICATION, loc);
        ind->subtype_ind.subtype_mark = subtype_mark;

        if (is_discriminant) {
            Syntax_Node *constraint = Node_New(NK_DISCRIMINANT_CONSTRAINT, loc);
            constraint->discriminant_constraint.associations = *items;
            ind->subtype_ind.constraint = constraint;
        } else {
            Syntax_Node *constraint = Node_New(NK_INDEX_CONSTRAINT, loc);
            constraint->index_constraint.ranges = *items;
            ind->subtype_ind.constraint = constraint;
        }

        return ind;
    }

    Syntax_Node *subtype_mark = name_or_apply;

    /* Check for RANGE constraint */
    if (Parser_Match(p, TK_RANGE)) {
        Syntax_Node *ind = Node_New(NK_SUBTYPE_INDICATION, loc);
        ind->subtype_ind.subtype_mark = subtype_mark;

        Syntax_Node *constraint = Node_New(NK_RANGE_CONSTRAINT, loc);
        constraint->range_constraint.range = Parse_Range(p);
        ind->subtype_ind.constraint = constraint;
        return ind;
    }

    /* Check for DIGITS constraint (floating-point types) */
    if (Parser_Match(p, TK_DIGITS)) {
        Syntax_Node *ind = Node_New(NK_SUBTYPE_INDICATION, loc);
        ind->subtype_ind.subtype_mark = subtype_mark;

        Syntax_Node *constraint = Node_New(NK_DIGITS_CONSTRAINT, loc);
        constraint->digits_constraint.digits_expr = Parse_Expression(p);

        /* Optional RANGE constraint after DIGITS */
        if (Parser_Match(p, TK_RANGE)) {
            constraint->digits_constraint.range = Parse_Range(p);
        }

        ind->subtype_ind.constraint = constraint;
        return ind;
    }

    /* Check for DELTA constraint (fixed-point types) */
    if (Parser_Match(p, TK_DELTA)) {
        Syntax_Node *ind = Node_New(NK_SUBTYPE_INDICATION, loc);
        ind->subtype_ind.subtype_mark = subtype_mark;

        Syntax_Node *constraint = Node_New(NK_DELTA_CONSTRAINT, loc);
        constraint->delta_constraint.delta_expr = Parse_Expression(p);

        /* Optional RANGE constraint after DELTA */
        if (Parser_Match(p, TK_RANGE)) {
            constraint->delta_constraint.range = Parse_Range(p);
        }

        ind->subtype_ind.constraint = constraint;
        return ind;
    }

    return subtype_mark;
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §9.11 Statement Parsing
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * Statements run in sequence while expressions form a tree, and parsing reflects this.
 */

/* Forward declarations */
static Syntax_Node *Parse_Statement(Parser *p);
static void Parse_Statement_Sequence(Parser *p, Node_List *list);
static void Parse_Declarative_Part(Parser *p, Node_List *list);
static Syntax_Node *Parse_Declaration(Parser *p);
static Syntax_Node *Parse_Enumeration_Type(Parser *p);
static Syntax_Node *Parse_Record_Type(Parser *p);
static Syntax_Node *Parse_Access_Type(Parser *p);
static Syntax_Node *Parse_Derived_Type(Parser *p);
static Syntax_Node *Parse_Type_Definition(Parser *p) {
    Source_Location loc = Parser_Location(p);

    /* Enumeration type */
    if (Parser_At(p, TK_LPAREN)) {
        return Parse_Enumeration_Type(p);
    }

    /* Array type */
    if (Parser_At(p, TK_ARRAY)) {
        return Parse_Array_Type(p);
    }

    /* Record type: RECORD ... END RECORD or NULL RECORD */
    if (Parser_At(p, TK_RECORD)) {
        return Parse_Record_Type(p);
    }

    /* Null record type: NULL RECORD */
    if (Parser_Match(p, TK_NULL)) {
        Parser_Expect(p, TK_RECORD);
        Syntax_Node *node = Node_New(NK_RECORD_TYPE, loc);
        node->record_type.is_null = true;
        return node;
    }

    /* Access type */
    if (Parser_At(p, TK_ACCESS)) {
        return Parse_Access_Type(p);
    }

    /* Derived type */
    if (Parser_At(p, TK_NEW)) {
        return Parse_Derived_Type(p);
    }

    /* Integer types: range, mod */
    if (Parser_Match(p, TK_RANGE)) {
        Syntax_Node *node = Node_New(NK_INTEGER_TYPE, loc);
        node->integer_type.range = Parse_Range(p);
        return node;
    }

    if (Parser_Match(p, TK_MOD)) {
        Syntax_Node *node = Node_New(NK_INTEGER_TYPE, loc);
        Syntax_Node *mod_expr = Parse_Expression(p);
        node->integer_type.is_modular = true;
        node->integer_type.modulus = 0;  /* Evaluated during semantic analysis */
        node->integer_type.range = mod_expr;
        return node;
    }

    /* Real types: digits, delta */
    if (Parser_Match(p, TK_DIGITS)) {
        Syntax_Node *node = Node_New(NK_REAL_TYPE, loc);
        node->real_type.precision = Parse_Expression(p);
        if (Parser_Match(p, TK_RANGE)) {
            node->real_type.range = Parse_Range(p);
        }
        return node;
    }

    if (Parser_Match(p, TK_DELTA)) {
        Syntax_Node *node = Node_New(NK_REAL_TYPE, loc);
        node->real_type.delta = Parse_Expression(p);
        if (Parser_Match(p, TK_RANGE)) {
            node->real_type.range = Parse_Range(p);
        }
        return node;
    }

    Parser_Error(p, "expected type definition");
    return Node_New(NK_INTEGER_TYPE, loc);
}

static Syntax_Node *Parse_Subprogram_Body(Parser *p, Syntax_Node *spec);
static Syntax_Node *Parse_Block_Statement(Parser *p, String_Slice label);
static Syntax_Node *Parse_Loop_Statement(Parser *p, String_Slice label);
/* ═══════════════════════════════════════════════════════════════════════════
 * §9.17 Pragmas
 * ═══════════════════════════════════════════════════════════════════════════
 */

static Syntax_Node *Parse_Pragma(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_PRAGMA);

    Syntax_Node *node = Node_New(NK_PRAGMA, loc);
    node->pragma_node.name = Parser_Identifier(p);

    if (Parser_Match(p, TK_LPAREN)) {
        Parse_Association_List(p, &node->pragma_node.arguments);
        Parser_Expect(p, TK_RPAREN);
    }

    return node;
}


/* ─────────────────────────────────────────────────────────────────────────
 * §9.11.1 Simple Statements
 * ───────────────────────────────────────────────────────────────────────── */

static Syntax_Node *Parse_Assignment_Or_Call(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Syntax_Node *target = Parse_Name(p);

    if (Parser_Match(p, TK_ASSIGN)) {
        Syntax_Node *node = Node_New(NK_ASSIGNMENT, loc);
        node->assignment.target = target;
        node->assignment.value = Parse_Expression(p);
        return node;
    }

    /* Procedure call (target is already an NK_APPLY or NK_IDENTIFIER) */
    Syntax_Node *call = Node_New(NK_CALL_STMT, loc);
    call->assignment.target = target;  /* Reuse field for simplicity */
    return call;
}

static Syntax_Node *Parse_Return_Statement(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_RETURN);

    Syntax_Node *node = Node_New(NK_RETURN, loc);
    if (not Parser_At(p, TK_SEMICOLON)) {
        node->return_stmt.expression = Parse_Expression(p);
    }
    return node;
}

static Syntax_Node *Parse_Exit_Statement(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_EXIT);

    Syntax_Node *node = Node_New(NK_EXIT, loc);
    if (Parser_At(p, TK_IDENTIFIER)) {
        node->exit_stmt.loop_name = Parser_Identifier(p);
    }
    if (Parser_Match(p, TK_WHEN)) {
        node->exit_stmt.condition = Parse_Expression(p);
    }
    return node;
}

static Syntax_Node *Parse_Goto_Statement(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_GOTO);

    Syntax_Node *node = Node_New(NK_GOTO, loc);
    node->goto_stmt.name = Parser_Identifier(p);
    return node;
}

static Syntax_Node *Parse_Raise_Statement(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_RAISE);

    Syntax_Node *node = Node_New(NK_RAISE, loc);
    if (Parser_At(p, TK_IDENTIFIER)) {
        node->raise_stmt.exception_name = Parse_Name(p);
    }
    return node;
}

static Syntax_Node *Parse_Delay_Statement(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_DELAY);

    Syntax_Node *node = Node_New(NK_DELAY, loc);
    node->delay_stmt.expression = Parse_Expression(p);
    return node;
}

static Syntax_Node *Parse_Abort_Statement(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_ABORT);

    Syntax_Node *node = Node_New(NK_ABORT, loc);
    do {
        Node_List_Push(&node->abort_stmt.task_names, Parse_Name(p));
    } while (Parser_Match(p, TK_COMMA));
    return node;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.11.2 If Statement
 * ───────────────────────────────────────────────────────────────────────── */

static Syntax_Node *Parse_If_Statement(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_IF);

    Syntax_Node *node = Node_New(NK_IF, loc);
    node->if_stmt.condition = Parse_Expression(p);
    Parser_Expect(p, TK_THEN);
    Parse_Statement_Sequence(p, &node->if_stmt.then_stmts);

    /* ELSIF parts */
    while (Parser_At(p, TK_ELSIF)) {
        Source_Location elsif_loc = Parser_Location(p);
        Parser_Advance(p);

        Syntax_Node *elsif = Node_New(NK_IF, elsif_loc);
        elsif->if_stmt.condition = Parse_Expression(p);
        Parser_Expect(p, TK_THEN);
        Parse_Statement_Sequence(p, &elsif->if_stmt.then_stmts);

        Node_List_Push(&node->if_stmt.elsif_parts, elsif);
    }

    /* ELSE part */
    if (Parser_Match(p, TK_ELSE)) {
        Parse_Statement_Sequence(p, &node->if_stmt.else_stmts);
    }

    Parser_Expect(p, TK_END);
    Parser_Expect(p, TK_IF);
    return node;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.11.3 Case Statement
 * ───────────────────────────────────────────────────────────────────────── */

static Syntax_Node *Parse_Case_Statement(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_CASE);

    Syntax_Node *node = Node_New(NK_CASE, loc);
    node->case_stmt.expression = Parse_Expression(p);
    Parser_Expect(p, TK_IS);

    /* Parse alternatives */
    while (Parser_At(p, TK_WHEN)) {
        Source_Location alt_loc = Parser_Location(p);
        Parser_Advance(p);

        Syntax_Node *alt = Node_New(NK_ASSOCIATION, alt_loc);

        /* Parse choices - use Parse_Choice to handle ranges and OTHERS */
        do {
            Node_List_Push(&alt->association.choices, Parse_Choice(p));
        } while (Parser_Match(p, TK_BAR));

        Parser_Expect(p, TK_ARROW);

        /* Statements for this alternative stored as expression temporarily */
        Syntax_Node *stmts = Node_New(NK_BLOCK, alt_loc);
        Parse_Statement_Sequence(p, &stmts->block_stmt.statements);
        alt->association.expression = stmts;

        Node_List_Push(&node->case_stmt.alternatives, alt);
    }

    Parser_Expect(p, TK_END);
    Parser_Expect(p, TK_CASE);
    return node;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.11.4 Loop Statement
 * ───────────────────────────────────────────────────────────────────────── */

static Syntax_Node *Parse_Loop_Statement(Parser *p, String_Slice label) {
    Source_Location loc = Parser_Location(p);
    Syntax_Node *node = Node_New(NK_LOOP, loc);
    node->loop_stmt.label = label;

    /* WHILE loop */
    if (Parser_Match(p, TK_WHILE)) {
        node->loop_stmt.iteration_scheme = Parse_Expression(p);
    }
    /* FOR loop */
    else if (Parser_Match(p, TK_FOR)) {
        Source_Location for_loc = Parser_Location(p);
        Syntax_Node *iter = Node_New(NK_BINARY_OP, for_loc);
        iter->binary.op = TK_IN;

        /* Iterator identifier */
        Syntax_Node *id = Node_New(NK_IDENTIFIER, for_loc);
        id->string_val.text = Parser_Identifier(p);
        iter->binary.left = id;

        Parser_Expect(p, TK_IN);

        node->loop_stmt.is_reverse = Parser_Match(p, TK_REVERSE);

        /* Discrete range */
        iter->binary.right = Parse_Range(p);
        node->loop_stmt.iteration_scheme = iter;
    }

    Parser_Expect(p, TK_LOOP);
    Parse_Statement_Sequence(p, &node->loop_stmt.statements);
    Parser_Expect(p, TK_END);
    Parser_Expect(p, TK_LOOP);

    if (label.data and Parser_At(p, TK_IDENTIFIER)) {
        Parser_Check_End_Name(p, label);
    }

    return node;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.11.5 Block Statement
 * ───────────────────────────────────────────────────────────────────────── */

static Syntax_Node *Parse_Block_Statement(Parser *p, String_Slice label) {
    Source_Location loc = Parser_Location(p);
    Syntax_Node *node = Node_New(NK_BLOCK, loc);
    node->block_stmt.label = label;

    if (Parser_Match(p, TK_DECLARE)) {
        Parse_Declarative_Part(p, &node->block_stmt.declarations);
    }

    Parser_Expect(p, TK_BEGIN);
    Parse_Statement_Sequence(p, &node->block_stmt.statements);

    if (Parser_Match(p, TK_EXCEPTION)) {
        while (Parser_At(p, TK_WHEN)) {
            Source_Location h_loc = Parser_Location(p);
            Parser_Advance(p);

            Syntax_Node *handler = Node_New(NK_EXCEPTION_HANDLER, h_loc);

            /* Exception choices */
            do {
                if (Parser_Match(p, TK_OTHERS)) {
                    Node_List_Push(&handler->handler.exceptions, Node_New(NK_OTHERS, h_loc));
                } else {
                    Node_List_Push(&handler->handler.exceptions, Parse_Name(p));
                }
            } while (Parser_Match(p, TK_BAR));

            Parser_Expect(p, TK_ARROW);
            Parse_Statement_Sequence(p, &handler->handler.statements);

            Node_List_Push(&node->block_stmt.handlers, handler);
        }
    }

    Parser_Expect(p, TK_END);
    if (label.data and Parser_At(p, TK_IDENTIFIER)) {
        Parser_Check_End_Name(p, label);
    }

    return node;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.11.6 Accept Statement
 *
 * ACCEPT is the server side of rendezvous where the caller blocks until accepted.
 * ───────────────────────────────────────────────────────────────────────── */

static Syntax_Node *Parse_Accept_Statement(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_ACCEPT);

    Syntax_Node *node = Node_New(NK_ACCEPT, loc);
    node->accept_stmt.entry_name = Parser_Identifier(p);

    /* Optional index and/or parameters
     * Need to distinguish:
     * - Entry index: (expression) like (5) or (I)
     * - Parameters: (id : type) like (X : INTEGER) */
    if (Parser_At(p, TK_LPAREN)) {
        /* Lookahead to distinguish index vs parameters */
        Token saved = p->current_token;
        Lexer saved_lexer = p->lexer;
        Parser_Advance(p);  /* consume ( */

        bool is_parameter_list = false;
        if (Parser_At(p, TK_IDENTIFIER)) {
            Parser_Advance(p);  /* past identifier */
            /* If followed by : or ,, it's a parameter list */
            is_parameter_list = Parser_At(p, TK_COLON) or Parser_At(p, TK_COMMA);
        }

        /* Restore and parse correctly */
        p->current_token = saved;
        p->lexer = saved_lexer;

        if (is_parameter_list) {
            /* This is a parameter list, not an index */
            Parse_Parameter_List(p, &node->accept_stmt.parameters);
        } else {
            /* Parse entry index (expression) */
            Parser_Advance(p);  /* consume ( */
            node->accept_stmt.index = Parse_Expression(p);
            Parser_Expect(p, TK_RPAREN);

            /* Now check for optional parameters after index */
            if (Parser_At(p, TK_LPAREN)) {
                Parse_Parameter_List(p, &node->accept_stmt.parameters);
            }
        }
    }

    /* Optional body */
    if (Parser_Match(p, TK_DO)) {
        Parse_Statement_Sequence(p, &node->accept_stmt.statements);
        Parser_Expect(p, TK_END);
        if (Parser_At(p, TK_IDENTIFIER)) {
            Parser_Check_End_Name(p, node->accept_stmt.entry_name);
        }
    }

    return node;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.11.7 Select Statement
 *
 * SELECT makes a nondeterministic choice among open alternatives at runtime.
 * ───────────────────────────────────────────────────────────────────────── */

static Syntax_Node *Parse_Select_Statement(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_SELECT);

    Syntax_Node *node = Node_New(NK_SELECT, loc);

    /* Parse alternatives.  Each alternative is optionally guarded:
     *   [WHEN condition =>] accept_stmt ; [stmts]
     *   [WHEN condition =>] delay_stmt  ; [stmts]
     *   [WHEN condition =>] TERMINATE ;
     *   entry_call_stmt ; [stmts]           (timed/conditional) */
    do {
        Source_Location alt_loc = Parser_Location(p);

        /* Optional guard — parse condition then fall through to alternative */
        Syntax_Node *guard = NULL;
        if (Parser_Match(p, TK_WHEN)) {
            guard = Parse_Expression(p);
            Parser_Expect(p, TK_ARROW);
        }

        if (Parser_Match(p, TK_TERMINATE)) {
            Syntax_Node *term = Node_New(NK_NULL_STMT, alt_loc);
            Node_List_Push(&node->select_stmt.alternatives, term);
            Parser_Expect(p, TK_SEMICOLON);
        } else if (Parser_Match(p, TK_DELAY)) {
            Syntax_Node *delay = Node_New(NK_DELAY, alt_loc);
            delay->delay_stmt.expression = Parse_Expression(p);
            Parser_Expect(p, TK_SEMICOLON);
            Node_List_Push(&node->select_stmt.alternatives, delay);
            /* Optional statement sequence after delay */
            while (not Parser_At(p, TK_OR) and not Parser_At(p, TK_ELSE) and
                   not Parser_At(p, TK_END) and not Parser_At(p, TK_EOF)) {
                Syntax_Node *stmt = Parse_Statement(p);
                Node_List_Push(&node->select_stmt.alternatives, stmt);
                if (not Parser_At(p, TK_OR) and not Parser_At(p, TK_ELSE) and not Parser_At(p, TK_END)) {
                    Parser_Expect(p, TK_SEMICOLON);
                }
            }
        } else if (Parser_At(p, TK_ACCEPT)) {
            Syntax_Node *accept = Parse_Accept_Statement(p);
            Node_List_Push(&node->select_stmt.alternatives, accept);
            Parser_Expect(p, TK_SEMICOLON);
            /* Optional sequence of statements after accept in select */
            while (not Parser_At(p, TK_OR) and not Parser_At(p, TK_ELSE) and
                   not Parser_At(p, TK_END) and not Parser_At(p, TK_EOF)) {
                Syntax_Node *stmt = Parse_Statement(p);
                Node_List_Push(&accept->accept_stmt.statements, stmt);
                if (not Parser_At(p, TK_OR) and not Parser_At(p, TK_ELSE) and not Parser_At(p, TK_END)) {
                    Parser_Expect(p, TK_SEMICOLON);
                }
            }
        } else if (Parser_At(p, TK_IDENTIFIER)) {
            /* Entry call alternative — conditional or timed entry call */
            Syntax_Node *entry_call = Parse_Statement(p);
            Node_List_Push(&node->select_stmt.alternatives, entry_call);
            Parser_Expect(p, TK_SEMICOLON);
            /* Optional sequence of statements after entry call */
            while (not Parser_At(p, TK_OR) and not Parser_At(p, TK_ELSE) and
                   not Parser_At(p, TK_END) and not Parser_At(p, TK_EOF)) {
                Syntax_Node *stmt = Parse_Statement(p);
                Node_List_Push(&node->select_stmt.alternatives, stmt);
                if (not Parser_At(p, TK_OR) and not Parser_At(p, TK_ELSE) and not Parser_At(p, TK_END)) {
                    Parser_Expect(p, TK_SEMICOLON);
                }
            }
        } else {
            break;
        }
        (void)guard;  /* Guard stored in AST if needed later */
    } while (Parser_Match(p, TK_OR));

    if (Parser_Match(p, TK_ELSE)) {
        node->select_stmt.else_part = Node_New(NK_BLOCK, loc);
        Parse_Statement_Sequence(p, &node->select_stmt.else_part->block_stmt.statements);
    }

    Parser_Expect(p, TK_END);
    Parser_Expect(p, TK_SELECT);
    return node;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.11.8 Statement Dispatch
 * ───────────────────────────────────────────────────────────────────────── */

static Syntax_Node *Parse_Statement(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Source_Location label_loc = loc;

    /* Check for label(s): <<label>> or identifier:
     * Ada allows multiple labels before a statement: <<L1>> <<L2>> stmt; */
    String_Slice label = Empty_Slice;

    /* Handle multiple consecutive labels */
    while (Parser_At(p, TK_LSHIFT) or
           (Parser_At(p, TK_IDENTIFIER) and Parser_Peek_At(p, TK_COLON))) {

        if (Parser_Match(p, TK_LSHIFT)) {
            if (label.length == 0) label_loc = loc;  /* Save first label location */
            label = Parser_Identifier(p);
            Parser_Expect(p, TK_RSHIFT);
        } else if (Parser_At(p, TK_IDENTIFIER)) {
            /* Lookahead for "identifier :" (label) vs assignment/call */
            Token saved = p->current_token;
            Lexer saved_lexer = p->lexer;
            String_Slice id = Parser_Identifier(p);

            if (Parser_Match(p, TK_COLON)) {
                /* This is a label */
                if (label.length == 0) label_loc = loc;  /* Save first label location */
                label = id;
            } else {
                /* Not a label - restore and let assignment/call handle it */
                p->current_token = saved;
                p->lexer = saved_lexer;
                break;
            }
        }
        loc = Parser_Location(p);  /* Update location to after labels */
    }

    Syntax_Node *stmt = NULL;

    /* Null statement */
    if (Parser_Match(p, TK_NULL)) {
        /* Semicolon is handled by Parse_Statement_Sequence */
        stmt = Node_New(NK_NULL_STMT, loc);
    }
    /* Compound statements - loops and blocks handle labels as names */
    else if (Parser_At(p, TK_LOOP) or Parser_At(p, TK_WHILE) or Parser_At(p, TK_FOR)) {
        return Parse_Loop_Statement(p, label);  /* Loop keeps label as name */
    }
    else if (Parser_At(p, TK_DECLARE) or Parser_At(p, TK_BEGIN)) {
        return Parse_Block_Statement(p, label);  /* Block keeps label as name */
    }
    else if (Parser_At(p, TK_IF)) stmt = Parse_If_Statement(p);
    else if (Parser_At(p, TK_CASE)) stmt = Parse_Case_Statement(p);
    else if (Parser_At(p, TK_ACCEPT)) stmt = Parse_Accept_Statement(p);
    else if (Parser_At(p, TK_SELECT)) stmt = Parse_Select_Statement(p);
    /* Simple statements */
    else if (Parser_At(p, TK_RETURN)) stmt = Parse_Return_Statement(p);
    else if (Parser_At(p, TK_EXIT)) stmt = Parse_Exit_Statement(p);
    else if (Parser_At(p, TK_GOTO)) stmt = Parse_Goto_Statement(p);
    else if (Parser_At(p, TK_RAISE)) stmt = Parse_Raise_Statement(p);
    else if (Parser_At(p, TK_DELAY)) stmt = Parse_Delay_Statement(p);
    else if (Parser_At(p, TK_ABORT)) stmt = Parse_Abort_Statement(p);
    /* Pragma in statement sequence (Ada 83 RM 2.8) */
    else if (Parser_At(p, TK_PRAGMA)) stmt = Parse_Pragma(p);
    /* Assignment or procedure call */
    else stmt = Parse_Assignment_Or_Call(p);

    /* Wrap in NK_LABEL if a label was present (except for loop/block which handle labels) */
    if (label.length > 0 and stmt != NULL) {
        Syntax_Node *label_node = Node_New(NK_LABEL, label_loc);
        label_node->label_node.name = label;
        label_node->label_node.statement = stmt;
        label_node->label_node.symbol = NULL;  /* Set during resolution */
        return label_node;
    }

    return stmt;
}

static void Parse_Statement_Sequence(Parser *p, Node_List *list) {
    while (not Parser_At(p, TK_EOF) and
           not Parser_At(p, TK_END) and
           not Parser_At(p, TK_ELSE) and
           not Parser_At(p, TK_ELSIF) and
           not Parser_At(p, TK_WHEN) and
           not Parser_At(p, TK_EXCEPTION) and
           not Parser_At(p, TK_OR)) {

        if (not Parser_Check_Progress(p)) break;

        Syntax_Node *stmt = Parse_Statement(p);
        Node_List_Push(list, stmt);

        if (not Parser_At(p, TK_END) and not Parser_At(p, TK_ELSE) and
            not Parser_At(p, TK_ELSIF) and not Parser_At(p, TK_WHEN) and
            not Parser_At(p, TK_EXCEPTION) and not Parser_At(p, TK_OR)) {
            Parser_Expect(p, TK_SEMICOLON);
        }
    }
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §9.12 Declaration Parsing
 * ═══════════════════════════════════════════════════════════════════════════
 */

/* ─────────────────────────────────────────────────────────────────────────
 * §9.12.1 Object Declaration (variables, constants)
 *
 * Multiple names can share one type declaration but each gets its own symbol.
 * ───────────────────────────────────────────────────────────────────────── */

static Syntax_Node *Parse_Object_Declaration(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Syntax_Node *node = Node_New(NK_OBJECT_DECL, loc);

    /* Identifier list */
    do {
        Syntax_Node *id = Node_New(NK_IDENTIFIER, Parser_Location(p));
        id->string_val.text = Parser_Identifier(p);
        Node_List_Push(&node->object_decl.names, id);
    } while (Parser_Match(p, TK_COMMA));

    Parser_Expect(p, TK_COLON);

    /* Check for exception declaration: identifier_list : EXCEPTION [RENAMES name] */
    if (Parser_Match(p, TK_EXCEPTION)) {
        /* Check for renaming */
        if (Parser_Match(p, TK_RENAMES)) {
            node->kind = NK_EXCEPTION_RENAMING;
            node->exception_decl.names = node->object_decl.names;
            node->exception_decl.renamed = Parse_Name(p);
        } else {
            node->kind = NK_EXCEPTION_DECL;
            node->exception_decl.names = node->object_decl.names;
        }
        return node;
    }

    node->object_decl.is_aliased = Parser_Match(p, TK_ACCESS);  /* ALIASED uses ACCESS token? */
    node->object_decl.is_constant = Parser_Match(p, TK_CONSTANT);

    /* Named number (number declaration): identifier : CONSTANT := static_expression; */
    /* No type specified, goes directly to := */
    if (not node->object_decl.is_constant or not Parser_At(p, TK_ASSIGN)) {
        /* Check for anonymous array type: ARRAY (...) OF ... */
        if (Parser_At(p, TK_ARRAY)) {
            node->object_decl.object_type = Parse_Array_Type(p);
        } else {
            node->object_decl.object_type = Parse_Subtype_Indication(p);
        }
    }

    /* Renames: X : T RENAMES Y */
    if (Parser_Match(p, TK_RENAMES)) {
        node->object_decl.is_rename = true;
        node->object_decl.init = Parse_Name(p);
        return node;
    }

    /* Initialization */
    if (Parser_Match(p, TK_ASSIGN)) {
        node->object_decl.init = Parse_Expression(p);
    }

    return node;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.12.2 Type Declaration
 *
 * Discriminants parameterize the type with values fixed when the object is created.
 * ───────────────────────────────────────────────────────────────────────── */

static Syntax_Node *Parse_Discriminant_Part(Parser *p) {
    if (not Parser_Match(p, TK_LPAREN)) return NULL;

    Source_Location loc = Parser_Location(p);
    Syntax_Node *disc_list = Node_New(NK_BLOCK, loc);  /* Container for discriminants */

    do {
        Source_Location d_loc = Parser_Location(p);
        Syntax_Node *disc = Node_New(NK_DISCRIMINANT_SPEC, d_loc);

        /* Name list */
        do {
            Syntax_Node *id = Node_New(NK_IDENTIFIER, Parser_Location(p));
            id->string_val.text = Parser_Identifier(p);
            Node_List_Push(&disc->discriminant.names, id);
        } while (Parser_Match(p, TK_COMMA));

        Parser_Expect(p, TK_COLON);
        disc->discriminant.disc_type = Parse_Subtype_Indication(p);

        if (Parser_Match(p, TK_ASSIGN)) {
            disc->discriminant.default_expr = Parse_Expression(p);
        }

        Node_List_Push(&disc_list->block_stmt.declarations, disc);
    } while (Parser_Match(p, TK_SEMICOLON));

    Parser_Expect(p, TK_RPAREN);
    return disc_list;
}

static Syntax_Node *Parse_Type_Declaration(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_TYPE);

    Syntax_Node *node = Node_New(NK_TYPE_DECL, loc);
    node->type_decl.name = Parser_Identifier(p);

    /* Discriminant part */
    if (Parser_At(p, TK_LPAREN)) {
        Syntax_Node *discs = Parse_Discriminant_Part(p);
        if (discs) {
            node->type_decl.discriminants = discs->block_stmt.declarations;
        }
    }

    /* Incomplete type declaration */
    if (Parser_Match(p, TK_SEMICOLON)) {
        return node;
    }

    Parser_Expect(p, TK_IS);

    node->type_decl.is_limited = Parser_Match(p, TK_LIMITED);
    node->type_decl.is_private = Parser_Match(p, TK_PRIVATE);

    if (not node->type_decl.is_private) {
        node->type_decl.definition = Parse_Type_Definition(p);
    }

    return node;
}

static Syntax_Node *Parse_Subtype_Declaration(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_SUBTYPE);

    Syntax_Node *node = Node_New(NK_SUBTYPE_DECL, loc);
    node->type_decl.name = Parser_Identifier(p);

    Parser_Expect(p, TK_IS);
    node->type_decl.definition = Parse_Subtype_Indication(p);

    return node;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.12.3 Type Definitions
 *
 * Parsing establishes structure while elaboration establishes meaning.
 * ───────────────────────────────────────────────────────────────────────── */

static Syntax_Node *Parse_Enumeration_Type(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_LPAREN);

    Syntax_Node *node = Node_New(NK_ENUMERATION_TYPE, loc);

    do {
        Source_Location lit_loc = Parser_Location(p);
        Syntax_Node *lit = Node_New(NK_IDENTIFIER, lit_loc);

        if (Parser_At(p, TK_IDENTIFIER)) {
            lit->string_val.text = Parser_Identifier(p);
        } else if (Parser_At(p, TK_CHARACTER)) {
            lit->string_val.text = Slice_Duplicate(p->current_token.text);
            Parser_Advance(p);
        } else {
            Parser_Error_At_Current(p, "enumeration literal");
            break;
        }

        Node_List_Push(&node->enum_type.literals, lit);
    } while (Parser_Match(p, TK_COMMA));

    Parser_Expect(p, TK_RPAREN);
    return node;
}

static Syntax_Node *Parse_Discrete_Range(Parser *p);

static Syntax_Node *Parse_Array_Type(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_ARRAY);
    Parser_Expect(p, TK_LPAREN);

    Syntax_Node *node = Node_New(NK_ARRAY_TYPE, loc);

    /* Index types: can be discrete_subtype_indication or discrete_range */
    do {
        Syntax_Node *idx = Parse_Discrete_Range(p);
        Node_List_Push(&node->array_type.indices, idx);
    } while (Parser_Match(p, TK_COMMA));

    /* Determine if constrained based on what we parsed.
     * An index is unconstrained if it's just a type mark (identifier/selected)
     * without a range constraint. A range or subtype_indication with constraint
     * means constrained. */
    node->array_type.is_constrained = true;
    for (size_t i = 0; i < node->array_type.indices.count; i++) {
        Syntax_Node *idx = node->array_type.indices.items[i];
        /* Just a type name without constraint = unconstrained */
        if (idx->kind == NK_IDENTIFIER or idx->kind == NK_SELECTED) {
            node->array_type.is_constrained = false;
            break;
        }
    }

    Parser_Expect(p, TK_RPAREN);
    Parser_Expect(p, TK_OF);
    node->array_type.component_type = Parse_Subtype_Indication(p);

    return node;
}

/* Parse discrete_range: can be subtype_indication or range */
static Syntax_Node *Parse_Discrete_Range(Parser *p) {
    Source_Location loc = Parser_Location(p);

    /* Check if this starts with an integer literal (anonymous range) */
    if (Parser_At(p, TK_INTEGER) or Parser_At(p, TK_CHARACTER)) {
        Syntax_Node *range = Node_New(NK_RANGE, loc);
        range->range.low = Parse_Expression(p);
        if (Parser_Match(p, TK_DOTDOT)) {
            range->range.high = Parse_Expression(p);
        }
        return range;
    }

    /* Otherwise try to parse as name, then check for range or constraint */
    Syntax_Node *name = Parse_Name(p);

    if (Parser_Match(p, TK_RANGE)) {
        /* Type RANGE low..high or Type RANGE <> */
        if (Parser_Match(p, TK_BOX)) {
            /* Unconstrained - return the type mark; <> is consumed */
            return name;
        }
        Syntax_Node *range = Node_New(NK_RANGE, loc);
        range->range.low = Parse_Expression(p);
        Parser_Expect(p, TK_DOTDOT);
        range->range.high = Parse_Expression(p);

        /* Create subtype indication with range constraint */
        Syntax_Node *ind = Node_New(NK_SUBTYPE_INDICATION, loc);
        ind->subtype_ind.subtype_mark = name;
        Syntax_Node *constraint = Node_New(NK_RANGE_CONSTRAINT, loc);
        constraint->range_constraint.range = range;
        ind->subtype_ind.constraint = constraint;
        return ind;
    }

    if (Parser_Match(p, TK_DOTDOT)) {
        /* Name is actually the low bound of a range */
        Syntax_Node *range = Node_New(NK_RANGE, loc);
        range->range.low = name;
        range->range.high = Parse_Expression(p);
        return range;
    }

    /* Just a type name */
    return name;
}

/* Forward declaration for variant part parsing */
static Syntax_Node *Parse_Variant_Part(Parser *p);

static Syntax_Node *Parse_Record_Type(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_RECORD);

    Syntax_Node *node = Node_New(NK_RECORD_TYPE, loc);

    /* NULL; as empty component statement (vs NULL RECORD which is parsed elsewhere) */
    /* Skip this check - NULL inside record body is handled in the loop below */

    /* Component list */
    while (not Parser_At(p, TK_END) and not Parser_At(p, TK_CASE) and not Parser_At(p, TK_EOF)) {
        if (not Parser_Check_Progress(p)) break;

        /* NULL; as empty component list */
        if (Parser_At(p, TK_NULL)) {
            Parser_Advance(p);
            Parser_Expect(p, TK_SEMICOLON);
            continue;
        }

        Source_Location c_loc = Parser_Location(p);
        Syntax_Node *comp = Node_New(NK_COMPONENT_DECL, c_loc);

        /* Component names */
        do {
            Syntax_Node *id = Node_New(NK_IDENTIFIER, Parser_Location(p));
            id->string_val.text = Parser_Identifier(p);
            Node_List_Push(&comp->component.names, id);
        } while (Parser_Match(p, TK_COMMA));

        Parser_Expect(p, TK_COLON);
        comp->component.component_type = Parse_Subtype_Indication(p);

        if (Parser_Match(p, TK_ASSIGN)) {
            comp->component.init = Parse_Expression(p);
        }

        Node_List_Push(&node->record_type.components, comp);
        Parser_Expect(p, TK_SEMICOLON);
    }

    /* Variant part */
    if (Parser_At(p, TK_CASE)) {
        node->record_type.variant_part = Parse_Variant_Part(p);
    }

    Parser_Expect(p, TK_END);
    Parser_Expect(p, TK_RECORD);
    return node;
}

static Syntax_Node *Parse_Variant_Part(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_CASE);

    Syntax_Node *node = Node_New(NK_VARIANT_PART, loc);
    node->variant_part.discriminant = Parser_Identifier(p);
    Parser_Expect(p, TK_IS);

    /* Variants */
    while (Parser_At(p, TK_WHEN)) {
        Source_Location v_loc = Parser_Location(p);
        Parser_Advance(p);

        Syntax_Node *variant = Node_New(NK_VARIANT, v_loc);

        /* Choices - can be expressions, ranges, or OTHERS */
        do {
            Node_List_Push(&variant->variant.choices, Parse_Choice(p));
        } while (Parser_Match(p, TK_BAR));

        Parser_Expect(p, TK_ARROW);

        /* Components in this variant */
        while (not Parser_At(p, TK_WHEN) and not Parser_At(p, TK_END) and
               not Parser_At(p, TK_CASE) and not Parser_At(p, TK_EOF)) {
            if (not Parser_Check_Progress(p)) break;

            /* NULL; as empty component list in variant */
            if (Parser_At(p, TK_NULL)) {
                Parser_Advance(p);
                Parser_Expect(p, TK_SEMICOLON);
                continue;
            }

            Source_Location c_loc = Parser_Location(p);
            Syntax_Node *comp = Node_New(NK_COMPONENT_DECL, c_loc);

            do {
                Syntax_Node *id = Node_New(NK_IDENTIFIER, Parser_Location(p));
                id->string_val.text = Parser_Identifier(p);
                Node_List_Push(&comp->component.names, id);
            } while (Parser_Match(p, TK_COMMA));

            Parser_Expect(p, TK_COLON);
            comp->component.component_type = Parse_Subtype_Indication(p);

            if (Parser_Match(p, TK_ASSIGN)) {
                comp->component.init = Parse_Expression(p);
            }

            Node_List_Push(&variant->variant.components, comp);
            Parser_Expect(p, TK_SEMICOLON);
        }

        /* Nested variant part */
        if (Parser_At(p, TK_CASE)) {
            variant->variant.variant_part = Parse_Variant_Part(p);
        }

        Node_List_Push(&node->variant_part.variants, variant);
    }

    Parser_Expect(p, TK_END);
    Parser_Expect(p, TK_CASE);
    Parser_Expect(p, TK_SEMICOLON);
    return node;
}

static Syntax_Node *Parse_Access_Type(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_ACCESS);

    Syntax_Node *node = Node_New(NK_ACCESS_TYPE, loc);
    node->access_type.is_constant = Parser_Match(p, TK_CONSTANT);
    node->access_type.designated = Parse_Subtype_Indication(p);
    return node;
}

static Syntax_Node *Parse_Derived_Type(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_NEW);

    Syntax_Node *node = Node_New(NK_DERIVED_TYPE, loc);
    node->derived_type.parent_type = Parse_Subtype_Indication(p);

    /* Parse_Subtype_Indication may have incorrectly consumed DIGITS/DELTA
     * constraints as part of the parent type. For derived types, these
     * constraints belong to the derived type definition, not the parent.
     * Extract them if present. */
    Syntax_Node *parent = node->derived_type.parent_type;
    if (parent and parent->kind == NK_SUBTYPE_INDICATION and
        parent->subtype_ind.constraint) {
        Syntax_Node *c = parent->subtype_ind.constraint;
        if (c->kind == NK_DIGITS_CONSTRAINT or c->kind == NK_DELTA_CONSTRAINT) {
            /* Move constraint from parent to derived type */
            Syntax_Node *constraint = Node_New(NK_REAL_TYPE, c->location);
            if (c->kind == NK_DIGITS_CONSTRAINT) {
                constraint->real_type.precision = c->digits_constraint.digits_expr;
                constraint->real_type.range = c->digits_constraint.range;
            } else {
                constraint->real_type.delta = c->delta_constraint.delta_expr;
                constraint->real_type.range = c->delta_constraint.range;
            }
            node->derived_type.constraint = constraint;
            /* Remove constraint from parent - use just the subtype mark */
            node->derived_type.parent_type = parent->subtype_ind.subtype_mark;
        }
    }

    /* Handle any remaining accuracy constraint (DIGITS or DELTA).
     * Ada RM 3.5.7: derived_type_definition ::=
     *   new subtype_indication [accuracy_constraint] [range_constraint]
     * accuracy_constraint ::= DIGITS expression | DELTA expression */
    if (Parser_At(p, TK_DIGITS) or Parser_At(p, TK_DELTA)) {
        /* Parse as NK_REAL_TYPE to reuse real type constraint handling */
        Syntax_Node *constraint = Node_New(NK_REAL_TYPE, Parser_Location(p));
        if (Parser_Match(p, TK_DIGITS)) {
            constraint->real_type.precision = Parse_Expression(p);
        } else {
            Parser_Advance(p);  /* Skip DELTA */
            constraint->real_type.delta = Parse_Expression(p);
        }
        if (Parser_Match(p, TK_RANGE)) {
            constraint->real_type.range = Parse_Range(p);
        }
        node->derived_type.constraint = constraint;
    } else if (Parser_At(p, TK_RANGE) or Parser_At(p, TK_LPAREN)) {
        node->derived_type.constraint = Parse_Subtype_Indication(p);
    }

    return node;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.13.2 Procedure/Function Specification
 * ───────────────────────────────────────────────────────────────────────── */

static Syntax_Node *Parse_Procedure_Specification(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_PROCEDURE);

    Syntax_Node *node = Node_New(NK_PROCEDURE_SPEC, loc);

    /* Name (can be identifier or operator string) */
    if (Parser_At(p, TK_STRING)) {
        node->subprogram_spec.name = Slice_Duplicate(p->current_token.text);
        Parser_Advance(p);
    } else {
        node->subprogram_spec.name = Parser_Identifier(p);
    }

    Parse_Parameter_List(p, &node->subprogram_spec.parameters);
    return node;
}

static Syntax_Node *Parse_Function_Specification(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_FUNCTION);

    Syntax_Node *node = Node_New(NK_FUNCTION_SPEC, loc);

    /* Name */
    if (Parser_At(p, TK_STRING)) {
        node->subprogram_spec.name = Slice_Duplicate(p->current_token.text);
        Parser_Advance(p);
    } else {
        node->subprogram_spec.name = Parser_Identifier(p);
    }

    Parse_Parameter_List(p, &node->subprogram_spec.parameters);

    Parser_Expect(p, TK_RETURN);
    node->subprogram_spec.return_type = Parse_Subtype_Indication(p);

    return node;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §9.13.3 Subprogram Body
 *
 * Declarations, then BEGIN, then statements. The structure is invariant.
 * ───────────────────────────────────────────────────────────────────────── */

static Syntax_Node *Parse_Subprogram_Body(Parser *p, Syntax_Node *spec) {
    Source_Location loc = spec ? spec->location : Parser_Location(p);
    bool is_function = spec and spec->kind == NK_FUNCTION_SPEC;

    Syntax_Node *node = Node_New(is_function ? NK_FUNCTION_BODY : NK_PROCEDURE_BODY, loc);
    node->subprogram_body.specification = spec;

    Parser_Expect(p, TK_IS);

    /* Check for SEPARATE */
    if (Parser_Match(p, TK_SEPARATE)) {
        node->subprogram_body.is_separate = true;
        return node;
    }

    Parse_Declarative_Part(p, &node->subprogram_body.declarations);

    Parser_Expect(p, TK_BEGIN);
    Parse_Statement_Sequence(p, &node->subprogram_body.statements);

    if (Parser_Match(p, TK_EXCEPTION)) {
        while (Parser_At(p, TK_WHEN)) {
            Source_Location h_loc = Parser_Location(p);
            Parser_Advance(p);

            Syntax_Node *handler = Node_New(NK_EXCEPTION_HANDLER, h_loc);

            do {
                if (Parser_Match(p, TK_OTHERS)) {
                    Node_List_Push(&handler->handler.exceptions, Node_New(NK_OTHERS, h_loc));
                } else {
                    Node_List_Push(&handler->handler.exceptions, Parse_Name(p));
                }
            } while (Parser_Match(p, TK_BAR));

            Parser_Expect(p, TK_ARROW);
            Parse_Statement_Sequence(p, &handler->handler.statements);

            Node_List_Push(&node->subprogram_body.handlers, handler);
        }
    }

    Parser_Expect(p, TK_END);
    if (spec and (Parser_At(p, TK_IDENTIFIER) or Parser_At(p, TK_STRING))) {
        /* Check end name - handle both identifier and operator string */
        Parser_Check_End_Name(p, spec->subprogram_spec.name);
    }

    return node;
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §9.14 Package Declarations and Bodies
 * ═══════════════════════════════════════════════════════════════════════════
 */

static Syntax_Node *Parse_Package_Specification(Parser *p) {
    /* Note: caller must consume TK_PACKAGE before calling */
    Source_Location loc = Parser_Location(p);

    Syntax_Node *node = Node_New(NK_PACKAGE_SPEC, loc);
    node->package_spec.name = Parser_Identifier(p);

    Parser_Expect(p, TK_IS);

    /* Visible declarations */
    Parse_Declarative_Part(p, &node->package_spec.visible_decls);

    /* Private part */
    if (Parser_Match(p, TK_PRIVATE)) {
        Parse_Declarative_Part(p, &node->package_spec.private_decls);
    }

    Parser_Expect(p, TK_END);
    if (Parser_At(p, TK_IDENTIFIER)) {
        Parser_Check_End_Name(p, node->package_spec.name);
    }

    return node;
}

static Syntax_Node *Parse_Package_Body(Parser *p) {
    /* Note: caller must consume TK_PACKAGE and TK_BODY before calling */
    Source_Location loc = Parser_Location(p);

    Syntax_Node *node = Node_New(NK_PACKAGE_BODY, loc);
    node->package_body.name = Parser_Identifier(p);

    Parser_Expect(p, TK_IS);

    /* Check for SEPARATE */
    if (Parser_Match(p, TK_SEPARATE)) {
        node->package_body.is_separate = true;
        return node;
    }

    Parse_Declarative_Part(p, &node->package_body.declarations);

    if (Parser_Match(p, TK_BEGIN)) {
        Parse_Statement_Sequence(p, &node->package_body.statements);

        if (Parser_Match(p, TK_EXCEPTION)) {
            while (Parser_At(p, TK_WHEN)) {
                Source_Location h_loc = Parser_Location(p);
                Parser_Advance(p);

                Syntax_Node *handler = Node_New(NK_EXCEPTION_HANDLER, h_loc);

                do {
                    if (Parser_Match(p, TK_OTHERS)) {
                        Node_List_Push(&handler->handler.exceptions, Node_New(NK_OTHERS, h_loc));
                    } else {
                        Node_List_Push(&handler->handler.exceptions, Parse_Name(p));
                    }
                } while (Parser_Match(p, TK_BAR));

                Parser_Expect(p, TK_ARROW);
                Parse_Statement_Sequence(p, &handler->handler.statements);

                Node_List_Push(&node->package_body.handlers, handler);
            }
        }
    }

    Parser_Expect(p, TK_END);
    if (Parser_At(p, TK_IDENTIFIER)) {
        Parser_Check_End_Name(p, node->package_body.name);
    }

    return node;
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §9.15 Generic Units
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * Generics are templates where instantiation means substitution with type checking.
 */

static void Parse_Generic_Formal_Part(Parser *p, Node_List *formals) {
    while (not Parser_At(p, TK_PROCEDURE) and not Parser_At(p, TK_FUNCTION) and
           not Parser_At(p, TK_PACKAGE) and not Parser_At(p, TK_EOF)) {

        if (not Parser_Check_Progress(p)) break;

        Source_Location loc = Parser_Location(p);

        /* Generic type formal: type T[(discriminants)] is private | type T is (<>) | etc */
        if (Parser_Match(p, TK_TYPE)) {
            Syntax_Node *formal = Node_New(NK_GENERIC_TYPE_PARAM, loc);

            /* Parse type name */
            formal->generic_type_param.name = Parser_Identifier(p);

            /* Parse optional discriminant part: (discriminant_spec {; discriminant_spec}) */
            if (Parser_Match(p, TK_LPAREN)) {
                /* Skip discriminant specifications until closing paren */
                int depth = 1;
                while (depth > 0 and not Parser_At(p, TK_EOF)) {
                    if (Parser_At(p, TK_LPAREN)) depth++;
                    else if (Parser_At(p, TK_RPAREN)) depth--;
                    if (depth > 0) Parser_Advance(p);
                }
                Parser_Expect(p, TK_RPAREN);
            }

            Parser_Expect(p, TK_IS);

            /* Parse type definition form */
            if (Parser_Match(p, TK_LIMITED)) {
                Parser_Expect(p, TK_PRIVATE);
                formal->generic_type_param.def_kind = GEN_DEF_LIMITED_PRIVATE;
            } else if (Parser_Match(p, TK_PRIVATE)) {
                formal->generic_type_param.def_kind = GEN_DEF_PRIVATE;
            } else if (Parser_Match(p, TK_LPAREN)) {
                /* (<>) for discrete types */
                Parser_Expect(p, TK_BOX);
                Parser_Expect(p, TK_RPAREN);
                formal->generic_type_param.def_kind = GEN_DEF_DISCRETE;
            } else if (Parser_Match(p, TK_RANGE)) {
                /* range <> for integer types */
                Parser_Expect(p, TK_BOX);
                formal->generic_type_param.def_kind = GEN_DEF_INTEGER;
            } else if (Parser_Match(p, TK_DIGITS)) {
                /* digits <> for float types */
                Parser_Expect(p, TK_BOX);
                formal->generic_type_param.def_kind = GEN_DEF_FLOAT;
            } else if (Parser_Match(p, TK_DELTA)) {
                /* delta <> for fixed types */
                Parser_Expect(p, TK_BOX);
                formal->generic_type_param.def_kind = GEN_DEF_FIXED;
            } else if (Parser_Match(p, TK_ARRAY)) {
                /* array (index {, index}) of element_type for array types */
                formal->generic_type_param.def_kind = GEN_DEF_ARRAY;
                Parser_Expect(p, TK_LPAREN);
                /* Parse index subtypes: subtype_mark [RANGE <>] or discrete_range */
                do {
                    Parse_Name(p);  /* index subtype mark */
                    if (Parser_Match(p, TK_RANGE)) {
                        if (Parser_At(p, TK_BOX)) {
                            Parser_Advance(p);  /* <> for unconstrained */
                        } else {
                            /* subtype_mark RANGE low..high (constrained) */
                            Parse_Expression(p);  /* low */
                            Parser_Expect(p, TK_DOTDOT);
                            Parse_Expression(p);  /* high */
                        }
                    }
                    /* else: just a subtype mark as index (constrained) */
                } while (Parser_Match(p, TK_COMMA));
                Parser_Expect(p, TK_RPAREN);
                Parser_Expect(p, TK_OF);
                formal->generic_type_param.def_detail = Parse_Subtype_Indication(p);
            } else if (Parser_Match(p, TK_ACCESS)) {
                /* access type_name for access types */
                formal->generic_type_param.def_kind = GEN_DEF_ACCESS;
                formal->generic_type_param.def_detail = Parse_Subtype_Indication(p);
            } else if (Parser_At(p, TK_NEW)) {
                /* new parent_type for derived types - skip NEW, parse parent */
                Parser_Advance(p);
                formal->generic_type_param.def_kind = GEN_DEF_DERIVED;
                formal->generic_type_param.def_detail = Parse_Subtype_Indication(p);
            } else {
                /* Unknown form - error recovery: skip to semicolon */
                Report_Error(formal->location, "unrecognized generic type definition form");
                formal->generic_type_param.def_kind = GEN_DEF_PRIVATE;
                while (not Parser_At(p, TK_SEMICOLON) and not Parser_At(p, TK_EOF)) {
                    Parser_Advance(p);
                }
            }

            Node_List_Push(formals, formal);
            Parser_Expect(p, TK_SEMICOLON);
            continue;
        }

        /* Generic object formal: identifier_list : [mode] type [:= default] */
        if (Parser_At(p, TK_IDENTIFIER)) {
            Syntax_Node *formal = Node_New(NK_GENERIC_OBJECT_PARAM, loc);

            /* Parse identifier list */
            do {
                Syntax_Node *id = Node_New(NK_IDENTIFIER, Parser_Location(p));
                id->string_val.text = Parser_Identifier(p);
                Node_List_Push(&formal->generic_object_param.names, id);
            } while (Parser_Match(p, TK_COMMA));

            Parser_Expect(p, TK_COLON);

            /* Parse mode: IN (default), OUT, or IN OUT */
            formal->generic_object_param.mode = GEN_MODE_IN;
            if (Parser_Match(p, TK_IN)) {
                if (Parser_Match(p, TK_OUT)) {
                    formal->generic_object_param.mode = GEN_MODE_IN_OUT;
                } else {
                    formal->generic_object_param.mode = GEN_MODE_IN;
                }
            } else if (Parser_Match(p, TK_OUT)) {
                formal->generic_object_param.mode = GEN_MODE_OUT;
            }

            /* Parse subtype mark */
            formal->generic_object_param.object_type = Parse_Subtype_Indication(p);

            /* Parse optional default expression */
            if (Parser_Match(p, TK_ASSIGN)) {
                formal->generic_object_param.default_expr = Parse_Expression(p);
            }

            Node_List_Push(formals, formal);
            Parser_Expect(p, TK_SEMICOLON);
            continue;
        }

        /* Generic subprogram formal: WITH PROCEDURE/FUNCTION spec [IS name | IS <>] */
        if (Parser_At(p, TK_WITH)) {
            Parser_Advance(p);  /* consume WITH */
            Syntax_Node *formal = Node_New(NK_GENERIC_SUBPROGRAM_PARAM, loc);

            if (Parser_Match(p, TK_PROCEDURE)) {
                formal->generic_subprog_param.is_function = false;
                formal->generic_subprog_param.name = Parser_Identifier(p);

                /* Optional parameters */
                if (Parser_At(p, TK_LPAREN)) {
                    Parse_Parameter_List(p, &formal->generic_subprog_param.parameters);
                }
            } else if (Parser_Match(p, TK_FUNCTION)) {
                formal->generic_subprog_param.is_function = true;

                /* Function name - can be identifier or operator string */
                if (Parser_At(p, TK_STRING)) {
                    formal->generic_subprog_param.name = Slice_Duplicate(p->current_token.text);
                    Parser_Advance(p);
                } else {
                    formal->generic_subprog_param.name = Parser_Identifier(p);
                }

                /* Optional parameters */
                if (Parser_At(p, TK_LPAREN)) {
                    Parse_Parameter_List(p, &formal->generic_subprog_param.parameters);
                }

                /* Return type */
                Parser_Expect(p, TK_RETURN);
                formal->generic_subprog_param.return_type = Parse_Name(p);
            }

            /* Optional default: IS name | IS <> */
            if (Parser_Match(p, TK_IS)) {
                if (Parser_Match(p, TK_BOX)) {
                    /* IS <> means any matching subprogram */
                    formal->generic_subprog_param.default_box = true;
                } else {
                    /* IS name means default to that subprogram */
                    formal->generic_subprog_param.default_name = Parse_Name(p);
                }
            }

            Node_List_Push(formals, formal);
            Parser_Expect(p, TK_SEMICOLON);
            continue;
        }

        break;
    }
}

static Syntax_Node *Parse_Generic_Declaration(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_GENERIC);

    Syntax_Node *node = Node_New(NK_GENERIC_DECL, loc);
    Parse_Generic_Formal_Part(p, &node->generic_decl.formals);

    /* The actual unit */
    if (Parser_At(p, TK_PROCEDURE)) {
        node->generic_decl.unit = Parse_Procedure_Specification(p);
    } else if (Parser_At(p, TK_FUNCTION)) {
        node->generic_decl.unit = Parse_Function_Specification(p);
    } else if (Parser_At(p, TK_PACKAGE)) {
        Parser_Advance(p);  /* consume PACKAGE */
        node->generic_decl.unit = Parse_Package_Specification(p);
    } else {
        Report_Error(node->location, "expected PROCEDURE, FUNCTION, or PACKAGE after generic formals");
    }

    return node;
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §9.16 Use and With Clauses
 * ═══════════════════════════════════════════════════════════════════════════
 */

static Syntax_Node *Parse_Use_Clause(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_USE);

    Syntax_Node *node = Node_New(NK_USE_CLAUSE, loc);

    do {
        Node_List_Push(&node->use_clause.names, Parse_Name(p));
    } while (Parser_Match(p, TK_COMMA));

    return node;
}

static Syntax_Node *Parse_With_Clause(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_WITH);

    Syntax_Node *node = Node_New(NK_WITH_CLAUSE, loc);

    do {
        Node_List_Push(&node->use_clause.names, Parse_Name(p));
    } while (Parser_Match(p, TK_COMMA));

    return node;
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §9.19 Representation Clauses
 * ═══════════════════════════════════════════════════════════════════════════
 */

static Syntax_Node *Parse_Representation_Clause(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Parser_Expect(p, TK_FOR);

    Syntax_Node *node = Node_New(NK_REPRESENTATION_CLAUSE, loc);

    /* Parse: FOR entity_name'attribute USE expression;
     *    or: FOR type_name USE RECORD ... END RECORD;
     *    or: FOR type_name USE (enum_rep_list);
     *    or: FOR object_name USE AT address; */

    /* Parse entity name (possibly qualified: T or T'ATTRIBUTE).
     * Parse_Name may consume the tick+attribute, producing NK_ATTRIBUTE. */
    node->rep_clause.entity_name = Parse_Name(p);

    /* If Parse_Name already consumed T'SIZE, decompose the NK_ATTRIBUTE
     * so rep_clause.entity_name = T (the prefix) and .attribute = SIZE */
    if (node->rep_clause.entity_name and
        node->rep_clause.entity_name->kind == NK_ATTRIBUTE) {
        Syntax_Node *attr_node = node->rep_clause.entity_name;
        node->rep_clause.attribute = attr_node->attribute.name;
        node->rep_clause.entity_name = attr_node->attribute.prefix;
    } else if (Parser_At(p, TK_TICK)) {
        /* Fallback: tick not consumed by Parse_Name */
        Parser_Advance(p);
        if (Parser_At(p, TK_IDENTIFIER)) {
            node->rep_clause.attribute = p->current_token.text;
            Parser_Advance(p);
        }
    }

    Parser_Expect(p, TK_USE);

    /* Check for different representation clause forms */
    if (Parser_Match(p, TK_RECORD)) {
        /* Record representation clause: FOR T USE RECORD ... END RECORD; */
        node->rep_clause.is_record_rep = true;

        /* Parse optional alignment: AT MOD alignment; */
        if (Parser_Match(p, TK_AT)) {
            Parser_Expect(p, TK_MOD);
            node->rep_clause.expression = Parse_Expression(p);
            Parser_Expect(p, TK_SEMICOLON);
        }

        /* Parse component clauses: component_name AT position RANGE first_bit..last_bit; */
        while (not Parser_At(p, TK_END) and not Parser_At(p, TK_EOF)) {
            Syntax_Node *comp_clause = Node_New(NK_ASSOCIATION, Parser_Location(p));
            Node_List_Push(&comp_clause->association.choices, Parse_Name(p));
            Parser_Expect(p, TK_AT);
            comp_clause->association.expression = Parse_Expression(p);
            /* Optional RANGE clause */
            if (Parser_Match(p, TK_RANGE)) {
                /* bit_range is now part of the expression */
                Parse_Range(p);  /* first_bit .. last_bit */
            }
            Parser_Expect(p, TK_SEMICOLON);
            Node_List_Push(&node->rep_clause.component_clauses, comp_clause);
        }
        Parser_Expect(p, TK_END);
        Parser_Expect(p, TK_RECORD);
    } else if (Parser_At(p, TK_LPAREN)) {
        /* Enumeration representation: FOR T USE (A => 0, B => 1, ...); */
        node->rep_clause.is_enum_rep = true;
        Parser_Advance(p);  /* consume ( */
        Parse_Association_List(p, &node->rep_clause.component_clauses);
        Parser_Expect(p, TK_RPAREN);
    } else if (Parser_Match(p, TK_AT)) {
        /* Address clause: FOR X USE AT address; */
        node->rep_clause.expression = Parse_Expression(p);
    } else {
        /* Attribute value: FOR T'SIZE USE 32; */
        node->rep_clause.expression = Parse_Expression(p);
    }

    return node;
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §9.20 Declaration Dispatch
 * ═══════════════════════════════════════════════════════════════════════════
 */

static Syntax_Node *Parse_Declaration(Parser *p) {
    Source_Location loc = Parser_Location(p);

    /* Generic */
    if (Parser_At(p, TK_GENERIC)) {
        Syntax_Node *generic = Parse_Generic_Declaration(p);
        Parser_Expect(p, TK_SEMICOLON);
        return generic;
    }

    /* Procedure/Function - could be spec, body, or generic instantiation */
    if (Parser_At(p, TK_PROCEDURE) or Parser_At(p, TK_FUNCTION)) {
        Token_Kind kind = p->current_token.kind;
        Parser_Advance(p);  /* consume PROCEDURE/FUNCTION */

        /* Get the name - can be identifier or operator string for functions */
        String_Slice name;
        if (Parser_At(p, TK_STRING)) {
            name = Slice_Duplicate(p->current_token.text);
            Parser_Advance(p);
        } else {
            name = Parser_Identifier(p);
        }

        /* Check for generic instantiation: NAME IS NEW */
        if (Parser_At(p, TK_IS)) {
            /* Peek ahead to see if it's IS NEW */
            Token saved = p->current_token;
            Lexer saved_lexer = p->lexer;
            Parser_Advance(p);  /* consume IS */

            if (Parser_At(p, TK_NEW)) {
                Parser_Advance(p);  /* consume NEW */

                /* Create generic instantiation node */
                Syntax_Node *node = Node_New(NK_GENERIC_INST, loc);
                node->generic_inst.unit_kind = kind;
                node->generic_inst.instance_name = name;

                /* Parse the generic unit name */
                node->generic_inst.generic_name = Parse_Simple_Name(p);

                /* Generic actuals */
                if (Parser_Match(p, TK_LPAREN)) {
                    Parse_Association_List(p, &node->generic_inst.actuals);
                    Parser_Expect(p, TK_RPAREN);
                }

                Parser_Expect(p, TK_SEMICOLON);
                return node;
            }

            /* Not IS NEW - restore and parse as spec/body */
            p->current_token = saved;
            p->lexer = saved_lexer;
        }

        /* Parse parameters (if any) - Parse_Parameter_List handles the parens */
        Node_List params = {0};
        if (Parser_At(p, TK_LPAREN)) {
            Parse_Parameter_List(p, &params);
        }

        /* Create the spec node */
        Syntax_Node *spec = Node_New(kind == TK_PROCEDURE ? NK_PROCEDURE_SPEC : NK_FUNCTION_SPEC, loc);
        spec->subprogram_spec.name = name;
        spec->subprogram_spec.parameters = params;

        /* For functions, parse return type */
        if (kind == TK_FUNCTION) {
            Parser_Expect(p, TK_RETURN);
            spec->subprogram_spec.return_type = Parse_Name(p);
        }

        /* Check for subprogram renaming: PROCEDURE P RENAMES Q; or FUNCTION F RENAMES G; */
        if (Parser_Match(p, TK_RENAMES)) {
            spec->kind = NK_SUBPROGRAM_RENAMING;
            spec->subprogram_spec.renamed = Parse_Name(p);
            Parser_Expect(p, TK_SEMICOLON);
            return spec;
        }

        /* Check for body or just spec */
        if (Parser_At(p, TK_IS)) {
            Syntax_Node *body = Parse_Subprogram_Body(p, spec);
            Parser_Expect(p, TK_SEMICOLON);
            return body;
        }

        /* Just a specification */
        Parser_Expect(p, TK_SEMICOLON);
        return spec;
    }

    /* Package */
    if (Parser_At(p, TK_PACKAGE)) {
        Parser_Advance(p);  /* consume PACKAGE */
        if (Parser_At(p, TK_BODY)) {
            Parser_Advance(p);  /* consume BODY */
            Syntax_Node *body = Parse_Package_Body(p);
            Parser_Expect(p, TK_SEMICOLON);
            return body;
        }
        /* Check for package renaming: PACKAGE name RENAMES old_name; */
        String_Slice pkg_name = Parser_Identifier(p);
        if (Parser_Match(p, TK_RENAMES)) {
            Syntax_Node *node = Node_New(NK_PACKAGE_RENAMING, loc);
            node->package_renaming.new_name = pkg_name;
            node->package_renaming.old_name = Parse_Name(p);
            Parser_Expect(p, TK_SEMICOLON);
            return node;
        }

        Parser_Expect(p, TK_IS);

        /* Check for generic instantiation: PACKAGE name IS NEW generic_name */
        if (Parser_Match(p, TK_NEW)) {
            Syntax_Node *node = Node_New(NK_GENERIC_INST, loc);
            node->generic_inst.unit_kind = TK_PACKAGE;
            node->generic_inst.instance_name = pkg_name;

            /* Parse the generic unit name */
            node->generic_inst.generic_name = Parse_Simple_Name(p);

            /* Generic actuals */
            if (Parser_Match(p, TK_LPAREN)) {
                Parse_Association_List(p, &node->generic_inst.actuals);
                Parser_Expect(p, TK_RPAREN);
            }

            Parser_Expect(p, TK_SEMICOLON);
            return node;
        }

        /* Not a generic instantiation - parse as specification */
        Syntax_Node *spec = Node_New(NK_PACKAGE_SPEC, loc);
        spec->package_spec.name = pkg_name;
        /* Parse visible declarations (each declaration consumes its own semicolon) */
        while (not Parser_At(p, TK_PRIVATE) and not Parser_At(p, TK_END) and not Parser_At(p, TK_EOF)) {
            if (not Parser_Check_Progress(p)) break;
            Syntax_Node *decl = Parse_Declaration(p);
            Node_List_Push(&spec->package_spec.visible_decls, decl);
        }
        /* Parse private declarations */
        if (Parser_Match(p, TK_PRIVATE)) {
            while (not Parser_At(p, TK_END) and not Parser_At(p, TK_EOF)) {
                if (not Parser_Check_Progress(p)) break;
                Syntax_Node *decl = Parse_Declaration(p);
                Node_List_Push(&spec->package_spec.private_decls, decl);
            }
        }
        Parser_Expect(p, TK_END);
        if (Parser_At(p, TK_IDENTIFIER)) {
            Parser_Check_End_Name(p, spec->package_spec.name);
        }
        Parser_Expect(p, TK_SEMICOLON);
        return spec;
    }

    /* Task declaration */
    if (Parser_At(p, TK_TASK)) {
        Parser_Advance(p);  /* consume TASK */

        /* TASK BODY name IS ... */
        if (Parser_At(p, TK_BODY)) {
            Parser_Advance(p);  /* consume BODY */
            Source_Location t_loc = Parser_Location(p);
            Syntax_Node *node = Node_New(NK_TASK_BODY, t_loc);
            node->task_body.name = Parser_Identifier(p);
            Parser_Expect(p, TK_IS);

            if (Parser_Match(p, TK_SEPARATE)) {
                node->task_body.is_separate = true;
                Parser_Expect(p, TK_SEMICOLON);
                return node;
            }

            Parse_Declarative_Part(p, &node->task_body.declarations);
            Parser_Expect(p, TK_BEGIN);
            Parse_Statement_Sequence(p, &node->task_body.statements);

            if (Parser_Match(p, TK_EXCEPTION)) {
                while (Parser_At(p, TK_WHEN)) {
                    Source_Location h_loc = Parser_Location(p);
                    Parser_Advance(p);

                    Syntax_Node *handler = Node_New(NK_EXCEPTION_HANDLER, h_loc);
                    do {
                        if (Parser_Match(p, TK_OTHERS)) {
                            Node_List_Push(&handler->handler.exceptions, Node_New(NK_OTHERS, h_loc));
                        } else {
                            Node_List_Push(&handler->handler.exceptions, Parse_Name(p));
                        }
                    } while (Parser_Match(p, TK_BAR));

                    Parser_Expect(p, TK_ARROW);
                    Parse_Statement_Sequence(p, &handler->handler.statements);
                    Node_List_Push(&node->task_body.handlers, handler);
                }
            }

            Parser_Expect(p, TK_END);
            if (Parser_At(p, TK_IDENTIFIER)) {
                Parser_Check_End_Name(p, node->task_body.name);
            }
            Parser_Expect(p, TK_SEMICOLON);
            return node;
        }

        /* TASK [TYPE] name [IS ... END name]; */
        bool is_type = Parser_Match(p, TK_TYPE);
        Source_Location t_loc = Parser_Location(p);
        Syntax_Node *node = Node_New(NK_TASK_SPEC, t_loc);
        node->task_spec.name = Parser_Identifier(p);
        node->task_spec.is_type = is_type;

        if (Parser_Match(p, TK_IS)) {
            /* Task spec with entries */
            while (not Parser_At(p, TK_END) and not Parser_At(p, TK_EOF)) {
                if (not Parser_Check_Progress(p)) break;

                if (Parser_Match(p, TK_ENTRY)) {
                    Source_Location e_loc = Parser_Location(p);
                    Syntax_Node *entry = Node_New(NK_ENTRY_DECL, e_loc);
                    entry->entry_decl.name = Parser_Identifier(p);

                    /* Entry may have family index: ENTRY name(index)
                     * and/or parameters: ENTRY name(...) or ENTRY name(index)(...)
                     * Family index is a discrete_subtype_definition (like 1..10)
                     * Parameters start with identifier : mode type */
                    if (Parser_At(p, TK_LPAREN)) {
                        /* Check if this is an entry family index or parameter list
                         * Entry family: (discrete_range) like (1..10) or (T'RANGE)
                         * Parameters: (id : mode type) - starts with identifier followed by : */
                        Token saved = p->current_token;
                        Lexer saved_lexer = p->lexer;
                        Parser_Advance(p);  /* consume ( for lookahead */

                        bool is_family_index = false;
                        if (not Parser_At(p, TK_IDENTIFIER)) {
                            /* Not starting with identifier - must be family index */
                            is_family_index = true;
                        } else {
                            /* Look ahead to see if it's id : (parameter) or just id (family) */
                            Token saved2 = p->current_token;
                            Lexer saved_lexer2 = p->lexer;
                            Parser_Advance(p);  /* past identifier */
                            is_family_index = not Parser_At(p, TK_COLON) and not Parser_At(p, TK_COMMA);
                            p->current_token = saved2;
                            p->lexer = saved_lexer2;
                        }

                        if (is_family_index) {
                            /* Parse discrete subtype definition - already past ( */
                            Syntax_Node *range = Parse_Range(p);
                            Node_List_Push(&entry->entry_decl.index_constraints, range);
                            Parser_Expect(p, TK_RPAREN);

                            /* Optionally parse parameters after family index */
                            if (Parser_At(p, TK_LPAREN)) {
                                Parse_Parameter_List(p, &entry->entry_decl.parameters);
                            }
                        } else {
                            /* Restore and use Parse_Parameter_List which handles ( ) */
                            p->current_token = saved;
                            p->lexer = saved_lexer;
                            Parse_Parameter_List(p, &entry->entry_decl.parameters);
                        }
                    }
                    Parser_Expect(p, TK_SEMICOLON);
                    Node_List_Push(&node->task_spec.entries, entry);
                } else if (Parser_At(p, TK_PRAGMA)) {
                    Node_List_Push(&node->task_spec.entries, Parse_Pragma(p));
                    Parser_Expect(p, TK_SEMICOLON);
                } else if (Parser_At(p, TK_FOR)) {
                    /* Representation clause in task spec */
                    Node_List_Push(&node->task_spec.entries, Parse_Representation_Clause(p));
                    Parser_Expect(p, TK_SEMICOLON);
                } else {
                    Parser_Error(p, "expected ENTRY, PRAGMA, FOR, or END in task spec");
                    Parser_Advance(p);
                }
            }
            Parser_Expect(p, TK_END);
            if (Parser_At(p, TK_IDENTIFIER)) {
                Parser_Check_End_Name(p, node->task_spec.name);
            }
        }

        Parser_Expect(p, TK_SEMICOLON);
        return node;
    }

    /* Type declaration */
    if (Parser_At(p, TK_TYPE)) {
        Syntax_Node *type_decl = Parse_Type_Declaration(p);
        /* Incomplete type declaration (no definition, not private/limited) already consumed semicolon */
        if (type_decl->type_decl.definition or type_decl->type_decl.is_private or
            type_decl->type_decl.is_limited) {
            Parser_Expect(p, TK_SEMICOLON);
        }
        return type_decl;
    }

    /* Subtype declaration */
    if (Parser_At(p, TK_SUBTYPE)) {
        Syntax_Node *subtype = Parse_Subtype_Declaration(p);
        Parser_Expect(p, TK_SEMICOLON);
        return subtype;
    }

    /* Use clause */
    if (Parser_At(p, TK_USE)) {
        Syntax_Node *use = Parse_Use_Clause(p);
        Parser_Expect(p, TK_SEMICOLON);
        return use;
    }

    /* Pragma */
    if (Parser_At(p, TK_PRAGMA)) {
        Syntax_Node *pragma = Parse_Pragma(p);
        Parser_Expect(p, TK_SEMICOLON);
        return pragma;
    }

    /* FOR representation clause */
    if (Parser_At(p, TK_FOR)) {
        Syntax_Node *rep = Parse_Representation_Clause(p);
        Parser_Expect(p, TK_SEMICOLON);
        return rep;
    }

    /* Object or exception declaration */
    if (Parser_At(p, TK_IDENTIFIER)) {
        Syntax_Node *obj = Parse_Object_Declaration(p);
        Parser_Expect(p, TK_SEMICOLON);
        return obj;
    }

    Parser_Error(p, "expected declaration");
    Parser_Synchronize(p);
    return Node_New(NK_NULL_STMT, loc);
}

static void Parse_Declarative_Part(Parser *p, Node_List *list) {
    while (not Parser_At(p, TK_BEGIN) and not Parser_At(p, TK_END) and
           not Parser_At(p, TK_PRIVATE) and not Parser_At(p, TK_EOF)) {

        if (not Parser_Check_Progress(p)) break;

        Syntax_Node *decl = Parse_Declaration(p);
        Node_List_Push(list, decl);
        /* Each declaration now consumes its own trailing semicolon */
    }
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §9.21 Compilation Unit
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * WITH establishes dependencies while USE imports names into the current namespace.
 */

static Syntax_Node *Parse_Context_Clause(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Syntax_Node *node = Node_New(NK_CONTEXT_CLAUSE, loc);

    while (Parser_At(p, TK_WITH) or Parser_At(p, TK_USE) or Parser_At(p, TK_PRAGMA)) {
        if (Parser_At(p, TK_WITH)) {
            Node_List_Push(&node->context.with_clauses, Parse_With_Clause(p));
            Parser_Expect(p, TK_SEMICOLON);
        } else if (Parser_At(p, TK_USE)) {
            Node_List_Push(&node->context.use_clauses, Parse_Use_Clause(p));
            Parser_Expect(p, TK_SEMICOLON);
        } else if (Parser_At(p, TK_PRAGMA)) {
            Parse_Pragma(p);  /* Configuration pragmas */
            Parser_Expect(p, TK_SEMICOLON);
        }
    }

    return node;
}

static Syntax_Node *Parse_Compilation_Unit(Parser *p) {
    Source_Location loc = Parser_Location(p);
    Syntax_Node *node = Node_New(NK_COMPILATION_UNIT, loc);

    node->compilation_unit.context = Parse_Context_Clause(p);

    /* Handle trailing pragmas at end of file (no more library units) */
    if (Parser_At(p, TK_EOF)) {
        node->compilation_unit.unit = NULL;
        return node;
    }

    /* Separate unit */
    if (Parser_Match(p, TK_SEPARATE)) {
        Parser_Expect(p, TK_LPAREN);
        node->compilation_unit.separate_parent = Parse_Name(p);
        Parser_Expect(p, TK_RPAREN);
        /* Parse the actual subunit below */
    }

    /* Main unit - Parse_Declaration now consumes its trailing semicolon */
    node->compilation_unit.unit = Parse_Declaration(p);

    return node;
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §10. TYPE SYSTEM — Ada Type Semantics
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * A type combines name, range, and representation as three orthogonal concerns.
 *
 * INVARIANT: All sizes are stored in BYTES, not bits.
 */

/* ─────────────────────────────────────────────────────────────────────────
 * §10.1 Type Kinds
 * ───────────────────────────────────────────────────────────────────────── */

typedef enum {
    TYPE_UNKNOWN = 0,

    /* Scalar types */
    TYPE_BOOLEAN,
    TYPE_CHARACTER,
    TYPE_INTEGER,
    TYPE_MODULAR,
    TYPE_ENUMERATION,
    TYPE_FLOAT,
    TYPE_FIXED,

    /* Composite types */
    TYPE_ARRAY,
    TYPE_RECORD,
    TYPE_STRING,      /* Special case of array */

    /* Access types */
    TYPE_ACCESS,

    /* Special types */
    TYPE_UNIVERSAL_INTEGER,
    TYPE_UNIVERSAL_REAL,
    TYPE_TASK,
    TYPE_SUBPROGRAM,  /* For formal subprogram parameters */
    TYPE_PRIVATE,
    TYPE_LIMITED_PRIVATE,
    TYPE_INCOMPLETE,
    TYPE_PACKAGE,     /* For package namespaces */

    TYPE_COUNT
} Type_Kind;

/* ─────────────────────────────────────────────────────────────────────────
 * §10.2 Type Information Structure
 *
 * Each type has:
 * - Kind and name
 * - Size and alignment (in BYTES)
 * - Bounds for scalars
 * - Component info for composites
 * ───────────────────────────────────────────────────────────────────────── */

typedef struct Type_Info Type_Info;
typedef struct Symbol Symbol;

/* ─────────────────────────────────────────────────────────────────────────
 * Runtime Check Bit Constants (GNAT-style, RM 11.5)
 *
 * Each bit controls a check category that can be independently suppressed
 * via pragma Suppress(Check_Name).  Stored in Type_Info.suppressed_checks
 * and Symbol.suppressed_checks as a bitmask.
 * ───────────────────────────────────────────────────────────────────────── */
#define CHK_RANGE          ((uint32_t)1)
#define CHK_OVERFLOW       ((uint32_t)2)
#define CHK_INDEX          ((uint32_t)4)
#define CHK_LENGTH         ((uint32_t)8)
#define CHK_DIVISION       ((uint32_t)16)
#define CHK_ACCESS         ((uint32_t)32)
#define CHK_DISCRIMINANT   ((uint32_t)64)
#define CHK_ELABORATION    ((uint32_t)128)
#define CHK_STORAGE        ((uint32_t)256)
#define CHK_ALL            ((uint32_t)0xFFFFFFFF)

/* Bound representation: explicit tagged union to avoid bitcast.
 * int_value is int128_t to support i128/u128 ranges (mod 2**128).
 * Values that fit in 64 bits are implicitly widened on assignment. */
typedef struct {
    enum { BOUND_NONE, BOUND_INTEGER, BOUND_FLOAT, BOUND_EXPR } kind;
    union {
        int128_t     int_value;
        double       float_value;
        Syntax_Node *expr;
    };
} Type_Bound;

/* Variant information for discriminated records (RM 3.7.3) */
typedef struct {
    int64_t  disc_value;         /* Discriminant value selecting this variant */
    bool     is_others;          /* WHEN OTHERS variant */
    uint32_t first_component;    /* Index of first component in this variant */
    uint32_t component_count;    /* Number of components in this variant */
    uint32_t variant_size;       /* Size of this variant's components in bytes */
} Variant_Info;

/* Component information for records */
typedef struct {
    String_Slice  name;
    Type_Info    *component_type;
    uint32_t      byte_offset;
    uint32_t      bit_offset;    /* For representation clauses */
    uint32_t      bit_size;
    Syntax_Node  *default_expr;  /* Default initialization expression (RM 3.7) */
    bool          is_discriminant;   /* True if this is a discriminant (RM 3.7.1) */
    int32_t       variant_index;     /* Which variant this belongs to (-1 = fixed part) */
} Component_Info;

/* Index information for arrays */
typedef struct {
    Type_Info *index_type;
    Type_Bound low_bound;
    Type_Bound high_bound;
} Index_Info;

struct Type_Info {
    Type_Kind    kind;
    String_Slice name;
    Symbol      *defining_symbol;

    /* Size and alignment in BYTES (not bits) */
    uint32_t     size;
    uint32_t     alignment;
    uint32_t     specified_bit_size;  /* Exact 'SIZE from rep clause (0 = not specified) */

    /* Scalar bounds */
    Type_Bound   low_bound;
    Type_Bound   high_bound;
    uint128_t    modulus;        /* For modular types: 0..2^128 */

    /* Base/parent type for subtypes and derived types */
    Type_Info   *base_type;
    Type_Info   *parent_type;    /* For derived types */

    /* Composite type info */
    union {
        struct {  /* TYPE_ARRAY */
            Index_Info *indices;
            uint32_t    index_count;
            Type_Info  *element_type;
            bool        is_constrained;
        } array;

        struct {  /* TYPE_RECORD */
            Component_Info *components;
            uint32_t        component_count;

            /* Discriminant tracking (RM 3.7) */
            uint32_t        discriminant_count;  /* Number of discriminant components */
            bool            has_discriminants;    /* Type has discriminant part */
            bool            all_defaults;         /* All discriminants have defaults (mutable) */
            bool            is_constrained;       /* Object/subtype is constrained */

            /* Variant part tracking (RM 3.7.3) */
            Variant_Info   *variants;
            uint32_t        variant_count;
            uint32_t        variant_offset;       /* Byte offset where variant part begins */
            uint32_t        max_variant_size;     /* Max size across all variants */
            Syntax_Node    *variant_part_node;    /* AST node for variant part */

            /* Discriminant constraint values (for constrained subtypes) */
            int64_t        *disc_constraint_values;  /* Array [discriminant_count] */
            Syntax_Node   **disc_constraint_exprs;   /* Runtime expr nodes (NULL if static) */
            bool            has_disc_constraints;
        } record;

        struct {  /* TYPE_ACCESS */
            Type_Info *designated_type;
            bool       is_access_constant;
        } access;

        struct {  /* TYPE_ENUMERATION */
            String_Slice *literals;
            uint32_t      literal_count;
            int64_t      *rep_values;    /* Optional representation clause values */
        } enumeration;

        struct {  /* TYPE_FIXED */
            double delta;   /* User-specified delta (smallest increment) */
            double small;   /* Implementation small: power of 2 <= delta */
            int    scale;   /* Scale factor: value = mantissa * 2^scale */
        } fixed;

        struct {  /* TYPE_FLOAT */
            int digits;     /* Declared DIGITS value (RM 3.5.7) */
        } flt;
    };

    /* Runtime check suppression */
    uint32_t     suppressed_checks;

    /* Pragma Pack - pack components to minimum size */
    bool         is_packed;

    /* Limited type flag (RM 7.5) - type cannot be copied */
    bool         is_limited;

    /* Freezing status - once frozen, representation cannot change */
    bool         is_frozen;

    /* STORAGE_SIZE specification (RM 13.7.1) — in bits, 0 = unspecified */
    int64_t      storage_size;

    /* Implicitly generated equality function name (set at freeze time) */
    const char  *equality_func_name;

    /* Runtime type elaboration (RM §3.3.1): constrained array types whose
     * bounds are BOUND_EXPR (function calls evaluated at elaboration time).
     * Nonzero ⇒ @__rt_type_<id>_size holds byte size after elaboration.
     * For record types with such components, @__rt_rec_<id>_off<i> holds
     * byte offset of component i and @__rt_rec_<id>_size the total. */
    uint32_t     rt_global_id;
};

/* ─────────────────────────────────────────────────────────────────────────
 * §10.2.1 Frozen Composite Types List
 *
 * Track composite types that need implicit equality operators.
 * These are added during Freeze_Type and processed during code generation.
 * ───────────────────────────────────────────────────────────────────────── */

static Type_Info *Frozen_Composite_Types[256];
static uint32_t   Frozen_Composite_Count = 0;

/* Global list of exception symbols for code generation */
static Symbol    *Exception_Symbols[256];
static uint32_t   Exception_Symbol_Count = 0;

/* ─────────────────────────────────────────────────────────────────────────
 * §10.3 Type Construction
 * ───────────────────────────────────────────────────────────────────────── */

static Type_Info *Type_New(Type_Kind kind, String_Slice name) {
    Type_Info *t = Arena_Allocate(sizeof(Type_Info));
    t->kind = kind;
    t->name = name;
    t->size = Default_Size_Bytes;
    t->alignment = Default_Align_Bytes;
    return t;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §10.4 Type Predicates
 * ───────────────────────────────────────────────────────────────────────── */

static inline bool Type_Is_Scalar(const Type_Info *t) {
    return t and t->kind >= TYPE_BOOLEAN and t->kind <= TYPE_FIXED;
}

static inline bool Type_Is_Discrete(const Type_Info *t) {
    return t and (t->kind == TYPE_BOOLEAN or t->kind == TYPE_CHARACTER or
                 t->kind == TYPE_INTEGER or t->kind == TYPE_MODULAR or
                 t->kind == TYPE_ENUMERATION);
}

static inline bool Type_Is_Numeric(const Type_Info *t) {
    return t and (t->kind == TYPE_INTEGER or t->kind == TYPE_MODULAR or
                 t->kind == TYPE_FLOAT or t->kind == TYPE_FIXED or
                 t->kind == TYPE_UNIVERSAL_INTEGER or t->kind == TYPE_UNIVERSAL_REAL);
}

static inline bool Type_Is_Real(const Type_Info *t) {
    return t and (t->kind == TYPE_FLOAT or t->kind == TYPE_FIXED or
                 t->kind == TYPE_UNIVERSAL_REAL);
}

/* Type uses floating-point LLVM representation (for codegen, not semantic analysis).
 * Fixed-point types are NOT included as they use integer representation. */
static inline bool Type_Is_Float_Representation(const Type_Info *t) {
    return t and (t->kind == TYPE_FLOAT or t->kind == TYPE_UNIVERSAL_REAL);
}

static inline bool Type_Is_Array_Like(const Type_Info *t) {
    return t and (t->kind == TYPE_ARRAY or t->kind == TYPE_STRING);
}

static inline bool Type_Is_Composite(const Type_Info *t) {
    return t and (t->kind == TYPE_ARRAY or t->kind == TYPE_RECORD or
                 t->kind == TYPE_STRING);
}

static inline bool Type_Is_Access(const Type_Info *t) {
    return t and t->kind == TYPE_ACCESS;
}

/* Per GNAT sem_util.ads — systematic predicates for every type class */
static inline bool Type_Is_Record(const Type_Info *t)    { return t and t->kind == TYPE_RECORD; }
static inline bool Type_Is_Task(const Type_Info *t)      { return t and t->kind == TYPE_TASK; }
static inline bool Type_Is_Float(const Type_Info *t)     { return t and t->kind == TYPE_FLOAT; }
static inline bool Type_Is_Fixed_Point(const Type_Info *t) { return t and t->kind == TYPE_FIXED; }

/* Derive LLVM float type string from a Type_Info.
 * Falls back to "double" for UNIVERSAL_REAL or when type info is unavailable. */
static inline const char *Float_Llvm_Type_Of(const Type_Info *t) {
    if (t and t->size > 0)
        return Llvm_Float_Type((uint32_t)To_Bits(t->size));
    return "double";  /* UNIVERSAL_REAL / unknown > 64-bit */
}
/* ─────────────────────────────────────────────────────────────────────────
 * IEEE 754 Named Constants — replaces magic numbers throughout codegen.
 * Single source of truth for float/double structural parameters.
 * ───────────────────────────────────────────────────────────────────────── */
#define IEEE_FLOAT_DIGITS       6
#define IEEE_DOUBLE_DIGITS      15
#define IEEE_FLOAT_MANTISSA     24
#define IEEE_DOUBLE_MANTISSA    53
#define IEEE_FLOAT_EMAX         128
#define IEEE_DOUBLE_EMAX        1024
#define IEEE_FLOAT_EMIN         (-125)
#define IEEE_DOUBLE_EMIN        (-1021)
#define IEEE_MACHINE_RADIX      2
#define IEEE_DOUBLE_MIN_NORMAL  2.2250738585072014e-308   /* 2^(-1022) */
#define IEEE_FLOAT_MIN_NORMAL   1.1754943508222875e-38    /* 2^(-126)  */
#define LOG2_OF_10              3.321928094887362

/* Check whether a float type maps to IEEE single precision.
 * Replaces the ad-hoc `type->size <= 4` test scattered across 13+ sites. */
static inline bool Float_Is_Single(const Type_Info *t) {
    return strcmp(Float_Llvm_Type_Of(t), "float") == 0;
}

/* Resolve effective DIGITS for a float type: uses declared digits if > 0,
 * else defaults from IEEE precision.  Replaces 5 copy-pasted blocks. */
static inline int Float_Effective_Digits(const Type_Info *t) {
    if (t and t->flt.digits > 0) return t->flt.digits;
    return Float_Is_Single(t) ? IEEE_FLOAT_DIGITS : IEEE_DOUBLE_DIGITS;
}

/* Compute model parameters for a floating-point type (RM 3.5.8).
 * mantissa = ceil(DIGITS * log2(10)) + 1
 * emax     = 4 * mantissa
 * Used by MANTISSA, EMAX, EPSILON, SMALL, LARGE attributes. */
static inline void Float_Model_Parameters(const Type_Info *t,
                                           int64_t *out_mantissa, int64_t *out_emax) {
    int digits = Float_Effective_Digits(t);
    int64_t mantissa = (int64_t)ceil(digits * LOG2_OF_10) + 1;
    int64_t emax = 4 * mantissa;
    if (out_mantissa) *out_mantissa = mantissa;
    if (out_emax)     *out_emax = emax;
}

static inline bool Type_Is_Private(const Type_Info *t) {
    return t and (t->kind == TYPE_PRIVATE or t->kind == TYPE_LIMITED_PRIVATE);
}
static inline bool Type_Is_Limited(const Type_Info *t) {
    return t and (t->kind == TYPE_LIMITED_PRIVATE or t->kind == TYPE_TASK);
}
static inline bool Type_Is_Integer_Like(const Type_Info *t) {
    return t and (t->kind == TYPE_INTEGER or t->kind == TYPE_MODULAR);
}
/* Modular types are unsigned in Ada (RM 3.5.4).  This predicate drives
 * codegen choices: zext vs sext, udiv vs sdiv, unsigned comparisons, etc. */
static inline bool Type_Is_Unsigned(const Type_Info *t) {
    return t and t->kind == TYPE_MODULAR;
}
static inline bool Type_Is_Enumeration(const Type_Info *t) {
    return t and t->kind == TYPE_ENUMERATION;
}
static inline bool Type_Is_Boolean(const Type_Info *t) { return t and t->kind == TYPE_BOOLEAN; }
static inline bool Type_Is_Character(const Type_Info *t) { return t and t->kind == TYPE_CHARACTER; }
static inline bool Type_Is_String(const Type_Info *t)  { return t and t->kind == TYPE_STRING; }

/* Needs fat pointer { ptr, { bound, bound } } for unconstrained array or access thereto */
static inline bool Type_Needs_Fat_Pointer(const Type_Info *t) {
    if (not t) return false;
    if (Type_Is_Access(t) and t->access.designated_type)
        return Type_Is_Array_Like(t->access.designated_type) and
               not t->access.designated_type->array.is_constrained;
    return Type_Is_Array_Like(t) and not t->array.is_constrained;
}

/* Check if array type is unconstrained (needs fat pointer representation) */
static inline bool Type_Is_Unconstrained_Array(const Type_Info *t) {
    return t and (t->kind == TYPE_ARRAY or t->kind == TYPE_STRING) and
           not t->array.is_constrained;
}

/* Constrained array: TYPE_ARRAY or TYPE_STRING with static bounds */
static inline bool Type_Is_Constrained_Array(const Type_Info *t) {
    return t and (t->kind == TYPE_ARRAY or t->kind == TYPE_STRING) and
           t->array.is_constrained;
}

/* Universal numeric types: compile-time only, no storage */
static inline bool Type_Is_Universal_Integer(const Type_Info *t) {
    return t and t->kind == TYPE_UNIVERSAL_INTEGER;
}
static inline bool Type_Is_Universal_Real(const Type_Info *t) {
    return t and t->kind == TYPE_UNIVERSAL_REAL;
}
static inline bool Type_Is_Universal(const Type_Info *t) {
    return t and (t->kind == TYPE_UNIVERSAL_INTEGER or
                 t->kind == TYPE_UNIVERSAL_REAL);
}

/* Check if array type has dynamic bounds (BOUND_EXPR) that need runtime access.
 * This includes constrained arrays like ARRAY(1..G) where G is a variable. */
static inline bool Type_Has_Dynamic_Bounds(const Type_Info *t) {
    if (not t or (t->kind != TYPE_ARRAY and t->kind != TYPE_STRING))
        return false;
    if (t->array.index_count == 0)
        return false;
    /* Check if any bound is a runtime expression, either on the array
     * index entry itself or on the index type (e.g., ARRAY(SNI,..)
     * where SNI has dynamic range -N..N). */
    for (uint32_t i = 0; i < t->array.index_count; i++) {
        if (t->array.indices[i].low_bound.kind == BOUND_EXPR or
            t->array.indices[i].high_bound.kind == BOUND_EXPR) {
            return true;
        }
        /* Also check if the index type itself has dynamic bounds */
        Type_Info *idx_ty = t->array.indices[i].index_type;
        if (idx_ty and (idx_ty->low_bound.kind == BOUND_EXPR or
                        idx_ty->high_bound.kind == BOUND_EXPR)) {
            return true;
        }
    }
    return false;
}

/* Check if an expression is a slice (NK_APPLY with NK_RANGE argument).
 * Slices produce fat pointers at runtime even when their declared type
 * is constrained, so they need special handling in comparisons. */
static inline bool Expression_Is_Slice(const Syntax_Node *node) {
    if (not node or node->kind != NK_APPLY) return false;
    for (uint32_t i = 0; i < node->apply.arguments.count; i++) {
        Syntax_Node *arg = node->apply.arguments.items[i];
        if (arg and arg->kind == NK_RANGE) return true;
    }
    return false;
}

/* Check if an expression will produce a fat pointer value at runtime.
 * This centralizes the "src_is_fat_ptr" detection pattern used in assignments
 * and comparisons: STRING, unconstrained arrays, slices, and concatenations
 * all produce fat pointer values { ptr, { bound, bound } }. */
static inline bool Expression_Produces_Fat_Pointer(const Syntax_Node *node,
                                                    const Type_Info *type) {
    /* Operation-specific checks FIRST: these operations always produce fat
     * pointers at runtime regardless of the expression's declared type.
     * E.g., concatenation of two constrained STRINGs still builds { ptr, ptr }. */
    if (node) {
        /* Aggregates return a fat pointer ALLOCA (ptr to { ptr, ptr }),
         * not a loaded { ptr, ptr } value.  Callers that need the value
         * must load from it.  Treat as "not fat" for the extractvalue
         * callers — specific call sites (assignment, etc.) handle the
         * alloca-based fat pointer specially. */
        if (node->kind == NK_AGGREGATE)
            return false;
        /* String literals always produce fat pointers */
        if (node->kind == NK_STRING)
            return true;
        /* Concatenation always returns fat pointer */
        if (node->kind == NK_BINARY_OP and node->binary.op == TK_AMPERSAND)
            return true;
        /* Slices always produce fat pointers even with constrained declared type */
        if (Expression_Is_Slice(node))
            return true;
    }
    /* Identifier-based check: if the node's own type has dynamic bounds or is
     * unconstrained, Generate_Identifier will load it as a fat pointer value. */
    if (node and node->kind == NK_IDENTIFIER and node->type) {
        const Type_Info *nty = node->type;
        if (Type_Has_Dynamic_Bounds(nty) or Type_Is_Unconstrained_Array(nty))
            return true;
    }
    /* Type-based checks: constrained arrays with STATIC bounds are flat allocas.
     * Constrained arrays with DYNAMIC bounds (e.g., STRING(1..F(X))) are stored
     * as fat pointers because their bounds are runtime-determined (RM 3.6.1). */
    if (type and Type_Is_Constrained_Array(type) and not Type_Has_Dynamic_Bounds(type))
        return false;
    if (type and Type_Is_Constrained_Array(type) and Type_Has_Dynamic_Bounds(type))
        return true;
    if (type and (Type_Is_String(type) or Type_Is_Unconstrained_Array(type)))
        return true;
    return false;
}

/* Check if a record field type requires loading as a fat pointer.
 * Unconstrained arrays, dynamic-bound arrays, and unconstrained STRING fields
 * are stored as fat pointers { ptr, { bound, bound } } in records.
 * Constrained STRING subtypes (e.g., STRING(1..6)) are flat arrays. */
static inline bool Type_Needs_Fat_Pointer_Load(const Type_Info *t) {
    if (not t) return false;
    /* Constrained arrays with dynamic bounds still need fat pointer load
     * because their bounds are runtime-determined (e.g., STRING(1..F) in records).
     * Only truly static constrained arrays are flat. */
    if (Type_Is_Constrained_Array(t) and not Type_Has_Dynamic_Bounds(t))
        return false;
    if (Type_Is_String(t)) return true;
    if (t->kind == TYPE_ARRAY and
        (not t->array.is_constrained or Type_Has_Dynamic_Bounds(t)))
        return true;
    return false;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §10.5 Base Type Traversal
 *
 * Per RM 3.3.1: The base type of a type is the ultimate ancestor.
 * For subtypes, follow base_type links; for derived types, follow parent_type.
 * ───────────────────────────────────────────────────────────────────────── */

static Type_Info *Type_Base(Type_Info *t) {
    while (t and t->base_type) t = t->base_type;
    return t;
}

/* Type_Root: Follow both base_type and parent_type chains to find the root
 * ancestor type. This is used for derived type compatibility checking where
 * we need to find the ultimate parent enumeration/integer type. */
static Type_Info *Type_Root(Type_Info *t) {
    while (t) {
        if (t->base_type) {
            t = t->base_type;
        } else if (t->parent_type) {
            t = t->parent_type;
        } else {
            break;
        }
    }
    return t;
}

/*
 * NOTE: Type compatibility checking is consolidated in Type_Covers()
 * defined in §11.6.2 (Overload Resolution section). That function provides
 * coverage checking for:
 * - Same type identity
 * - Universal type compatibility
 * - Base type matching
 * - Array/string structural compatibility
 * - Access type designated type compatibility
 */

/* ─────────────────────────────────────────────────────────────────────────
 * §10.6 Type Freezing
 *
 * Freezing determines the point at which a type's representation is fixed.
 * The compiler must track what the RM permits but the programmer cannot see.
 * Per RM 13.14:
 * - Types are frozen by object declarations, bodies, end of declarative part
 * - Subtypes freeze their base type
 * - Composite types freeze their component types
 * - Once frozen, size/alignment/layout cannot change
 * ───────────────────────────────────────────────────────────────────────── */

/* Forward declaration for Symbol */
typedef struct Symbol Symbol;

/* Freeze a type and all its dependencies
 * Per RM 13.14: When a type is frozen, its representation is fixed */
static void Freeze_Type(Type_Info *t) {
    if (not t or t->is_frozen) return;

    /* Mark as frozen first to prevent infinite recursion */
    t->is_frozen = true;

    /* Freeze base type if present */
    if (t->base_type) {
        Freeze_Type(t->base_type);
    }

    /* Freeze parent type for derived types */
    if (t->parent_type) {
        Freeze_Type(t->parent_type);
    }

    /* Freeze component types for composites */
    switch (t->kind) {
        case TYPE_ARRAY:
        case TYPE_STRING:
            /* Freeze element type */
            if (t->array.element_type) {
                Freeze_Type(t->array.element_type);
            }
            /* Freeze index types */
            for (uint32_t i = 0; i < t->array.index_count; i++) {
                if (t->array.indices[i].index_type) {
                    Freeze_Type(t->array.indices[i].index_type);
                }
            }
            break;

        case TYPE_RECORD:
            /* Freeze all component types */
            for (uint32_t i = 0; i < t->record.component_count; i++) {
                if (t->record.components[i].component_type) {
                    Freeze_Type(t->record.components[i].component_type);
                }
            }
            break;

        case TYPE_ACCESS:
            /* Access type freezing does NOT freeze designated type */
            /* Per RM 13.14: "Freezing an access type does not freeze
               its designated subtype" */
            break;

        default:
            break;
    }

    /* Register composite types for implicit equality function generation
     * Per RM 4.5.2: Equality is predefined for all non-limited types */
    if (Type_Is_Composite(t) and Frozen_Composite_Count < 256) {
        Frozen_Composite_Types[Frozen_Composite_Count++] = t;

        /* Generate a unique function name for this type's equality */
        char *name_buf = Arena_Allocate(64);
        snprintf(name_buf, 64, "_ada_eq_%.*s_%u",
                 (int)(t->name.length > 20 ? 20 : t->name.length),
                 t->name.data,
                 Frozen_Composite_Count);
        t->equality_func_name = name_buf;
    }
}

/* ─────────────────────────────────────────────────────────────────────────
 * §10.7 LLVM Type Mapping
 *
 * The source type is semantic while the target type is representational.
 * ───────────────────────────────────────────────────────────────────────── */

/* Forward declarations for array helpers (defined after Type_Bound_Value) */
static int128_t Type_Bound_Value(Type_Bound b);

/* File-scope map of generic formal>actual types for the current instance
 * being code-generated.  Used by Type_To_Llvm to resolve generic formal
 * types (TYPE_PRIVATE) to their actual types without requiring a
 * Code_Generator parameter. */
static struct {
    uint32_t count;
    struct { String_Slice formal_name; Type_Info *actual_type; } mappings[32];
} g_generic_type_map = {0};

static const char *Type_To_Llvm(Type_Info *t) {
    if (not t) {
        fprintf(stderr, "error: Type_To_Llvm called with NULL type\n");
        return Llvm_Int_Type(64);  /* ERROR path — caller bug */
    }

    /* For private/limited private/incomplete types, resolve through parent_type
     * chain to find the actual representation type (Ada RM 7.4.1, 3.4). */
    if ((Type_Is_Private(t) or t->kind == TYPE_INCOMPLETE) and t->parent_type) {
        return Type_To_Llvm(t->parent_type);
    }
    /* Unresolved private/limited private types without a full view (parent_type).
     * This occurs for generic formal type parameters whose actual type was not
     * propagated through expansion.  Resolve through the current generic
     * instance's actual type mapping (formal_name > actual_type). */
    if (Type_Is_Private(t) and not t->parent_type) {
        if (g_generic_type_map.count > 0 and t->name.data) {
            for (uint32_t i = 0; i < g_generic_type_map.count; i++) {
                if (g_generic_type_map.mappings[i].actual_type and
                    Slice_Equal_Ignore_Case(t->name,
                                            g_generic_type_map.mappings[i].formal_name))
                    return Type_To_Llvm(g_generic_type_map.mappings[i].actual_type);
            }
        }
        return "ptr";
    }

    switch (t->kind) {
        case TYPE_BOOLEAN:    return "i8";  /* Boolean stored as i8, NOT i1 */
        case TYPE_CHARACTER:  return "i8";
        case TYPE_INTEGER:
        case TYPE_MODULAR:
        case TYPE_ENUMERATION:
        case TYPE_UNIVERSAL_INTEGER:
        case TYPE_FIXED:  /* Fixed-point uses scaled integer representation */
            return Llvm_Int_Type((uint32_t)To_Bits(t->size));
        case TYPE_FLOAT:
        case TYPE_UNIVERSAL_REAL:
            return Llvm_Float_Type((uint32_t)To_Bits(t->size));
        case TYPE_ACCESS:
            /* Access to unconstrained array/STRING needs fat pointer representation.
             * GNAT LLVM style: fat pointer is always { ptr, ptr }. */
            if (t->access.designated_type) {
                Type_Info *d = t->access.designated_type;
                if (Type_Is_String(d) or Type_Is_Unconstrained_Array(d)) {
                    return FAT_PTR_TYPE;
                }
            }
            return "ptr";
        case TYPE_RECORD:
        case TYPE_TASK:
            return "ptr";
        case TYPE_ARRAY:
            /* Unconstrained arrays use fat pointers { ptr, ptr } */
            return (t->array.is_constrained) ? "ptr" : FAT_PTR_TYPE;
        case TYPE_STRING:
            /* Unconstrained STRING > fat pointer { ptr, ptr }
             * Constrained STRING (e.g., STRING(1..6)) > ptr to flat array */
            return (t->array.is_constrained) ? "ptr" : FAT_PTR_TYPE;
        default:
            fprintf(stderr, "error: Type_To_Llvm unhandled type kind %d for '%.*s'\n",
                    t->kind, (int)t->name.length, t->name.data);
            return Llvm_Int_Type((uint32_t)To_Bits(t->size));  /* ERROR path — derive from size */
    }
}

/* Like Type_To_Llvm but for function signatures: constrained arrays with
 * dynamic bounds are passed/returned as fat pointers {ptr, ptr}. */
static const char *Type_To_Llvm_Sig(Type_Info *t) {
    if (t and (t->kind == TYPE_ARRAY or t->kind == TYPE_STRING) and
        t->array.is_constrained and Type_Has_Dynamic_Bounds(t))
        return FAT_PTR_TYPE;
    return Type_To_Llvm(t);
}

/* ─────────────────────────────────────────────────────────────────────────
 * §10.8 GNAT LLVM-Style Fat Pointer Type Helpers
 *
 * GNAT LLVM uses native index types for array bounds in fat pointers.
 * Instead of always i64, STRING (indexed by POSITIVE/INTEGER) uses i32,
 * CHARACTER-indexed arrays use i8, etc.
 * ───────────────────────────────────────────────────────────────────────── */

/* Get the native LLVM type for array bounds based on the index type.
 * Every call site MUST supply an actual array/string/access-to-array type. */
static const char *Array_Bound_Llvm_Type(const Type_Info *t) {
    if (not t) {
        fprintf(stderr, "BUG: Array_Bound_Llvm_Type called with NULL\n");
        return STRING_BOUND_TYPE;  /* safety net — default STRING bound type */
    }
    /* Access > designated type */
    if (t->kind == TYPE_ACCESS and t->access.designated_type)
        t = t->access.designated_type;
    /* Private/incomplete > parent */
    if ((Type_Is_Private(t) or t->kind == TYPE_INCOMPLETE) and t->parent_type)
        return Array_Bound_Llvm_Type(t->parent_type);
    /* STRING > derive bound type from index type (POSITIVE > INTEGER).
     * GNAT LLVM style: Bound_Sub_GT from index subtype's base type. */
    if (t->kind == TYPE_STRING) {
        if (t->array.index_count > 0 and t->array.indices and
            t->array.indices[0].index_type) {
            return Type_To_Llvm(t->array.indices[0].index_type);
        }
        return STRING_BOUND_TYPE;  /* pre-init fallback only */
    }
    if (t->kind != TYPE_ARRAY) {
        fprintf(stderr, "BUG: Array_Bound_Llvm_Type: non-array kind %d '%.*s'\n",
                t->kind, (int)t->name.length, t->name.data);
        return STRING_BOUND_TYPE;  /* safety net — default STRING bound type */
    }
    /* Resolve from index_type — GNAT LLVM style: use Bound_Sub_GT.
     * For multi-dimensional arrays, return the WIDEST type across all
     * dimensions to avoid truncating bounds of wider index types.
     * E.g., ARRAY(BOOLEAN, INTEGER RANGE ..) > use i32 not i8. */
    if (t->array.index_count > 0 and t->array.indices and
        t->array.indices[0].index_type) {
        const char *widest = Type_To_Llvm(t->array.indices[0].index_type);
        uint32_t widest_sz = t->array.indices[0].index_type->size;
        for (uint32_t i = 1; i < t->array.index_count; i++) {
            if (t->array.indices[i].index_type and
                t->array.indices[i].index_type->size > widest_sz) {
                widest = Type_To_Llvm(t->array.indices[i].index_type);
                widest_sz = t->array.indices[i].index_type->size;
            }
        }
        return widest;
    }
    /* No index type info — infer from array context.
     * This can happen for dynamically constrained arrays. */
    if (t->array.index_count > 0 and t->array.indices) {
        /* Try to infer from bound values */
        Type_Bound lb = t->array.indices[0].low_bound;
        Type_Bound hb = t->array.indices[0].high_bound;
        if (lb.kind == BOUND_INTEGER and hb.kind == BOUND_INTEGER) {
            /* Static bounds — use minimum width that fits */
            return Llvm_Int_Type(Bits_For_Range(lb.int_value, hb.int_value));
        }
    }
    /* Last resort: INTEGER is the standard index type in Ada 83 */
    fprintf(stderr, "note: Array_Bound_Llvm_Type: no index type for '%.*s'\n",
            (int)t->name.length, t->name.data);
    return STRING_BOUND_TYPE;
}

/* Get the LLVM bounds struct type string for a given bound type.
 * e.g., Bounds_Type_For("i32") > "{ i32, i32 }".
 * Used when allocating/loading/storing the bounds struct behind
 * the second pointer in a { ptr, ptr } fat pointer. */
static const char *Bounds_Type_For(const char *bt) {
    /* GNAT LLVM style: bounds struct uses the NATIVE index type.
     * e.g. Bounds_Type_For("i32") > "{ i32, i32 }"
     * See gnatllvm-arrays-create.adb:586-636.
     * Dispatch by bit width to avoid strcmp chain. */
    if (not bt or bt[0] != 'i') return STRING_BOUNDS_STRUCT;
    int bits = atoi(bt + 1);
    switch (bits) {
        case 8:   return "{ i8, i8 }";
        case 16:  return "{ i16, i16 }";
        case 32:  return "{ i32, i32 }";
        case 64:  return "{ i64, i64 }";
        case 128: return "{ i128, i128 }";
        default:  return STRING_BOUNDS_STRUCT;
    }
}

/* Return the allocation size in bytes for a bounds struct { bt, bt }.
 * Used when allocating bounds on the secondary stack (for returned fat ptrs). */
static int Bounds_Alloc_Size(const char *bt) {
    /* Size = 2 * (bits / 8).  E.g. { i32, i32 } = 8 bytes. */
    if (not bt or bt[0] != 'i') return STRING_BOUNDS_ALLOC;
    int bits = atoi(bt + 1);
    return 2 * (bits / 8);
}


/* ═══════════════════════════════════════════════════════════════════════════
 * §11. SYMBOL TABLE — Scoped Name Resolution
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * The symbol table implements Ada's visibility and overloading rules:
 *
 * - Hierarchical scopes (packages can nest, blocks create new scopes)
 * - Overloading: same name, different parameter profiles
 * - Use clauses: make names directly visible without qualification
 * - Visibility: immediately visible, use-visible, directly visible
 *
 * We use a hash table with chaining and a scope stack for nested contexts.
 * Collisions are inevitable; we make them cheap rather than trying to
 * eliminate them.
 */

/* ─────────────────────────────────────────────────────────────────────────
 * §11.1 Symbol Kinds
 *
 * Eighteen kinds where the RM defines most and the implementation adds two.
 * ───────────────────────────────────────────────────────────────────────── */

typedef enum {
    SYMBOL_UNKNOWN = 0,
    SYMBOL_VARIABLE,
    SYMBOL_CONSTANT,
    SYMBOL_TYPE,
    SYMBOL_SUBTYPE,
    SYMBOL_PROCEDURE,
    SYMBOL_FUNCTION,
    SYMBOL_PARAMETER,
    SYMBOL_PACKAGE,
    SYMBOL_EXCEPTION,
    SYMBOL_LABEL,
    SYMBOL_LOOP,
    SYMBOL_ENTRY,
    SYMBOL_COMPONENT,
    SYMBOL_DISCRIMINANT,
    SYMBOL_LITERAL,      /* Enumeration literal */
    SYMBOL_GENERIC,
    SYMBOL_GENERIC_INSTANCE,
    SYMBOL_COUNT
} Symbol_Kind;

/* ─────────────────────────────────────────────────────────────────────────
 * §11.2 Symbol Structure
 *
 * The symbol table maps names to meanings while the scope stack provides context.
 * ───────────────────────────────────────────────────────────────────────── */

typedef struct Symbol Symbol;
typedef struct Scope Scope;

/* Parameter mode */
typedef enum {
    PARAM_IN = 0,
    PARAM_OUT,
    PARAM_IN_OUT
} Parameter_Mode;

/* Parameter information for subprograms */
typedef struct {
    String_Slice    name;
    Type_Info      *param_type;
    Parameter_Mode  mode;
    Syntax_Node    *default_value;
    struct Symbol  *param_sym;    /* Symbol for this parameter in function body */
} Parameter_Info;

/* Check if parameter mode requires pass-by-reference (OUT or IN OUT) */
static inline bool Param_Is_By_Reference(Parameter_Mode mode) {
    return mode == PARAM_OUT or mode == PARAM_IN_OUT;
}

struct Symbol {
    Symbol_Kind     kind;
    String_Slice    name;
    Source_Location location;

    /* Type information */
    Type_Info      *type;

    /* Scope membership */
    Scope          *defining_scope;
    Symbol         *parent;         /* Enclosing package/subprogram symbol */

    /* Overloading chain */
    Symbol         *next_overload;

    /* Hash table chaining */
    Symbol         *next_in_bucket;

    /* Visibility */
    enum {
        VIS_HIDDEN = 0,
        VIS_IMMEDIATELY_VISIBLE = 1,
        VIS_USE_VISIBLE = 2,
        VIS_DIRECTLY_VISIBLE = 3
    } visibility;

    /* Declaration reference */
    Syntax_Node    *declaration;

    /* Subprogram-specific */
    Parameter_Info *parameters;
    uint32_t        parameter_count;
    Type_Info      *return_type;    /* NULL for procedures */

    /* Package-specific */
    Symbol        **exported;       /* Visible part symbols */
    uint32_t        exported_count;

    /* Unique identifier for mangling */
    uint32_t        unique_id;

    /* Nesting level for static link computation */
    uint32_t        nesting_level;

    /* Frame offset for static link variable access */
    int64_t         frame_offset;

    /* Scope created by this symbol (for functions/procedures) */
    Scope          *scope;

    /* ─────────────────────────────────────────────────────────────────────
     * Pragma Effects
     * ───────────────────────────────────────────────────────────────────── */

    /* pragma Inline */
    bool            is_inline;

    /* pragma Import / Export */
    bool            is_imported;
    bool            is_exported;
    String_Slice    external_name;       /* External linker name */
    String_Slice    link_name;           /* Link section name */
    enum {
        CONVENTION_ADA = 0,
        CONVENTION_C,
        CONVENTION_STDCALL,
        CONVENTION_INTRINSIC,
        CONVENTION_ASSEMBLER
    } convention;

    /* pragma Suppress checks */
    uint32_t        suppressed_checks;   /* Bitmask of suppressed checks */

    /* pragma Unreferenced */
    bool            is_unreferenced;

    /* Code generation flags */
    bool            extern_emitted;      /* Extern declaration already emitted */
    bool            body_emitted;        /* Function/procedure body already emitted */
    bool            is_named_number;     /* Named number (constant without explicit type) */
    bool            is_overloaded;       /* Part of an overload set (needs unique_id suffix) */
    bool            body_claimed;        /* Body has been matched to this spec (for homographs) */
    bool            is_predefined;       /* Predefined operator from STANDARD */
    bool            needs_address_marker; /* Needs @__addr.X global for 'ADDRESS */
    bool            is_identity_function; /* Function body is just RETURN param (can inline) */
    bool            alloca_emitted;      /* Alloca already emitted for this symbol in current fn */

    /* Discriminant constraint (RM 3.7.2) */
    bool            is_disc_constrained;  /* Object has discriminant constraints */

    /* Fat pointer storage: set when variable needs { ptr, ptr } representation.
     * True for unconstrained arrays and constrained arrays with dynamic bounds. */
    bool            needs_fat_ptr_storage;

    /* Derived type operations (RM 3.4) */
    Symbol         *parent_operation;    /* Parent operation that implements this derived op */
    Type_Info      *derived_from_type;   /* The derived type this op is for */

    /* LLVM label ID for SYMBOL_LABEL */
    uint32_t        llvm_label_id;       /* 0 = not yet assigned */
    uint32_t        loop_exit_label_id;  /* EXIT label for named loops */

    /* Entry index within task (for SYMBOL_ENTRY) */
    uint32_t        entry_index;         /* 0-based index for entry matching */

    /* For RENAMES: pointer to the renamed object's AST node */
    Syntax_Node    *renamed_object;

    /* ─────────────────────────────────────────────────────────────────────
     * Generic Support
     * ───────────────────────────────────────────────────────────────────── */

    /* For SYMBOL_GENERIC: the generic template */
    Syntax_Node    *generic_formals;     /* List of NK_GENERIC_*_PARAM nodes */
    Syntax_Node    *generic_unit;        /* The procedure/function/package spec */
    Syntax_Node    *generic_body;        /* Associated body (if found) */

    /* For SYMBOL_GENERIC_INSTANCE: instantiation info */
    Symbol         *generic_template;    /* The SYMBOL_GENERIC being instantiated */
    Symbol         *instantiated_subprogram;  /* The resolved subprogram instance */

    /* Generic formal->actual mapping (array parallel to generic_formals) */
    struct {
        String_Slice formal_name;
        Type_Info   *actual_type;        /* For type formals */
        Symbol      *actual_subprogram;  /* For subprogram formals */
        Syntax_Node *actual_expr;        /* For object formals */
        Token_Kind   builtin_operator;   /* For built-in operators as subprogram actuals */
    } *generic_actuals;
    uint32_t        generic_actual_count;

    /* For generic instances: expanded (cloned) trees with substitutions */
    Syntax_Node    *expanded_spec;       /* Cloned spec with actuals substituted */
    Syntax_Node    *expanded_body;       /* Cloned body with actuals substituted */
};

/* Populate the global type map from a generic instance's actuals.
 * Called when entering a generic instance codegen context so that
 * Type_To_Llvm can resolve formal private types to their actuals. */
static void Set_Generic_Type_Map(Symbol *inst) {
    g_generic_type_map.count = 0;
    if (not inst) return;
    /* Walk up: subprogram inside generic package uses package's actuals */
    Symbol *holder = inst;
    if (holder and not holder->generic_actuals and holder->parent and
        holder->parent->kind == SYMBOL_PACKAGE and holder->parent->generic_actuals)
        holder = holder->parent;
    if (not holder or not holder->generic_actuals) return;
    for (uint32_t i = 0; i < holder->generic_actual_count and i < 32; i++) {
        g_generic_type_map.mappings[i].formal_name =
            holder->generic_actuals[i].formal_name;
        g_generic_type_map.mappings[i].actual_type =
            holder->generic_actuals[i].actual_type;
        g_generic_type_map.count++;
    }
}

/* ─────────────────────────────────────────────────────────────────────────
 * Check_Is_Suppressed — GNAT-style check suppression query (RM 11.5)
 *
 * Consults the suppressed_checks bitmask on:
 *   1. The target type (if provided)
 *   2. The target type's base_type (if different)
 *   3. The symbol (if provided)
 * Returns true if the specified check_bit is suppressed at any level.
 * ───────────────────────────────────────────────────────────────────────── */
static bool Check_Is_Suppressed(Type_Info *type, Symbol *sym, uint32_t check_bit) {
    if (type && (type->suppressed_checks & check_bit)) return true;
    if (type && type->base_type && (type->base_type->suppressed_checks & check_bit)) return true;
    if (sym && (sym->suppressed_checks & check_bit)) return true;
    return false;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §11.3 Scope Structure
 *
 * Each scope has its own hash table with 1024 buckets, which covers most programs.
 * ───────────────────────────────────────────────────────────────────────── */

#define SYMBOL_TABLE_SIZE 1024

struct Scope {
    Symbol  *buckets[SYMBOL_TABLE_SIZE];
    Scope   *parent;
    Symbol  *owner;             /* Package/subprogram owning this scope */
    uint32_t nesting_level;

    /* Linear list of all symbols for enumeration (static link support) */
    Symbol **symbols;
    uint32_t symbol_count;
    uint32_t symbol_capacity;
    int64_t  frame_size;        /* Total size of frame for this scope */

    /* Frame variables propagated from child scopes (DECLARE blocks, loops).
     * Separate from 'symbols' to avoid affecting symbol lookup.
     * Used only for generating frame aliases in nested functions. */
    Symbol **frame_vars;
    uint32_t frame_var_count;
    uint32_t frame_var_capacity;
};

typedef struct {
    Scope   *current_scope;
    Scope   *global_scope;

    /* Predefined types */
    Type_Info *type_boolean;
    Type_Info *type_integer;
    Type_Info *type_float;
    Type_Info *type_character;
    Type_Info *type_string;
    Type_Info *type_duration;
    Type_Info *type_universal_integer;
    Type_Info *type_universal_real;
    Type_Info *type_address;  /* SYSTEM.ADDRESS */

    /* Unique ID counter for symbol mangling */
    uint32_t   next_unique_id;
} Symbol_Manager;

/* ─────────────────────────────────────────────────────────────────────────
 * §11.4 Scope Operations
 *
 * Lexical scoping is a tree; visibility rules turn it into a forest.
 * ───────────────────────────────────────────────────────────────────────── */

static Scope *Scope_New(Scope *parent) {
    Scope *scope = Arena_Allocate(sizeof(Scope));
    scope->parent = parent;
    scope->nesting_level = parent ? parent->nesting_level + 1 : 0;
    /* Inherit frame_size from parent so nested scope variables get unique offsets.
     * This ensures variables in DECLARE blocks don't overlap with outer variables. */
    scope->frame_size = parent ? parent->frame_size : 0;
    return scope;
}


static void Symbol_Manager_Push_Scope(Symbol_Manager *sm, Symbol *owner) {
    Scope *scope = Scope_New(sm->current_scope);
    scope->owner = owner;
    sm->current_scope = scope;
}

static void Symbol_Manager_Pop_Scope(Symbol_Manager *sm) {
    if (sm->current_scope->parent) {
        /* Propagate frame_size up to parent - parent needs to allocate enough
         * space for all variables, including those in nested blocks. */
        if (sm->current_scope->frame_size > sm->current_scope->parent->frame_size) {
            sm->current_scope->parent->frame_size = sm->current_scope->frame_size;
        }
        /* Propagate frame variables from child scope to parent scope.
         * Variables in DECLARE blocks share the enclosing function's frame,
         * so nested functions need frame aliases for ALL variables, not just
         * those in the immediate parent scope. Only skip if this scope IS the
         * function's own body scope (i.e., child->owner->scope == child).
         * We use the separate frame_vars list to avoid polluting symbol lookup. */
        Scope *child = sm->current_scope;
        Scope *parent = child->parent;
        bool is_function_body_scope = (child->owner and
            (child->owner->kind == SYMBOL_FUNCTION or
             child->owner->kind == SYMBOL_PROCEDURE) and
            child->owner->scope == child);
        if (not is_function_body_scope) {
            /* This is a block scope (DECLARE/loop/etc), not a subprogram's own body scope.
             * Propagate its storage-bearing symbols to parent's frame_vars for alias generation. */
            for (uint32_t i = 0; i < child->symbol_count; i++) {
                Symbol *var = child->symbols[i];
                if (var and (var->kind == SYMBOL_VARIABLE or
                            var->kind == SYMBOL_PARAMETER or
                            var->kind == SYMBOL_DISCRIMINANT or
                            (var->kind == SYMBOL_CONSTANT and not var->is_named_number))) {
                    if (parent->frame_var_count >= parent->frame_var_capacity) {
                        parent->frame_var_capacity = parent->frame_var_capacity ? parent->frame_var_capacity * 2 : 32;
                        parent->frame_vars = realloc(parent->frame_vars,
                            parent->frame_var_capacity * sizeof(Symbol *));
                    }
                    parent->frame_vars[parent->frame_var_count++] = var;
                }
            }
            /* Also propagate any frame_vars that were already collected in the child
             * (from even deeper nested scopes). */
            for (uint32_t i = 0; i < child->frame_var_count; i++) {
                if (parent->frame_var_count >= parent->frame_var_capacity) {
                    parent->frame_var_capacity = parent->frame_var_capacity ? parent->frame_var_capacity * 2 : 32;
                    parent->frame_vars = realloc(parent->frame_vars,
                        parent->frame_var_capacity * sizeof(Symbol *));
                }
                parent->frame_vars[parent->frame_var_count++] = child->frame_vars[i];
            }
        }
        sm->current_scope = parent;
    }
}

/* Push an existing scope (used for separate subunits to reuse parent's scope) */
static void Symbol_Manager_Push_Existing_Scope(Symbol_Manager *sm, Scope *scope) {
    if (scope) {
        scope->parent = sm->current_scope;
        sm->current_scope = scope;
    }
}

/* ─────────────────────────────────────────────────────────────────────────
 * §11.5 Symbol Table Operations
 * ───────────────────────────────────────────────────────────────────────── */

static uint32_t Symbol_Hash_Name(String_Slice name) {
    return (uint32_t)(Slice_Hash(name) % SYMBOL_TABLE_SIZE);
}

static Symbol *Symbol_New(Symbol_Kind kind, String_Slice name, Source_Location loc) {
    Symbol *sym = Arena_Allocate(sizeof(Symbol));
    sym->kind = kind;
    sym->name = name;
    sym->location = loc;
    sym->visibility = VIS_IMMEDIATELY_VISIBLE;
    return sym;
}

static void Symbol_Add(Symbol_Manager *sm, Symbol *sym) {
    Scope *scope = sm->current_scope;

    uint32_t hash = Symbol_Hash_Name(sym->name);
    Symbol *existing = scope->buckets[hash];

    /* Check if symbol is already in this bucket (avoid self-cycle) */
    while (existing) {
        if (existing == sym) return;  /* Already added */
        if (existing->defining_scope == scope and
            Slice_Equal_Ignore_Case(existing->name, sym->name)) {
            /* Overloading: add to chain if subprograms or enumeration literals */
            /* Per RM 8.6, enumeration literals are overloadable like functions */
            if ((existing->kind == SYMBOL_PROCEDURE or existing->kind == SYMBOL_FUNCTION or
                 existing->kind == SYMBOL_LITERAL) and
                (sym->kind == SYMBOL_PROCEDURE or sym->kind == SYMBOL_FUNCTION or
                 sym->kind == SYMBOL_LITERAL)) {
                /* Check if sym is already in the overload chain (prevents cycles) */
                Symbol *chain = existing;
                while (chain) {
                    if (chain == sym) return;  /* Already in chain */
                    chain = chain->next_overload;
                }
                /* Only assign unique_id if not already set (symbol may have been
                 * added to another scope already) */
                if (sym->unique_id == 0)
                    sym->unique_id = sm->next_unique_id++;
                sym->is_overloaded = true;
                existing->is_overloaded = true;  /* Mark first decl as overloaded too */
                sym->next_overload = existing->next_overload;
                existing->next_overload = sym;
                sym->parent = scope->owner;
                return;
            }
            /* Allow variable to shadow type with same name (single task declaration).
             * Per RM 9.1, a single task declaration creates both a task type and
             * an anonymous object of that type with the same name. The object
             * shadows the type for normal name lookups. */
            if (sym->kind == SYMBOL_VARIABLE and existing->kind == SYMBOL_TYPE) {
                break;  /* Proceed to add the variable - it will shadow the type */
            }
            /* Deferred constant completion (RM 7.4): update existing symbol's
             * declaration to the full declaration which has the initializer. */
            if (existing->kind == SYMBOL_CONSTANT and sym->kind == SYMBOL_CONSTANT
                and sym->declaration and sym->declaration->kind == NK_OBJECT_DECL
                and sym->declaration->object_decl.init) {
                existing->declaration = sym->declaration;
                if (sym->type) existing->type = sym->type;
                return;
            }
            /* Same symbol already exists at this scope - skip */
            return;
        }
        existing = existing->next_in_bucket;
    }

    /* Only assign unique_id if not already set */
    if (sym->unique_id == 0)
        sym->unique_id = sm->next_unique_id++;
    sym->defining_scope = scope;
    sym->nesting_level = scope->nesting_level;

    sym->next_in_bucket = scope->buckets[hash];
    scope->buckets[hash] = sym;

    /* Set parent to enclosing package/subprogram for nested symbol support */
    sym->parent = scope->owner;

    /* Add to linear symbol list for enumeration (static link support) */
    if (scope->symbol_count >= scope->symbol_capacity) {
        uint32_t new_cap = scope->symbol_capacity ? scope->symbol_capacity * 2 : 16;
        Symbol **new_syms = Arena_Allocate(new_cap * sizeof(Symbol*));
        if (scope->symbols) memcpy(new_syms, scope->symbols, scope->symbol_count * sizeof(Symbol*));
        scope->symbols = new_syms;
        scope->symbol_capacity = new_cap;
    }
    scope->symbols[scope->symbol_count++] = sym;

    /* Track frame offset for variables/parameters/constants/discriminants.
     * Named numbers (is_named_number) have no storage — skip frame allocation
     * so their pre-set frame_offset (e.g. ASCII.DEL=127) is preserved. */
    if ((sym->kind == SYMBOL_VARIABLE or sym->kind == SYMBOL_PARAMETER or
         sym->kind == SYMBOL_CONSTANT or sym->kind == SYMBOL_DISCRIMINANT) and
        not (sym->kind == SYMBOL_CONSTANT and sym->is_named_number)) {
        sym->frame_offset = scope->frame_size;
        uint32_t var_size = sym->type ? sym->type->size : 8;
        /* Fat pointers for dynamic/unconstrained arrays need { ptr, { bound, bound } } */
        if (sym->type and (Type_Has_Dynamic_Bounds(sym->type) or Type_Is_Unconstrained_Array(sym->type))) {
            var_size = FAT_PTR_ALLOC_SIZE;
            sym->needs_fat_ptr_storage = true;
        }
        if (var_size == 0) {
            fprintf(stderr, "warning: variable '%.*s' has zero size, defaulting to 8 bytes\n",
                    (int)sym->name.length, sym->name.data);
            var_size = 8;
        }
        scope->frame_size += var_size;
    }
}

/* Find symbol by name, searching enclosing scopes */
static Symbol *Symbol_Find(Symbol_Manager *sm, String_Slice name) {
    uint32_t hash = Symbol_Hash_Name(name);

    for (Scope *scope = sm->current_scope; scope; scope = scope->parent) {
        for (Symbol *sym = scope->buckets[hash]; sym; sym = sym->next_in_bucket) {
            if (Slice_Equal_Ignore_Case(sym->name, name) and
                sym->visibility >= VIS_IMMEDIATELY_VISIBLE) {
                return sym;
            }
        }
    }

    return NULL;
}

/* Find symbol by name and type (for enumeration literal disambiguation) */
static Symbol *Symbol_Find_By_Type(Symbol_Manager *sm, String_Slice name, Type_Info *expected_type) {
    if (not expected_type) return Symbol_Find(sm, name);
    /* Get base type for matching (handles derived types and constrained subtypes).
     * Follow both parent_type (derived types) and base_type (constrained subtypes). */
    Type_Info *base_expected = expected_type;
    while (base_expected) {
        if (base_expected->parent_type)
            base_expected = base_expected->parent_type;
        else if (base_expected->base_type)
            base_expected = base_expected->base_type;
        else
            break;
    }

    uint32_t hash = Symbol_Hash_Name(name);
    /* Character literals are case-sensitive in Ada (RM 2.6), unlike identifiers.
     * Hash is case-insensitive so char lits with different case share a bucket.
     * Use case-insensitive at bucket level, case-sensitive in overload chain. */
    bool is_char_lit = (name.length >= 1 and name.data[0] == '\'');
    /* Search all scopes for a matching symbol - don't stop at first name match,
     * keep searching if the type doesn't match (for enumeration literal overloading) */
    for (Scope *scope = sm->current_scope; scope; scope = scope->parent) {
        for (Symbol *sym = scope->buckets[hash]; sym; sym = sym->next_in_bucket) {
            if (Slice_Equal_Ignore_Case(sym->name, name) and
                sym->visibility >= VIS_IMMEDIATELY_VISIBLE) {
                /* Search through overload chain (for enumeration literals) */
                for (Symbol *ovl = sym; ovl; ovl = ovl->next_overload) {
                    /* For character literals, require exact case match (RM 2.6) */
                    if (is_char_lit and not Slice_Equal(ovl->name, name)) continue;
                    /* Check if type matches (either directly or via base type) */
                    Type_Info *sym_base = ovl->type;
                    while (sym_base) {
                        if (sym_base->parent_type)
                            sym_base = sym_base->parent_type;
                        else if (sym_base->base_type)
                            sym_base = sym_base->base_type;
                        else
                            break;
                    }
                    if (sym_base == base_expected) {
                        return ovl;
                    }
                }
                /* Type didn't match in this scope - continue to parent scopes */
            }
        }
    }
    return NULL;  /* No matching symbol found */
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §11.6 OVERLOAD RESOLUTION
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * Overload resolution is a two-pass process:
 *
 * 1. Bottom-up pass: Collect all possible interpretations of each identifier
 *    based on visibility rules. Each interpretation is a (Symbol, Type) pair.
 *
 * 2. Top-down pass: Given context type expectations, select the unique valid
 *    interpretation using disambiguation rules.
 *
 * Key concepts:
 * - Interp: Record of (Nam, Typ, Opnd_Typ) representing one interpretation
 * - Covers: Type compatibility test (T1 covers T2 if T2's values are legal for T1)
 * - Disambiguate: Select best interpretation when multiple are valid
 *
 * Per RM 8.6: Overload resolution identifies the unique declaration for each
 * identifier. It fails if no interpretation is valid or if multiple are valid.
 */

/* ─────────────────────────────────────────────────────────────────────────
 * §11.6.1 Interpretation Structure
 *
 * "type Interp is record Nam, Typ, Opnd_Typ..."
 * We store interpretations in a contiguous array during resolution.
 * Sixty-four interpretations suffices since deeper ambiguity signals a pathological program.
 * ───────────────────────────────────────────────────────────────────────── */

#define MAX_INTERPRETATIONS 64

typedef struct {
    Symbol    *nam;           /* The entity (function, procedure, operator) */
    Type_Info *typ;           /* The result type */
    Type_Info *opnd_typ;      /* For comparison ops: operand type for visibility */
    bool       is_universal;  /* True if operands are universal types */
    uint32_t   scope_depth;   /* Nesting level for hiding rules */
} Interpretation;

typedef struct {
    Interpretation items[MAX_INTERPRETATIONS];
    uint32_t       count;
} Interp_List;

/* ─────────────────────────────────────────────────────────────────────────
 * §11.6.2 Type Covering (Compatibility)
 *
 * For example: T1 covers T2 if values of T2 are legal where T1 is expected.
 *
 * Key rules from RM 8.6:
 * - Same type: always covers
 * - Subtypes of same base type: cover each other
 * - Universal types: Universal_Integer covers any integer type, etc.
 * ───────────────────────────────────────────────────────────────────────── */

static bool Type_Covers(Type_Info *expected, Type_Info *actual) {
    /* Null types are permissive (incomplete analysis) */
    if (not expected or not actual) return true;

    /* Same type always covers */
    if (expected == actual) return true;

    /* Universal_Integer covers any discrete type */
    if (Type_Is_Universal_Integer(expected)) return Type_Is_Discrete(actual);
    if (Type_Is_Universal_Integer(actual))   return Type_Is_Discrete(expected);

    /* Universal_Real covers any real type */
    if (Type_Is_Universal_Real(expected)) return Type_Is_Real(actual);
    if (Type_Is_Universal_Real(actual))   return Type_Is_Real(expected);

    /* Same base type covers */
    Type_Info *base_exp = Type_Base(expected);
    Type_Info *base_act = Type_Base(actual);
    if (base_exp == base_act) return true;
    if (base_exp == actual or expected == base_act) return true;

    /* For derived types, check if they share the same root type (RM 3.4).
     * This handles enumeration/integer literals from parent types being
     * compatible with derived types. E.g., if T is new PARENT, then
     * enumeration literal E4 from PARENT is compatible with T. */
    Type_Info *root_exp = Type_Root(expected);
    Type_Info *root_act = Type_Root(actual);
    if (root_exp and root_act and root_exp == root_act) return true;

    /* SYSTEM.ADDRESS compatibility (RM 13.7): all ADDRESS types are interoperable
     * This handles the case where 'ADDRESS attribute returns a built-in ADDRESS
     * type but the target is declared as SYSTEM.ADDRESS from the package */
    if (Slice_Equal_Ignore_Case(expected->name, S("ADDRESS")) and
        Slice_Equal_Ignore_Case(actual->name, S("ADDRESS"))) {
        return true;
    }

    /* Array/string compatibility: same structure */
    if (Type_Is_Array_Like(expected) and Type_Is_Array_Like(actual)) {
        /* STRING is compatible with CHARACTER arrays */
        if (Type_Is_String(expected) or Type_Is_String(actual)) {
            return true;
        }
        /* Arrays with same element type */
        if (expected->array.element_type and actual->array.element_type) {
            return Type_Covers(expected->array.element_type,
                              actual->array.element_type);
        }
        return true;
    }

    /* Access types: check designated type compatibility */
    if (Type_Is_Access(expected) and Type_Is_Access(actual)) {
        if (expected->access.designated_type and actual->access.designated_type) {
            return Type_Covers(expected->access.designated_type,
                              actual->access.designated_type);
        }
        return true;
    }

    /* NULL literal covers any access type */
    if (Type_Is_Access(expected) and not actual) {
        return true;
    }

    /* Enumeration types from generic instantiation: same name means compatible.
     * This handles the case where instantiation creates new type objects
     * that should be compatible with the original generic spec's types. */
    if (Type_Is_Enumeration(expected) and Type_Is_Enumeration(actual) and
        expected->name.data and actual->name.data and
        Slice_Equal_Ignore_Case(expected->name, actual->name)) {
        return true;
    }

    /* Boolean types: both boolean types are always compatible */
    if (Type_Is_Boolean(expected) and Type_Is_Boolean(actual)) {
        return true;
    }

    /* Integer/derived types from generic instantiation: same name means compatible */
    if (expected->kind == TYPE_INTEGER and actual->kind == TYPE_INTEGER and
        expected->name.data and actual->name.data and
        Slice_Equal_Ignore_Case(expected->name, actual->name)) {
        return true;
    }

    /* Float/fixed-point types: same name means compatible (RM 12.3) */
    if (Type_Is_Float(expected) and Type_Is_Float(actual) and
        expected->name.data and actual->name.data and
        Slice_Equal_Ignore_Case(expected->name, actual->name)) {
        return true;
    }
    if (Type_Is_Fixed_Point(expected) and Type_Is_Fixed_Point(actual) and
        expected->name.data and actual->name.data and
        Slice_Equal_Ignore_Case(expected->name, actual->name)) {
        return true;
    }

    /* Character literals as enumeration literals (RM 3.5.1):
     * An enumeration type can define character literals (e.g., TYPE T IS ('A', 'B');).
     * When comparing, CHARACTER type should be compatible with such enumerations.
     * Check by looking for literals that start with single quote. */
    {
        Type_Info *char_type = NULL;
        Type_Info *enum_type = NULL;
        if (Type_Is_Character(expected) and Type_Is_Enumeration(actual)) {
            char_type = expected;
            enum_type = actual;
        } else if (Type_Is_Character(actual) and Type_Is_Enumeration(expected)) {
            char_type = actual;
            enum_type = expected;
        }
        /* Also check derived enumeration types via root */
        if (not enum_type and Type_Is_Character(expected)) {
            Type_Info *act_root = Type_Root(actual);
            if (Type_Is_Enumeration(act_root)) {
                enum_type = act_root;
                char_type = expected;
            }
        }
        if (not enum_type and Type_Is_Character(actual)) {
            Type_Info *exp_root = Type_Root(expected);
            if (Type_Is_Enumeration(exp_root)) {
                enum_type = exp_root;
                char_type = actual;
            }
        }
        if (char_type and enum_type and enum_type->enumeration.literals) {
            /* Check if enum has any character literals */
            for (uint32_t i = 0; i < enum_type->enumeration.literal_count; i++) {
                String_Slice lit = enum_type->enumeration.literals[i];
                if (lit.length > 0 and lit.data[0] == '\'') {
                    return true;  /* Enum has character literals */
                }
            }
        }
    }

    return false;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §11.6.3 Parameter Conformance
 *
 * Check if an argument list matches a subprogram's parameter profile.
 * Per RM 6.4.1: actual parameters must be type conformant with formals.
 * ───────────────────────────────────────────────────────────────────────── */

/* Forward declaration for Resolve_Expression - needed for argument resolution */

typedef struct {
    Type_Info **types;       /* Array of argument types */
    uint32_t    count;       /* Number of arguments */
    String_Slice *names;     /* Named association names (NULL for positional) */
} Argument_Info;

/* Check if arguments match a symbol's parameter profile */
static bool Arguments_Match_Profile(Symbol *sym, Argument_Info *args) {
    if (not sym) return false;

    /* Track which formal parameters are covered by arguments */
    bool *param_covered = Arena_Allocate(sym->parameter_count * sizeof(bool));
    for (uint32_t i = 0; i < sym->parameter_count; i++) {
        param_covered[i] = false;
    }

    /* Check type compatibility for each argument and mark params covered */
    for (uint32_t i = 0; i < args->count; i++) {
        Type_Info *arg_type = args->types[i];
        Type_Info *param_type = NULL;
        uint32_t param_idx = i;

        /* Handle named association */
        if (args->names and args->names[i].data) {
            bool found = false;
            for (uint32_t j = 0; j < sym->parameter_count; j++) {
                if (Slice_Equal_Ignore_Case(sym->parameters[j].name, args->names[i])) {
                    param_type = sym->parameters[j].param_type;
                    param_idx = j;
                    found = true;
                    break;
                }
            }
            if (not found) return false;
        } else {
            /* Positional: use i-th parameter */
            if (i >= sym->parameter_count) return false;
            param_type = sym->parameters[i].param_type;
        }

        /* Mark this parameter as covered */
        if (param_idx < sym->parameter_count) {
            param_covered[param_idx] = true;
        }

        if (not Type_Covers(param_type, arg_type)) {
            return false;
        }
    }

    /* Verify all required parameters (no default value) are covered */
    for (uint32_t i = 0; i < sym->parameter_count; i++) {
        if (not param_covered[i] and not sym->parameters[i].default_value) {
            return false;  /* Required parameter not provided */
        }
    }

    return true;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §11.6.4 Interpretation Collection
 *
 * Gather candidates first, filter later. Visibility determines the set.
 * ───────────────────────────────────────────────────────────────────────── */

/* Collect all visible interpretations of a name */
static void Collect_Interpretations(Symbol_Manager *sm, String_Slice name,
                                    Interp_List *interps) {
    interps->count = 0;
    uint32_t hash = Symbol_Hash_Name(name);

    /* Search all enclosing scopes */
    for (Scope *scope = sm->current_scope; scope; scope = scope->parent) {
        for (Symbol *sym = scope->buckets[hash]; sym; sym = sym->next_in_bucket) {
            if (not Slice_Equal_Ignore_Case(sym->name, name)) continue;
            if (sym->visibility < VIS_IMMEDIATELY_VISIBLE) continue;

            /* Add this interpretation and all overloads */
            Symbol *s = sym;
            while (s and interps->count < MAX_INTERPRETATIONS) {
                /* Check if we already have this interpretation */
                bool duplicate = false;
                for (uint32_t i = 0; i < interps->count; i++) {
                    if (interps->items[i].nam == s) {
                        duplicate = true;
                        break;
                    }
                }

                if (not duplicate) {
                    interps->items[interps->count++] = (Interpretation){
                        .nam = s,
                        .typ = (s->kind == SYMBOL_FUNCTION) ? s->return_type : s->type,
                        .opnd_typ = NULL,
                        .is_universal = false,
                        .scope_depth = scope->nesting_level
                    };
                }

                s = s->next_overload;
            }
        }
    }
}

/* Filter interpretations by argument compatibility */
static void Filter_By_Arguments(Interp_List *interps, Argument_Info *args) {
    uint32_t write_idx = 0;

    for (uint32_t i = 0; i < interps->count; i++) {
        Symbol *sym = interps->items[i].nam;

        /* Non-callable symbols don't filter by arguments */
        if (sym->kind != SYMBOL_FUNCTION and sym->kind != SYMBOL_PROCEDURE) {
            interps->items[write_idx++] = interps->items[i];
            continue;
        }

        /* Keep if arguments match */
        if (Arguments_Match_Profile(sym, args)) {
            interps->items[write_idx++] = interps->items[i];
        }
    }

    interps->count = write_idx;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §11.6.5 Disambiguation
 *
 * Nearer scope, exact type match, and user definitions all take priority.
 * ───────────────────────────────────────────────────────────────────────── */

/* Check if sym1 hides sym2 (user-defined hiding predefined, or inner scope) */
static bool Symbol_Hides(Symbol *sym1, Symbol *sym2) {
    if (not sym1 or not sym2) return false;

    /* User-defined function can hide predefined operator */
    if ((sym1->kind == SYMBOL_FUNCTION or sym1->kind == SYMBOL_PROCEDURE) and
        sym2->nesting_level == 0) {  /* Predefined are at level 0 */
        return true;
    }

    /* Inner scope hides outer scope */
    if (sym1->nesting_level > sym2->nesting_level) {
        return true;
    }

    return false;
}

/* Score an interpretation for preference ranking (higher = better) */
static int32_t Score_Interpretation(Interpretation *interp,
                                    Type_Info *context_type,
                                    Argument_Info *args) {
    int32_t score = 0;
    Symbol *sym = interp->nam;

    /* Prefer non-universal interpretations */
    if (not Type_Is_Universal(interp->typ)) {
        score += 1000;
    }

    /* Prefer exact context type match */
    if (context_type and interp->typ == context_type) {
        score += 500;
    }

    /* Prefer immediately visible over USE-visible (RM 8.4).
     * Derived type operations are immediately visible while parent
     * operations via USE clause are use-visible. */
    if (sym and sym->visibility == VIS_IMMEDIATELY_VISIBLE) {
        score += 200;
    }

    /* Prefer inner scopes (user-defined over predefined) */
    score += (int32_t)(interp->scope_depth * 10);

    /* For functions: prefer exact argument type matches */
    if (sym and (sym->kind == SYMBOL_FUNCTION or sym->kind == SYMBOL_PROCEDURE) and args) {
        for (uint32_t i = 0; i < args->count and i < sym->parameter_count; i++) {
            Type_Info *arg_type = args->types[i];
            Type_Info *param_type = sym->parameters[i].param_type;

            /* Exact match is better than just coverage */
            if (arg_type == param_type) {
                score += 100;
            } else if (Type_Base(arg_type) == Type_Base(param_type)) {
                score += 50;
            }
        }
    }

    return score;
}

/* Select the best interpretation from a list */
static Symbol *Disambiguate(Interp_List *interps, Type_Info *context_type,
                           Argument_Info *args) {
    if (interps->count == 0) return NULL;
    if (interps->count == 1) return interps->items[0].nam;

    /* Score all interpretations */
    int32_t best_score = INT32_MIN;
    Symbol *best = NULL;
    int tied_count = 0;

    for (uint32_t i = 0; i < interps->count; i++) {
        int32_t score = Score_Interpretation(&interps->items[i], context_type, args);

        if (score > best_score) {
            best_score = score;
            best = interps->items[i].nam;
            tied_count = 1;
        } else if (score == best_score) {
            /* Check hiding rules */
            if (Symbol_Hides(interps->items[i].nam, best)) {
                best = interps->items[i].nam;
            } else if (not Symbol_Hides(best, interps->items[i].nam)) {
                tied_count++;
            }
        }
    }

    /* If still tied, check for universal vs specific preference */
    if (tied_count > 1 and context_type) {
        /* Prefer interpretation matching context exactly */
        for (uint32_t i = 0; i < interps->count; i++) {
            if (interps->items[i].typ == context_type) {
                return interps->items[i].nam;
            }
        }

        /* Prefer non-universal */
        for (uint32_t i = 0; i < interps->count; i++) {
            if (not Type_Is_Universal(interps->items[i].typ)) {
                return interps->items[i].nam;
            }
        }
    }

    return best;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §11.6.6 Unified Overload Resolution Entry Point
 *
 * Collect, filter, disambiguate, fail if not unique.
 * ───────────────────────────────────────────────────────────────────────── */

static Symbol *Resolve_Overloaded_Call(Symbol_Manager *sm,
                                       String_Slice name,
                                       Argument_Info *args,
                                       Type_Info *context_type) {
    Interp_List interps;

    /* Phase 1: Collect all visible interpretations */
    Collect_Interpretations(sm, name, &interps);

    if (interps.count == 0) {
        return NULL;  /* No visible interpretation */
    }

    /* Phase 2: Filter by argument compatibility */
    if (args and args->count > 0) {
        Filter_By_Arguments(&interps, args);

        if (interps.count == 0) {
            return NULL;  /* No matching profile */
        }
    }

    /* Phase 3: Apply context type filtering if provided */
    if (context_type and interps.count > 1) {
        uint32_t write_idx = 0;
        for (uint32_t i = 0; i < interps.count; i++) {
            if (Type_Covers(context_type, interps.items[i].typ)) {
                interps.items[write_idx++] = interps.items[i];
            }
        }
        if (write_idx > 0) {
            interps.count = write_idx;
        }
        /* If no matches, keep all for better error reporting */
    }

    /* Phase 4: Disambiguate if multiple interpretations remain */
    return Disambiguate(&interps, context_type, args);
}

/* ─────────────────────────────────────────────────────────────────────────
 * §11.7 Symbol Manager Initialization
 * ───────────────────────────────────────────────────────────────────────── */

static void Symbol_Manager_Init_Predefined(Symbol_Manager *sm) {
    /* Create predefined types */
    sm->type_boolean = Type_New(TYPE_BOOLEAN, S("BOOLEAN"));
    sm->type_boolean->size = 1;
    sm->type_boolean->low_bound = (Type_Bound){BOUND_INTEGER, {.int_value = 0}};
    sm->type_boolean->high_bound = (Type_Bound){BOUND_INTEGER, {.int_value = 1}};

    sm->type_integer = Type_New(TYPE_INTEGER, S("INTEGER"));
    sm->type_integer->size = 4;  /* 32-bit INTEGER — matches GNAT and standard Ada convention */
    sm->type_integer->low_bound = (Type_Bound){BOUND_INTEGER, {.int_value = INT32_MIN}};
    sm->type_integer->high_bound = (Type_Bound){BOUND_INTEGER, {.int_value = INT32_MAX}};

    sm->type_float = Type_New(TYPE_FLOAT, S("FLOAT"));
    sm->type_float->size = 8;  /* double precision */
    sm->type_float->flt.digits = 15;  /* IEEE double: ~15 decimal digits */

    sm->type_character = Type_New(TYPE_CHARACTER, S("CHARACTER"));
    sm->type_character->size = 1;
    sm->type_character->low_bound  = (Type_Bound){ .kind = BOUND_INTEGER, .int_value = 0   };
    sm->type_character->high_bound = (Type_Bound){ .kind = BOUND_INTEGER, .int_value = 127 };

    sm->type_string = Type_New(TYPE_STRING, S("STRING"));
    sm->type_string->size = 16;  /* Fat pointer: ptr + length */
    sm->type_string->array.element_type = sm->type_character;  /* STRING is array of CHARACTER */
    /* STRING's index type is POSITIVE (RM 3.6.3).  Wire it into the type
     * system so Array_Bound_Llvm_Type can derive the bound type from the
     * index, exactly as GNAT LLVM's Bound_Sub_GT is derived from the index
     * subtype's base type (see gnatllvm-arrays-create.adb).
     * NOTE: type_positive is allocated below; we back-patch after it exists. */

    /* DURATION is a predefined fixed-point type for time intervals */
    sm->type_duration = Type_New(TYPE_FIXED, S("DURATION"));
    sm->type_duration->size = 8;  /* 64-bit for high precision */
    sm->type_duration->fixed.delta = 0.00001;  /* 10 microsecond resolution */

    sm->type_universal_integer = Type_New(TYPE_UNIVERSAL_INTEGER, S("universal_integer"));
    sm->type_universal_integer->size = 4;  /* 32 bits — same as INTEGER (RM 3.5.4) */
    sm->type_universal_real = Type_New(TYPE_UNIVERSAL_REAL, S("universal_real"));
    sm->type_universal_real->size = 8;  /* 64 bits / double precision */

    /* Add predefined type symbols to global scope */
    Symbol *sym_boolean = Symbol_New(SYMBOL_TYPE, S("BOOLEAN"), No_Location);
    sym_boolean->type = sm->type_boolean;
    Symbol_Add(sm, sym_boolean);

    Symbol *sym_integer = Symbol_New(SYMBOL_TYPE, S("INTEGER"), No_Location);
    sym_integer->type = sm->type_integer;
    Symbol_Add(sm, sym_integer);

    /* NATURAL is subtype INTEGER range 0..INTEGER'LAST */
    Symbol *sym_natural = Symbol_New(SYMBOL_SUBTYPE, S("NATURAL"), No_Location);
    Type_Info *type_natural = Type_New(TYPE_INTEGER, S("NATURAL"));
    type_natural->base_type = sm->type_integer;
    type_natural->size = sm->type_integer->size;
    type_natural->alignment = sm->type_integer->alignment;
    type_natural->low_bound = (Type_Bound){ .kind = BOUND_INTEGER, .int_value = 0 };
    type_natural->high_bound = sm->type_integer->high_bound;
    sym_natural->type = type_natural;
    Symbol_Add(sm, sym_natural);

    /* POSITIVE is subtype INTEGER range 1..INTEGER'LAST */
    Symbol *sym_positive = Symbol_New(SYMBOL_SUBTYPE, S("POSITIVE"), No_Location);
    Type_Info *type_positive = Type_New(TYPE_INTEGER, S("POSITIVE"));
    type_positive->base_type = sm->type_integer;
    type_positive->size = sm->type_integer->size;
    type_positive->alignment = sm->type_integer->alignment;
    type_positive->low_bound = (Type_Bound){ .kind = BOUND_INTEGER, .int_value = 1 };
    type_positive->high_bound = sm->type_integer->high_bound;
    sym_positive->type = type_positive;
    Symbol_Add(sm, sym_positive);

    /* Back-patch STRING's index type to POSITIVE (deferred from above).
     * This makes Array_Bound_Llvm_Type derive STRING's bound type from
     * POSITIVE's base type (INTEGER), matching GNAT LLVM's Bound_Sub_GT. */
    sm->type_string->array.indices = Arena_Allocate(sizeof(Index_Info));
    sm->type_string->array.index_count = 1;
    sm->type_string->array.indices[0].index_type = type_positive;
    sm->type_string->array.indices[0].low_bound =
        (Type_Bound){ .kind = BOUND_INTEGER, .int_value = 1 };
    sm->type_string->array.indices[0].high_bound =
        sm->type_integer->high_bound;

    Symbol *sym_float = Symbol_New(SYMBOL_TYPE, S("FLOAT"), No_Location);
    sym_float->type = sm->type_float;
    Symbol_Add(sm, sym_float);

    Symbol *sym_duration = Symbol_New(SYMBOL_TYPE, S("DURATION"), No_Location);
    sym_duration->type = sm->type_duration;
    Symbol_Add(sm, sym_duration);

    Symbol *sym_character = Symbol_New(SYMBOL_TYPE, S("CHARACTER"), No_Location);
    sym_character->type = sm->type_character;
    Symbol_Add(sm, sym_character);

    Symbol *sym_string = Symbol_New(SYMBOL_TYPE, S("STRING"), No_Location);
    sym_string->type = sm->type_string;
    Symbol_Add(sm, sym_string);

    /* Boolean literals */
    Symbol *sym_false = Symbol_New(SYMBOL_LITERAL, S("FALSE"), No_Location);
    sym_false->type = sm->type_boolean;
    Symbol_Add(sm, sym_false);

    Symbol *sym_true = Symbol_New(SYMBOL_LITERAL, S("TRUE"), No_Location);
    sym_true->type = sm->type_boolean;
    sym_true->frame_offset = 1;  /* TRUE has position 1 in BOOLEAN (RM 3.5.3) */
    Symbol_Add(sm, sym_true);

    /* Predefined exceptions (RM 11.1) */
    Symbol *sym_constraint_error = Symbol_New(SYMBOL_EXCEPTION, S("CONSTRAINT_ERROR"), No_Location);
    Symbol_Add(sm, sym_constraint_error);

    Symbol *sym_numeric_error = Symbol_New(SYMBOL_EXCEPTION, S("NUMERIC_ERROR"), No_Location);
    Symbol_Add(sm, sym_numeric_error);

    Symbol *sym_program_error = Symbol_New(SYMBOL_EXCEPTION, S("PROGRAM_ERROR"), No_Location);
    Symbol_Add(sm, sym_program_error);

    Symbol *sym_storage_error = Symbol_New(SYMBOL_EXCEPTION, S("STORAGE_ERROR"), No_Location);
    Symbol_Add(sm, sym_storage_error);

    Symbol *sym_tasking_error = Symbol_New(SYMBOL_EXCEPTION, S("TASKING_ERROR"), No_Location);
    Symbol_Add(sm, sym_tasking_error);

    /* SYSTEM.ADDRESS (RM 13.7) - implementation-defined private type
     * In our implementation, ADDRESS is a 64-bit integer type.
     * Bounds cover full i64 range so ptrtoint values always pass checks. */
    sm->type_address = Type_New(TYPE_INTEGER, S("ADDRESS"));
    sm->type_address->size = 8;  /* 64-bit addresses */
    sm->type_address->alignment = 8;
    sm->type_address->low_bound  = (Type_Bound){.kind = BOUND_INTEGER, .int_value = INT64_MIN};
    sm->type_address->high_bound = (Type_Bound){.kind = BOUND_INTEGER, .int_value = INT64_MAX};

    /* STANDARD package (RM 8.6) - the implicit library containing predefined types
     * All visible entities are implicitly declared here */
    Symbol *pkg_standard = Symbol_New(SYMBOL_PACKAGE, S("STANDARD"), No_Location);
    Type_Info *pkg_standard_type = Type_New(TYPE_PACKAGE, S("STANDARD"));
    pkg_standard->type = pkg_standard_type;
    Symbol_Add(sm, pkg_standard);

    /* ASCII package (RM C.3) - predefined character constants
     * In Ada 83, ASCII is a package in STANDARD, always visible */
    Symbol *pkg_ascii = Symbol_New(SYMBOL_PACKAGE, S("ASCII"), No_Location);
    Type_Info *pkg_ascii_type = Type_New(TYPE_PACKAGE, S("ASCII"));
    pkg_ascii->type = pkg_ascii_type;
    pkg_ascii->parent = pkg_standard;  /* Child of STANDARD */
    Symbol_Add(sm, pkg_ascii);

    /* STANDARD exports ASCII */
    pkg_standard->exported = Arena_Allocate(1 * sizeof(Symbol*));
    pkg_standard->exported_count = 1;
    pkg_standard->exported[0] = pkg_ascii;

    /* ASCII control characters and named constants */
    static const struct { const char *name; uint8_t val; } ascii_chars[] = {
        {"NUL",0},{"SOH",1},{"STX",2},{"ETX",3},{"EOT",4},{"ENQ",5},{"ACK",6},{"BEL",7},
        {"BS",8},{"HT",9},{"LF",10},{"VT",11},{"FF",12},{"CR",13},{"SO",14},{"SI",15},
        {"DLE",16},{"DC1",17},{"DC2",18},{"DC3",19},{"DC4",20},{"NAK",21},{"SYN",22},
        {"ETB",23},{"CAN",24},{"EM",25},{"SUB",26},{"ESC",27},{"FS",28},{"GS",29},
        {"RS",30},{"US",31},{"DEL",127},
        /* Named punctuation */
        {"EXCLAM",'!'},{"QUOTATION",'"'},{"SHARP",'#'},{"DOLLAR",'$'},{"PERCENT",'%'},
        {"AMPERSAND",'&'},{"COLON",':'},{"SEMICOLON",';'},{"QUERY",'?'},{"AT_SIGN",'@'},
        {"L_BRACKET",'['},{"BACK_SLASH",'\\'},{"R_BRACKET",']'},{"CIRCUMFLEX",'^'},
        {"UNDERLINE",'_'},{"GRAVE",'`'},{"L_BRACE",'{'},{"BAR",'|'},{"R_BRACE",'}'},
        {"TILDE",'~'},
        /* Lowercase letters */
        {"LC_A",'a'},{"LC_B",'b'},{"LC_C",'c'},{"LC_D",'d'},{"LC_E",'e'},{"LC_F",'f'},
        {"LC_G",'g'},{"LC_H",'h'},{"LC_I",'i'},{"LC_J",'j'},{"LC_K",'k'},{"LC_L",'l'},
        {"LC_M",'m'},{"LC_N",'n'},{"LC_O",'o'},{"LC_P",'p'},{"LC_Q",'q'},{"LC_R",'r'},
        {"LC_S",'s'},{"LC_T",'t'},{"LC_U",'u'},{"LC_V",'v'},{"LC_W",'w'},{"LC_X",'x'},
        {"LC_Y",'y'},{"LC_Z",'z'},
    };
    uint32_t ascii_count = sizeof(ascii_chars) / sizeof(ascii_chars[0]);
    pkg_ascii->exported = Arena_Allocate(ascii_count * sizeof(Symbol*));
    pkg_ascii->exported_count = ascii_count;
    for (uint32_t i = 0; i < ascii_count; i++) {
        String_Slice name = { ascii_chars[i].name, strlen(ascii_chars[i].name) };
        Symbol *ch = Symbol_New(SYMBOL_CONSTANT, name, No_Location);
        ch->type = sm->type_character;
        ch->parent = pkg_ascii;
        ch->frame_offset = ascii_chars[i].val;  /* Store char value */
        ch->is_named_number = true;  /* Treat as compile-time constant */
        Symbol_Add(sm, ch);
        pkg_ascii->exported[i] = ch;
    }

    /* ─────────────────────────────────────────────────────────────────────────
     * Predefined Operators (RM 4.5) — Needed for operator renaming
     *
     * Per LRM 4.5.3-4.5.6, predefined operators exist for all numeric types.
     * We add symbols for these so RENAMES "+" etc. can resolve them.
     * ───────────────────────────────────────────────────────────────────────── */
    static const struct { const char *name; bool is_binary; bool returns_bool; } predef_ops[] = {
        {"+", true, false}, {"-", true, false}, {"*", true, false},
        {"/", true, false}, {"mod", true, false}, {"rem", true, false},
        {"**", true, false}, {"abs", false, false},
        {"=", true, true}, {"/=", true, true},
        {"<", true, true}, {"<=", true, true},
        {">", true, true}, {">=", true, true},
    };
    Type_Info *num_types[] = { sm->type_integer, sm->type_float };
    for (uint32_t ti = 0; ti < 2; ti++) {
        Type_Info *ty = num_types[ti];
        for (uint32_t i = 0; i < sizeof(predef_ops)/sizeof(predef_ops[0]); i++) {
            String_Slice op_name = { predef_ops[i].name, strlen(predef_ops[i].name) };
            Symbol *op_sym = Symbol_New(SYMBOL_FUNCTION, op_name, No_Location);
            op_sym->is_predefined = true;
            op_sym->return_type = predef_ops[i].returns_bool ? sm->type_boolean : ty;
            if (predef_ops[i].is_binary) {
                op_sym->parameter_count = 2;
                op_sym->parameters = Arena_Allocate(2 * sizeof(Parameter_Info));
                op_sym->parameters[0] = (Parameter_Info){S("LEFT"), ty, PARAM_IN, NULL, NULL};
                op_sym->parameters[1] = (Parameter_Info){S("RIGHT"), ty, PARAM_IN, NULL, NULL};
            } else {
                op_sym->parameter_count = 1;
                op_sym->parameters = Arena_Allocate(1 * sizeof(Parameter_Info));
                op_sym->parameters[0] = (Parameter_Info){S("RIGHT"), ty, PARAM_IN, NULL, NULL};
            }
            Symbol_Add(sm, op_sym);
        }
    }
}

static Symbol_Manager *Symbol_Manager_New(void) {
    Symbol_Manager *sm = Arena_Allocate(sizeof(Symbol_Manager));
    sm->global_scope = Scope_New(NULL);
    sm->current_scope = sm->global_scope;
    sm->next_unique_id = 1;
    Symbol_Manager_Init_Predefined(sm);
    return sm;
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §12. SEMANTIC ANALYSIS — Type Checking and Resolution
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * A permissive parser gives the type checker material to work with.
 *
 * Semantic analysis performs:
 * - Name resolution: bind identifiers to symbols
 * - Type checking: verify type compatibility of operations
 * - Overload resolution: select correct subprogram
 * - Constraint checking: verify bounds, indices, etc.
 */

/* ─────────────────────────────────────────────────────────────────────────
 * §12.1 Expression Resolution
 * ───────────────────────────────────────────────────────────────────────── */

static Type_Info *Resolve_Expression(Symbol_Manager *sm, Syntax_Node *node);
static void Resolve_Statement(Symbol_Manager *sm, Syntax_Node *node);

static Type_Info *Resolve_Identifier(Symbol_Manager *sm, Syntax_Node *node) {
    Symbol *sym = Symbol_Find(sm, node->string_val.text);

    if (not sym) {
        Report_Error(node->location, "undefined identifier '%.*s'",
                    node->string_val.text.length, node->string_val.text.data);
        return sm->type_integer;  /* ??? Continue; one error is better than ten. */
    }

    node->symbol = sym;

    /* For parameterless functions, the result type is the return type.
     * In Ada, a function name without parentheses is a valid call. */
    if (sym->kind == SYMBOL_FUNCTION and sym->return_type) {
        node->type = sym->return_type;
        return sym->return_type;
    }

    node->type = sym->type;
    return sym->type;
}

static Type_Info *Resolve_Selected(Symbol_Manager *sm, Syntax_Node *node) {
    /* Resolve prefix first */
    Type_Info *prefix_type = Resolve_Expression(sm, node->selected.prefix);

    /* Strip quotes from operator selectors: P."/=" > P./= (RM 6.1)
     * The parser stores string-form operators with quotes, but
     * the symbol table stores them without quotes. */
    if (node->selected.selector.length >= 3 and
        node->selected.selector.data[0] == '"' and
        node->selected.selector.data[node->selected.selector.length - 1] == '"') {
        node->selected.selector.data += 1;
        node->selected.selector.length -= 2;
    }

    /* Handle .ALL for explicit dereference (RM 4.1) */
    if (Type_Is_Access(prefix_type) and
        Slice_Equal_Ignore_Case(node->selected.selector, S("ALL"))) {
        node->type = prefix_type->access.designated_type;
        return node->type;
    }

    /* Get effective type for record component lookup (handle implicit dereference) */
    Type_Info *record_type = prefix_type;
    if (Type_Is_Access(prefix_type) and Type_Is_Record(prefix_type->access.designated_type)) {
        record_type = prefix_type->access.designated_type;
    }

    if (Type_Is_Record(record_type)) {
        /* Look up component */
        for (uint32_t i = 0; i < record_type->record.component_count; i++) {
            if (Slice_Equal_Ignore_Case(record_type->record.components[i].name,
                                        node->selected.selector)) {
                node->type = record_type->record.components[i].component_type;
                return node->type;
            }
        }
        Report_Error(node->location, "no component '%.*s' in record type",
                    node->selected.selector.length, node->selected.selector.data);
    } else if (Type_Is_Task(prefix_type) or
               (Type_Is_Access(prefix_type) and prefix_type->access.designated_type and
                Type_Is_Task(prefix_type->access.designated_type))) {
        /* Task entry selection: T.E1 where T is a task object (RM 9.5).
         * Also handles P.E1 where P is access-to-task (implicit dereference). */
        Type_Info *task_type = Type_Is_Task(prefix_type) ? prefix_type
                             : prefix_type->access.designated_type;
        Symbol *type_sym = task_type->defining_symbol;
        if (type_sym) {
            for (uint32_t i = 0; i < type_sym->exported_count; i++) {
                if (Slice_Equal_Ignore_Case(type_sym->exported[i]->name,
                                           node->selected.selector)) {
                    node->symbol = type_sym->exported[i];
                    node->type = type_sym->exported[i]->type;
                    return node->type;
                }
            }
        }
        Report_Error(node->location, "no entry '%.*s' in task type",
                    (int)node->selected.selector.length, node->selected.selector.data);
    } else {
        /* Could be qualified name - look up in prefix's exported/visible symbols.
         * Per RM 4.1.3, qualified names can use package, procedure, or function
         * as prefix to access items declared within that scope. */
        Symbol *prefix_sym = node->selected.prefix->symbol;
        if (prefix_sym and prefix_sym->kind == SYMBOL_PACKAGE) {
            /* Search package's exported symbols */
            for (uint32_t i = 0; i < prefix_sym->exported_count; i++) {
                if (Slice_Equal_Ignore_Case(prefix_sym->exported[i]->name,
                                           node->selected.selector)) {
                    node->symbol = prefix_sym->exported[i];
                    /* For function symbols, the expression type is the return
                     * type (RM 4.1.3).  sym->type may be NULL for locally
                     * declared functions where only return_type is set. */
                    Symbol *sel = prefix_sym->exported[i];
                    node->type = (sel->kind == SYMBOL_FUNCTION and sel->return_type)
                                 ? sel->return_type : sel->type;
                    return node->type;
                }
            }
            /* Also search the package's scope for predefined operators and
             * other symbols not explicitly in the exported list (RM 4.1.3).
             * This handles P."/=", P."=", P."<" etc. for predefined operators
             * of types declared in the package. */
            if (prefix_sym->scope) {
                uint32_t hash = Symbol_Hash_Name(node->selected.selector);
                for (Symbol *s = prefix_sym->scope->buckets[hash]; s; s = s->next_in_bucket) {
                    if (Slice_Equal_Ignore_Case(s->name, node->selected.selector) and
                        s->visibility >= VIS_IMMEDIATELY_VISIBLE) {
                        node->symbol = s;
                        node->type = (s->kind == SYMBOL_FUNCTION and s->return_type)
                                     ? s->return_type : s->type;
                        return node->type;
                    }
                }
            }

            /* Inherited enum literals for derived types (RM 3.4(12)).
             * When a package has TYPE T IS NEW BOOLEAN, P.FALSE and P.TRUE
             * must resolve to literals of T. Find a global literal matching
             * the selector name whose type is a parent of some exported type. */
            {
                String_Slice sel = node->selected.selector;
                uint32_t h = Symbol_Hash_Name(sel);
                for (Scope *sc = sm->current_scope; sc; sc = sc->parent) {
                    for (Symbol *lit = sc->buckets[h]; lit; lit = lit->next_in_bucket) {
                        if (lit->kind != SYMBOL_LITERAL) continue;
                        if (!Slice_Equal_Ignore_Case(lit->name, sel)) continue;
                        Type_Info *lit_type = lit->type;
                        if (!lit_type) continue;
                        for (uint32_t i = 0; i < prefix_sym->exported_count; i++) {
                            Symbol *es = prefix_sym->exported[i];
                            if (es->kind != SYMBOL_TYPE and es->kind != SYMBOL_SUBTYPE) continue;
                            Type_Info *et = es->type;
                            if (!et) continue;
                            /* Check if exported type == or derives from literal's type.
                             * Walk both parent_type and base_type chains at each level
                             * to handle anonymous intermediate types. */
                            {
                                Type_Info *anc = et;
                                int depth = 0;
                                while (anc and depth < 20) {
                                    if (anc == lit_type) {
                                        if (anc == et) {
                                            node->symbol = lit;
                                        } else {
                                            Symbol *new_lit = Symbol_New(SYMBOL_LITERAL, sel, No_Location);
                                            new_lit->type = et;
                                            new_lit->frame_offset = lit->frame_offset;
                                            node->symbol = new_lit;
                                        }
                                        node->type = et;
                                        return node->type;
                                    }
                                    /* Try parent_type first, then base_type */
                                    if (anc->parent_type) anc = anc->parent_type;
                                    else if (anc->base_type) anc = anc->base_type;
                                    else break;
                                    depth++;
                                }
                            }
                        }
                    }
                }
            }

            /* Synthesize predefined operators for types declared in the package
             * (RM 4.5). Every type implicitly declares =, /=, and for ordered
             * types also <, <=, >, >=. Numeric types add +, -, *, /, etc.
             * We lazily create these symbols when first referenced via P."op". */
            {
                String_Slice sel = node->selected.selector;
                bool is_comparison = (Slice_Equal_Ignore_Case(sel, S("=")) or
                                      Slice_Equal_Ignore_Case(sel, S("/=")) or
                                      Slice_Equal_Ignore_Case(sel, S("<")) or
                                      Slice_Equal_Ignore_Case(sel, S("<=")) or
                                      Slice_Equal_Ignore_Case(sel, S(">")) or
                                      Slice_Equal_Ignore_Case(sel, S(">=")));
                bool is_logical = (Slice_Equal_Ignore_Case(sel, S("and")) or
                                   Slice_Equal_Ignore_Case(sel, S("or")) or
                                   Slice_Equal_Ignore_Case(sel, S("xor")) or
                                   Slice_Equal_Ignore_Case(sel, S("not")));
                bool is_arith = (Slice_Equal_Ignore_Case(sel, S("+")) or
                                 Slice_Equal_Ignore_Case(sel, S("-")) or
                                 Slice_Equal_Ignore_Case(sel, S("*")) or
                                 Slice_Equal_Ignore_Case(sel, S("/")) or
                                 Slice_Equal_Ignore_Case(sel, S("mod")) or
                                 Slice_Equal_Ignore_Case(sel, S("rem")) or
                                 Slice_Equal_Ignore_Case(sel, S("**")) or
                                 Slice_Equal_Ignore_Case(sel, S("abs")));
                bool is_concat = Slice_Equal_Ignore_Case(sel, S("&"));
                if (is_comparison or is_arith or is_logical or is_concat) {
                    /* Find first type in the package's exports */
                    Type_Info *op_type = NULL;
                    for (uint32_t i = 0; i < prefix_sym->exported_count; i++) {
                        Symbol *es = prefix_sym->exported[i];
                        if (es->kind == SYMBOL_TYPE and es->type) {
                            bool type_ok = false;
                            if (is_comparison) type_ok = true;  /* All types have = /= < etc */
                            else if (is_arith) type_ok = Type_Is_Numeric(es->type);
                            else if (is_logical) type_ok = Type_Is_Boolean(es->type) or
                                    (Type_Is_Array_Like(es->type) and es->type->array.element_type and
                                     Type_Is_Boolean(es->type->array.element_type));
                            else if (is_concat) type_ok = Type_Is_Array_Like(es->type);
                            if (type_ok) { op_type = es->type; break; }
                        }
                    }
                    if (op_type) {
                        bool is_unary = (Slice_Equal_Ignore_Case(sel, S("abs")) or
                                         Slice_Equal_Ignore_Case(sel, S("not")));
                        bool returns_bool = is_comparison;
                        /* Create a synthetic predefined operator symbol */
                        Symbol *op_sym = Symbol_New(SYMBOL_FUNCTION, sel, No_Location);
                        op_sym->is_predefined = true;
                        op_sym->return_type = returns_bool ? sm->type_boolean : op_type;
                        if (is_unary) {
                            op_sym->parameter_count = 1;
                            op_sym->parameters = Arena_Allocate(1 * sizeof(Parameter_Info));
                            op_sym->parameters[0] = (Parameter_Info){S("RIGHT"), op_type, PARAM_IN, NULL, NULL};
                        } else {
                            op_sym->parameter_count = 2;
                            op_sym->parameters = Arena_Allocate(2 * sizeof(Parameter_Info));
                            op_sym->parameters[0] = (Parameter_Info){S("LEFT"), op_type, PARAM_IN, NULL, NULL};
                            op_sym->parameters[1] = (Parameter_Info){S("RIGHT"), op_type, PARAM_IN, NULL, NULL};
                        }
                        /* Install in package scope for future lookups */
                        if (prefix_sym->scope) {
                            uint32_t h = Symbol_Hash_Name(sel);
                            op_sym->defining_scope = prefix_sym->scope;
                            op_sym->next_in_bucket = prefix_sym->scope->buckets[h];
                            prefix_sym->scope->buckets[h] = op_sym;
                        }
                        node->symbol = op_sym;
                        node->type = op_sym->return_type;
                        return node->type;
                    }
                }
            }
        }
        /* For procedure/function prefix, search the subprogram's scope.
         * This handles cases like MAIN.A_B_C where MAIN is a procedure
         * and A_B_C is an enum literal or type declared within it. */
        if (prefix_sym and (prefix_sym->kind == SYMBOL_PROCEDURE or
                          prefix_sym->kind == SYMBOL_FUNCTION) and
            prefix_sym->scope) {
            Scope *subp_scope = prefix_sym->scope;
            uint32_t hash = Symbol_Hash_Name(node->selected.selector);
            for (Symbol *s = subp_scope->buckets[hash]; s; s = s->next_in_bucket) {
                if (Slice_Equal_Ignore_Case(s->name, node->selected.selector) and
                    s->visibility >= VIS_IMMEDIATELY_VISIBLE) {
                    node->symbol = s;
                    node->type = s->type;
                    return node->type;
                }
            }
        }
    }

    Report_Error(node->location, "cannot resolve selected component '%.*s'",
                 (int)node->selected.selector.length, node->selected.selector.data);
    return sm->type_integer;  /* Error recovery */
}

/* Get the operator name string for a token kind */
static String_Slice Operator_Name(Token_Kind op) {
    /* Return bare (unquoted) operator designators.  The lexer strips quotes
     * from operator symbol declarations (RM 6.1), so symbol table entries
     * store bare names like +, mod, **.  Match that convention here. */
    switch (op) {
        case TK_PLUS:      return S("+");
        case TK_MINUS:     return S("-");
        case TK_STAR:      return S("*");
        case TK_SLASH:     return S("/");
        case TK_MOD:       return S("mod");
        case TK_REM:       return S("rem");
        case TK_EXPON:     return S("**");
        case TK_AMPERSAND: return S("&");
        case TK_AND:       return S("and");
        case TK_OR:        return S("or");
        case TK_XOR:       return S("xor");
        case TK_EQ:        return S("=");
        case TK_NE:        return S("/=");
        case TK_LT:        return S("<");
        case TK_LE:        return S("<=");
        case TK_GT:        return S(">");
        case TK_GE:        return S(">=");
        case TK_NOT:       return S("not");
        case TK_ABS:       return S("abs");
        default:           return S("");
    }
}

/* Resolve a character literal as an enumeration literal given a context type.
 * Used for comparisons and assignments where a character literal should be
 * interpreted as an enumeration value. Returns true if resolved. */
static bool Resolve_Char_As_Enum(Symbol_Manager *sm, Syntax_Node *char_node, Type_Info *enum_type) {
    if (not char_node or char_node->kind != NK_CHARACTER or not enum_type)
        return false;
    /* Find base enumeration type by following both parent_type and base_type chains.
     * parent_type is used for derived types (TYPE T IS NEW X)
     * base_type is used for constrained subtypes (SUBTYPE S IS X RANGE ...) */
    Type_Info *base_enum = enum_type;
    while (base_enum) {
        if (base_enum->parent_type)
            base_enum = base_enum->parent_type;
        else if (base_enum->base_type)
            base_enum = base_enum->base_type;
        else
            break;
    }
    if (not base_enum or base_enum->kind != TYPE_ENUMERATION or not base_enum->enumeration.literals)
        return false;
    /* Get the character from the literal (format: 'X') */
    String_Slice lit_text = char_node->string_val.text;
    char ch = lit_text.length >= 2 ? lit_text.data[1] : 0;
    /* Look for matching character literal in enum */
    for (uint32_t j = 0; j < base_enum->enumeration.literal_count; j++) {
        String_Slice lit_name = base_enum->enumeration.literals[j];
        if (lit_name.length == 3 and
            lit_name.data[0] == '\'' and
            lit_name.data[1] == ch and
            lit_name.data[2] == '\'') {
            /* Found matching enum literal - find symbol with matching type */
            Symbol *lit_sym = Symbol_Find_By_Type(sm, lit_name, base_enum);
            if (lit_sym and lit_sym->kind == SYMBOL_LITERAL) {
                char_node->symbol = lit_sym;
                char_node->type = enum_type;
                return true;
            }
        }
    }
    return false;
}

static Type_Info *Resolve_Binary_Op(Symbol_Manager *sm, Syntax_Node *node) {
    Token_Kind op = node->binary.op;
    /* Membership tests (RM 4.4): X IN T, where X can be an aggregate.
     * Resolve type name first, propagate type to left aggregate (RM 4.3.3).
     * Must resolve right BEFORE left so type can propagate to aggregate. */
    if ((op == TK_IN or op == TK_NOT) and node->binary.left->kind == NK_AGGREGATE and
        not node->binary.left->type and node->binary.right) {
        Syntax_Node *type_name = node->binary.right;
        /* Resolve right (type name) first to get its symbol */
        Resolve_Expression(sm, type_name);
        if (type_name->symbol and type_name->symbol->kind == SYMBOL_TYPE)
            node->binary.left->type = type_name->symbol->type;
    }
    /* Resolve left first; then propagate its type to an untyped aggregate
     * on the right BEFORE resolving, so record component choices can be
     * looked up in the correct type (RM 4.3, 4.5.2). */
    Type_Info *left_type = Resolve_Expression(sm, node->binary.left);
    if (node->binary.right->kind == NK_AGGREGATE and not node->binary.right->type and left_type)
        node->binary.right->type = left_type;
    Type_Info *right_type = Resolve_Expression(sm, node->binary.right);

    /*
     * Per RM 4.5: Binary operators can be user-defined. We first check for
     * user-defined operators, then fall back to predefined semantics.
     *
     * User-defined operators are functions with designator names like "+" that
     * take two parameters of the appropriate types.
     */

    /* Try to find a user-defined operator */
    String_Slice op_name = Operator_Name(op);
    if (op_name.length > 0) {
        Type_Info *arg_types[2] = { left_type, right_type };
        Argument_Info args = {
            .types = arg_types,
            .count = 2,
            .names = NULL
        };

        Symbol *user_op = Resolve_Overloaded_Call(sm, op_name, &args, NULL);
        if (user_op and user_op->kind == SYMBOL_FUNCTION) {
            /* Skip predefined operators when either operand is universal:
             * universal types must propagate through arithmetic (RM 4.10).
             * Predefined *(FLOAT,FLOAT)>FLOAT would swallow UNIVERSAL_REAL. */
            if (user_op->is_predefined and
                (Type_Is_Universal(left_type) or Type_Is_Universal(right_type)))
                goto predefined_semantics;
            node->symbol = user_op;
            node->type = user_op->return_type;
            return node->type;
        }
    }

    /* Fall back to predefined operator semantics */
    predefined_semantics:
    switch (op) {
        case TK_PLUS: case TK_MINUS: case TK_STAR: case TK_SLASH:
        case TK_MOD: case TK_REM: case TK_EXPON:
            /* Numeric operators */
            if (not Type_Is_Numeric(left_type) or not Type_Is_Numeric(right_type)) {
                Report_Error(node->location, "numeric operands required for %s",
                            Token_Name[op]);
            }
            /* Result type determination (RM 4.5.5):
             * - Mixed real/integer: result is the real type (real "wins")
             * - Same class: prefer non-universal type
             * - Both universal: keep universal (propagates to context) */
            if (Type_Is_Real(left_type) and not Type_Is_Real(right_type)) {
                /* Left is real, right is integer -> result is left (real) */
                node->type = left_type;
            } else if (Type_Is_Real(right_type) and not Type_Is_Real(left_type)) {
                /* Right is real, left is integer -> result is right (real) */
                node->type = right_type;
            } else if (Type_Is_Universal(left_type) and not Type_Is_Universal(right_type)) {
                node->type = right_type;
            } else if (not Type_Is_Universal(left_type)) {
                node->type = left_type;
            } else {
                /* Both universal - result is universal */
                node->type = left_type;
            }
            break;

        case TK_AMPERSAND:
            /* String/array/character concatenation (RM 4.5.3).
             * Valid operand combinations:
             *   STRING & STRING -> STRING
             *   STRING & CHARACTER -> STRING
             *   CHARACTER & STRING -> STRING
             *   CHARACTER & CHARACTER -> STRING
             *   ARRAY & ARRAY -> ARRAY (same element type)
             *   ARRAY & ELEMENT -> ARRAY
             *   ELEMENT & ARRAY -> ARRAY */
            {
                bool left_ok = Type_Is_Array_Like(left_type) or
                               Type_Is_Character(left_type);
                bool right_ok = Type_Is_Array_Like(right_type) or
                                Type_Is_Character(right_type);
                if (not left_ok and not right_ok) {
                    Report_Error(node->location, "concatenation requires string, array, or character");
                }
                /* Propagate type to aggregate operands (RM 4.3):
                 * In A & (1, 2), the aggregate gets its type from A */
                if (node->binary.right->kind == NK_AGGREGATE and not node->binary.right->type and left_type) {
                    node->binary.right->type = left_type;
                    Resolve_Expression(sm, node->binary.right);
                }
                if (node->binary.left->kind == NK_AGGREGATE and not node->binary.left->type and right_type) {
                    node->binary.left->type = right_type;
                    Resolve_Expression(sm, node->binary.left);
                }
                /* Result type: prefer user-defined array type over predefined STRING.
                 * Per RM 4.5.3, concatenation returns the array type. String literals
                 * are ambiguous and should adopt the context type. */
                if (Type_Is_Array_Like(left_type) and left_type->kind == TYPE_ARRAY) {
                    /* User-defined array type takes precedence */
                    node->type = left_type;
                } else if (Type_Is_Array_Like(right_type) and right_type->kind == TYPE_ARRAY) {
                    node->type = right_type;
                } else if (Type_Is_String(left_type)) {
                    node->type = left_type;
                } else if (Type_Is_String(right_type)) {
                    node->type = right_type;
                } else if (Type_Is_Array_Like(left_type)) {
                    node->type = left_type;
                } else if (Type_Is_Array_Like(right_type)) {
                    node->type = right_type;
                } else {
                    /* CHARACTER & CHARACTER -> STRING */
                    node->type = sm->type_string;
                }
            }
            break;

        case TK_AND: case TK_OR: case TK_XOR:
        case TK_AND_THEN: case TK_OR_ELSE:
            /* Boolean operators - can also operate on arrays of Boolean */
            if (left_type and left_type->kind != TYPE_BOOLEAN) {
                if (left_type->kind != TYPE_ARRAY or
                    not left_type->array.element_type or
                    left_type->array.element_type->kind != TYPE_BOOLEAN) {
                    Report_Error(node->location, "Boolean operands required");
                }
            }
            node->type = left_type ? left_type : sm->type_boolean;
            break;

        case TK_EQ: case TK_NE: case TK_LT: case TK_LE: case TK_GT: case TK_GE:
            /* Comparison operators */
            /* Handle aggregates without type context (RM 4.3):
             * In A = (1, 2, 3), the aggregate gets its type from A.
             * Per GNAT sem_res.adb Find_Unique_Type, propagate type context. */
            if (node->binary.right->kind == NK_AGGREGATE and not node->binary.right->type and left_type) {
                /* Propagate type from left operand to aggregate */
                node->binary.right->type = left_type;
                /* Re-resolve aggregate with proper type context */
                Resolve_Expression(sm, node->binary.right);
                right_type = node->binary.right->type;
            }
            if (node->binary.left->kind == NK_AGGREGATE and not node->binary.left->type and right_type) {
                /* Propagate type from right operand to aggregate */
                node->binary.left->type = right_type;
                /* Re-resolve aggregate with proper type context */
                Resolve_Expression(sm, node->binary.left);
                left_type = node->binary.left->type;
            }
            /* Handle character literals that should be enum literals */
            if (Type_Is_Enumeration(left_type) or
                Type_Is_Enumeration(left_type ? left_type->parent_type : NULL)) {
                if (node->binary.right->kind == NK_CHARACTER) {
                    if (Resolve_Char_As_Enum(sm, node->binary.right, left_type)) {
                        right_type = node->binary.right->type;
                    }
                }
            }
            if (Type_Is_Enumeration(right_type) or
                Type_Is_Enumeration(right_type ? right_type->parent_type : NULL)) {
                if (node->binary.left->kind == NK_CHARACTER) {
                    if (Resolve_Char_As_Enum(sm, node->binary.left, right_type)) {
                        left_type = node->binary.left->type;
                    }
                }
            }
            /* Disambiguate overloaded enum literals using comparison context
             * (RM 8.6): if types mismatch and one operand is a literal, re-resolve
             * it against the other operand's type via Symbol_Find_By_Type. */
            if (not Type_Covers(left_type, right_type) and not Type_Covers(right_type, left_type)) {
                if (node->binary.right->kind == NK_IDENTIFIER and
                    node->binary.right->symbol and
                    node->binary.right->symbol->kind == SYMBOL_LITERAL and left_type) {
                    Symbol *s = Symbol_Find_By_Type(sm,
                        node->binary.right->string_val.text, left_type);
                    if (s) {
                        node->binary.right->symbol = s;
                        node->binary.right->type = s->type ? s->type : left_type;
                        right_type = node->binary.right->type;
                    }
                }
                if (node->binary.left->kind == NK_IDENTIFIER and
                    node->binary.left->symbol and
                    node->binary.left->symbol->kind == SYMBOL_LITERAL and right_type) {
                    Symbol *s = Symbol_Find_By_Type(sm,
                        node->binary.left->string_val.text, right_type);
                    if (s) {
                        node->binary.left->symbol = s;
                        node->binary.left->type = s->type ? s->type : right_type;
                        left_type = node->binary.left->type;
                    }
                }
            }
            if (not Type_Covers(left_type, right_type) and not Type_Covers(right_type, left_type)) {
                Report_Error(node->location, "incompatible types for comparison");
            }
            node->type = sm->type_boolean;
            break;

        case TK_IN:
        case TK_NOT:  /* NOT IN is encoded as TK_NOT in binary op */
            /* Membership test: X IN range.  Per Ada RM 4.5.2, the range
             * is resolved in the context of the tested expression's type.
             * GNAT: Resolve_Membership_Op propagates left type to range. */
            if (left_type and (Type_Is_Enumeration(left_type) or
                (left_type->parent_type and Type_Is_Enumeration(left_type->parent_type)))) {
                Syntax_Node *rhs = node->binary.right;
                if (rhs and rhs->kind == NK_RANGE) {
                    if (rhs->range.low and rhs->range.low->kind == NK_CHARACTER)
                        Resolve_Char_As_Enum(sm, rhs->range.low, left_type);
                    if (rhs->range.high and rhs->range.high->kind == NK_CHARACTER)
                        Resolve_Char_As_Enum(sm, rhs->range.high, left_type);
                }
            }
            node->type = sm->type_boolean;
            break;

        default:
            Report_Error(node->location, "unhandled binary operator in type resolution");
            node->type = sm->type_integer;
    }

    return node->type;
}

static Type_Info *Resolve_Apply(Symbol_Manager *sm, Syntax_Node *node) {
    /*
     * Apply node resolution - handles multiple Ada constructs:
     * 1. Function/procedure calls: Put(X), Process(A, B)
     * 2. Array indexing: Arr(I), Matrix(I, J)
     * 3. Type conversions: Integer(X), Float(Y)
     * 4. Constrained subtype indications: String(1..10)
     *
     * For calls, we use the overload resolution engine to handle:
     * - Overloaded subprogram names
     * - Named parameter associations
     * - Default parameter values
     */

    /* First, resolve all arguments to get their types */
    uint32_t arg_count = (uint32_t)node->apply.arguments.count;
    Type_Info **arg_types = NULL;
    String_Slice *arg_names = NULL;

    if (arg_count > 0) {
        arg_types = Arena_Allocate(arg_count * sizeof(Type_Info*));
        arg_names = Arena_Allocate(arg_count * sizeof(String_Slice));

        for (uint32_t i = 0; i < arg_count; i++) {
            Syntax_Node *arg = node->apply.arguments.items[i];

            /* Handle named associations: Name => Value */
            if (arg->kind == NK_ASSOCIATION and arg->association.choices.count == 1) {
                Syntax_Node *name_node = arg->association.choices.items[0];
                if (name_node->kind == NK_IDENTIFIER) {
                    arg_names[i] = name_node->string_val.text;
                }
                /* Resolve the value expression */
                if (arg->association.expression) {
                    arg_types[i] = Resolve_Expression(sm, arg->association.expression);
                }
            } else {
                arg_names[i] = (String_Slice){0};  /* Positional */
                /* Defer aggregate resolution: aggregates need parameter type
                 * context for record component names (RM 4.3, 6.4). They'll
                 * be resolved after the callable is identified. */
                if (arg->kind == NK_AGGREGATE)
                    arg_types[i] = NULL;
                else
                    arg_types[i] = Resolve_Expression(sm, arg);
            }
        }
    }

    Argument_Info args = {
        .types = arg_types,
        .count = arg_count,
        .names = arg_names
    };

    /* Resolve the prefix */
    Syntax_Node *prefix = node->apply.prefix;
    Symbol *prefix_sym = NULL;

    /* For identifier prefix, use overload resolution */
    if (prefix->kind == NK_IDENTIFIER) {
        prefix_sym = Resolve_Overloaded_Call(sm, prefix->string_val.text, &args, NULL);
        if (prefix_sym) {
            prefix->symbol = prefix_sym;
            prefix->type = (prefix_sym->kind == SYMBOL_FUNCTION) ?
                           prefix_sym->return_type : prefix_sym->type;
        } else {
            /* Fall back to simple lookup for non-callable names */
            prefix_sym = Symbol_Find(sm, prefix->string_val.text);
            if (prefix_sym) {
                prefix->symbol = prefix_sym;
                prefix->type = prefix_sym->type;
            }
        }
    } else {
        /* For complex prefix (selected, etc.), resolve normally */
        Resolve_Expression(sm, prefix);
        prefix_sym = prefix->symbol;
    }

    Type_Info *prefix_type = prefix->type;

    /* Handle based on what the prefix resolves to */
    if (prefix_sym) {

        /* ─── Case 1: Function/Procedure Call ─── */
        /* Only treat as a call if prefix is an identifier referring to a callable.
         * If prefix is a complex expression (e.g., func(...)), it's already resolved
         * and we should check its result type for indexing instead. */
        bool prefix_is_call_target = (prefix->kind == NK_IDENTIFIER or
                                      prefix->kind == NK_SELECTED);
        if (prefix_is_call_target and
            (prefix_sym->kind == SYMBOL_FUNCTION or prefix_sym->kind == SYMBOL_PROCEDURE)) {
            node->symbol = prefix_sym;
            node->type = prefix_sym->return_type;  /* NULL for procedures */
            /* Re-resolve arguments based on parameter types.
             * This handles:
             * - Character literals like FN('A') where 'A' must be resolved as
             *   the enumeration literal for the parameter's type, not ASCII.
             * - Aggregates like FN((1,2,3)) where the aggregate needs the
             *   parameter type to determine its type (RM 4.3). */
            for (uint32_t i = 0; i < arg_count and i < prefix_sym->parameter_count; i++) {
                Syntax_Node *arg = node->apply.arguments.items[i];
                /* Handle named associations */
                if (arg->kind == NK_ASSOCIATION and arg->association.expression) {
                    arg = arg->association.expression;
                }
                Type_Info *param_type = prefix_sym->parameters[i].param_type;
                if (arg->kind == NK_CHARACTER) {
                    Resolve_Char_As_Enum(sm, arg, param_type);
                }
                /* Propagate type to aggregate arguments */
                if (arg->kind == NK_AGGREGATE and not arg->type and param_type) {
                    arg->type = param_type;
                    Resolve_Expression(sm, arg);
                }
            }
            return node->type;
        }

        /* ─── Case 2: Type Conversion or Constrained Subtype ─── */
        if (prefix_sym->kind == SYMBOL_TYPE or prefix_sym->kind == SYMBOL_SUBTYPE) {
            Type_Info *base_type = prefix_sym->type;

            /* Check for constrained subtype indication: STRING(1..5) */
            if (Type_Is_Array_Like(base_type)) {
                /* Check if arguments are ranges (subtype indication) vs values (indexing) */
                bool has_range = false;
                for (uint32_t i = 0; i < arg_count; i++) {
                    Syntax_Node *arg = node->apply.arguments.items[i];
                    if (arg->kind == NK_RANGE) {
                        has_range = true;
                        break;
                    }
                }

                if (has_range) {
                    /* Constrained array/string subtype indication */
                    Type_Info *constrained = Type_New(TYPE_ARRAY, base_type->name);
                    constrained->array.is_constrained = true;
                    constrained->array.index_count = arg_count;

                    /* Element type */
                    if (Type_Is_String(base_type)) {
                        constrained->array.element_type = sm->type_character;
                    } else if (base_type->array.element_type) {
                        constrained->array.element_type = base_type->array.element_type;
                    }

                    /* Process index constraints */
                    if (arg_count > 0) {
                        constrained->array.indices = Arena_Allocate(
                            arg_count * sizeof(Index_Info));

                        for (uint32_t i = 0; i < arg_count; i++) {
                            Syntax_Node *arg = node->apply.arguments.items[i];
                            Index_Info *info = &constrained->array.indices[i];
                            /* Inherit index_type from base type (e.g., POSITIVE for STRING).
                             * This is critical for RM 4.5.3 concatenation length checks. */
                            if (base_type->array.index_count > i and base_type->array.indices[i].index_type) {
                                info->index_type = base_type->array.indices[i].index_type;
                            } else {
                                info->index_type = sm->type_integer;  /* Default fallback */
                            }

                            if (arg->kind == NK_RANGE) {
                                if (arg->range.low and arg->range.low->kind == NK_INTEGER) {
                                    info->low_bound = (Type_Bound){
                                        .kind = BOUND_INTEGER,
                                        .int_value = arg->range.low->integer_lit.value
                                    };
                                }
                                if (arg->range.high and arg->range.high->kind == NK_INTEGER) {
                                    info->high_bound = (Type_Bound){
                                        .kind = BOUND_INTEGER,
                                        .int_value = arg->range.high->integer_lit.value
                                    };
                                }
                            }
                        }

                        /* Compute size - only for fully static bounds */
                        {
                            bool all_static = true;
                            int128_t count = 1;
                            for (uint32_t i = 0; i < arg_count; i++) {
                                Type_Bound *lo_b = &constrained->array.indices[i].low_bound;
                                Type_Bound *hi_b = &constrained->array.indices[i].high_bound;
                                if ((lo_b->kind == BOUND_EXPR and lo_b->expr and lo_b->expr->symbol) or
                                    (hi_b->kind == BOUND_EXPR and hi_b->expr and hi_b->expr->symbol)) {
                                    all_static = false; break;
                                }
                                int128_t lo = Type_Bound_Value(*lo_b);
                                int128_t hi = Type_Bound_Value(*hi_b);
                                int128_t dim = hi - lo + 1;
                                if (dim < 0) dim = 0;
                                count *= dim;
                            }
                            if (not all_static) {
                                constrained->size = 0;
                            } else if (all_static and count >= 0) {
                                uint32_t elem_size = constrained->array.element_type ?
                                                     constrained->array.element_type->size : 1;
                                constrained->size = (uint32_t)(count * elem_size);
                            }
                        }
                    }

                    node->type = constrained;
                    return constrained;
                }
            }

            /* Regular type conversion: Integer(X) */
            if (arg_count == 1) {
                node->type = prefix_sym->type;
                return node->type;
            }
        }
    }

    /* ─── Case 2b: Predefined operator called via string syntax ─── */
    /* Ada allows "+"(X, Y) or "&"(A, B) as equivalent to X + Y or A & B.
     * Handle predefined operators that don't have explicit symbol entries.
     * Note: The lexer strips quotes from operator strings, so "&" becomes just &. */
    if (not prefix_sym and prefix->kind == NK_IDENTIFIER) {
        String_Slice name = prefix->string_val.text;
        /* Check for single-character operators (lexer stripped quotes) */
        if (name.length == 1 and arg_count == 2) {
            char op_char = name.data[0];
            if (op_char == '&') {
                /* "&"(A, B) is array/string concatenation */
                Syntax_Node *left = node->apply.arguments.items[0];
                Syntax_Node *right = node->apply.arguments.items[1];
                Type_Info *left_type = Resolve_Expression(sm, left);
                Type_Info *right_type = Resolve_Expression(sm, right);
                /* Result is the array type (prefer left if array, else right) */
                if (left_type and Type_Is_Array_Like(left_type)) {
                    node->type = left_type;
                } else if (right_type and Type_Is_Array_Like(right_type)) {
                    node->type = right_type;
                } else if (Type_Is_String(left_type)) {
                    node->type = left_type;
                } else if (Type_Is_String(right_type)) {
                    node->type = right_type;
                } else {
                    node->type = sm->type_string;  /* Default for character concat */
                }
                return node->type;
            }
            /* Handle arithmetic operators */
            if (op_char == '+' or op_char == '-' or op_char == '*' or op_char == '/') {
                Syntax_Node *left = node->apply.arguments.items[0];
                Syntax_Node *right = node->apply.arguments.items[1];
                Type_Info *left_type = Resolve_Expression(sm, left);
                Type_Info *right_type = Resolve_Expression(sm, right);
                /* Result is the numeric type (prefer left) */
                node->type = left_type ? left_type : right_type;
                return node->type;
            }
        }
        /* Check for two-character operators like <=, >=, /=, ** */
        if (name.length == 2 and arg_count == 2) {
            if ((name.data[0] == '<' and name.data[1] == '=') or
                (name.data[0] == '>' and name.data[1] == '=') or
                (name.data[0] == '/' and name.data[1] == '=')) {
                /* Comparison operators return BOOLEAN */
                Syntax_Node *left = node->apply.arguments.items[0];
                Syntax_Node *right = node->apply.arguments.items[1];
                Resolve_Expression(sm, left);
                Resolve_Expression(sm, right);
                node->type = sm->type_boolean;
                return node->type;
            }
            if (name.data[0] == '*' and name.data[1] == '*') {
                /* Exponentiation */
                Syntax_Node *left = node->apply.arguments.items[0];
                Syntax_Node *right = node->apply.arguments.items[1];
                Type_Info *left_type = Resolve_Expression(sm, left);
                Resolve_Expression(sm, right);
                node->type = left_type;
                return node->type;
            }
        }
        /* Unary operators with one argument */
        if (arg_count == 1) {
            if (name.length == 1) {
                char op_char = name.data[0];
                if (op_char == '+' or op_char == '-') {
                    node->type = Resolve_Expression(sm, node->apply.arguments.items[0]);
                    return node->type;
                }
            }
            /* Unary word operators: "NOT"(X), "ABS"(X) (RM 4.5.6, 4.5.7) */
            if (Slice_Equal_Ignore_Case(name, S("not"))) {
                Syntax_Node *operand = node->apply.arguments.items[0];
                Type_Info *ot = Resolve_Expression(sm, operand);
                /* NOT preserves boolean array type */
                if (ot and Type_Is_Array_Like(ot) and ot->array.element_type and
                    Type_Is_Boolean(ot->array.element_type))
                    node->type = ot;
                else
                    node->type = sm->type_boolean;
                return node->type;
            }
            if (Slice_Equal_Ignore_Case(name, S("abs"))) {
                node->type = Resolve_Expression(sm, node->apply.arguments.items[0]);
                return node->type;
            }
        }
        /* Binary word operators: "AND"/"OR"/"XOR"/"MOD"/"REM"(L,R) (RM 4.5) */
        if (arg_count == 2) {
            if (Slice_Equal_Ignore_Case(name, S("and")) or
                Slice_Equal_Ignore_Case(name, S("or"))  or
                Slice_Equal_Ignore_Case(name, S("xor")) or
                Slice_Equal_Ignore_Case(name, S("mod")) or
                Slice_Equal_Ignore_Case(name, S("rem"))) {
                Type_Info *lt = Resolve_Expression(sm, node->apply.arguments.items[0]);
                Resolve_Expression(sm, node->apply.arguments.items[1]);
                node->type = lt;
                return node->type;
            }
        }
    }

    /* ─── Case 3: Array Indexing/Slicing (with implicit access dereference) ─── */
    /* Per RM 4.1(3), A(I) where A is access-to-array is equivalent to A.ALL(I) */
    Type_Info *indexed_type = prefix_type;
    if (Type_Is_Access(prefix_type) and prefix_type->access.designated_type) {
        indexed_type = prefix_type->access.designated_type;  /* Implicit dereference */
    }
    if (Type_Is_Array_Like(indexed_type)) {
        /* Check if this is a slice (range argument) vs indexing (scalar argument) */
        bool is_slice = false;
        for (uint32_t i = 0; i < arg_count; i++) {
            Syntax_Node *arg = node->apply.arguments.items[i];
            if (arg and arg->kind == NK_RANGE) {
                is_slice = true;
                break;
            }
        }

        if (is_slice) {
            /* Slice: result type is the same array/string type */
            node->type = indexed_type;
        } else {
            /* Indexing: result type is the element type */
            node->type = indexed_type->array.element_type;
            if (not node->type and Type_Is_String(indexed_type)) {
                node->type = sm->type_character;
            }
        }
        return node->type;
    }

    /* ─── Case 3b: Generic subprogram recursive call ─── */
    /* Per Ada RM 12.3(17), within a generic subprogram body the name of
     * the subprogram denotes the current instance (recursive call).
     * GNAT: Analyze_Call handles this via the Is_Generic_Subprogram check. */
    if (prefix_sym and prefix_sym->kind == SYMBOL_GENERIC and prefix_sym->generic_unit) {
        Syntax_Node *gu = prefix_sym->generic_unit;
        if (gu->kind == NK_FUNCTION_SPEC) {
            /* Return type from the generic function spec */
            if (gu->subprogram_spec.return_type)
                node->type = gu->subprogram_spec.return_type->type;
            if (not node->type) node->type = sm->type_integer;
            return node->type;
        }
        if (gu->kind == NK_PROCEDURE_SPEC) {
            node->type = NULL;  /* Procedure call — no return type */
            return NULL;
        }
    }

    /* ─── Case 4: Unresolved - report error and recover ─── */
    if (prefix->kind == NK_IDENTIFIER) {
        Report_Error(node->location, "cannot resolve '%.*s' as callable or indexable",
                    (int)prefix->string_val.text.length, prefix->string_val.text.data);
    }

    return sm->type_integer;  /* Error recovery */
}

/* ─────────────────────────────────────────────────────────────────────────
 * Evaluate Constant Numeric Expression (for delta, bounds in type defs)
 * Returns NaN if not a static constant expression
 * ───────────────────────────────────────────────────────────────────────── */
static bool Is_Integer_Expr(Syntax_Node *n);  /* Forward declaration */

static bool Is_Integer_Expr(Syntax_Node *n) {
    /* Returns true if the expression is integer-typed (for division semantics) */
    if (not n) return false;
    switch (n->kind) {
        case NK_INTEGER: return true;
        case NK_REAL:    return false;
        case NK_IDENTIFIER:
        case NK_SELECTED: {
            /* Check if named number/constant is integer */
            Symbol *sym = n->symbol;
            if (sym and sym->kind == SYMBOL_CONSTANT and sym->is_named_number and
                sym->declaration and sym->declaration->kind == NK_OBJECT_DECL) {
                return Is_Integer_Expr(sym->declaration->object_decl.init);
            }
            /* Check type if available */
            if (Type_Is_Integer_Like(n->type)) return true;
            return false;
        }
        case NK_UNARY_OP:
            return Is_Integer_Expr(n->unary.operand);
        case NK_BINARY_OP:
            return Is_Integer_Expr(n->binary.left) and Is_Integer_Expr(n->binary.right);
        case NK_APPLY:
            /* For type conversions TYPE(arg), check if arg is integer */
            if (n->apply.arguments.count == 1 and
                n->apply.prefix and n->apply.prefix->symbol and
                n->apply.prefix->symbol->kind == SYMBOL_TYPE) {
                return Is_Integer_Expr(n->apply.arguments.items[0]);
            }
            return false;
        default:
            return false;
    }
}

static double Eval_Const_Numeric(Syntax_Node *n) {
    if (not n) return 0.0/0.0;
    switch (n->kind) {
        case NK_REAL:    return n->real_lit.value;
        case NK_INTEGER: return (double)n->integer_lit.value;
        case NK_CHARACTER:
            /* Character literals have position value in symbol->frame_offset */
            if (n->symbol and n->symbol->kind == SYMBOL_LITERAL) {
                return (double)n->symbol->frame_offset;
            }
            /* Fallback: use ASCII code - character literals store their value in string_val.text */
            /* Format is 'X' (length 3) - extract the middle character at index 1 */
            if (n->string_val.text.length >= 2) {
                return (double)(unsigned char)n->string_val.text.data[1];
            }
            if (n->string_val.text.length == 1) {
                return (double)(unsigned char)n->string_val.text.data[0];
            }
            return 0.0/0.0;
        case NK_IDENTIFIER:
        case NK_SELECTED: {
            /* Check for character/enum literal first */
            Symbol *sym = n->symbol;
            if (sym and sym->kind == SYMBOL_LITERAL) {
                return (double)sym->frame_offset;
            }
            /* Named number or constant - evaluate via symbol's declaration */
            if (sym and sym->kind == SYMBOL_CONSTANT) {
                if (sym->declaration and sym->declaration->kind == NK_OBJECT_DECL
                    and sym->declaration->object_decl.init)
                    return Eval_Const_Numeric(sym->declaration->object_decl.init);
                /* Predefined constant (e.g. ASCII.DEL) — value in frame_offset */
                return (double)sym->frame_offset;
            }
            /* Variable with constant init (typed constants get variable-like alloc) */
            if (sym and sym->kind == SYMBOL_VARIABLE and sym->declaration
                and sym->declaration->kind == NK_OBJECT_DECL
                and sym->declaration->object_decl.is_constant
                and sym->declaration->object_decl.init) {
                return Eval_Const_Numeric(sym->declaration->object_decl.init);
            }
            return 0.0/0.0;
        }
        case NK_QUALIFIED:
            /* Qualified expression: TYPE'(expr) - evaluate the inner expression */
            if (n->qualified.expression) {
                Syntax_Node *inner = n->qualified.expression;
                /* Handle character literal inside qualified expression:
                 * look up in the qualifying type's enumeration literals */
                if (inner->kind == NK_CHARACTER and n->qualified.subtype_mark and
                    n->qualified.subtype_mark->type) {
                    Type_Info *qual_type = n->qualified.subtype_mark->type;
                    /* Walk up to find the base enumeration type with literals */
                    while (Type_Is_Enumeration(qual_type) and
                           not qual_type->enumeration.literals) {
                        qual_type = qual_type->base_type ? qual_type->base_type : qual_type->parent_type;
                    }
                    if (Type_Is_Enumeration(qual_type) and
                        qual_type->enumeration.literals) {
                        /* Extract the character from 'X' format */
                        String_Slice lit_text = inner->string_val.text;
                        char ch = lit_text.length >= 2 ? lit_text.data[1] : 0;
                        /* Look for matching character literal in enum */
                        for (uint32_t j = 0; j < qual_type->enumeration.literal_count; j++) {
                            String_Slice lit_name = qual_type->enumeration.literals[j];
                            if (lit_name.length == 3 and
                                lit_name.data[0] == '\'' and
                                lit_name.data[1] == ch and
                                lit_name.data[2] == '\'') {
                                return (double)j;  /* Position in enumeration */
                            }
                        }
                    }
                }
                return Eval_Const_Numeric(inner);
            }
            return 0.0/0.0;
        case NK_APPLY: {
            /* Type conversions: TYPE_NAME(expr) - evaluate the argument */
            if (n->apply.prefix and n->apply.arguments.count == 1) {
                Syntax_Node *arg = n->apply.arguments.items[0];
                Syntax_Node *prefix = n->apply.prefix;
                if (prefix->kind == NK_IDENTIFIER and prefix->symbol and
                    prefix->symbol->kind == SYMBOL_TYPE) {
                    return Eval_Const_Numeric(arg);
                }
            }
            return 0.0/0.0;
        }
        case NK_UNARY_OP:
            if (n->unary.op == TK_MINUS) return -Eval_Const_Numeric(n->unary.operand);
            if (n->unary.op == TK_PLUS)  return Eval_Const_Numeric(n->unary.operand);
            if (n->unary.op == TK_ABS)   return fabs(Eval_Const_Numeric(n->unary.operand));
            return 0.0/0.0;
        case NK_ATTRIBUTE: {
            /* T'SIZE, T'FIRST, T'LAST, T'POS, T'LENGTH etc. */
            Type_Info *ty = n->attribute.prefix ? n->attribute.prefix->type : NULL;
            String_Slice a = n->attribute.name;
            if (not ty) return 0.0/0.0;
            if (Slice_Equal_Ignore_Case(a, S("SIZE")))
                return (double)(ty->size * 8);
            if (Slice_Equal_Ignore_Case(a, S("FIRST"))) {
                if (ty->low_bound.kind == BOUND_INTEGER) return (double)ty->low_bound.int_value;
                if (ty->low_bound.kind == BOUND_FLOAT)   return ty->low_bound.float_value;
            }
            if (Slice_Equal_Ignore_Case(a, S("LAST"))) {
                if (ty->high_bound.kind == BOUND_INTEGER) return (double)ty->high_bound.int_value;
                if (ty->high_bound.kind == BOUND_FLOAT)   return ty->high_bound.float_value;
            }
            if (Slice_Equal_Ignore_Case(a, S("LENGTH"))) {
                if (Type_Is_Array_Like(ty) and ty->array.index_count > 0) {
                    int128_t lo = Type_Bound_Value(ty->array.indices[0].low_bound);
                    int128_t hi = Type_Bound_Value(ty->array.indices[0].high_bound);
                    return (double)(hi - lo + 1);
                }
            }
            if (Slice_Equal_Ignore_Case(a, S("POS")) and
                n->attribute.arguments.count == 1)
                return Eval_Const_Numeric(n->attribute.arguments.items[0]);
            return 0.0/0.0;
        }
        case NK_BINARY_OP: {
            double l = Eval_Const_Numeric(n->binary.left);
            double r = Eval_Const_Numeric(n->binary.right);
            switch (n->binary.op) {
                case TK_PLUS:  return l + r;
                case TK_MINUS: return l - r;
                case TK_STAR:  return l * r;
                case TK_SLASH:
                    if (r == 0) return 0.0/0.0;
                    /* Ada integer division truncates toward zero (RM 4.5.5) */
                    /* Only use integer division if BOTH operands are integer-typed */
                    if (Is_Integer_Expr(n->binary.left) and Is_Integer_Expr(n->binary.right) and
                        l == floor(l) and r == floor(r) and
                        fabs(l) < 1e15 and fabs(r) < 1e15) {
                        int64_t li = (int64_t)l;
                        int64_t ri = (int64_t)r;
                        return (double)(li / ri);  /* Integer division */
                    }
                    return l / r;
                case TK_EXPON: return pow(l, r);
                default:       return 0.0/0.0;
            }
        }
        default: return 0.0/0.0;
    }
}

/* RM 4.10: Exact rational evaluator for static universal_real expressions.
 * Returns true and fills *out if the expression is a compile-time constant
 * representable as an exact rational number.  Used so that comparisons like
 * 0.1*0.1 = 0.01 or (2/3)**10 chain correctly without IEEE rounding errors. */
static bool Eval_Const_Rational(Syntax_Node *n, Rational *out) {
    if (!n) return false;
    switch (n->kind) {
        case NK_REAL:
            if (n->real_lit.big_value) {
                *out = Rational_From_Big_Real(n->real_lit.big_value);
                return true;
            }
            /* Fallback: wrap double as rational — loses exactness */
            return false;
        case NK_INTEGER:
            *out = Rational_From_Int((int64_t)n->integer_lit.value);
            return true;
        case NK_IDENTIFIER:
        case NK_SELECTED: {
            Symbol *sym = n->symbol;
            if (sym and sym->kind == SYMBOL_CONSTANT and sym->declaration
                and sym->declaration->kind == NK_OBJECT_DECL
                and sym->declaration->object_decl.init)
                return Eval_Const_Rational(sym->declaration->object_decl.init, out);
            if (sym and sym->kind == SYMBOL_VARIABLE and sym->declaration
                and sym->declaration->kind == NK_OBJECT_DECL
                and sym->declaration->object_decl.is_constant
                and sym->declaration->object_decl.init)
                return Eval_Const_Rational(sym->declaration->object_decl.init, out);
            return false;
        }
        case NK_QUALIFIED:
            if (n->qualified.expression)
                return Eval_Const_Rational(n->qualified.expression, out);
            return false;
        case NK_APPLY:
            if (n->apply.prefix and n->apply.arguments.count == 1 and
                n->apply.prefix->symbol and
                n->apply.prefix->symbol->kind == SYMBOL_TYPE)
                return Eval_Const_Rational(n->apply.arguments.items[0], out);
            return false;
        case NK_UNARY_OP: {
            Rational operand;
            if (!Eval_Const_Rational(n->unary.operand, &operand)) return false;
            if (n->unary.op == TK_MINUS) {
                operand.num = Big_Integer_Clone(operand.num);
                operand.num->is_negative = !operand.num->is_negative;
            } else if (n->unary.op == TK_ABS) {
                operand.num = Big_Integer_Clone(operand.num);
                operand.num->is_negative = false;
            }
            *out = operand;
            return true;
        }
        case NK_BINARY_OP: {
            Rational l, r;
            /* For exponentiation, exponent must be integer */
            if (n->binary.op == TK_EXPON) {
                if (!Eval_Const_Rational(n->binary.left, &l)) return false;
                double re = Eval_Const_Numeric(n->binary.right);
                if (re != re or re != floor(re) or fabs(re) > 1000) return false;
                *out = Rational_Pow(l, (int)re);
                return true;
            }
            if (!Eval_Const_Rational(n->binary.left, &l)) return false;
            if (!Eval_Const_Rational(n->binary.right, &r)) return false;
            switch (n->binary.op) {
                case TK_PLUS:  *out = Rational_Add(l, r); return true;
                case TK_MINUS: *out = Rational_Sub(l, r); return true;
                case TK_STAR:  *out = Rational_Mul(l, r); return true;
                case TK_SLASH:
                    if (r.num->count == 0) return false;
                    *out = Rational_Div(l, r); return true;
                default: return false;
            }
        }
        default: return false;
    }
}

/* Integer-precise constant evaluator for modular type modulus expressions.
 * Unlike Eval_Const_Numeric (which uses double, losing precision above 2^53),
 * this evaluates in uint128_t for exact results up to 2^128.
 * Returns true on success, false if the expression is not a compile-time
 * integer constant.  Handles 2**64, 2**128, and all intermediate values
 * without sentinel hacks. */
static bool Eval_Const_Uint128(Syntax_Node *n, uint128_t *out) {
    if (not n) return false;
    switch (n->kind) {
        case NK_INTEGER:
            /* integer_lit.value is int64_t; for values > INT64_MAX, use big_value */
            if (n->integer_lit.big_value) {
                return Big_Integer_To_Uint128(n->integer_lit.big_value, out);
            }
            *out = (uint128_t)(uint64_t)n->integer_lit.value;
            return true;
        case NK_IDENTIFIER:
        case NK_SELECTED: {
            Symbol *sym = n ? n->symbol : NULL;
            if (sym and sym->kind == SYMBOL_CONSTANT and sym->is_named_number and
                sym->declaration and sym->declaration->kind == NK_OBJECT_DECL) {
                return Eval_Const_Uint128(sym->declaration->object_decl.init, out);
            }
            return false;
        }
        case NK_UNARY_OP:
            if (n->unary.op == TK_PLUS) return Eval_Const_Uint128(n->unary.operand, out);
            if (n->unary.op == TK_MINUS) {
                uint128_t v;
                if (Eval_Const_Uint128(n->unary.operand, &v)) {
                    *out = (uint128_t)(-(int128_t)v);
                    return true;
                }
            }
            return false;
        case NK_BINARY_OP: {
            uint128_t l, r;
            if (not Eval_Const_Uint128(n->binary.left, &l)) return false;
            if (not Eval_Const_Uint128(n->binary.right, &r)) return false;
            switch (n->binary.op) {
                case TK_PLUS:  *out = l + r; return true;
                case TK_MINUS: *out = l - r; return true;
                case TK_STAR:  *out = l * r; return true;
                case TK_SLASH: if (r == 0) return false; *out = l / r; return true;
                case TK_EXPON: {
                    /* Integer exponentiation: l ** r.  For modular type declarations,
                     * the common case is 2**N.  2**64 and 2**128 compute exactly
                     * in uint128_t (2**128 wraps to 0, but we cap r at 127 for
                     * the shift path below). */
                    if (l == 2 and r <= 128) {
                        /* Fast path: 2**N via shift.  2**128 = 0 in uint128_t,
                         * but we return it as 0 which the caller interprets as
                         * "the 128-bit boundary" for mod types. */
                        *out = (r == 128) ? (uint128_t)0 : ((uint128_t)1 << r);
                        return true;
                    }
                    uint128_t result = 1;
                    for (uint128_t i = 0; i < r; i++) result *= l;
                    *out = result;
                    return true;
                }
                default: return false;
            }
        }
        case NK_APPLY: {
            /* Type conversions: TYPE_NAME(expr) */
            if (n->apply.prefix and n->apply.arguments.count == 1) {
                Syntax_Node *prefix = n->apply.prefix;
                if (prefix->kind == NK_IDENTIFIER and prefix->symbol and
                    prefix->symbol->kind == SYMBOL_TYPE) {
                    return Eval_Const_Uint128(n->apply.arguments.items[0], out);
                }
            }
            return false;
        }
        default: return false;
    }
}

/* Return bound value as int128_t.  For most types this fits in 64 bits;
 * for mod 2**128 the high bound is 2^128-1 which requires the full range. */
static int128_t Type_Bound_Value(Type_Bound b) {
    if (b.kind == BOUND_INTEGER) return b.int_value;
    if (b.kind == BOUND_FLOAT) return (int128_t)b.float_value;
    if (b.kind == BOUND_EXPR and b.expr) {
        /* Try to evaluate expression bound at compile time */
        double val = Eval_Const_Numeric(b.expr);
        if (val == val) return (int128_t)val;  /* Not NaN */
    }
    return 0;  /* Handle other bound kinds as needed */
}

/* Format an int128_t as a decimal string.  Returns pointer to a static
 * thread-local buffer.  Handles the full range -2^127 .. 2^127-1.
 * Used for emitting i128 constants in LLVM IR (which accepts arbitrary
 * width decimal literals). */
static const char *I128_Decimal(int128_t v) {
    static _Thread_local char buf[42];  /* -170141183460469231731687303715884105728 + NUL */
    if (v == 0) return "0";
    char *p = buf + sizeof(buf) - 1;
    *p = '\0';
    bool neg = v < 0;
    uint128_t u = neg ? (uint128_t)(-(v + 1)) + 1 : (uint128_t)v;
    while (u) { *--p = '0' + (char)(u % 10); u /= 10; }
    if (neg) *--p = '-';
    return p;
}

/* Format a uint128_t as a decimal string.  Returns pointer to a static
 * thread-local buffer.  Handles 0 .. 2^128-1. */
static const char *U128_Decimal(uint128_t v) {
    static _Thread_local char buf[40];  /* 340282366920938463463374607431768211455 + NUL */
    if (v == 0) return "0";
    char *p = buf + sizeof(buf) - 1;
    *p = '\0';
    while (v) { *--p = '0' + (char)(v % 10); v /= 10; }
    return p;
}

/* Get array element count for constrained arrays, 0 for unconstrained */
static int128_t Array_Element_Count(Type_Info *t) {
    if (not t or t->kind != TYPE_ARRAY or not t->array.is_constrained)
        return 0;
    if (t->array.index_count == 0)
        return 0;
    /* Product of all dimension lengths (RM 3.6.1) */
    int128_t total = 1;
    for (uint32_t d = 0; d < t->array.index_count; d++) {
        int128_t lo = Type_Bound_Value(t->array.indices[d].low_bound);
        int128_t hi = Type_Bound_Value(t->array.indices[d].high_bound);
        int128_t dim = hi - lo + 1;
        if (dim <= 0) return 0;
        total *= dim;
    }
    return total;
}

/* Get array low bound for index adjustment */
static int128_t Array_Low_Bound(Type_Info *t) {
    if (not t or t->kind != TYPE_ARRAY or t->array.index_count == 0)
        return 0;
    return Type_Bound_Value(t->array.indices[0].low_bound);
}

static Type_Info *Resolve_Expression(Symbol_Manager *sm, Syntax_Node *node) {
    if (not node) return NULL;

    switch (node->kind) {
        case NK_INTEGER:
            node->type = sm->type_universal_integer;
            return node->type;

        case NK_REAL:
            node->type = sm->type_universal_real;
            return node->type;

        case NK_CHARACTER:
            node->type = sm->type_character;
            return node->type;

        case NK_STRING:
            node->type = sm->type_string;
            return node->type;

        case NK_NULL:
            node->type = NULL;  /* Matches any access type */
            return NULL;

        case NK_IDENTIFIER:
            return Resolve_Identifier(sm, node);

        case NK_SELECTED:
            return Resolve_Selected(sm, node);

        case NK_BINARY_OP:
            return Resolve_Binary_Op(sm, node);

        case NK_UNARY_OP:
            node->type = Resolve_Expression(sm, node->unary.operand);
            if (node->unary.op == TK_NOT) {
                /* NOT preserves array-of-BOOLEAN type (RM 4.5.6);
                 * for scalar operands it returns BOOLEAN. */
                Type_Info *ot = node->unary.operand ? node->unary.operand->type : NULL;
                if (ot and Type_Is_Array_Like(ot) and
                    ot->array.element_type and
                    Type_Is_Boolean(ot->array.element_type)) {
                    node->type = ot;  /* boolean array > boolean array */
                } else {
                    node->type = sm->type_boolean;
                }
            } else if (node->unary.op == TK_ALL) {
                /* .ALL dereference: result is the designated type (RM 4.1) */
                Type_Info *operand_type = node->unary.operand->type;
                if (Type_Is_Access(operand_type)) {
                    node->type = operand_type->access.designated_type;
                }
            }
            return node->type;

        case NK_APPLY:
            return Resolve_Apply(sm, node);

        case NK_ATTRIBUTE:
            Resolve_Expression(sm, node->attribute.prefix);
            /* Resolve attribute arguments with type context for certain attributes */
            {
                Type_Info *prefix_type = node->attribute.prefix->type;
                String_Slice attr = node->attribute.name;

                /* For POS, SUCC, PRED, IMAGE - argument should be of prefix type */
                bool needs_enum_context =
                    (Type_Is_Enumeration(prefix_type) or
                     Type_Is_Enumeration(prefix_type ? prefix_type->parent_type : NULL)) and
                    (Slice_Equal_Ignore_Case(attr, S("POS")) or
                     Slice_Equal_Ignore_Case(attr, S("SUCC")) or
                     Slice_Equal_Ignore_Case(attr, S("PRED")) or
                     Slice_Equal_Ignore_Case(attr, S("IMAGE")));

                for (uint32_t i = 0; i < node->attribute.arguments.count; i++) {
                    Syntax_Node *arg = node->attribute.arguments.items[i];
                    bool resolved_as_enum = false;
                    /* Check if character literal should be resolved as enum literal */
                    if (needs_enum_context and arg and arg->kind == NK_CHARACTER) {
                        /* Get the character from the literal (format: 'X') */
                        String_Slice lit_text = arg->string_val.text;
                        char ch = lit_text.length >= 2 ? lit_text.data[1] : 0;
                        /* Find enum type (handle derived types) */
                        Type_Info *enum_type = prefix_type;
                        while (enum_type and enum_type->parent_type)
                            enum_type = enum_type->parent_type;
                        /* Look for matching character literal in enum */
                        if (Type_Is_Enumeration(enum_type) and
                            enum_type->enumeration.literals) {
                            for (uint32_t j = 0; j < enum_type->enumeration.literal_count; j++) {
                                String_Slice lit_name = enum_type->enumeration.literals[j];
                                if (lit_name.length == 3 and
                                    lit_name.data[0] == '\'' and
                                    lit_name.data[1] == ch and
                                    lit_name.data[2] == '\'') {
                                    /* Found matching enum literal - set symbol with type match */
                                    Symbol *lit_sym = Symbol_Find_By_Type(sm, lit_name, enum_type);
                                    if (lit_sym and lit_sym->kind == SYMBOL_LITERAL) {
                                        arg->symbol = lit_sym;
                                        arg->type = prefix_type;
                                        resolved_as_enum = true;
                                    }
                                    break;
                                }
                            }
                        }
                    }
                    /* Only resolve if not already resolved as enum literal */
                    if (not resolved_as_enum) {
                        Resolve_Expression(sm, arg);
                    }
                }
            }
            /* Attribute type depends on attribute name and prefix type */
            {
                Type_Info *prefix_type = node->attribute.prefix->type;
                String_Slice attr = node->attribute.name;

                /* Implicit dereference for access types (RM 4.1(3))
                 * A1'FIRST where A1 is access-to-array is equivalent to A1.ALL'FIRST */
                if (Type_Is_Access(prefix_type) and
                    prefix_type->access.designated_type) {
                    prefix_type = prefix_type->access.designated_type;
                }

                /* FIRST, LAST return the index type for arrays, base type for scalars */
                if (Slice_Equal_Ignore_Case(attr, S("FIRST")) or
                    Slice_Equal_Ignore_Case(attr, S("LAST"))) {
                    if (Type_Is_Array_Like(prefix_type)) {
                        /* For arrays, FIRST/LAST return the actual index type for that dimension */
                        uint32_t dim = 0;  /* Default to first dimension (0-indexed) */
                        if (node->attribute.arguments.count > 0) {
                            Syntax_Node *dim_arg = node->attribute.arguments.items[0];
                            if (dim_arg and dim_arg->kind == NK_INTEGER) {
                                dim = (uint32_t)(dim_arg->integer_lit.value - 1);
                            }
                        }
                        /* Get the index type for this dimension */
                        if (prefix_type->kind == TYPE_ARRAY and
                            prefix_type->array.indices and
                            dim < prefix_type->array.index_count and
                            prefix_type->array.indices[dim].index_type) {
                            node->type = prefix_type->array.indices[dim].index_type;
                        } else {
                            /* Default to INTEGER for strings or missing info */
                            node->type = sm->type_integer;
                        }
                    } else {
                        /* For scalar types, return the type itself */
                        node->type = prefix_type ? prefix_type : sm->type_integer;
                    }
                }
                /* VAL, SUCC, PRED return the base type (for scalar types) */
                else if (Slice_Equal_Ignore_Case(attr, S("VAL")) or
                         Slice_Equal_Ignore_Case(attr, S("SUCC")) or
                         Slice_Equal_Ignore_Case(attr, S("PRED"))) {
                    node->type = prefix_type ? prefix_type : sm->type_integer;
                }
                /* POS returns universal integer */
                else if (Slice_Equal_Ignore_Case(attr, S("POS"))) {
                    node->type = sm->type_universal_integer;
                }
                /* IMAGE returns STRING */
                else if (Slice_Equal_Ignore_Case(attr, S("IMAGE"))) {
                    node->type = sm->type_string;
                }
                /* SIZE, LENGTH, COUNT, WIDTH, MANTISSA, etc. return universal integer */
                else if (Slice_Equal_Ignore_Case(attr, S("SIZE")) or
                         Slice_Equal_Ignore_Case(attr, S("LENGTH")) or
                         Slice_Equal_Ignore_Case(attr, S("COUNT")) or
                         Slice_Equal_Ignore_Case(attr, S("WIDTH")) or
                         Slice_Equal_Ignore_Case(attr, S("MANTISSA")) or
                         Slice_Equal_Ignore_Case(attr, S("MACHINE_MANTISSA")) or
                         Slice_Equal_Ignore_Case(attr, S("DIGITS")) or
                         Slice_Equal_Ignore_Case(attr, S("EMAX")) or
                         Slice_Equal_Ignore_Case(attr, S("MACHINE_EMAX")) or
                         Slice_Equal_Ignore_Case(attr, S("MACHINE_EMIN")) or
                         Slice_Equal_Ignore_Case(attr, S("MACHINE_RADIX")) or
                         Slice_Equal_Ignore_Case(attr, S("SAFE_EMAX")) or
                         Slice_Equal_Ignore_Case(attr, S("STORAGE_SIZE")) or
                         Slice_Equal_Ignore_Case(attr, S("MODULUS")) or
                         Slice_Equal_Ignore_Case(attr, S("AFT")) or
                         Slice_Equal_Ignore_Case(attr, S("FORE"))) {
                    node->type = sm->type_universal_integer;
                }
                /* Floating-point type attributes returning universal_real (RM 3.5.8) */
                else if (Slice_Equal_Ignore_Case(attr, S("EPSILON")) or
                         Slice_Equal_Ignore_Case(attr, S("SMALL")) or
                         Slice_Equal_Ignore_Case(attr, S("LARGE")) or
                         Slice_Equal_Ignore_Case(attr, S("SAFE_SMALL")) or
                         Slice_Equal_Ignore_Case(attr, S("SAFE_LARGE")) or
                         Slice_Equal_Ignore_Case(attr, S("DELTA")) or
                         Slice_Equal_Ignore_Case(attr, S("MODEL_EPSILON")) or
                         Slice_Equal_Ignore_Case(attr, S("MODEL_SMALL"))) {
                    node->type = sm->type_universal_real;
                }
                /* Boolean attributes (RM 3.5.8, 3.7.1, 9.9) */
                else if (Slice_Equal_Ignore_Case(attr, S("MACHINE_OVERFLOWS")) or
                         Slice_Equal_Ignore_Case(attr, S("MACHINE_ROUNDS")) or
                         Slice_Equal_Ignore_Case(attr, S("CONSTRAINED")) or
                         Slice_Equal_Ignore_Case(attr, S("CALLABLE")) or
                         Slice_Equal_Ignore_Case(attr, S("TERMINATED"))) {
                    node->type = sm->type_boolean;
                }
                /* ADDRESS attribute returns SYSTEM.ADDRESS (RM 13.7.2) */
                else if (Slice_Equal_Ignore_Case(attr, S("ADDRESS"))) {
                    node->type = sm->type_address;
                }
                /* BASE attribute returns the base type (RM 3.3.2) */
                else if (Slice_Equal_Ignore_Case(attr, S("BASE"))) {
                    /* T'BASE is a type, used as prefix for other attributes like T'BASE'FIRST
                     * The type should be the base type of the prefix type.
                     * For derived types (TYPE T IS NEW X), follow parent_type chain.
                     * For constrained subtypes (SUBTYPE S IS X RANGE ...), follow base_type chain.
                     * Use Type_Root to handle both cases and find the root type. */
                    if (prefix_type) {
                        Type_Info *base = Type_Root(prefix_type);
                        node->type = base ? base : prefix_type;
                    } else {
                        node->type = sm->type_integer;
                    }
                }
                /* VALUE attribute returns the type itself (converts string to type) */
                else if (Slice_Equal_Ignore_Case(attr, S("VALUE"))) {
                    /* T'VALUE(S) returns a value of type T */
                    node->type = prefix_type ? prefix_type : sm->type_integer;
                }
                /* Default to integer for unhandled attributes */
                else {
                    node->type = sm->type_integer;
                }
            }
            return node->type;

        case NK_QUALIFIED:
            /* Resolve subtype mark first to get the type */
            Resolve_Expression(sm, node->qualified.subtype_mark);
            /* Propagate type to expression (critical for aggregates) */
            if (node->qualified.expression and
                node->qualified.expression->kind == NK_AGGREGATE and
                node->qualified.subtype_mark->type) {
                node->qualified.expression->type = node->qualified.subtype_mark->type;
            }
            Resolve_Expression(sm, node->qualified.expression);
            /* Re-resolve overloaded literals against qualifying type (RM 4.7):
             * WEEKEND'(SAT) must pick WEEKEND.SAT, not WEEK.SAT;
             * CHAR'('B') must use CHAR position, not ASCII code. */
            if (node->qualified.expression and node->qualified.subtype_mark->type) {
                Type_Info *qt = node->qualified.subtype_mark->type;
                Syntax_Node *inner = node->qualified.expression;
                if (inner->kind == NK_IDENTIFIER) {
                    if (not Type_Covers(qt, inner->type) and not Type_Covers(inner->type, qt)) {
                        Symbol *s = Symbol_Find_By_Type(sm, inner->string_val.text, qt);
                        if (s) { inner->symbol = s; inner->type = s->type ? s->type : qt; }
                    }
                } else if (inner->kind == NK_CHARACTER) {
                    Resolve_Char_As_Enum(sm, inner, qt);
                }
            }
            node->type = node->qualified.subtype_mark->type;
            return node->type;

        case NK_AGGREGATE:
            {
                Type_Info *agg_type = node->type;
                bool is_record_agg = Type_Is_Record(agg_type);
                uint32_t positional_idx = 0;

                for (uint32_t i = 0; i < node->aggregate.items.count; i++) {
                    Syntax_Node *item = node->aggregate.items.items[i];

                    if (is_record_agg and item->kind == NK_ASSOCIATION) {
                        /* For record aggregates, choices are field names - don't resolve as variables */
                        /* Find component type from first choice for nested aggregates */
                        Type_Info *comp_type = NULL;
                        if (item->association.choices.count > 0) {
                            Syntax_Node *choice = item->association.choices.items[0];
                            if (choice->kind == NK_IDENTIFIER) {
                                String_Slice comp_name = choice->string_val.text;
                                for (uint32_t j = 0; j < agg_type->record.component_count; j++) {
                                    if (Slice_Equal_Ignore_Case(agg_type->record.components[j].name, comp_name)) {
                                        comp_type = agg_type->record.components[j].component_type;
                                        break;
                                    }
                                }
                            }
                        }
                        /* Propagate component type to nested aggregates */
                        if (item->association.expression) {
                            if (item->association.expression->kind == NK_AGGREGATE and comp_type) {
                                item->association.expression->type = comp_type;
                            }
                            Resolve_Expression(sm, item->association.expression);
                        }
                    } else if (is_record_agg) {
                        /* Positional item in record aggregate - propagate component type */
                        if (positional_idx < agg_type->record.component_count) {
                            Type_Info *comp_type = agg_type->record.components[positional_idx].component_type;
                            if (item->kind == NK_AGGREGATE and comp_type) {
                                item->type = comp_type;
                            }
                            positional_idx++;
                        }
                        Resolve_Expression(sm, item);
                    } else {
                        /* For array aggregates, propagate element type to nested aggregates */
                        Type_Info *elem_type = NULL;
                        if (Type_Is_Array_Like(agg_type) and agg_type->array.element_type) {
                            elem_type = agg_type->array.element_type;
                        }
                        /* For multi-dimensional arrays (index_count > 1), inner aggregates
                         * represent "rows" (slices along the first dimension).  Create an
                         * implicit 1-D array type from the remaining dimensions so that
                         * Generate_Aggregate can handle them as composite elements (RM 4.3.2). */
                        Type_Info *inner_agg_type = elem_type;
                        if (Type_Is_Array_Like(agg_type) and agg_type->array.index_count > 1) {
                            Type_Info *row_type = Type_New(TYPE_ARRAY, S(""));
                            row_type->array.element_type = agg_type->array.element_type;
                            row_type->array.is_constrained = true;
                            row_type->array.index_count = agg_type->array.index_count - 1;
                            row_type->array.indices = Arena_Allocate(
                                row_type->array.index_count * sizeof(Index_Info));
                            /* Copy remaining dimensions (skip first) and derive
                             * bounds from index_type when BOUND_NONE (unconstrained).
                             * RM 4.3.3(6): lower bound comes from index subtype. */
                            for (uint32_t d = 0; d < row_type->array.index_count; d++) {
                                row_type->array.indices[d] = agg_type->array.indices[d + 1];
                                if (row_type->array.indices[d].low_bound.kind == BOUND_NONE and
                                    row_type->array.indices[d].index_type)
                                    row_type->array.indices[d].low_bound =
                                        row_type->array.indices[d].index_type->low_bound;
                                if (row_type->array.indices[d].high_bound.kind == BOUND_NONE and
                                    row_type->array.indices[d].index_type)
                                    row_type->array.indices[d].high_bound =
                                        row_type->array.indices[d].index_type->high_bound;
                            }
                            /* Calculate row size */
                            uint32_t row_elems = 1;
                            for (uint32_t d = 0; d < row_type->array.index_count; d++) {
                                int128_t lo = Type_Bound_Value(row_type->array.indices[d].low_bound);
                                int128_t hi = Type_Bound_Value(row_type->array.indices[d].high_bound);
                                int128_t cnt = hi - lo + 1;
                                if (cnt > 0) row_elems *= (uint32_t)cnt;
                            }
                            uint32_t el_sz = agg_type->array.element_type ?
                                             agg_type->array.element_type->size : 8;
                            if (el_sz == 0) el_sz = 8;
                            row_type->size = row_elems * el_sz;
                            row_type->alignment = agg_type->alignment;
                            inner_agg_type = row_type;
                        }
                        if (inner_agg_type and item->kind == NK_ASSOCIATION and item->association.expression) {
                            Syntax_Node *expr = item->association.expression;
                            if (expr->kind == NK_AGGREGATE) {
                                expr->type = inner_agg_type;
                            }
                        } else if (inner_agg_type and item->kind == NK_AGGREGATE) {
                            item->type = inner_agg_type;
                        }
                        Resolve_Expression(sm, item);
                    }
                }
                return node->type;  /* Type from context */
            }

        case NK_ALLOCATOR:
            /* Resolve subtype mark first to get allocated type */
            Resolve_Expression(sm, node->allocator.subtype_mark);
            if (node->allocator.expression) {
                /* Propagate type to initializer (critical for aggregates).
                 * Parser destructures T'(agg) so expression is directly the aggregate */
                if (node->allocator.expression->kind == NK_AGGREGATE and
                    node->allocator.subtype_mark and
                    node->allocator.subtype_mark->type) {
                    node->allocator.expression->type = node->allocator.subtype_mark->type;
                }
                Resolve_Expression(sm, node->allocator.expression);
            }
            /* Create access type pointing to allocated type */
            {
                Type_Info *access_type = Type_New(TYPE_ACCESS, S(""));
                access_type->size = 8;
                access_type->alignment = 8;
                if (node->allocator.subtype_mark and node->allocator.subtype_mark->type) {
                    access_type->access.designated_type = node->allocator.subtype_mark->type;
                }
                node->type = access_type;
            }
            return node->type;

        case NK_RANGE:
            if (node->range.low) Resolve_Expression(sm, node->range.low);
            if (node->range.high) Resolve_Expression(sm, node->range.high);
            /* Ada RM 4.1.1: in a range L..H, character literals must be
             * resolved against the other operand's enum type (like binary ops).
             * GNAT: overload resolution propagates expected type to both bounds. */
            {
                Type_Info *lt = node->range.low  ? node->range.low->type  : NULL;
                Type_Info *ht = node->range.high ? node->range.high->type : NULL;
                if (ht and Type_Is_Enumeration(ht) and
                    node->range.low and node->range.low->kind == NK_CHARACTER)
                    Resolve_Char_As_Enum(sm, node->range.low, ht);
                else if (lt and Type_Is_Enumeration(lt) and
                         node->range.high and node->range.high->kind == NK_CHARACTER)
                    Resolve_Char_As_Enum(sm, node->range.high, lt);
                /* Also handle derived enum types via parent chain */
                if (ht and ht->parent_type and Type_Is_Enumeration(ht->parent_type) and
                    node->range.low and node->range.low->kind == NK_CHARACTER)
                    Resolve_Char_As_Enum(sm, node->range.low, ht);
                else if (lt and lt->parent_type and Type_Is_Enumeration(lt->parent_type) and
                         node->range.high and node->range.high->kind == NK_CHARACTER)
                    Resolve_Char_As_Enum(sm, node->range.high, lt);
            }
            node->type = node->range.low ? node->range.low->type : NULL;
            if (not node->type) node->type = node->range.high ? node->range.high->type : NULL;
            return node->type;

        case NK_ASSOCIATION:
            for (uint32_t i = 0; i < node->association.choices.count; i++) {
                Resolve_Expression(sm, node->association.choices.items[i]);
            }
            if (node->association.expression) {
                /* For case alternatives, expression is a block with statements */
                if (node->association.expression->kind == NK_BLOCK) {
                    Resolve_Statement(sm, node->association.expression);
                } else {
                    Resolve_Expression(sm, node->association.expression);
                }
            }
            return node->association.expression ? node->association.expression->type : NULL;

        case NK_ARRAY_TYPE:
            {
                /* Create array type info from syntax node */
                Type_Info *array_type = Type_New(TYPE_ARRAY, S(""));
                array_type->array.is_constrained = node->array_type.is_constrained;
                array_type->array.index_count = (uint32_t)node->array_type.indices.count;

                /* Allocate index info */
                if (array_type->array.index_count > 0) {
                    array_type->array.indices = Arena_Allocate(
                        array_type->array.index_count * sizeof(Index_Info));

                    for (uint32_t i = 0; i < array_type->array.index_count; i++) {
                        Syntax_Node *idx = node->array_type.indices.items[i];
                        Resolve_Expression(sm, idx);

                        Index_Info *info = &array_type->array.indices[i];
                        info->index_type = sm->type_integer;

                        /* Extract bounds from range or subtype indication */
                        Syntax_Node *range_node = NULL;
                        if (idx->kind == NK_RANGE) {
                            range_node = idx;
                            /* Infer index type from range bounds' type */
                            if (idx->range.low and idx->range.low->type) {
                                info->index_type = idx->range.low->type;
                            } else if (idx->range.high and idx->range.high->type) {
                                info->index_type = idx->range.high->type;
                            }
                        } else if (idx->kind == NK_SUBTYPE_INDICATION and
                                   idx->subtype_ind.constraint and
                                   idx->subtype_ind.constraint->kind == NK_RANGE_CONSTRAINT) {
                            range_node = idx->subtype_ind.constraint->range_constraint.range;
                            /* Also use the subtype mark's type for index type */
                            if (idx->subtype_ind.subtype_mark and idx->subtype_ind.subtype_mark->type) {
                                info->index_type = idx->subtype_ind.subtype_mark->type;
                            }
                        } else if (idx->kind == NK_SUBTYPE_INDICATION and
                                   idx->subtype_ind.subtype_mark and
                                   idx->subtype_ind.subtype_mark->type) {
                            /* Unconstrained index type (just a type mark, no constraint) */
                            info->index_type = idx->subtype_ind.subtype_mark->type;
                        } else if (idx->type) {
                            /* Use resolved type from identifier/expression (e.g., BOOLEAN) */
                            info->index_type = idx->type;
                        }
                        if (range_node and range_node->kind == NK_RANGE and
                            range_node->range.low and range_node->range.high) {
                            /* Helper to extract static integer from various expression forms */
                            bool extract_static_bound(Syntax_Node *expr, int64_t *out) {
                                if (not expr) return false;
                                /* Integer literal */
                                if (expr->kind == NK_INTEGER) {
                                    *out = expr->integer_lit.value;
                                    return true;
                                }
                                /* Character/enum literal (symbol with frame_offset as position) */
                                if (expr->symbol and expr->symbol->kind == SYMBOL_LITERAL) {
                                    *out = expr->symbol->frame_offset;
                                    return true;
                                }
                                /* Qualified expression: TYPE'(expr) - evaluate inner expression */
                                if (expr->kind == NK_QUALIFIED and expr->qualified.expression) {
                                    Syntax_Node *inner = expr->qualified.expression;
                                    if (inner->kind == NK_INTEGER) {
                                        *out = inner->integer_lit.value;
                                        return true;
                                    }
                                    if (inner->symbol and inner->symbol->kind == SYMBOL_LITERAL) {
                                        *out = inner->symbol->frame_offset;
                                        return true;
                                    }
                                    /* Handle character literal inside qualified expression:
                                     * look up in the qualifying type's enumeration literals */
                                    if (inner->kind == NK_CHARACTER and expr->qualified.subtype_mark) {
                                        /* First resolve the subtype_mark to get its type */
                                        if (not expr->qualified.subtype_mark->type) {
                                            Resolve_Expression(sm, expr->qualified.subtype_mark);
                                        }
                                        Type_Info *qual_type = expr->qualified.subtype_mark->type;
                                        /* Walk up to find the base enumeration type with literals */
                                        while (Type_Is_Enumeration(qual_type) and
                                               not qual_type->enumeration.literals) {
                                            qual_type = qual_type->base_type ? qual_type->base_type : qual_type->parent_type;
                                        }
                                        if (Type_Is_Enumeration(qual_type) and
                                            qual_type->enumeration.literals) {
                                            /* Extract the character from 'X' format */
                                            String_Slice lit_text = inner->string_val.text;
                                            char ch = lit_text.length >= 2 ? lit_text.data[1] : 0;
                                            /* Look for matching character literal in enum */
                                            for (uint32_t j = 0; j < qual_type->enumeration.literal_count; j++) {
                                                String_Slice lit_name = qual_type->enumeration.literals[j];
                                                if (lit_name.length == 3 and
                                                    lit_name.data[0] == '\'' and
                                                    lit_name.data[1] == ch and
                                                    lit_name.data[2] == '\'') {
                                                    *out = (int64_t)j;  /* Position in enumeration */
                                                    return true;
                                                }
                                            }
                                        }
                                    }
                                    /* Try constant evaluation for other inner expressions */
                                    double val = Eval_Const_Numeric(inner);
                                    if (val == val) {  /* Not NaN */
                                        *out = (int64_t)val;
                                        return true;
                                    }
                                }
                                /* Try general constant evaluation */
                                double val = Eval_Const_Numeric(expr);
                                if (val == val) {  /* Not NaN */
                                    *out = (int64_t)val;
                                    return true;
                                }
                                return false;
                            }
                            int64_t low_val, high_val;
                            if (extract_static_bound(range_node->range.low, &low_val)) {
                                info->low_bound = (Type_Bound){
                                    .kind = BOUND_INTEGER,
                                    .int_value = low_val
                                };
                            } else {
                                /* Non-static bound - store expression reference */
                                info->low_bound = (Type_Bound){
                                    .kind = BOUND_EXPR,
                                    .expr = range_node->range.low
                                };
                            }
                            if (extract_static_bound(range_node->range.high, &high_val)) {
                                info->high_bound = (Type_Bound){
                                    .kind = BOUND_INTEGER,
                                    .int_value = high_val
                                };
                            } else {
                                /* Non-static bound - store expression reference */
                                info->high_bound = (Type_Bound){
                                    .kind = BOUND_EXPR,
                                    .expr = range_node->range.high
                                };
                            }
                        }
                    }
                }

                /* Resolve component type */
                if (node->array_type.component_type) {
                    Resolve_Expression(sm, node->array_type.component_type);
                    array_type->array.element_type = node->array_type.component_type->type;
                } else {
                    array_type->array.element_type = sm->type_integer;
                }

                /* Compute size - only when ALL bounds are statically known.
                 * Skip if any bound is BOUND_EXPR that evaluates to a value
                 * suggesting the bound can't be determined at compile time
                 * (e.g. discriminant references). RM 3.6.1 */
                if (array_type->array.is_constrained and array_type->array.index_count > 0) {
                    bool all_static = true;
                    int128_t count = 1;
                    for (uint32_t i = 0; i < array_type->array.index_count; i++) {
                        Type_Bound *lo_b = &array_type->array.indices[i].low_bound;
                        Type_Bound *hi_b = &array_type->array.indices[i].high_bound;
                        if ((lo_b->kind == BOUND_EXPR or lo_b->kind == BOUND_NONE) and
                            lo_b->kind != BOUND_INTEGER) {
                            /* Try static eval; if it returns 0 for a bound that
                             * references a symbol, treat as non-static */
                            if (lo_b->kind == BOUND_EXPR and lo_b->expr and lo_b->expr->symbol) {
                                all_static = false; break;
                            }
                        }
                        if ((hi_b->kind == BOUND_EXPR or hi_b->kind == BOUND_NONE) and
                            hi_b->kind != BOUND_INTEGER) {
                            if (hi_b->kind == BOUND_EXPR and hi_b->expr and hi_b->expr->symbol) {
                                all_static = false; break;
                            }
                        }
                        int128_t lo = Type_Bound_Value(*lo_b);
                        int128_t hi = Type_Bound_Value(*hi_b);
                        int128_t dim = hi - lo + 1;
                        if (dim < 0) dim = 0;
                        count *= dim;
                    }
                    if (not all_static) {
                        array_type->size = 0;
                    } else if (all_static and count >= 0) {
                        uint32_t elem_size = array_type->array.element_type ?
                                             array_type->array.element_type->size : 8;
                        array_type->size = (uint32_t)(count * elem_size);
                    }
                }

                node->type = array_type;
                return array_type;
            }

        case NK_ENUMERATION_TYPE:
            {
                /* Create enumeration type info from syntax node
                 * Note: Literal symbols are created later in NK_TYPE_DECL processing
                 * so they reference the named type, not this anonymous type */
                Type_Info *enum_type = Type_New(TYPE_ENUMERATION, S(""));
                uint32_t lit_count = (uint32_t)node->enum_type.literals.count;

                enum_type->enumeration.literal_count = lit_count;
                if (lit_count > 0) {
                    enum_type->enumeration.literals = Arena_Allocate(
                        lit_count * sizeof(String_Slice));

                    for (uint32_t i = 0; i < lit_count; i++) {
                        Syntax_Node *lit = node->enum_type.literals.items[i];
                        enum_type->enumeration.literals[i] = lit->string_val.text;
                    }
                }

                /* Size based on number of literals */
                if (lit_count <= 256) {
                    enum_type->size = 1;  /* Fits in 1 byte */
                } else if (lit_count <= 65536) {
                    enum_type->size = 2;  /* Fits in 2 bytes */
                } else {
                    enum_type->size = 4;  /* 4 bytes for large enums */
                }
                enum_type->alignment = enum_type->size;
                enum_type->low_bound = (Type_Bound){.kind = BOUND_INTEGER, .int_value = 0};
                enum_type->high_bound = (Type_Bound){.kind = BOUND_INTEGER, .int_value = lit_count - 1};

                node->type = enum_type;
                return enum_type;
            }

        case NK_DERIVED_TYPE:
            {
                /* Derived type: type T is new Parent [constraint] */
                Resolve_Expression(sm, node->derived_type.parent_type);
                Type_Info *parent = node->derived_type.parent_type ?
                                    node->derived_type.parent_type->type : NULL;
                if (not parent) {
                    node->type = NULL;
                    return NULL;
                }

                /* Create new type that inherits from parent */
                Type_Info *derived = Type_New(parent->kind, S(""));
                derived->parent_type = parent;
                derived->size = parent->size;
                derived->alignment = parent->alignment;
                derived->low_bound = parent->low_bound;
                derived->high_bound = parent->high_bound;

                /* Copy kind-specific info */
                if (Type_Is_Enumeration(parent)) {
                    derived->enumeration = parent->enumeration;
                } else if (Type_Is_Array_Like(parent)) {
                    derived->array = parent->array;
                } else if (Type_Is_Record(parent)) {
                    derived->record = parent->record;
                } else if (Type_Is_Access(parent)) {
                    derived->access = parent->access;
                } else if (Type_Is_Fixed_Point(parent)) {
                    derived->fixed = parent->fixed;
                } else if (Type_Is_Float(parent)) {
                    derived->flt = parent->flt;
                }

                /* Apply constraint if present */
                if (node->derived_type.constraint) {
                    Resolve_Expression(sm, node->derived_type.constraint);

                    /* Handle real type constraints (DIGITS/DELTA with optional RANGE) */
                    Syntax_Node *c = node->derived_type.constraint;
                    if (c->kind == NK_REAL_TYPE and Type_Is_Float(derived)) {
                        /* Apply DIGITS constraint */
                        if (c->real_type.precision and
                            c->real_type.precision->kind == NK_INTEGER) {
                            int digits = (int)c->real_type.precision->integer_lit.value;
                            derived->flt.digits = digits;
                            /* Adjust size if needed */
                            derived->size = (digits <= 6) ? 4 : 8;
                            derived->alignment = derived->size;
                        }
                        /* Apply RANGE constraint */
                        if (c->real_type.range and c->real_type.range->kind == NK_RANGE) {
                            Syntax_Node *range = c->real_type.range;
                            if (range->range.low) {
                                double lo = Eval_Const_Numeric(range->range.low);
                                if (lo == lo) {
                                    derived->low_bound = (Type_Bound){
                                        .kind = BOUND_FLOAT, .float_value = lo
                                    };
                                } else {
                                    derived->low_bound = (Type_Bound){
                                        .kind = BOUND_EXPR, .expr = range->range.low
                                    };
                                }
                            }
                            if (range->range.high) {
                                double hi = Eval_Const_Numeric(range->range.high);
                                if (hi == hi) {
                                    derived->high_bound = (Type_Bound){
                                        .kind = BOUND_FLOAT, .float_value = hi
                                    };
                                } else {
                                    derived->high_bound = (Type_Bound){
                                        .kind = BOUND_EXPR, .expr = range->range.high
                                    };
                                }
                            }
                        }
                    }
                    /* Other constraint types handled in subtype_indication */
                }

                node->type = derived;
                return derived;
            }

        case NK_ACCESS_TYPE:
            {
                /* Create access type pointing to designated type */
                Type_Info *access_type = Type_New(TYPE_ACCESS, S(""));
                access_type->size = 8;  /* Pointer size */
                access_type->alignment = 8;

                /* Resolve designated subtype */
                if (node->access_type.designated) {
                    Resolve_Expression(sm, node->access_type.designated);
                    access_type->access.designated_type = node->access_type.designated->type;
                }

                node->type = access_type;
                return access_type;
            }

        case NK_RECORD_TYPE:
            {
                /* Create record type info from syntax node (RM 3.7, 3.7.3) */
                Type_Info *record_type = Type_New(TYPE_RECORD, S(""));

                /* Helper: count components in a variant part recursively */
                uint32_t Count_Variant_Components(Syntax_Node *vp) {
                    if (not vp) return 0;
                    uint32_t count = 0;
                    for (uint32_t i = 0; i < vp->variant_part.variants.count; i++) {
                        Syntax_Node *v = vp->variant_part.variants.items[i];
                        for (uint32_t j = 0; j < v->variant.components.count; j++) {
                            Syntax_Node *c = v->variant.components.items[j];
                            if (c->kind == NK_COMPONENT_DECL)
                                count += (uint32_t)c->component.names.count;
                        }
                        count += Count_Variant_Components(v->variant.variant_part);
                    }
                    return count;
                }

                /* Helper: count variants (top-level only) */
                uint32_t Count_Variants(Syntax_Node *vp) {
                    if (not vp) return 0;
                    return (uint32_t)vp->variant_part.variants.count;
                }

                /* Count total components (each decl may have multiple names) */
                uint32_t total_comps = 0;
                for (uint32_t i = 0; i < node->record_type.components.count; i++) {
                    Syntax_Node *comp = node->record_type.components.items[i];
                    if (comp->kind == NK_COMPONENT_DECL) {
                        total_comps += (uint32_t)comp->component.names.count;
                    }
                }
                /* Also count components in variant parts */
                total_comps += Count_Variant_Components(node->record_type.variant_part);

                bool has_variant_part = node->record_type.variant_part != NULL;
                uint32_t num_variants = Count_Variants(node->record_type.variant_part);

                record_type->record.component_count = total_comps;
                if (total_comps > 0) {
                    record_type->record.components = Arena_Allocate(
                        total_comps * sizeof(Component_Info));

                    uint32_t offset = 0;
                    uint32_t comp_idx = 0;

                    /* Helper: add a fixed-part component to the list */
                    void Add_Fixed_Component(Syntax_Node *comp) {
                        if (comp->kind != NK_COMPONENT_DECL) return;
                        Resolve_Expression(sm, comp->component.component_type);
                        Type_Info *comp_type = comp->component.component_type ?
                                               comp->component.component_type->type : sm->type_integer;
                        uint32_t comp_size = comp_type ? comp_type->size : 8;

                        /* Discriminant-dependent array components: compute maximum
                         * size from the discriminant subtype's range (RM 3.7.1).
                         * The static size is 0 because bounds aren't known at compile
                         * time; use max extent for the record layout so subsequent
                         * components are placed at the correct fixed offset. */
                        if (comp_type and comp_size == 0 and Type_Is_Array_Like(comp_type)
                            and comp_type->array.is_constrained
                            and comp_type->array.index_count > 0) {
                            int128_t max_count = 1;
                            bool got_max = true;
                            for (uint32_t xi = 0; xi < comp_type->array.index_count; xi++) {
                                Type_Bound *alb = &comp_type->array.indices[xi].low_bound;
                                Type_Bound *ahb = &comp_type->array.indices[xi].high_bound;
                                int128_t lo = 0, hi = 0;
                                /* Low bound: static or from index type */
                                if (alb->kind == BOUND_INTEGER) {
                                    lo = alb->int_value;
                                } else if (alb->kind == BOUND_EXPR and alb->expr
                                           and alb->expr->symbol and alb->expr->symbol->type) {
                                    Type_Info *st = alb->expr->symbol->type;
                                    if (st->low_bound.kind == BOUND_INTEGER)
                                        lo = st->low_bound.int_value;
                                    else { got_max = false; break; }
                                } else { got_max = false; break; }
                                /* High bound: static or max from discriminant type */
                                if (ahb->kind == BOUND_INTEGER) {
                                    hi = ahb->int_value;
                                } else if (ahb->kind == BOUND_EXPR and ahb->expr
                                           and ahb->expr->symbol and ahb->expr->symbol->type) {
                                    Type_Info *st = ahb->expr->symbol->type;
                                    if (st->high_bound.kind == BOUND_INTEGER)
                                        hi = st->high_bound.int_value;
                                    else { got_max = false; break; }
                                } else { got_max = false; break; }
                                int128_t extent = hi - lo + 1;
                                if (extent < 0) extent = 0;
                                max_count *= extent;
                            }
                            if (got_max and max_count > 0) {
                                uint32_t esz = (comp_type->array.element_type and
                                    comp_type->array.element_type->size > 0)
                                    ? comp_type->array.element_type->size : 1;
                                comp_size = (uint32_t)(max_count * esz);
                            }
                        }
                        if (comp->component.init) {
                            /* Propagate component type to aggregate inits */
                            if (comp->component.init->kind == NK_AGGREGATE and
                                not comp->component.init->type and comp_type)
                                comp->component.init->type = comp_type;
                            Resolve_Expression(sm, comp->component.init);
                        }
                        for (uint32_t j = 0; j < comp->component.names.count; j++) {
                            Component_Info *info = &record_type->record.components[comp_idx++];
                            info->name = comp->component.names.items[j]->string_val.text;
                            info->component_type = comp_type;
                            info->byte_offset = offset;
                            info->bit_offset = 0;
                            info->bit_size = comp_type ? comp_type->size * 8 : 64;
                            info->default_expr = comp->component.init;
                            info->is_discriminant = false;
                            info->variant_index = -1;  /* Fixed part */
                            offset += comp_size;
                        }
                    }

                    /* Process fixed (non-variant) components */
                    for (uint32_t i = 0; i < node->record_type.components.count; i++) {
                        Add_Fixed_Component(node->record_type.components.items[i]);
                    }

                    /* Record the variant_offset = end of fixed part */
                    uint32_t variant_offset = offset;
                    record_type->record.variant_offset = variant_offset;

                    /* Process variant part: all variants OVERLAP at variant_offset (RM 3.7.3)
                     * Record size = fixed_part + MAX(variant_sizes), not SUM */
                    if (has_variant_part) {
                        Syntax_Node *vp = node->record_type.variant_part;
                        record_type->record.variant_part_node = vp;

                        /* Allocate variant info array */
                        record_type->record.variant_count = num_variants;
                        record_type->record.variants = Arena_Allocate(
                            num_variants * sizeof(Variant_Info));

                        uint32_t max_variant_size = 0;

                        for (uint32_t vi = 0; vi < vp->variant_part.variants.count; vi++) {
                            Syntax_Node *v = vp->variant_part.variants.items[vi];
                            Variant_Info *vinfo = &record_type->record.variants[vi];

                            /* Extract discriminant value from first choice */
                            vinfo->disc_value = 0;
                            vinfo->is_others = false;
                            if (v->variant.choices.count > 0) {
                                Syntax_Node *choice = v->variant.choices.items[0];
                                if (choice->kind == NK_INTEGER) {
                                    vinfo->disc_value = choice->integer_lit.value;
                                } else if (choice->kind == NK_IDENTIFIER) {
                                    /* Enumeration literal — covers BOOLEAN, CHARACTER,
                                     * and user-defined enum types (RM 3.7.3).
                                     * frame_offset stores the ordinal position for all
                                     * SYMBOL_LITERAL symbols. */
                                    Resolve_Expression(sm, choice);
                                    if (choice->symbol and
                                        choice->symbol->kind == SYMBOL_LITERAL) {
                                        vinfo->disc_value =
                                            (int64_t)choice->symbol->frame_offset;
                                    } else if (choice->symbol and choice->symbol->type and
                                        Type_Is_Enumeration(choice->symbol->type)) {
                                        /* Fallback: search enumeration literals by name */
                                        Type_Info *et = choice->symbol->type;
                                        for (uint32_t li = 0; li < et->enumeration.literal_count; li++) {
                                            if (Slice_Equal_Ignore_Case(et->enumeration.literals[li],
                                                                        choice->string_val.text)) {
                                                vinfo->disc_value = (int64_t)li;
                                                break;
                                            }
                                        }
                                    }
                                } else if (choice->kind == NK_OTHERS) {
                                    vinfo->is_others = true;
                                }
                            }

                            vinfo->first_component = comp_idx;

                            /* Add variant components - all start at variant_offset */
                            uint32_t var_local_offset = 0;
                            uint32_t var_comp_count = 0;
                            for (uint32_t j = 0; j < v->variant.components.count; j++) {
                                Syntax_Node *vc = v->variant.components.items[j];
                                if (vc->kind != NK_COMPONENT_DECL) continue;
                                Resolve_Expression(sm, vc->component.component_type);
                                Type_Info *comp_type = vc->component.component_type ?
                                                       vc->component.component_type->type : sm->type_integer;
                                uint32_t comp_size = comp_type ? comp_type->size : 8;
                                if (vc->component.init) {
                                    if (vc->component.init->kind == NK_AGGREGATE and
                                        not vc->component.init->type and comp_type)
                                        vc->component.init->type = comp_type;
                                    Resolve_Expression(sm, vc->component.init);
                                }
                                for (uint32_t k = 0; k < vc->component.names.count; k++) {
                                    Component_Info *info = &record_type->record.components[comp_idx++];
                                    info->name = vc->component.names.items[k]->string_val.text;
                                    info->component_type = comp_type;
                                    info->byte_offset = variant_offset + var_local_offset;
                                    info->bit_offset = 0;
                                    info->bit_size = comp_type ? comp_type->size * 8 : 64;
                                    info->default_expr = vc->component.init;
                                    info->is_discriminant = false;
                                    info->variant_index = (int32_t)vi;
                                    var_local_offset += comp_size;
                                    var_comp_count++;
                                }
                            }

                            /* Handle nested variant parts recursively (simple flattening) */
                            if (v->variant.variant_part) {
                                Syntax_Node *nvp = v->variant.variant_part;
                                for (uint32_t ni = 0; ni < nvp->variant_part.variants.count; ni++) {
                                    Syntax_Node *nv = nvp->variant_part.variants.items[ni];
                                    for (uint32_t nj = 0; nj < nv->variant.components.count; nj++) {
                                        Syntax_Node *nc = nv->variant.components.items[nj];
                                        if (nc->kind != NK_COMPONENT_DECL) continue;
                                        Resolve_Expression(sm, nc->component.component_type);
                                        Type_Info *comp_type = nc->component.component_type ?
                                                               nc->component.component_type->type : sm->type_integer;
                                        uint32_t comp_size = comp_type ? comp_type->size : 8;
                                        if (nc->component.init) {
                                            if (nc->component.init->kind == NK_AGGREGATE and
                                                not nc->component.init->type and comp_type)
                                                nc->component.init->type = comp_type;
                                            Resolve_Expression(sm, nc->component.init);
                                        }
                                        for (uint32_t k = 0; k < nc->component.names.count; k++) {
                                            Component_Info *info = &record_type->record.components[comp_idx++];
                                            info->name = nc->component.names.items[k]->string_val.text;
                                            info->component_type = comp_type;
                                            info->byte_offset = variant_offset + var_local_offset;
                                            info->bit_offset = 0;
                                            info->bit_size = comp_type ? comp_type->size * 8 : 64;
                                            info->default_expr = nc->component.init;
                                            info->is_discriminant = false;
                                            info->variant_index = (int32_t)vi;
                                            var_local_offset += comp_size;
                                            var_comp_count++;
                                        }
                                    }
                                }
                            }

                            vinfo->component_count = var_comp_count;
                            vinfo->variant_size = var_local_offset;
                            if (var_local_offset > max_variant_size) {
                                max_variant_size = var_local_offset;
                            }
                        }

                        record_type->record.max_variant_size = max_variant_size;
                        /* Record size = fixed part + maximum variant size (RM 3.7.3) */
                        record_type->size = variant_offset + max_variant_size;
                    } else {
                        record_type->size = offset;
                    }
                    record_type->alignment = 8;

                    /* Adjust size for discriminant-dependent array/string components
                     * whose sizes are not included in the static offset sum. The max
                     * size is derived from the discriminant subtype's range (RM 3.7.1). */
                    for (uint32_t aci = 0; aci < record_type->record.component_count; aci++) {
                        Component_Info *acomp = &record_type->record.components[aci];
                        Type_Info *acti = acomp->component_type;
                        if (not acti or not Type_Is_Array_Like(acti)) continue;
                        for (uint32_t axi = 0; axi < acti->array.index_count; axi++) {
                            Type_Bound *alo = &acti->array.indices[axi].low_bound;
                            Type_Bound *ahi = &acti->array.indices[axi].high_bound;
                            if (ahi->kind == BOUND_EXPR and ahi->expr and ahi->expr->symbol) {
                                Symbol *disc_s = ahi->expr->symbol;
                                Type_Info *disc_ty = disc_s->type;
                                if (disc_ty and disc_ty->high_bound.kind == BOUND_INTEGER) {
                                    int64_t max_hi = disc_ty->high_bound.int_value;
                                    int64_t lo_val = (alo->kind == BOUND_INTEGER) ?
                                                      alo->int_value : 0;
                                    int64_t max_ext = max_hi - lo_val + 1;
                                    if (max_ext < 0) max_ext = 0;
                                    uint32_t elem_sz = (acti->array.element_type and
                                        acti->array.element_type->size > 0) ?
                                        acti->array.element_type->size : 1;
                                    uint32_t needed = acomp->byte_offset +
                                        (uint32_t)(max_ext * elem_sz);
                                    if (needed > record_type->size)
                                        record_type->size = needed;
                                }
                            }
                        }
                    }
                }

                node->type = record_type;
                return record_type;
            }

        case NK_SUBTYPE_INDICATION:
            {
                /* Helper: Try to extract a static integer value from a bound expression.
                 * Returns true if value was extracted, false otherwise. */
                bool Try_Static_Bound(Syntax_Node *expr, int64_t *out_val) {
                    if (not expr) return false;
                    if (expr->kind == NK_INTEGER) {
                        *out_val = expr->integer_lit.value;
                        return true;
                    }
                    if (expr->kind == NK_UNARY_OP and expr->unary.operand and
                        expr->unary.operand->kind == NK_INTEGER) {
                        int64_t val = expr->unary.operand->integer_lit.value;
                        if (expr->unary.op == TK_MINUS) val = -val;
                        *out_val = val;
                        return true;
                    }
                    if (expr->symbol and expr->symbol->kind == SYMBOL_LITERAL) {
                        *out_val = expr->symbol->frame_offset;
                        return true;
                    }
                    /* Character literal 'X' — extract ASCII value from text.
                     * Per Ada RM 3.5.2, character position = Character'Pos(C).
                     * Eval_Scalar_Literal handles char literals via
                     * Enumeration_Rep of the entity. */
                    if (expr->kind == NK_CHARACTER) {
                        String_Slice t = expr->string_val.text;
                        if (t.length >= 2) { *out_val = (unsigned char)t.data[1]; return true; }
                        if (t.length == 1) { *out_val = (unsigned char)t.data[0]; return true; }
                    }
                    /* Handle TYPE'POS(X) or TYPE'VAL(N) as NK_APPLY */
                    if (expr->kind == NK_APPLY and expr->apply.prefix and
                        expr->apply.prefix->kind == NK_ATTRIBUTE) {
                        Syntax_Node *attr = expr->apply.prefix;
                        String_Slice attr_name = attr->attribute.name;
                        if (Slice_Equal_Ignore_Case(attr_name, S("POS")) and
                            expr->apply.arguments.count == 1) {
                            Syntax_Node *arg = expr->apply.arguments.items[0];
                            if (arg and arg->symbol and arg->symbol->kind == SYMBOL_LITERAL) {
                                *out_val = arg->symbol->frame_offset;
                                return true;
                            }
                        }
                        /* Handle TYPE'VAL(N) where N is static */
                        if (Slice_Equal_Ignore_Case(attr_name, S("VAL")) and
                            expr->apply.arguments.count == 1) {
                            Syntax_Node *arg = expr->apply.arguments.items[0];
                            int64_t inner_val;
                            if (Try_Static_Bound(arg, &inner_val)) {
                                *out_val = inner_val;
                                return true;
                            }
                        }
                    }
                    /* Handle type conversions: TYPE_NAME(arg) where arg is static */
                    if (expr->kind == NK_APPLY and expr->apply.prefix and
                        expr->apply.prefix->kind == NK_IDENTIFIER and
                        expr->apply.prefix->symbol and
                        expr->apply.prefix->symbol->kind == SYMBOL_TYPE and
                        expr->apply.arguments.count == 1) {
                        int64_t arg_val;
                        if (Try_Static_Bound(expr->apply.arguments.items[0], &arg_val)) {
                            *out_val = arg_val;
                            return true;
                        }
                    }
                    /* Handle TYPE'VAL(...) or TYPE'POS(...) as NK_ATTRIBUTE with arguments */
                    if (expr->kind == NK_ATTRIBUTE and expr->attribute.arguments.count == 1) {
                        String_Slice attr_name = expr->attribute.name;
                        Syntax_Node *arg = expr->attribute.arguments.items[0];
                        if (Slice_Equal_Ignore_Case(attr_name, S("VAL"))) {
                            int64_t inner_val;
                            if (Try_Static_Bound(arg, &inner_val)) {
                                *out_val = inner_val;
                                return true;
                            }
                        }
                        if (Slice_Equal_Ignore_Case(attr_name, S("POS"))) {
                            if (arg and arg->symbol and arg->symbol->kind == SYMBOL_LITERAL) {
                                *out_val = arg->symbol->frame_offset;
                                return true;
                            }
                        }
                    }
                    return false;
                }

                /* Resolve the base type */
                Resolve_Expression(sm, node->subtype_ind.subtype_mark);
                Type_Info *base_type = node->subtype_ind.subtype_mark->type;

                if (not base_type) {
                    return NULL;
                }

                /* Check for index constraint (STRING(1..5) style) */
                Syntax_Node *constraint = node->subtype_ind.constraint;
                /* For access-to-array, the index constraint applies to the
                 * designated type.  Resolve by creating a constrained access
                 * type whose designated_type is a constrained array. (RM 3.7.1) */
                if (constraint and constraint->kind == NK_INDEX_CONSTRAINT and
                    Type_Is_Access(base_type) and base_type->access.designated_type and
                    Type_Is_Array_Like(base_type->access.designated_type)) {
                    Type_Info *des_base = base_type->access.designated_type;
                    Type_Info *des_con = Type_New(TYPE_ARRAY, des_base->name);
                    *des_con = *des_base;
                    des_con->base_type = des_base;
                    des_con->array.is_constrained = true;
                    des_con->array.index_count = (uint32_t)constraint->index_constraint.ranges.count;
                    if (des_con->array.index_count > 0) {
                        des_con->array.indices = Arena_Allocate(
                            des_con->array.index_count * sizeof(Index_Info));
                        for (uint32_t i = 0; i < des_con->array.index_count; i++) {
                            Syntax_Node *range = constraint->index_constraint.ranges.items[i];
                            Resolve_Expression(sm, range);
                            Index_Info *info = &des_con->array.indices[i];
                            /* Inherit index_type from base (e.g., POSITIVE for STRING) */
                            if (des_base->array.index_count > i and des_base->array.indices[i].index_type) {
                                info->index_type = des_base->array.indices[i].index_type;
                            } else {
                                info->index_type = sm->type_integer;
                            }
                            if (range->kind == NK_RANGE) {
                                if (range->range.low) {
                                    double v = Eval_Const_Numeric(range->range.low);
                                    if (v == v) info->low_bound = (Type_Bound){
                                        .kind = BOUND_INTEGER, .int_value = (int128_t)v};
                                    else info->low_bound = (Type_Bound){
                                        .kind = BOUND_EXPR, .expr = range->range.low};
                                }
                                if (range->range.high) {
                                    double v = Eval_Const_Numeric(range->range.high);
                                    if (v == v) info->high_bound = (Type_Bound){
                                        .kind = BOUND_INTEGER, .int_value = (int128_t)v};
                                    else info->high_bound = (Type_Bound){
                                        .kind = BOUND_EXPR, .expr = range->range.high};
                                }
                            }
                        }
                    }
                    Type_Info *acc_con = Type_New(TYPE_ACCESS, base_type->name);
                    *acc_con = *base_type;
                    acc_con->base_type = base_type;
                    acc_con->access.designated_type = des_con;
                    node->type = acc_con;
                    return acc_con;
                }
                if (constraint and constraint->kind == NK_INDEX_CONSTRAINT and
                    Type_Is_Array_Like(base_type)) {
                    /* Create constrained array type */
                    Type_Info *constrained = Type_New(TYPE_ARRAY, base_type->name);
                    constrained->array.is_constrained = true;
                    constrained->array.index_count = (uint32_t)constraint->index_constraint.ranges.count;
                    /* Set base_type to original type for tracing unconstrained arrays */
                    constrained->base_type = base_type;

                    /* For STRING, element type is CHARACTER */
                    if (Type_Is_String(base_type)) {
                        constrained->array.element_type = sm->type_character;
                    } else if (base_type->array.element_type) {
                        constrained->array.element_type = base_type->array.element_type;
                    }

                    /* Process index constraints */
                    if (constrained->array.index_count > 0) {
                        constrained->array.indices = Arena_Allocate(
                            constrained->array.index_count * sizeof(Index_Info));

                        for (uint32_t i = 0; i < constrained->array.index_count; i++) {
                            Syntax_Node *range = constraint->index_constraint.ranges.items[i];
                            Resolve_Expression(sm, range);

                            Index_Info *info = &constrained->array.indices[i];
                            /* Inherit index_type from base (e.g., POSITIVE for STRING) */
                            if (base_type->array.index_count > i and base_type->array.indices[i].index_type) {
                                info->index_type = base_type->array.indices[i].index_type;
                            } else {
                                info->index_type = sm->type_integer;
                            }

                            if (range->kind == NK_RANGE) {
                                /* Try to evaluate bounds as static constants */
                                if (range->range.low) {
                                    double val = Eval_Const_Numeric(range->range.low);
                                    if (val == val) {  /* Not NaN - static value */
                                        info->low_bound = (Type_Bound){
                                            .kind = BOUND_INTEGER,
                                            .int_value = (int64_t)val
                                        };
                                    } else {
                                        /* Non-static bound - store expression reference */
                                        info->low_bound = (Type_Bound){
                                            .kind = BOUND_EXPR,
                                            .expr = range->range.low
                                        };
                                    }
                                }
                                if (range->range.high) {
                                    double val = Eval_Const_Numeric(range->range.high);
                                    if (val == val) {  /* Not NaN - static value */
                                        info->high_bound = (Type_Bound){
                                            .kind = BOUND_INTEGER,
                                            .int_value = (int64_t)val
                                        };
                                    } else {
                                        /* Non-static bound - store expression reference */
                                        info->high_bound = (Type_Bound){
                                            .kind = BOUND_EXPR,
                                            .expr = range->range.high
                                        };
                                    }
                                }
                            }
                        }

                        /* Compute size - only for fully static bounds */
                        {
                            bool all_static = true;
                            int128_t count = 1;
                            for (uint32_t i = 0; i < constrained->array.index_count; i++) {
                                Type_Bound *lo_b = &constrained->array.indices[i].low_bound;
                                Type_Bound *hi_b = &constrained->array.indices[i].high_bound;
                                if ((lo_b->kind == BOUND_EXPR and lo_b->expr and lo_b->expr->symbol) or
                                    (hi_b->kind == BOUND_EXPR and hi_b->expr and hi_b->expr->symbol)) {
                                    all_static = false; break;
                                }
                                int128_t lo = Type_Bound_Value(*lo_b);
                                int128_t hi = Type_Bound_Value(*hi_b);
                                int128_t dim = hi - lo + 1;
                                if (dim < 0) dim = 0;
                                count *= dim;
                            }
                            if (not all_static) {
                                /* Discriminant-dependent bounds: size unknown at compile
                                 * time.  Mark with 0 so record layout uses max. (RM 3.7.1) */
                                constrained->size = 0;
                            } else if (all_static and count >= 0) {
                                uint32_t elem_size = constrained->array.element_type ?
                                                     constrained->array.element_type->size : 1;
                                constrained->size = (uint32_t)(count * elem_size);
                            }
                        }
                    }

                    node->type = constrained;
                    return constrained;
                }

                /* Check for scalar range constraint (ENUM RANGE A..B or INTEGER RANGE X..Y) */
                if (constraint and constraint->kind == NK_RANGE_CONSTRAINT) {
                    Syntax_Node *range = constraint->range_constraint.range;
                    if (range) {
                        Resolve_Expression(sm, range);

                        /* Create a constrained subtype */
                        Type_Info *constrained = Type_New(base_type->kind, base_type->name);
                        constrained->base_type = base_type;
                        constrained->size = base_type->size;
                        constrained->alignment = base_type->alignment;

                        /* Copy type-specific info from base type */
                        if (Type_Is_Enumeration(base_type)) {
                            constrained->enumeration = base_type->enumeration;
                        } else if (Type_Is_Fixed_Point(base_type)) {
                            constrained->fixed = base_type->fixed;
                        }

                        /* Set bounds from range.
                         * Following GNAT's approach: try compile-time evaluation first,
                         * if not possible, store expression for later evaluation. */
                        if (range->kind == NK_RANGE) {
                            Syntax_Node *lo = range->range.low;
                            Syntax_Node *hi = range->range.high;
                            int64_t val;
                            if (lo) {
                                if (Try_Static_Bound(lo, &val)) {
                                    constrained->low_bound = (Type_Bound){
                                        .kind = BOUND_INTEGER, .int_value = val
                                    };
                                } else {
                                    /* Store expression for later evaluation */
                                    constrained->low_bound = (Type_Bound){
                                        .kind = BOUND_EXPR, .expr = lo
                                    };
                                }
                            }
                            if (hi) {
                                if (Try_Static_Bound(hi, &val)) {
                                    constrained->high_bound = (Type_Bound){
                                        .kind = BOUND_INTEGER, .int_value = val
                                    };
                                } else {
                                    /* Store expression for later evaluation */
                                    constrained->high_bound = (Type_Bound){
                                        .kind = BOUND_EXPR, .expr = hi
                                    };
                                }
                            }
                        }

                        node->type = constrained;
                        return constrained;
                    }
                }

                /* Check for DELTA constraint (fixed-point subtypes with different delta) */
                if (constraint and constraint->kind == NK_DELTA_CONSTRAINT) {
                    Resolve_Expression(sm, constraint->delta_constraint.delta_expr);
                    if (constraint->delta_constraint.range)
                        Resolve_Expression(sm, constraint->delta_constraint.range);

                    /* Create constrained fixed-point subtype with new delta */
                    Type_Info *constrained = Type_New(TYPE_FIXED, base_type->name);
                    constrained->base_type = base_type;
                    constrained->size = base_type->size;
                    constrained->alignment = base_type->alignment;

                    /* Evaluate the delta expression */
                    double delta = Eval_Const_Numeric(constraint->delta_constraint.delta_expr);
                    if (delta != delta or delta <= 0.0) delta = base_type->fixed.delta;

                    /* Compute small as largest power of 2 <= delta (per RM 3.5.9) */
                    double small = 1.0;
                    if (delta > 0.0) {
                        while (small > delta) small /= 2.0;
                        while (small * 2.0 <= delta) small *= 2.0;
                    }

                    constrained->fixed.delta = delta;
                    constrained->fixed.small = small;

                    /* Compute scale factor: small = 2^scale */
                    int scale = 0;
                    double temp = small;
                    while (temp < 1.0 and scale > -64) { temp *= 2.0; scale--; }
                    while (temp > 1.0 and scale < 64) { temp /= 2.0; scale++; }
                    constrained->fixed.scale = scale;

                    /* Set bounds from range, or inherit from base type */
                    /* Start by inheriting base type bounds */
                    constrained->low_bound = base_type->low_bound;
                    constrained->high_bound = base_type->high_bound;
                    /* If explicit range given, override with evaluated bounds.
                     * Following GNAT's approach: try compile-time evaluation first,
                     * if not possible, store expression for later evaluation. */
                    if (constraint->delta_constraint.range and
                        constraint->delta_constraint.range->kind == NK_RANGE) {
                        Syntax_Node *range = constraint->delta_constraint.range;
                        if (range->range.low) {
                            double lo = Eval_Const_Numeric(range->range.low);
                            if (lo == lo) {
                                /* Compile-time known */
                                constrained->low_bound = (Type_Bound){
                                    .kind = BOUND_FLOAT, .float_value = lo
                                };
                            } else {
                                /* Store expression for later evaluation (per GNAT sem_attr) */
                                constrained->low_bound = (Type_Bound){
                                    .kind = BOUND_EXPR, .expr = range->range.low
                                };
                            }
                        }
                        if (range->range.high) {
                            double hi = Eval_Const_Numeric(range->range.high);
                            if (hi == hi) {
                                /* Compile-time known */
                                constrained->high_bound = (Type_Bound){
                                    .kind = BOUND_FLOAT, .float_value = hi
                                };
                            } else {
                                /* Store expression for later evaluation (per GNAT sem_attr) */
                                constrained->high_bound = (Type_Bound){
                                    .kind = BOUND_EXPR, .expr = range->range.high
                                };
                            }
                        }
                    }

                    node->type = constrained;
                    return constrained;
                }

                /* Check for DIGITS constraint (floating-point subtypes) */
                if (constraint and constraint->kind == NK_DIGITS_CONSTRAINT) {
                    Resolve_Expression(sm, constraint->digits_constraint.digits_expr);
                    if (constraint->digits_constraint.range)
                        Resolve_Expression(sm, constraint->digits_constraint.range);

                    /* Create constrained floating-point subtype with specified DIGITS */
                    Type_Info *constrained = Type_New(TYPE_FLOAT, base_type->name);
                    constrained->base_type = base_type;
                    constrained->size = base_type->size;
                    constrained->alignment = base_type->alignment;

                    /* Evaluate the digits expression */
                    double digits_val = Eval_Const_Numeric(constraint->digits_constraint.digits_expr);
                    if (digits_val != digits_val or digits_val < 1) digits_val = base_type->flt.digits;
                    constrained->flt.digits = (int)digits_val;

                    /* Set bounds from range, or inherit from base type */
                    constrained->low_bound = base_type->low_bound;
                    constrained->high_bound = base_type->high_bound;

                    /* If explicit range given, override with evaluated bounds */
                    if (constraint->digits_constraint.range and
                        constraint->digits_constraint.range->kind == NK_RANGE) {
                        Syntax_Node *range = constraint->digits_constraint.range;
                        if (range->range.low) {
                            double lo = Eval_Const_Numeric(range->range.low);
                            if (lo == lo) {
                                constrained->low_bound = (Type_Bound){
                                    .kind = BOUND_FLOAT, .float_value = lo
                                };
                            } else {
                                constrained->low_bound = (Type_Bound){
                                    .kind = BOUND_EXPR, .expr = range->range.low
                                };
                            }
                        }
                        if (range->range.high) {
                            double hi = Eval_Const_Numeric(range->range.high);
                            if (hi == hi) {
                                constrained->high_bound = (Type_Bound){
                                    .kind = BOUND_FLOAT, .float_value = hi
                                };
                            } else {
                                constrained->high_bound = (Type_Bound){
                                    .kind = BOUND_EXPR, .expr = range->range.high
                                };
                            }
                        }
                    }

                    node->type = constrained;
                    return constrained;
                }

                /* Reclassify NK_INDEX_CONSTRAINT as discriminant constraint
                 * when the base type is a discriminated record (RM 3.7.2).
                 * Also handles access-to-record types (RM 3.7.1).
                 * Positional discriminant constraints like R1(IDENT_BOOL(TRUE))
                 * get parsed as NK_INDEX_CONSTRAINT because they lack named assocs.
                 * Convert each range item to a positional association. */
                Type_Info *disc_target = base_type;
                bool disc_via_access = false;
                if (Type_Is_Access(base_type) and base_type->access.designated_type and
                    Type_Is_Record(base_type->access.designated_type) and
                    base_type->access.designated_type->record.has_discriminants) {
                    disc_target = base_type->access.designated_type;
                    disc_via_access = true;
                }
                if (constraint and constraint->kind == NK_INDEX_CONSTRAINT and
                    Type_Is_Record(disc_target) and disc_target->record.has_discriminants) {
                    Syntax_Node *disc_c = Node_New(NK_DISCRIMINANT_CONSTRAINT, constraint->location);
                    disc_c->discriminant_constraint.associations.count = constraint->index_constraint.ranges.count;
                    disc_c->discriminant_constraint.associations.capacity = constraint->index_constraint.ranges.capacity;
                    disc_c->discriminant_constraint.associations.items = Arena_Allocate(
                        disc_c->discriminant_constraint.associations.count * sizeof(Syntax_Node *));
                    for (uint32_t i = 0; i < constraint->index_constraint.ranges.count; i++) {
                        Syntax_Node *expr = constraint->index_constraint.ranges.items[i];
                        /* Wrap each expression in an association node (positional) */
                        Syntax_Node *assoc = Node_New(NK_ASSOCIATION, expr->location);
                        assoc->association.expression = expr;
                        assoc->association.choices.count = 0;
                        disc_c->discriminant_constraint.associations.items[i] = assoc;
                    }
                    node->subtype_ind.constraint = disc_c;
                    constraint = disc_c;
                }

                /* Check for discriminant constraint (REC(A => E1, B => E2) style)
                 * Discriminant constraints use named associations where the choices
                 * are discriminant names - they should NOT be resolved as identifiers.
                 * Only the value expressions should be resolved. (RM 3.7.2) */
                if (constraint and constraint->kind == NK_DISCRIMINANT_CONSTRAINT) {
                    uint32_t assoc_count = constraint->discriminant_constraint.associations.count;
                    for (uint32_t i = 0; i < assoc_count; i++) {
                        Syntax_Node *assoc = constraint->discriminant_constraint.associations.items[i];
                        if (assoc->kind == NK_ASSOCIATION and assoc->association.expression) {
                            /* Only resolve the value expression, not the choices */
                            Resolve_Expression(sm, assoc->association.expression);
                        }
                    }

                    /* Create a constrained subtype with discriminant values stored.
                     * For access-to-record, create a constrained designated type
                     * and wrap it in a new access type. (RM 3.7.1) */
                    Type_Info *rec_base = disc_target;
                    if (Type_Is_Record(rec_base) and rec_base->record.has_discriminants) {
                        Type_Info *constrained = Type_New(TYPE_RECORD, rec_base->name);
                        *constrained = *rec_base;  /* Copy all fields */
                        constrained->base_type = rec_base;
                        constrained->record.is_constrained = true;
                        constrained->record.has_disc_constraints = true;

                        /* Allocate and fill constraint value + expression arrays */
                        uint32_t dc = rec_base->record.discriminant_count;
                        constrained->record.disc_constraint_values = Arena_Allocate(
                            dc * sizeof(int64_t));
                        constrained->record.disc_constraint_exprs = Arena_Allocate(
                            dc * sizeof(Syntax_Node *));
                        for (uint32_t ci = 0; ci < dc; ci++) {
                            constrained->record.disc_constraint_values[ci] = 0;
                            constrained->record.disc_constraint_exprs[ci] = NULL;
                        }

                        /* Extract discriminant values from associations.
                         * For static values, store the integer. For runtime expressions
                         * (function calls etc.), store the AST node for codegen evaluation. */
                        for (uint32_t i = 0; i < assoc_count; i++) {
                            Syntax_Node *assoc = constraint->discriminant_constraint.associations.items[i];
                            if (assoc->kind != NK_ASSOCIATION) continue;
                            Syntax_Node *expr = assoc->association.expression;
                            int64_t val = 0;
                            bool is_static = false;
                            if (expr and expr->kind == NK_INTEGER) {
                                val = expr->integer_lit.value;
                                is_static = true;
                            } else if (expr and expr->kind == NK_IDENTIFIER and expr->symbol and
                                       expr->symbol->type and Type_Is_Boolean(expr->symbol->type)) {
                                /* BOOLEAN literal: FALSE=0, TRUE=1 */
                                val = Slice_Equal_Ignore_Case(expr->string_val.text, S("TRUE"))
                                    ? 1 : 0;
                                is_static = true;
                            } else if (expr and expr->kind == NK_IDENTIFIER and expr->symbol and
                                       expr->symbol->type and Type_Is_Enumeration(expr->symbol->type)) {
                                /* Enum literal: find position */
                                Type_Info *et = expr->symbol->type;
                                for (uint32_t li = 0; li < et->enumeration.literal_count; li++) {
                                    if (Slice_Equal_Ignore_Case(et->enumeration.literals[li],
                                                                expr->string_val.text)) {
                                        val = (int64_t)li;
                                        break;
                                    }
                                }
                                is_static = true;
                            } else if (expr and expr->kind == NK_IDENTIFIER and expr->symbol and
                                       expr->symbol->kind == SYMBOL_CONSTANT) {
                                /* Named number or constant */
                                double cv = Eval_Const_Numeric(expr);
                                if (cv == cv) { val = (int64_t)cv; is_static = true; }
                            }

                            /* Match association to discriminant by position or name */
                            if (assoc->association.choices.count > 0) {
                                for (uint32_t ci = 0; ci < assoc->association.choices.count; ci++) {
                                    Syntax_Node *choice = assoc->association.choices.items[ci];
                                    if (choice->kind == NK_IDENTIFIER) {
                                        for (uint32_t di = 0; di < dc; di++) {
                                            if (Slice_Equal_Ignore_Case(
                                                    constrained->record.components[di].name,
                                                    choice->string_val.text)) {
                                                constrained->record.disc_constraint_values[di] = val;
                                                if (not is_static)
                                                    constrained->record.disc_constraint_exprs[di] = expr;
                                                break;
                                            }
                                        }
                                    }
                                }
                            } else if (i < dc) {
                                /* Positional */
                                constrained->record.disc_constraint_values[i] = val;
                                if (not is_static)
                                    constrained->record.disc_constraint_exprs[i] = expr;
                            }
                        }

                        if (disc_via_access) {
                            /* Wrap constrained record in a new access type */
                            Type_Info *acc_con = Type_New(TYPE_ACCESS, base_type->name);
                            *acc_con = *base_type;
                            acc_con->base_type = base_type;
                            acc_con->access.designated_type = constrained;
                            node->type = acc_con;
                            return acc_con;
                        }
                        node->type = constrained;
                        return constrained;
                    }

                    /* Fallback: return base type if not a discriminated record */
                    node->type = base_type;
                    return base_type;
                }

                /* Otherwise just use base type */
                node->type = base_type;
                return base_type;
            }

        case NK_INTEGER_TYPE:
            {
                if (node->integer_type.is_modular) {
                    /* Modular type definition: type T is mod M (RM 3.5.4)
                     * Range is 0 .. M-1, all arithmetic wraps modulo M.
                     * The modulus expression is stored in integer_type.range. */
                    Type_Info *mod_type = Type_New(TYPE_MODULAR, S(""));

                    Resolve_Expression(sm, node->integer_type.range);

                    /* Evaluate modulus using 128-bit-precise evaluator.
                     * uint128_t handles 2**64 and 2**128 directly — no sentinel
                     * hacks needed.  2**128 wraps to 0 in uint128_t arithmetic
                     * (same as 2**64 wraps to 0 in uint64_t), so we detect it
                     * by checking if the exponent is 128.  For 2**64, the
                     * evaluator returns (uint128_t)1 << 64 = exact value. */
                    uint128_t modulus = 0;
                    bool is_pow2_128 = false;  /* true only for mod 2**128 */
                    if (Eval_Const_Uint128(node->integer_type.range, &modulus)) {
                        if (modulus == 0) {
                            /* 2**128 overflows uint128_t to 0.  Detect it
                             * explicitly from the AST exponent value. */
                            Syntax_Node *expr = node->integer_type.range;
                            if (expr->kind == NK_BINARY_OP and expr->binary.op == TK_EXPON) {
                                uint128_t base, exp;
                                if (Eval_Const_Uint128(expr->binary.left, &base) and
                                    Eval_Const_Uint128(expr->binary.right, &exp) and
                                    base == 2 and exp == 128) {
                                    is_pow2_128 = true;
                                }
                            }
                        }
                    } else {
                        /* Non-constant modulus: use double evaluator as fallback */
                        double dval = Eval_Const_Numeric(node->integer_type.range);
                        if (dval == dval and dval > 0) modulus = (uint128_t)dval;
                    }

                    mod_type->modulus = modulus;
                    node->integer_type.modulus = modulus;

                    /* Bounds: 0 .. modulus-1 (RM 3.5.4(9)).
                     * int128_t can represent 0 .. 2^127-1 directly.  For
                     * mod 2**128, the high bound is 2^128-1 which overflows
                     * int128_t, so we store it as -1 (all bits set). */
                    mod_type->low_bound = (Type_Bound){ .kind = BOUND_INTEGER, .int_value = 0 };
                    if (is_pow2_128) {
                        /* 2^128 - 1 = (int128_t)(-1) — all 128 bits set */
                        mod_type->high_bound = (Type_Bound){ .kind = BOUND_INTEGER, .int_value = (int128_t)-1 };
                    } else {
                        mod_type->high_bound = (Type_Bound){ .kind = BOUND_INTEGER, .int_value = (int128_t)(modulus - 1) };
                    }

                    /* Compute size from modulus */
                    uint32_t bits;
                    if (is_pow2_128) {
                        bits = Width_128;
                    } else {
                        bits = Bits_For_Modulus(modulus);
                    }
                    mod_type->size = (uint32_t)(bits / 8);
                    mod_type->alignment = mod_type->size;
                    if (mod_type->alignment > 16) mod_type->alignment = 16;  /* Max alignment 16 bytes for i128 */

                    node->type = mod_type;
                    return mod_type;

                } else {
                    /* Signed integer type definition: range L .. H */
                    Type_Info *int_type = Type_New(TYPE_INTEGER, S(""));

                    /* Resolve range bounds if present */
                    if (node->integer_type.range) {
                        Resolve_Expression(sm, node->integer_type.range);
                        Syntax_Node *range = node->integer_type.range;
                        if (range->kind == NK_RANGE and range->range.low and range->range.high) {
                            /* Extract low bound - literals, unary minus, or constants */
                            Syntax_Node *lo = range->range.low;
                            if (lo->kind == NK_INTEGER) {
                                int_type->low_bound = (Type_Bound){
                                    .kind = BOUND_INTEGER,
                                    .int_value = lo->integer_lit.value
                                };
                            } else if (lo->kind == NK_UNARY_OP and lo->unary.operand and
                                       lo->unary.operand->kind == NK_INTEGER) {
                                int64_t val = lo->unary.operand->integer_lit.value;
                                if (lo->unary.op == TK_MINUS) val = -val;
                                int_type->low_bound = (Type_Bound){
                                    .kind = BOUND_INTEGER,
                                    .int_value = val
                                };
                            } else {
                                double val = Eval_Const_Numeric(lo);
                                if (val == val) {
                                    int_type->low_bound = (Type_Bound){
                                        .kind = BOUND_INTEGER,
                                        .int_value = (int64_t)val
                                    };
                                }
                            }
                            /* Extract high bound - literals, unary minus, or constants */
                            Syntax_Node *hi = range->range.high;
                            if (hi->kind == NK_INTEGER) {
                                int_type->high_bound = (Type_Bound){
                                    .kind = BOUND_INTEGER,
                                    .int_value = hi->integer_lit.value
                                };
                            } else if (hi->kind == NK_UNARY_OP and hi->unary.operand and
                                       hi->unary.operand->kind == NK_INTEGER) {
                                int64_t val = hi->unary.operand->integer_lit.value;
                                if (hi->unary.op == TK_MINUS) val = -val;
                                int_type->high_bound = (Type_Bound){
                                    .kind = BOUND_INTEGER,
                                    .int_value = val
                                };
                            } else {
                                double val = Eval_Const_Numeric(hi);
                                if (val == val) {
                                    int_type->high_bound = (Type_Bound){
                                        .kind = BOUND_INTEGER,
                                        .int_value = (int64_t)val
                                    };
                                }
                            }
                        }
                    }

                    /* Compute appropriate size from bounds */
                    if (int_type->low_bound.kind == BOUND_INTEGER and
                        int_type->high_bound.kind == BOUND_INTEGER) {
                        uint32_t bits = Bits_For_Range(int_type->low_bound.int_value,
                                                       int_type->high_bound.int_value);
                        int_type->size = (uint32_t)(bits / 8);
                        if (int_type->size == 0) int_type->size = 1;
                        int_type->alignment = int_type->size;
                        if (int_type->alignment > 8) int_type->alignment = 8;
                    } else {
                        int_type->size = 8;  /* Default to 64-bit */
                        int_type->alignment = 8;
                    }
                    node->type = int_type;
                    return int_type;
                }
            }

        case NK_REAL_TYPE:
            {
                /* Real type definition: digits D or delta D */
                if (node->real_type.delta) {
                    /* Fixed-point type: TYPE_FIXED with delta */
                    Type_Info *fixed_type = Type_New(TYPE_FIXED, S(""));
                    Resolve_Expression(sm, node->real_type.delta);

                    /* Extract delta value using constant expression evaluation */
                    double delta = Eval_Const_Numeric(node->real_type.delta);
                    if (delta != delta or delta <= 0.0) delta = 0.001;  /* NaN or invalid -> fallback */

                    /* Compute small as largest power of 2 <= delta (per RM 3.5.9) */
                    double small = 1.0;
                    if (delta > 0.0) {
                        /* Find largest 2^n <= delta */
                        while (small > delta) small /= 2.0;
                        while (small * 2.0 <= delta) small *= 2.0;
                    }

                    /* Compute scale factor: small = 2^scale */
                    int scale = 0;
                    double temp = small;
                    if (temp >= 1.0) {
                        while (temp >= 2.0) { temp /= 2.0; scale++; }
                    } else {
                        while (temp < 1.0) { temp *= 2.0; scale--; }
                    }

                    fixed_type->fixed.delta = delta;
                    fixed_type->fixed.small = small;
                    fixed_type->fixed.scale = scale;

                    /* Resolve range if present */
                    if (node->real_type.range) {
                        Resolve_Expression(sm, node->real_type.range);
                        Syntax_Node *range = node->real_type.range;
                        if (range->kind == NK_RANGE) {
                            /* Extract bound values using constant expression evaluation */
                            Syntax_Node *lo = range->range.low;
                            Syntax_Node *hi = range->range.high;
                            if (lo) {
                                double val = Eval_Const_Numeric(lo);
                                if (val == val) {  /* not NaN */
                                    fixed_type->low_bound = (Type_Bound){.kind = BOUND_FLOAT, .float_value = val};
                                }
                            }
                            if (hi) {
                                double val = Eval_Const_Numeric(hi);
                                if (val == val) {  /* not NaN */
                                    fixed_type->high_bound = (Type_Bound){.kind = BOUND_FLOAT, .float_value = val};
                                }
                            }
                        }
                    }

                    /* Size: typically 32 or 64 bits depending on range and precision */
                    fixed_type->size = 8;  /* 64-bit for safe default */
                    fixed_type->alignment = 8;
                    node->type = fixed_type;
                    return fixed_type;
                } else {
                    /* Floating-point type: digits D */
                    Type_Info *float_type = Type_New(TYPE_FLOAT, S(""));

                    /* Resolve digits expression */
                    if (node->real_type.precision) {
                        Resolve_Expression(sm, node->real_type.precision);
                    }

                    /* Resolve range if present */
                    if (node->real_type.range) {
                        Resolve_Expression(sm, node->real_type.range);
                    }

                    /* Size based on digits: <=6 = float, >6 = double */
                    int digits = 15;  /* Default double precision */
                    if (node->real_type.precision) {
                        if (node->real_type.precision->kind == NK_INTEGER) {
                            digits = (int)node->real_type.precision->integer_lit.value;
                        } else {
                            double val = Eval_Const_Numeric(node->real_type.precision);
                            if (val == val) digits = (int)val;
                        }
                    }
                    float_type->flt.digits = digits;  /* Store declared DIGITS */
                    float_type->size = (digits <= 6) ? 4 : 8;
                    float_type->alignment = float_type->size;

                    /* Set bounds from range constraint if present */
                    if (node->real_type.range and node->real_type.range->kind == NK_RANGE) {
                        Syntax_Node *range = node->real_type.range;
                        if (range->range.low) {
                            double lo = Eval_Const_Numeric(range->range.low);
                            if (lo == lo) {
                                float_type->low_bound = (Type_Bound){
                                    .kind = BOUND_FLOAT, .float_value = lo
                                };
                            } else {
                                float_type->low_bound = (Type_Bound){
                                    .kind = BOUND_EXPR, .expr = range->range.low
                                };
                            }
                        }
                        if (range->range.high) {
                            double hi = Eval_Const_Numeric(range->range.high);
                            if (hi == hi) {
                                float_type->high_bound = (Type_Bound){
                                    .kind = BOUND_FLOAT, .float_value = hi
                                };
                            } else {
                                float_type->high_bound = (Type_Bound){
                                    .kind = BOUND_EXPR, .expr = range->range.high
                                };
                            }
                        }
                    }

                    node->type = float_type;
                    return float_type;
                }
            }

        default:
            return NULL;
    }
}

/* ─────────────────────────────────────────────────────────────────────────
 * §12.2 Statement Resolution
 * ───────────────────────────────────────────────────────────────────────── */

static void Resolve_Declaration_List(Symbol_Manager *sm, Node_List *list);
/* Freeze all types declared in a list
 * Per RM 13.14: At the end of a declarative part, all entities are frozen */
static void Freeze_Declaration_List(Node_List *list) {
    for (uint32_t i = 0; i < list->count; i++) {
        Syntax_Node *node = list->items[i];
        if (not node) continue;

        switch (node->kind) {
            case NK_TYPE_DECL:
            case NK_SUBTYPE_DECL:
                if (node->symbol and node->symbol->type) {
                    Freeze_Type(node->symbol->type);
                }
                break;

            case NK_OBJECT_DECL:
                /* Objects already freeze their type at declaration */
                break;

            case NK_PROCEDURE_BODY:
            case NK_FUNCTION_BODY:
                /* Subprogram bodies freeze all visible entities */
                break;

            default:
                break;
        }
    }
}

/* Populate a package symbol's exported[] array from its visible declarations.
 * This must be called after all visible declarations are resolved so that
 * decl->symbol pointers are valid. Used by both inline packages and loaded specs. */
static void Populate_Package_Exports(Symbol *pkg_sym, Syntax_Node *pkg_spec) {
    if (not pkg_sym or not pkg_spec or pkg_spec->kind != NK_PACKAGE_SPEC) return;

    Node_List *visible = &pkg_spec->package_spec.visible_decls;

    /* Count exports including nested items (enum literals, multiple object names) */
    uint32_t count = 0;
    for (uint32_t i = 0; i < visible->count; i++) {
        Syntax_Node *decl = visible->items[i];
        if (not decl) continue;
        if (decl->kind == NK_OBJECT_DECL) {
            count += (uint32_t)decl->object_decl.names.count;
        } else if (decl->kind == NK_TYPE_DECL or decl->kind == NK_SUBTYPE_DECL) {
            count++;
            /* Enumeration literals (direct or inherited from derived type) */
            if (decl->type_decl.definition and
                decl->type_decl.definition->kind == NK_ENUMERATION_TYPE) {
                count += (uint32_t)decl->type_decl.definition->enum_type.literals.count;
            } else if (decl->symbol and decl->symbol->type and
                       Type_Is_Enumeration(decl->symbol->type) and
                       decl->symbol->type->enumeration.literal_count > 0) {
                /* Derived enum type: count inherited literals */
                count += decl->symbol->type->enumeration.literal_count;
            }
        } else if (decl->kind == NK_PROCEDURE_SPEC or decl->kind == NK_FUNCTION_SPEC or
                   decl->kind == NK_PROCEDURE_BODY or decl->kind == NK_FUNCTION_BODY) {
            count++;
        } else if (decl->kind == NK_EXCEPTION_DECL) {
            count += (uint32_t)decl->exception_decl.names.count;
        } else if (decl->kind == NK_PACKAGE_SPEC) {
            count++;  /* Nested packages */
        } else if (decl->kind == NK_GENERIC_DECL) {
            count++;  /* Nested generics (e.g., TEXT_IO.INTEGER_IO) */
        } else if (decl->kind == NK_TASK_SPEC) {
            count++;  /* Task type/object symbol */
        }
    }

    if (count == 0) return;

    /* Allocate and fill */
    pkg_sym->exported = Arena_Allocate(count * sizeof(Symbol*));
    pkg_sym->exported_count = 0;

    for (uint32_t i = 0; i < visible->count; i++) {
        Syntax_Node *decl = visible->items[i];
        if (not decl) continue;

        if (decl->kind == NK_OBJECT_DECL) {
            for (uint32_t j = 0; j < decl->object_decl.names.count; j++) {
                Syntax_Node *name_node = decl->object_decl.names.items[j];
                if (name_node->symbol) {
                    pkg_sym->exported[pkg_sym->exported_count++] = name_node->symbol;
                }
            }
        } else if ((decl->kind == NK_TYPE_DECL or decl->kind == NK_SUBTYPE_DECL) and decl->symbol) {
            pkg_sym->exported[pkg_sym->exported_count++] = decl->symbol;
            /* Enumeration literals */
            if (decl->type_decl.definition and
                decl->type_decl.definition->kind == NK_ENUMERATION_TYPE) {
                Node_List *lits = &decl->type_decl.definition->enum_type.literals;
                for (uint32_t j = 0; j < lits->count; j++) {
                    if (lits->items[j]->symbol) {
                        pkg_sym->exported[pkg_sym->exported_count++] = lits->items[j]->symbol;
                    }
                }
            } else if (decl->symbol->type and Type_Is_Enumeration(decl->symbol->type) and
                       decl->symbol->type->enumeration.literal_count > 0) {
                /* Derived enum type: export inherited literal symbols.
                 * These were created during NK_TYPE_DECL resolution for NK_DERIVED_TYPE. */
                Type_Info *etype = decl->symbol->type;
                for (uint32_t j = 0; j < etype->enumeration.literal_count; j++) {
                    String_Slice lit_name = etype->enumeration.literals[j];
                    /* Find the literal symbol with matching name and type in scope */
                    bool found = false;
                    if (pkg_sym->scope) {
                        uint32_t h = Symbol_Hash_Name(lit_name);
                        for (Symbol *s = pkg_sym->scope->buckets[h]; s; s = s->next_in_bucket) {
                            if (s->kind == SYMBOL_LITERAL and s->type == etype and
                                Slice_Equal_Ignore_Case(s->name, lit_name)) {
                                pkg_sym->exported[pkg_sym->exported_count++] = s;
                                found = true;
                                break;
                            }
                        }
                    }
                    /* If not found in scope (e.g., overloaded away), create a new symbol */
                    if (!found) {
                        Symbol *lit_sym = Symbol_New(SYMBOL_LITERAL, lit_name, decl->location);
                        lit_sym->type = etype;
                        lit_sym->frame_offset = (int64_t)j;
                        pkg_sym->exported[pkg_sym->exported_count++] = lit_sym;
                    }
                }
            }
        } else if ((decl->kind == NK_PROCEDURE_SPEC or decl->kind == NK_FUNCTION_SPEC or
                    decl->kind == NK_PROCEDURE_BODY or decl->kind == NK_FUNCTION_BODY) and decl->symbol) {
            pkg_sym->exported[pkg_sym->exported_count++] = decl->symbol;
        } else if (decl->kind == NK_EXCEPTION_DECL) {
            for (uint32_t j = 0; j < decl->exception_decl.names.count; j++) {
                Syntax_Node *name_node = decl->exception_decl.names.items[j];
                if (name_node->symbol) {
                    pkg_sym->exported[pkg_sym->exported_count++] = name_node->symbol;
                }
            }
        } else if (decl->kind == NK_PACKAGE_SPEC and decl->symbol) {
            pkg_sym->exported[pkg_sym->exported_count++] = decl->symbol;
        } else if (decl->kind == NK_GENERIC_DECL and decl->symbol) {
            /* Export nested generic packages/subprograms (e.g., TEXT_IO.INTEGER_IO) */
            pkg_sym->exported[pkg_sym->exported_count++] = decl->symbol;
        } else if (decl->kind == NK_TASK_SPEC and decl->symbol) {
            /* Export task type/object symbol.
             * For single tasks (not task types), decl->symbol is the type symbol
             * which carries the TYPE_TASK info and exported entries.
             * RM 9.1: task objects declared in a package spec are visible via
             * selected component notation (e.g., PKG.TASK_NAME.ENTRY). */
            pkg_sym->exported[pkg_sym->exported_count++] = decl->symbol;
        }
    }
}


/* Pre-register labels in a statement list to allow forward gotos.
 * Labels can appear as:
 *   1. NK_LABEL nodes wrapping other statements
 *   2. The .label field of NK_BLOCK or NK_LOOP nodes (Ada allows naming blocks/loops) */
static void Preregister_Labels(Symbol_Manager *sm, Node_List *list) {
    for (uint32_t i = 0; i < list->count; i++) {
        Syntax_Node *node = list->items[i];
        if (not node) continue;

        String_Slice label_name = Empty_Slice;
        Source_Location label_loc = node->location;
        Symbol **label_sym_ptr = NULL;

        switch (node->kind) {
            case NK_LABEL:
                label_name = node->label_node.name;
                label_sym_ptr = &node->label_node.symbol;
                break;
            case NK_BLOCK:
                label_name = node->block_stmt.label;
                label_sym_ptr = &node->block_stmt.label_symbol;
                break;
            case NK_LOOP:
                label_name = node->loop_stmt.label;
                label_sym_ptr = &node->loop_stmt.label_symbol;
                break;
            default:
                break;
        }

        if (label_name.data and label_name.length > 0) {
            Symbol *label_sym = Symbol_New(SYMBOL_LABEL, label_name, label_loc);
            label_sym->type = sm->type_address;
            Symbol_Add(sm, label_sym);
            if (label_sym_ptr) *label_sym_ptr = label_sym;
        }
    }
}

static void Resolve_Statement_List(Symbol_Manager *sm, Node_List *list) {
    /* First pass: register all labels to allow forward gotos */
    Preregister_Labels(sm, list);
    /* Second pass: resolve all statements */
    for (uint32_t i = 0; i < list->count; i++) {
        Resolve_Statement(sm, list->items[i]);
    }
}

static void Resolve_Statement(Symbol_Manager *sm, Syntax_Node *node) {
    if (not node) return;

    switch (node->kind) {
        case NK_ASSIGNMENT:
            Resolve_Expression(sm, node->assignment.target);
            /* Propagate target type to aggregate values for context-dependent typing */
            if (node->assignment.value->kind == NK_AGGREGATE and
                node->assignment.target->type) {
                node->assignment.value->type = node->assignment.target->type;
            }
            Resolve_Expression(sm, node->assignment.value);
            /* Resolve character literal as enum literal in assignment (RM 3.5.1) */
            if (node->assignment.value->kind == NK_CHARACTER and
                node->assignment.target->type) {
                Type_Info *et = node->assignment.target->type;
                /* Follow parent_type (private>full), base_type chains to enum */
                while (et and et->kind != TYPE_ENUMERATION) {
                    if (et->parent_type) et = et->parent_type;
                    else if (et->base_type) et = et->base_type;
                    else break;
                }
                if (et and et->kind == TYPE_ENUMERATION)
                    Resolve_Char_As_Enum(sm, node->assignment.value, et);
            }
            /* Type check: value must be compatible with target */
            if (node->assignment.target->type and node->assignment.value->type) {
                if (not Type_Covers(node->assignment.target->type,
                                node->assignment.value->type)) {
                    Report_Error(node->location, "type mismatch in assignment");
                }
            }
            break;

        case NK_CALL_STMT:
            Resolve_Expression(sm, node->assignment.target);
            break;

        case NK_RETURN:
            if (node->return_stmt.expression) {
                /* Propagate enclosing function's return type to untyped
                 * aggregates so they can resolve component types (RM 5.8) */
                Syntax_Node *rexpr = node->return_stmt.expression;
                if (rexpr->kind == NK_AGGREGATE and not rexpr->type) {
                    Symbol *owner = sm->current_scope->owner;
                    if (owner and owner->kind == SYMBOL_FUNCTION and owner->return_type)
                        rexpr->type = owner->return_type;
                }
                Resolve_Expression(sm, rexpr);
            }
            break;

        case NK_IF:
            Resolve_Expression(sm, node->if_stmt.condition);
            Resolve_Statement_List(sm, &node->if_stmt.then_stmts);
            for (uint32_t i = 0; i < node->if_stmt.elsif_parts.count; i++) {
                Resolve_Statement(sm, node->if_stmt.elsif_parts.items[i]);
            }
            Resolve_Statement_List(sm, &node->if_stmt.else_stmts);
            break;

        case NK_CASE:
            Resolve_Expression(sm, node->case_stmt.expression);
            for (uint32_t i = 0; i < node->case_stmt.alternatives.count; i++) {
                Resolve_Statement(sm, node->case_stmt.alternatives.items[i]);
            }
            break;

        case NK_LOOP:
            {
                Syntax_Node *iter = node->loop_stmt.iteration_scheme;
                bool is_for_loop = iter and iter->kind == NK_BINARY_OP and
                                   iter->binary.op == TK_IN;
                if (is_for_loop) {
                    /* FOR loop - create loop variable in new scope.
                     * Inherit owner from enclosing scope for proper name mangling */
                    Symbol *enclosing_owner = sm->current_scope->owner;
                    Symbol_Manager_Push_Scope(sm, enclosing_owner);
                    Syntax_Node *loop_id = iter->binary.left;
                    /* Resolve range expression FIRST to get its type */
                    Resolve_Expression(sm, iter->binary.right);
                    if (loop_id and loop_id->kind == NK_IDENTIFIER) {
                        Symbol *loop_var = Symbol_New(SYMBOL_VARIABLE,
                                                      loop_id->string_val.text,
                                                      loop_id->location);
                        /* Loop variable type comes from the range expression.
                         * Per Ada RM 5.5(6): if the range is universal_integer,
                         * the loop parameter is of type INTEGER. GNAT LLVM:
                         * see Emit_Loop_Statement — uses Standard_Integer for
                         * universal ranges. */
                        Type_Info *range_type = iter->binary.right->type;
                        if (not range_type or range_type->kind == TYPE_UNIVERSAL_INTEGER)
                            range_type = sm->type_integer;
                        loop_var->type = range_type;
                        Symbol_Add(sm, loop_var);
                        loop_id->symbol = loop_var;
                    }
                    Resolve_Statement_List(sm, &node->loop_stmt.statements);
                    Symbol_Manager_Pop_Scope(sm);
                } else {
                    /* WHILE or bare LOOP */
                    if (iter) Resolve_Expression(sm, iter);
                    Resolve_Statement_List(sm, &node->loop_stmt.statements);
                }
            }
            break;

        case NK_BLOCK:
            /* Inherit owner from enclosing scope for proper symbol parenting */
            Symbol_Manager_Push_Scope(sm, sm->current_scope->owner);
            /* Resolve declarations first (adds symbols to scope) */
            Resolve_Declaration_List(sm, &node->block_stmt.declarations);
            /* Freeze all types at end of declarative part (RM 13.14) */
            Freeze_Declaration_List(&node->block_stmt.declarations);
            /* Then resolve statements that use those symbols */
            Resolve_Statement_List(sm, &node->block_stmt.statements);
            for (uint32_t i = 0; i < node->block_stmt.handlers.count; i++) {
                Resolve_Statement(sm, node->block_stmt.handlers.items[i]);
            }
            Symbol_Manager_Pop_Scope(sm);
            break;

        case NK_EXIT:
            if (node->exit_stmt.loop_name.data) {
                Symbol *loop_sym = Symbol_Find(sm, node->exit_stmt.loop_name);
                if (loop_sym and (loop_sym->kind == SYMBOL_LOOP or loop_sym->kind == SYMBOL_LABEL))
                    node->exit_stmt.target = loop_sym;
            }
            if (node->exit_stmt.condition) {
                Resolve_Expression(sm, node->exit_stmt.condition);
            }
            break;

        case NK_RAISE:
            if (node->raise_stmt.exception_name) {
                Resolve_Expression(sm, node->raise_stmt.exception_name);
            }
            break;

        case NK_EXCEPTION_HANDLER:
            /* Resolve exception names */
            for (uint32_t i = 0; i < node->handler.exceptions.count; i++) {
                Syntax_Node *exc = node->handler.exceptions.items[i];
                if (exc and exc->kind != NK_OTHERS) {
                    Resolve_Expression(sm, exc);
                }
            }
            Resolve_Statement_List(sm, &node->handler.statements);
            break;

        case NK_ASSOCIATION:
            /* Case alternative - resolve choices and body */
            for (uint32_t i = 0; i < node->association.choices.count; i++) {
                Resolve_Expression(sm, node->association.choices.items[i]);
            }
            if (node->association.expression) {
                if (node->association.expression->kind == NK_BLOCK) {
                    Resolve_Statement(sm, node->association.expression);
                } else {
                    Resolve_Expression(sm, node->association.expression);
                }
            }
            break;

        case NK_LABEL:
            {
                /* Label symbol was pre-registered by Preregister_Labels.
                 * Just resolve the labeled statement. */
                if (node->label_node.statement) {
                    Resolve_Statement(sm, node->label_node.statement);
                }
            }
            break;

        case NK_GOTO:
            {
                /* Look up the target label */
                Symbol *label = Symbol_Find(sm, node->goto_stmt.name);
                if (not label) {
                    Report_Error(node->location, "undefined label '%.*s'",
                                (int)node->goto_stmt.name.length,
                                node->goto_stmt.name.data);
                } else if (label->kind != SYMBOL_LABEL and label->kind != SYMBOL_LOOP) {
                    Report_Error(node->location, "'%.*s' is not a label",
                                (int)node->goto_stmt.name.length,
                                node->goto_stmt.name.data);
                } else {
                    /* Store resolved label for code generation */
                    node->goto_stmt.target = label;
                }
            }
            break;

        case NK_ACCEPT:
            /* ACCEPT statement for task entry - resolve index and parameters.
             * Each accept statement has its own scope for parameters to avoid
             * naming conflicts with parameters from other accept statements
             * in the same selective wait (e.g., multiple accepts with param X). */

            /* Look up the entry symbol by name - it should be in the task's scope */
            node->accept_stmt.entry_sym = Symbol_Find(sm, node->accept_stmt.entry_name);

            if (node->accept_stmt.index) {
                Resolve_Expression(sm, node->accept_stmt.index);
            }
            /* Push new scope for accept parameters - use current scope owner
             * so parameters are considered local (not global) for naming.
             * Each accept statement needs its own scope because multiple accepts
             * in a selective wait may have parameters with the same name. */
            Symbol_Manager_Push_Scope(sm, sm->current_scope->owner);
            /* Resolve accept parameters */
            for (uint32_t i = 0; i < node->accept_stmt.parameters.count; i++) {
                Syntax_Node *param = node->accept_stmt.parameters.items[i];
                if (param and param->kind == NK_PARAM_SPEC) {
                    if (param->param_spec.param_type) {
                        Resolve_Expression(sm, param->param_spec.param_type);
                    }
                    /* Add parameter names to scope for the accept body */
                    for (uint32_t j = 0; j < param->param_spec.names.count; j++) {
                        Syntax_Node *name = param->param_spec.names.items[j];
                        if (name and name->kind == NK_IDENTIFIER) {
                            Symbol *param_sym = Symbol_New(SYMBOL_PARAMETER,
                                name->string_val.text, name->location);
                            if (param->param_spec.param_type)
                                param_sym->type = param->param_spec.param_type->type;
                            Symbol_Add(sm, param_sym);
                            name->symbol = param_sym;
                        }
                    }
                }
            }
            /* Resolve accept body statements */
            Resolve_Statement_List(sm, &node->accept_stmt.statements);
            /* Pop accept scope */
            Symbol_Manager_Pop_Scope(sm);
            break;

        case NK_SELECT:
            /* SELECT statement - resolve alternatives */
            for (uint32_t i = 0; i < node->select_stmt.alternatives.count; i++) {
                Syntax_Node *alt = node->select_stmt.alternatives.items[i];
                if (alt) Resolve_Statement(sm, alt);
            }
            break;

        case NK_DELAY:
            /* DELAY statement - resolve delay expression */
            if (node->delay_stmt.expression) {
                Resolve_Expression(sm, node->delay_stmt.expression);
            }
            break;

        default:
            break;
    }
}

static char *Read_File(const char *path, size_t *out_size) {
    FILE *f = fopen(path, "rb");
    if (not f) return NULL;

    fseek(f, 0, SEEK_END);
    long fsize = ftell(f);
    if (fsize < 0) { fclose(f); return NULL; }
    size_t size = (size_t)fsize;
    fseek(f, 0, SEEK_SET);

    char *buffer = malloc(size + 1);
    if (not buffer) { fclose(f); return NULL; }

    size_t read = fread(buffer, 1, size, f);
    fclose(f);

    buffer[read] = '\0';
    *out_size = read;
    return buffer;
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §15. ALI FILE WRITER — GNAT-Compatible Library Information
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * Ada Library Information (.ali) files record compilation dependencies and
 * unit metadata. Format follows GNAT's lib-writ.ads specification:
 *
 *   V "version"              -- compiler version
 *   P flags                  -- compilation parameters
 *   U name source version    -- unit entry
 *   W name [source ali]      -- with dependency
 *   D source timestamp       -- source dependency
 *
 * The ALI file enables:
 *   • Separate compilation with dependency tracking
 *   • Binder consistency checking
 *   • IDE cross-reference navigation
 */

/* ─────────────────────────────────────────────────────────────────────────
 * §15.1 Unit_Info — Compilation unit metadata collector
 * ───────────────────────────────────────────────────────────────────────── */

typedef struct {
    String_Slice      unit_name;        /* Canonical Ada name (Package.Child%b) */
    String_Slice      source_name;      /* File name (package-child.adb) */
    uint32_t          source_checksum;  /* CRC32 of source text */
    bool              is_body;          /* spec (false) or body (true) */
    bool              is_generic;       /* Generic declaration */
    bool              is_preelaborate;  /* Pragma Preelaborate */
    bool              is_pure;          /* Pragma Pure */
    bool              has_elaboration;  /* Has elaboration code */
} Unit_Info;

typedef struct {
    String_Slice      name;             /* WITH'd unit name */
    String_Slice      source_file;      /* Source file name */
    String_Slice      ali_file;         /* ALI file name */
    bool              is_limited;       /* LIMITED WITH */
    bool              elaborate;        /* Pragma Elaborate */
    bool              elaborate_all;    /* Pragma Elaborate_All */
} With_Info;

typedef struct {
    String_Slice      source_file;      /* Depended-on source */
    uint32_t          timestamp;        /* Modification time (Unix epoch) */
    uint32_t          checksum;         /* CRC32 */
} Dependency_Info;

/* Exported symbol info for X lines */
typedef struct {
    String_Slice      name;             /* Ada name */
    String_Slice      mangled_name;     /* LLVM symbol name */
    char              kind;             /* T=type, S=subtype, V=variable, C=constant, P=procedure, F=function, E=exception */
    uint32_t          line;             /* Declaration line number */
    String_Slice      type_name;        /* Type name (for typed symbols) */
    String_Slice      llvm_type;        /* LLVM type signature (e.g., "i64", "ptr", "void (i64)") */
    uint32_t          param_count;      /* Parameter count (for subprograms) */
} Export_Info;

typedef struct {
    Unit_Info         units[8];         /* Units in this compilation */
    uint32_t          unit_count;
    With_Info         withs[64];        /* WITH dependencies */
    uint32_t          with_count;
    Dependency_Info   deps[128];        /* Source dependencies */
    uint32_t          dep_count;
    Export_Info       exports[256];     /* Exported symbols */
    uint32_t          export_count;
} ALI_Info;

/* ─────────────────────────────────────────────────────────────────────────
 * §15.2 CRC32 — Fast checksum for source identity
 *
 * Standard CRC-32/ISO-HDLC polynomial: 0xEDB88320 (bit-reversed 0x04C11DB7)
 * ───────────────────────────────────────────────────────────────────────── */

static uint32_t Crc32_Table[256];
static bool Crc32_Table_Initialized = false;

static void Crc32_Init_Table(void) {
    if (Crc32_Table_Initialized) return;
    for (uint32_t i = 0; i < 256; i++) {
        uint32_t crc = i;
        for (int j = 0; j < 8; j++)
            crc = (crc >> 1) ^ (0xEDB88320 & -(crc & 1));
        Crc32_Table[i] = crc;
    }
    Crc32_Table_Initialized = true;
}

static uint32_t Crc32(const char *data, size_t length) {
    Crc32_Init_Table();
    uint32_t crc = 0xFFFFFFFF;
    for (size_t i = 0; i < length; i++)
        crc = Crc32_Table[(crc ^ (uint8_t)data[i]) & 0xFF] ^ (crc >> 8);
    return ~crc;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §15.3 Unit_Name_To_File — GNAT naming convention
 *
 * Maps Ada unit names to file names:
 *   Package_Name      > package_name.ads
 *   Package_Name%b    > package_name.adb
 *   Parent.Child      > parent-child.ads
 * ───────────────────────────────────────────────────────────────────────── */

static void Unit_Name_To_File(String_Slice unit_name, bool is_body,
                              char *out, size_t out_size) {
    size_t j = 0;
    for (size_t i = 0; i < unit_name.length and j < out_size - 5; i++) {
        char c = unit_name.data[i];
        if (c == '.') {
            out[j++] = '-';  /* Dots become hyphens */
        } else if (c >= 'A' and c <= 'Z') {
            out[j++] = c - 'A' + 'a';  /* Lowercase */
        } else {
            out[j++] = c;
        }
    }
    /* Append extension */
    const char *ext = is_body ? ".adb" : ".ads";
    for (int k = 0; ext[k] and j < out_size - 1; k++)
        out[j++] = ext[k];
    out[j] = '\0';
}

/* ─────────────────────────────────────────────────────────────────────────
 * §15.4 ALI_Collect — Gather unit info from parsed AST
 * ───────────────────────────────────────────────────────────────────────── */

static void ALI_Collect_Withs(ALI_Info *ali, Syntax_Node *ctx) {
    if (not ctx) return;

    for (uint32_t i = 0; i < ctx->context.with_clauses.count; i++) {
        Syntax_Node *with_node = ctx->context.with_clauses.items[i];
        if (not with_node) continue;

        /* Each WITH clause may have multiple names */
        for (uint32_t j = 0; j < with_node->use_clause.names.count; j++) {
            Syntax_Node *name = with_node->use_clause.names.items[j];
            if (not name or ali->with_count >= 64) continue;

            With_Info *w = &ali->withs[ali->with_count++];
            w->name = name->kind == NK_IDENTIFIER ?
                      name->string_val.text : (String_Slice){0};
            w->is_limited = false;  /* TODO: detect LIMITED WITH */
            w->elaborate = false;
            w->elaborate_all = false;

            /* Derive file names from unit name */
            char file_buf[256];
            if (w->name.data) {
                Unit_Name_To_File(w->name, false, file_buf, sizeof(file_buf));
                w->source_file = Slice_Duplicate((String_Slice){file_buf, strlen(file_buf)});
                size_t len = strlen(file_buf);
                if (len > 4) {
                    file_buf[len-3] = 'a';
                    file_buf[len-2] = 'l';
                    file_buf[len-1] = 'i';
                }
                w->ali_file = Slice_Duplicate((String_Slice){file_buf, strlen(file_buf)});
            }
        }
    }
}

/* Helper: extract unit name from a subprogram spec/body */
static String_Slice Get_Subprogram_Name(Syntax_Node *node) {
    if (not node) return (String_Slice){"UNKNOWN", 7};
    if (node->kind == NK_PROCEDURE_SPEC or node->kind == NK_FUNCTION_SPEC)
        return node->subprogram_spec.name;
    if (node->kind == NK_PROCEDURE_BODY or node->kind == NK_FUNCTION_BODY) {
        /* Body has spec nested inside */
        if (node->subprogram_body.specification)
            return Get_Subprogram_Name(node->subprogram_body.specification);
    }
    return (String_Slice){"UNKNOWN", 7};
}

/* Forward declarations for functions used by ALI_Collect_Exports */
static String_Slice Mangle_Qualified_Name(String_Slice parent, String_Slice name);
static String_Slice LLVM_Type_Basic(Symbol_Manager *sm, String_Slice ada_type);

/* ─────────────────────────────────────────────────────────────────────────
 * §15.4.2 ALI_Collect_Exports — Gather exported symbols from package spec
 * ───────────────────────────────────────────────────────────────────────── */

static void ALI_Collect_Exports(ALI_Info *ali, Syntax_Node *unit, Symbol_Manager *sm) {
    if (not unit or unit->kind != NK_PACKAGE_SPEC) return;

    String_Slice pkg_name = unit->package_spec.name;
    Node_List *decls = &unit->package_spec.visible_decls;

    for (uint32_t i = 0; i < decls->count and ali->export_count < 256; i++) {
        Syntax_Node *decl = decls->items[i];
        if (not decl) continue;

        Export_Info *exp = &ali->exports[ali->export_count];
        exp->line = decl->location.line;
        exp->param_count = 0;
        exp->type_name = (String_Slice){0};
        exp->mangled_name = (String_Slice){0};
        exp->llvm_type = (String_Slice){0};

        switch (decl->kind) {
            case NK_TYPE_DECL:
                exp->name = decl->type_decl.name;
                exp->kind = 'T';
                exp->mangled_name = Mangle_Qualified_Name(pkg_name, exp->name);
                exp->llvm_type = LLVM_Type_Basic(sm, exp->name);
                ali->export_count++;
                break;

            case NK_SUBTYPE_DECL:
                exp->name = decl->type_decl.name;
                exp->kind = 'S';
                exp->mangled_name = Mangle_Qualified_Name(pkg_name, exp->name);
                if (decl->type_decl.definition) {
                    Syntax_Node *def = decl->type_decl.definition;
                    if (def->kind == NK_IDENTIFIER) {
                        exp->type_name = def->string_val.text;
                        exp->llvm_type = LLVM_Type_Basic(sm, exp->type_name);
                    } else if (def->kind == NK_SUBTYPE_INDICATION and def->subtype_ind.subtype_mark) {
                        if (def->subtype_ind.subtype_mark->kind == NK_IDENTIFIER) {
                            exp->type_name = def->subtype_ind.subtype_mark->string_val.text;
                            exp->llvm_type = LLVM_Type_Basic(sm, exp->type_name);
                        }
                    }
                }
                if (not exp->llvm_type.data) {
                    const char *int_t = Llvm_Int_Type((uint32_t)To_Bits(sm->type_integer->size));
                    exp->llvm_type = (String_Slice){int_t, strlen(int_t)};
                }
                ali->export_count++;
                break;

            case NK_OBJECT_DECL:
                for (uint32_t j = 0; j < decl->object_decl.names.count and ali->export_count < 256; j++) {
                    Syntax_Node *name = decl->object_decl.names.items[j];
                    if (name and name->kind == NK_IDENTIFIER) {
                        exp = &ali->exports[ali->export_count];
                        exp->name = name->string_val.text;
                        exp->kind = decl->object_decl.is_constant ? 'C' : 'V';
                        exp->line = name->location.line;
                        exp->mangled_name = Mangle_Qualified_Name(pkg_name, exp->name);
                        if (decl->object_decl.object_type and decl->object_decl.object_type->kind == NK_IDENTIFIER) {
                            exp->type_name = decl->object_decl.object_type->string_val.text;
                            exp->llvm_type = LLVM_Type_Basic(sm, exp->type_name);
                        } else {
                            const char *int_t = Llvm_Int_Type((uint32_t)To_Bits(sm->type_integer->size));
                            exp->llvm_type = (String_Slice){int_t, strlen(int_t)};
                        }
                        ali->export_count++;
                    }
                }
                break;

            case NK_PROCEDURE_SPEC:
                exp->name = decl->subprogram_spec.name;
                exp->kind = 'P';
                exp->mangled_name = Mangle_Qualified_Name(pkg_name, exp->name);
                for (uint32_t j = 0; j < decl->subprogram_spec.parameters.count; j++) {
                    Syntax_Node *ps = decl->subprogram_spec.parameters.items[j];
                    if (ps and ps->kind == NK_PARAM_SPEC)
                        exp->param_count += ps->param_spec.names.count;
                }
                exp->llvm_type = (String_Slice){"void", 4};
                ali->export_count++;
                break;

            case NK_FUNCTION_SPEC:
                exp->name = decl->subprogram_spec.name;
                exp->kind = 'F';
                exp->mangled_name = Mangle_Qualified_Name(pkg_name, exp->name);
                for (uint32_t j = 0; j < decl->subprogram_spec.parameters.count; j++) {
                    Syntax_Node *ps = decl->subprogram_spec.parameters.items[j];
                    if (ps and ps->kind == NK_PARAM_SPEC)
                        exp->param_count += ps->param_spec.names.count;
                }
                if (decl->subprogram_spec.return_type and decl->subprogram_spec.return_type->kind == NK_IDENTIFIER) {
                    exp->type_name = decl->subprogram_spec.return_type->string_val.text;
                    exp->llvm_type = LLVM_Type_Basic(sm, exp->type_name);
                } else {
                    const char *int_t = Llvm_Int_Type((uint32_t)To_Bits(sm->type_integer->size));
                    exp->llvm_type = (String_Slice){int_t, strlen(int_t)};
                }
                ali->export_count++;
                break;

            case NK_EXCEPTION_DECL:
                for (uint32_t j = 0; j < decl->exception_decl.names.count and ali->export_count < 256; j++) {
                    Syntax_Node *name = decl->exception_decl.names.items[j];
                    if (name and name->kind == NK_IDENTIFIER) {
                        exp = &ali->exports[ali->export_count];
                        exp->name = name->string_val.text;
                        exp->kind = 'E';
                        exp->line = name->location.line;
                        exp->mangled_name = Mangle_Qualified_Name(pkg_name, exp->name);
                        exp->llvm_type = (String_Slice){"i8", 2};  /* Exception identity */
                        ali->export_count++;
                    }
                }
                break;

            default:
                break;
        }
    }
}


static void ALI_Collect_Unit(ALI_Info *ali, Syntax_Node *cu,
                             const char *source, size_t source_size,
                             Symbol_Manager *sm) {
    if (not cu or ali->unit_count >= 8) return;

    Syntax_Node *unit = cu->compilation_unit.unit;
    if (not unit) return;

    Unit_Info *u = &ali->units[ali->unit_count++];

    /* Extract unit name based on declaration kind */
    switch (unit->kind) {
        case NK_PACKAGE_SPEC:
            u->unit_name = unit->package_spec.name;
            u->is_body = false;
            break;
        case NK_PACKAGE_BODY:
            u->unit_name = unit->package_body.name;
            u->is_body = true;
            break;
        case NK_PROCEDURE_BODY:
        case NK_PROCEDURE_SPEC:
            u->unit_name = Get_Subprogram_Name(unit);
            u->is_body = unit->kind == NK_PROCEDURE_BODY;
            break;
        case NK_FUNCTION_BODY:
        case NK_FUNCTION_SPEC:
            u->unit_name = Get_Subprogram_Name(unit);
            u->is_body = unit->kind == NK_FUNCTION_BODY;
            break;
        case NK_GENERIC_DECL:
            u->is_generic = true;
            if (unit->generic_decl.unit) {
                Syntax_Node *inner = unit->generic_decl.unit;
                if (inner->kind == NK_PACKAGE_SPEC)
                    u->unit_name = inner->package_spec.name;
                else if (inner->kind == NK_PROCEDURE_SPEC or inner->kind == NK_FUNCTION_SPEC)
                    u->unit_name = inner->subprogram_spec.name;
            }
            u->is_body = false;
            break;
        default:
            u->unit_name = (String_Slice){"UNKNOWN", 7};
            u->is_body = false;
    }

    /* Compute source checksum */
    u->source_checksum = Crc32(source, source_size);

    /* Derive source file name */
    char file_buf[256];
    Unit_Name_To_File(u->unit_name, u->is_body, file_buf, sizeof(file_buf));
    u->source_name = Slice_Duplicate((String_Slice){file_buf, strlen(file_buf)});

    /* Check for elaboration pragmas (simplified) */
    u->is_preelaborate = false;
    u->is_pure = false;
    u->has_elaboration = true;  /* Assume has elaboration unless proven otherwise */

    /* Collect WITH dependencies */
    ALI_Collect_Withs(ali, cu->compilation_unit.context);

    /* Collect exported symbols from package specs */
    if (unit and unit->kind == NK_PACKAGE_SPEC) {
        ALI_Collect_Exports(ali, unit, sm);
    }
}

/* LLVM type signature derived from the type system via Symbol_Manager.
 * Looks up the Ada type name in the symbol table and uses Type_To_Llvm
 * to get the correct LLVM representation. */
static String_Slice LLVM_Type_Basic(Symbol_Manager *sm, String_Slice ada_type) {
    /* Look up in the symbol table for proper type-system derivation */
    Symbol *sym = Symbol_Find(sm, ada_type);
    if (sym and sym->type) {
        const char *llvm = Type_To_Llvm(sym->type);
        return (String_Slice){llvm, strlen(llvm)};
    }
    /* Error: type not found in symbol table */
    fprintf(stderr, "error: LLVM_Type_Basic: type '%.*s' not found in symbol table\n",
            (int)ada_type.length, ada_type.data);
    const char *fallback = Llvm_Int_Type((uint32_t)To_Bits(sm->type_integer->size));
    return (String_Slice){fallback, strlen(fallback)};
}

/* ─────────────────────────────────────────────────────────────────────────
 * §15.5 ALI_Write — Emit .ali file in GNAT format
 *
 * Per lib-writ.ads, the minimum valid ALI file needs:
 *   V line (version) — MUST be first
 *   P line (parameters) — MUST be present
 *   At least one U line (unit)
 * ───────────────────────────────────────────────────────────────────────── */

#define ALI_VERSION "Ada83 1.0 built " __DATE__ " " __TIME__

static void ALI_Write(FILE *out, ALI_Info *ali) {
    /* V line: Version — must be first per GNAT spec */
    fprintf(out, "V \"%s\"\n", ALI_VERSION);

    /* P line: Parameters/flags — ZX = zero-cost exceptions */
    fprintf(out, "P ZX\n");

    /* Blank line before restrictions */
    fprintf(out, "\n");

    /* R line: Restrictions (minimal) */
    fprintf(out, "RN\n");

    /* U lines: Unit entries */
    for (uint32_t i = 0; i < ali->unit_count; i++) {
        Unit_Info *u = &ali->units[i];

        /* U unit-name source-name version [flags] */
        fprintf(out, "\nU %.*s%s %.*s %08X",
                (int)u->unit_name.length, u->unit_name.data,
                u->is_body ? "%b" : "%s",
                (int)u->source_name.length, u->source_name.data,
                u->source_checksum);

        /* Flags */
        if (u->is_generic) fprintf(out, " GE");
        if (u->is_preelaborate) fprintf(out, " PR");
        if (u->is_pure) fprintf(out, " PU");
        if (not u->has_elaboration) fprintf(out, " NE");
        if (not u->is_body) fprintf(out, " PK");
        else fprintf(out, " SU");
        fprintf(out, "\n");

        /* W lines: WITH dependencies for this unit */
        for (uint32_t j = 0; j < ali->with_count; j++) {
            With_Info *w = &ali->withs[j];
            if (not w->name.data) continue;

            char line_type = w->is_limited ? 'Y' : 'W';
            fprintf(out, "%c %.*s%s",
                    line_type,
                    (int)w->name.length, w->name.data,
                    "%s");  /* Assume spec dependency */

            if (w->source_file.data) {
                fprintf(out, " %.*s %.*s",
                        (int)w->source_file.length, w->source_file.data,
                        (int)w->ali_file.length, w->ali_file.data);
            }

            if (w->elaborate) fprintf(out, " E");
            if (w->elaborate_all) fprintf(out, " EA");
            fprintf(out, "\n");
        }
    }

    /* D lines: Source dependencies */
    fprintf(out, "\n");
    for (uint32_t i = 0; i < ali->unit_count; i++) {
        Unit_Info *u = &ali->units[i];
        /* Self-dependency */
        fprintf(out, "D %.*s 00000000 %08X\n",
                (int)u->source_name.length, u->source_name.data,
                u->source_checksum);
    }
    for (uint32_t i = 0; i < ali->with_count; i++) {
        With_Info *w = &ali->withs[i];
        if (w->source_file.data) {
            fprintf(out, "D %.*s 00000000 00000000\n",
                    (int)w->source_file.length, w->source_file.data);
        }
    }

    /* X lines: Exported symbols (extended format for Ada83 separate compilation)
     *
     * Format: X kind name:line llvm_type @mangled [ada_type] [(params)]
     *
     *   kind: T=type, S=subtype, V=variable, C=constant, P=procedure, F=function, E=exception
     *   llvm_type: LLVM IR type signature (i64, double, void, ptr, etc.)
     *   @mangled: LLVM symbol name for linking
     *   ada_type: Ada type name for typed symbols
     *   (params): Parameter count for subprograms
     *
     * This provides everything needed to compile against the package without source:
     *   - Type checking via ada_type
     *   - Code generation via llvm_type and @mangled
     *   - Linking via @mangled symbol references
     */
    if (ali->export_count > 0) {
        fprintf(out, "\n");
        for (uint32_t i = 0; i < ali->export_count; i++) {
            Export_Info *x = &ali->exports[i];

            /* X kind name:line */
            fprintf(out, "X %c %.*s:%u",
                    x->kind,
                    (int)x->name.length, x->name.data,
                    x->line);

            /* llvm_type */
            if (x->llvm_type.data) {
                fprintf(out, " %.*s", (int)x->llvm_type.length, x->llvm_type.data);
            } else {
                fprintf(out, " i64");
            }

            /* @mangled */
            if (x->mangled_name.data) {
                fprintf(out, " @%.*s", (int)x->mangled_name.length, x->mangled_name.data);
            }

            /* ada_type (for typed symbols) */
            if (x->type_name.data) {
                fprintf(out, " %.*s", (int)x->type_name.length, x->type_name.data);
            }

            /* (params) for subprograms */
            if (x->param_count > 0) {
                fprintf(out, " (%u)", x->param_count);
            }

            fprintf(out, "\n");
        }
    }
}

/* ─────────────────────────────────────────────────────────────────────────
 * §15.6 Generate_ALI_File — Entry point for ALI generation
 * ───────────────────────────────────────────────────────────────────────── */

static void Generate_ALI_File(const char *output_path,
                              Syntax_Node **units, int unit_count,
                              const char *source, size_t source_size,
                              Symbol_Manager *sm) {
    /* Build ALI path from output path (replace .ll with .ali) */
    char ali_path[512];
    size_t len = strlen(output_path);
    if (len > 3 and strcmp(output_path + len - 3, ".ll") == 0) {
        snprintf(ali_path, sizeof(ali_path), "%.*s.ali", (int)(len - 3), output_path);
    } else {
        snprintf(ali_path, sizeof(ali_path), "%s.ali", output_path);
    }

    FILE *ali_file = fopen(ali_path, "w");
    if (not ali_file) {
        fprintf(stderr, "Warning: cannot create ALI file '%s'\n", ali_path);
        return;
    }

    /* Collect information from all compilation units */
    ALI_Info ali = {0};
    for (int i = 0; i < unit_count; i++) {
        ALI_Collect_Unit(&ali, units[i], source, source_size, sm);
    }

    /* Write ALI file */
    ALI_Write(ali_file, &ali);
    fclose(ali_file);

    fprintf(stderr, "Generated ALI file '%s'\n", ali_path);
}

/* ─────────────────────────────────────────────────────────────────────────
 * §15.7 ALI_Reader — Parse .ali files for dependency management
 *
 * We read ALI files to:
 *   1. Skip recompilation of unchanged units (checksum match)
 *   2. Load exported symbols from precompiled packages
 *   3. Track dependencies for elaboration ordering
 *   4. Find generic templates for instantiation
 * ───────────────────────────────────────────────────────────────────────── */

/* Parsed export from X line */
typedef struct {
    char            kind;            /* T/S/V/C/P/F/E */
    char           *name;            /* Ada symbol name */
    char           *mangled_name;    /* LLVM symbol name for linking */
    char           *llvm_type;       /* LLVM type signature */
    uint32_t        line;            /* Source line */
    char           *type_name;       /* Ada type name (or NULL) */
    uint32_t        param_count;     /* For subprograms */
} ALI_Export;

/* Cached ALI information for loaded units
 * ALI_Cache_Entry is forward declared as ALI_Cache_Entry_Forward in the
 * Load_Package_Spec forward declarations section. */
typedef struct ALI_Cache_Entry_Forward {
    char           *unit_name;       /* Canonical name (e.g., "text_io") */
    char           *source_file;     /* Source file name */
    char           *ali_file;        /* ALI file path */
    uint32_t        checksum;        /* Source checksum from ALI */
    bool            is_spec;         /* true = spec, false = body */
    bool            is_generic;      /* Generic unit */
    bool            is_preelaborate; /* Has Preelaborate pragma */
    bool            is_pure;         /* Has Pure pragma */
    bool            loaded;          /* Symbols already loaded */

    /* With dependencies */
    char           *withs[64];       /* WITH'd unit names */
    uint32_t        with_count;

    /* Exported symbols from X lines */
    ALI_Export      exports[256];
    uint32_t        export_count;
} ALI_Cache_Entry;

/* Global ALI cache */
static ALI_Cache_Entry ALI_Cache[256];
static uint32_t        ALI_Cache_Count = 0;

/* Skip whitespace */
static const char *ALI_Skip_Ws(const char *p) {
    while (*p == ' ' or *p == '\t') p++;
    return p;
}

/* Read until whitespace or newline, return end pointer */
static const char *ALI_Read_Token(const char *p, char *buf, size_t bufsize) {
    p = ALI_Skip_Ws(p);
    size_t i = 0;
    while (*p and *p != ' ' and *p != '\t' and *p != '\n' and i < bufsize - 1) {
        buf[i++] = *p++;
    }
    buf[i] = '\0';
    return p;
}

/* Parse a hex value */
static uint32_t ALI_Parse_Hex(const char *s) {
    uint32_t val = 0;
    while (*s) {
        char c = *s++;
        if (c >= '0' and c <= '9') val = (val << 4) | (c - '0');
        else if (c >= 'A' and c <= 'F') val = (val << 4) | (c - 'A' + 10);
        else if (c >= 'a' and c <= 'f') val = (val << 4) | (c - 'a' + 10);
        else break;
    }
    return val;
}

/* Read and parse an ALI file, returning cache entry or NULL */
static ALI_Cache_Entry *ALI_Read(const char *ali_path) {
    /* Check if already cached */
    for (uint32_t i = 0; i < ALI_Cache_Count; i++) {
        if (ALI_Cache[i].ali_file and strcmp(ALI_Cache[i].ali_file, ali_path) == 0) {
            return &ALI_Cache[i];
        }
    }

    /* Read ALI file */
    FILE *f = fopen(ali_path, "r");
    if (not f) return NULL;

    /* Allocate cache entry */
    if (ALI_Cache_Count >= 256) {
        fclose(f);
        return NULL;
    }
    ALI_Cache_Entry *entry = &ALI_Cache[ALI_Cache_Count++];
    memset(entry, 0, sizeof(*entry));
    entry->ali_file = strdup(ali_path);

    char line[1024];
    char token[256];

    while (fgets(line, sizeof(line), f)) {
        const char *p = line;

        if (line[0] == 'V') {
            /* Version line: V "version" — reject if compiler build differs.
             * This ensures stale ALI files from an older compiler rebuild
             * are not reused; the unit will be reparsed from source. */
            char ver[256] = {0};
            const char *q = strchr(line, '"');
            if (q) {
                q++;
                const char *end = strchr(q, '"');
                if (end and (size_t)(end - q) < sizeof(ver)) {
                    memcpy(ver, q, (size_t)(end - q));
                    ver[end - q] = '\0';
                }
            }
            if (strcmp(ver, ALI_VERSION) != 0) {
                /* ALI was produced by a different compiler build — stale */
                fclose(f);
                ALI_Cache_Count--;  /* release the cache slot */
                return NULL;
            }
            continue;
        }
        else if (line[0] == 'P') {
            /* Parameters line: P flags */
            continue;
        }
        else if (line[0] == 'U') {
            /* Unit line: U name source checksum [flags] */
            p = ALI_Read_Token(p + 1, token, sizeof(token));  /* Skip 'U' */

            /* Unit name (with %s/%b suffix) */
            char *pct = strchr(token, '%');
            if (pct) {
                entry->is_spec = (pct[1] == 's');
                *pct = '\0';
            }
            entry->unit_name = strdup(token);

            /* Source file */
            p = ALI_Read_Token(p, token, sizeof(token));
            entry->source_file = strdup(token);

            /* Checksum */
            p = ALI_Read_Token(p, token, sizeof(token));
            entry->checksum = ALI_Parse_Hex(token);

            /* Parse flags */
            while (*p and *p != '\n') {
                p = ALI_Read_Token(p, token, sizeof(token));
                if (strcmp(token, "GE") == 0) entry->is_generic = true;
                else if (strcmp(token, "PR") == 0) entry->is_preelaborate = true;
                else if (strcmp(token, "PU") == 0) entry->is_pure = true;
            }
        }
        else if (line[0] == 'W' or line[0] == 'Y' or line[0] == 'Z') {
            /* With line: W/Y/Z name [source ali] [flags] */
            p = ALI_Read_Token(p + 1, token, sizeof(token));

            /* Strip %s/%b suffix */
            char *pct = strchr(token, '%');
            if (pct) *pct = '\0';

            if (entry->with_count < 64) {
                entry->withs[entry->with_count++] = strdup(token);
            }
        }
        else if (line[0] == 'D') {
            /* Dependency line: D source timestamp checksum — informational */
            continue;
        }
        else if (line[0] == 'X') {
            /* Export line: X kind name:line llvm_type @mangled [ada_type] [(params)]
             *
             * Example: X F Get_Value:9 i64 @test_exports__get_value Counter
             */
            if (entry->export_count >= 256) continue;

            ALI_Export *exp = &entry->exports[entry->export_count];
            memset(exp, 0, sizeof(*exp));

            p = ALI_Skip_Ws(p + 1);  /* Skip 'X' */

            /* Kind (single char: T/S/V/C/P/F/E) */
            exp->kind = *p++;
            p = ALI_Skip_Ws(p);

            /* Name:line */
            p = ALI_Read_Token(p, token, sizeof(token));
            char *colon = strchr(token, ':');
            if (colon) {
                *colon = '\0';
                exp->name = strdup(token);
                exp->line = (uint32_t)atoi(colon + 1);
            } else {
                exp->name = strdup(token);
                exp->line = 0;
            }

            /* llvm_type */
            p = ALI_Skip_Ws(p);
            if (*p and *p != '\n') {
                p = ALI_Read_Token(p, token, sizeof(token));
                if (token[0]) exp->llvm_type = strdup(token);
            }

            /* @mangled */
            p = ALI_Skip_Ws(p);
            if (*p == '@') {
                p++;  /* Skip '@' */
                p = ALI_Read_Token(p, token, sizeof(token));
                if (token[0]) exp->mangled_name = strdup(token);
            }

            /* Remaining tokens: ada_type and/or (params) */
            while (*p and *p != '\n') {
                p = ALI_Skip_Ws(p);
                if (*p == '(') {
                    /* (params) */
                    p = ALI_Read_Token(p, token, sizeof(token));
                    exp->param_count = (uint32_t)atoi(token + 1);
                } else if (*p and *p != '\n') {
                    /* ada_type */
                    p = ALI_Read_Token(p, token, sizeof(token));
                    if (token[0] and token[0] != '(') {
                        if (exp->type_name) free(exp->type_name);
                        exp->type_name = strdup(token);
                    }
                }
            }

            entry->export_count++;
        }
    }

    fclose(f);
    return entry;
}

/* Check if an ALI file is up-to-date with its source */
static bool ALI_Is_Current(const char *ali_path, const char *source_path) {
    ALI_Cache_Entry *entry = ALI_Read(ali_path);
    if (not entry) return false;

    /* Read source and compute checksum */
    size_t source_size;
    char *source = Read_File(source_path, &source_size);
    if (not source) return false;

    uint32_t current_checksum = Crc32(source, source_size);
    free(source);

    return (current_checksum == entry->checksum);
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §15.7 ELABORATION MODEL — GNAT LLVM-Style Dependency Graph Algorithm
 *
 * Implements the full GNAT LLVM elaboration ordering algorithm as described
 * in bindo-elaborators.adb. This determines the safe order in which library
 * units must be elaborated at program startup (Ada RM 10.2).
 *
 * The algorithm proceeds in phases:
 *   1. BUILD GRAPH: Create vertices for units, edges for dependencies
 *   2. FIND COMPONENTS: Tarjan's SCC for cyclic dependency handling
 *   3. ELABORATE: Topological sort with priority ordering
 *   4. VALIDATE: Verify all constraints satisfied
 *
 * Key insight from GNAT: Edges are classified as "strong" (must-satisfy) or
 * "weak" (can-ignore-for-dynamic-model). This allows breaking cycles when
 * compiled with -gnatE (dynamic elaboration checking).
 *
 * Style: Haskell-like C99 with algebraic data types (tagged unions),
 * pure functions where possible, and composition over mutation.
 * ═══════════════════════════════════════════════════════════════════════════ */

/* ─────────────────────────────────────────────────────────────────────────
 * §15.7.1 Algebraic Types — Sum types via tagged unions
 *
 * Following the Haskell pattern: data Kind = A | B | C
 * In C99: enum for tag, union for payload, struct wrapper.
 * ───────────────────────────────────────────────────────────────────────── */

/* Unit_Kind: What kind of compilation unit is this vertex? */
typedef enum {
    UNIT_SPEC,       /* Package/subprogram specification with separate body */
    UNIT_BODY,       /* Package/subprogram body (paired with spec) */
    UNIT_SPEC_ONLY,  /* Spec without body (e.g., pure package spec) */
    UNIT_BODY_ONLY   /* Body without explicit spec (e.g., main subprogram) */
} Elab_Unit_Kind;

/* Edge_Kind: What dependency relationship does this edge represent?
 * Per GNAT bindo-graphs.ads, edge kinds determine precedence and strength. */
typedef enum {
    EDGE_WITH,            /* WITH clause dependency (strong) */
    EDGE_ELABORATE,       /* pragma Elaborate (strong) */
    EDGE_ELABORATE_ALL,   /* pragma Elaborate_All (strong, transitive) */
    EDGE_SPEC_BEFORE_BODY,/* Spec must elaborate before its body (strong) */
    EDGE_INVOCATION,      /* Call discovered during elaboration (weak) */
    EDGE_FORCED           /* Compiler-forced ordering (strong) */
} Elab_Edge_Kind;

/* Precedence_Kind: Result of comparing two vertices for elaboration order */
typedef enum {
    PREC_HIGHER,  /* First vertex should elaborate first */
    PREC_EQUAL,   /* No preference (use tiebreaker) */
    PREC_LOWER    /* Second vertex should elaborate first */
} Elab_Precedence;

/* Elaboration order status after algorithm completion */
typedef enum {
    ELAB_ORDER_OK,                    /* Valid order found */
    ELAB_ORDER_HAS_CYCLE,             /* Unresolvable cycle detected */
    ELAB_ORDER_HAS_ELABORATE_ALL_CYCLE /* Elaborate_All cycle (fatal) */
} Elab_Order_Status;

/* ─────────────────────────────────────────────────────────────────────────
 * §15.7.2 Graph Vertex — Compilation unit representation
 *
 * Each vertex represents one compilation unit (spec or body).
 * Tracks pending predecessor counts for the elaboration algorithm.
 * ───────────────────────────────────────────────────────────────────────── */

typedef struct Elab_Vertex Elab_Vertex;
typedef struct Elab_Edge   Elab_Edge;

struct Elab_Vertex {
    /* Identity */
    uint32_t         id;              /* Unique vertex ID */
    String_Slice     name;            /* Unit name (e.g., "Text_IO") */
    Elab_Unit_Kind   kind;            /* Spec/Body/Spec_Only/Body_Only */
    Symbol          *symbol;          /* Associated package/subprogram symbol */

    /* Component membership (set by Tarjan's SCC) */
    uint32_t         component_id;    /* SCC ID (0 = not yet assigned) */

    /* Pending predecessor counts (decremented during elaboration) */
    uint32_t         pending_strong;  /* Strong predecessors remaining */
    uint32_t         pending_weak;    /* Weak predecessors remaining */

    /* Flags */
    bool             in_elab_order;   /* Already added to elaboration order? */
    bool             is_preelaborate; /* pragma Preelaborate */
    bool             is_pure;         /* pragma Pure */
    bool             has_elab_body;   /* pragma Elaborate_Body */
    bool             is_predefined;   /* Ada.*, System.*, Interfaces.* */
    bool             is_internal;     /* GNAT.*, Ada83.* internal units */
    bool             needs_elab_code; /* Has elaboration code to run? */

    /* Spec/body pairing */
    Elab_Vertex     *body_vertex;     /* For spec: pointer to body vertex */
    Elab_Vertex     *spec_vertex;     /* For body: pointer to spec vertex */

    /* Edge lists (indices into graph's edge array) */
    uint32_t         first_pred_edge; /* First incoming edge index (or 0) */
    uint32_t         first_succ_edge; /* First outgoing edge index (or 0) */

    /* Tarjan's algorithm temporaries */
    int32_t          tarjan_index;    /* Discovery index (-1 = unvisited) */
    int32_t          tarjan_lowlink;  /* Lowest reachable index */
    bool             tarjan_on_stack; /* Currently on the DFS stack? */
};

/* ─────────────────────────────────────────────────────────────────────────
 * §15.7.3 Graph Edge — Dependency relationship
 *
 * Edges are intrusive linked lists through vertices for O(1) iteration.
 * Each edge knows whether it's "strong" (must satisfy) or "weak" (can skip).
 * ───────────────────────────────────────────────────────────────────────── */

struct Elab_Edge {
    uint32_t         id;              /* Unique edge ID */
    Elab_Edge_Kind   kind;            /* WITH/ELABORATE/etc. */
    bool             is_strong;       /* Strong edge must be satisfied */

    /* Endpoints */
    uint32_t         pred_vertex_id;  /* Predecessor (must elaborate first) */
    uint32_t         succ_vertex_id;  /* Successor (elaborates after) */

    /* Linked list threading */
    uint32_t         next_pred_edge;  /* Next edge with same predecessor */
    uint32_t         next_succ_edge;  /* Next edge with same successor */
};

/* Is this edge kind inherently strong? */
static inline bool Edge_Kind_Is_Strong(Elab_Edge_Kind k) {
    return k != EDGE_INVOCATION;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §15.7.4 Graph Structure — Vertices + Edges + Components
 *
 * Uses arena allocation for vertices/edges, dynamic arrays for order.
 * Maximum capacities chosen to handle large Ada programs.
 * ───────────────────────────────────────────────────────────────────────── */

#define ELAB_MAX_VERTICES 512
#define ELAB_MAX_EDGES    2048
#define ELAB_MAX_COMPONENTS 256

typedef struct {
    /* Vertices */
    Elab_Vertex      vertices[ELAB_MAX_VERTICES];
    uint32_t         vertex_count;

    /* Edges */
    Elab_Edge        edges[ELAB_MAX_EDGES];
    uint32_t         edge_count;

    /* Components (SCCs) */
    uint32_t         component_pending_strong[ELAB_MAX_COMPONENTS];
    uint32_t         component_pending_weak[ELAB_MAX_COMPONENTS];
    uint32_t         component_count;

    /* Elaboration order (result) */
    Elab_Vertex     *order[ELAB_MAX_VERTICES];
    uint32_t         order_count;

    /* Has Elaborate_All cycle? (fatal error) */
    bool             has_elaborate_all_cycle;
} Elab_Graph;

/* ─────────────────────────────────────────────────────────────────────────
 * §15.7.5 Graph Construction — Pure creation functions
 *
 * Functions return new graph/vertex/edge without side effects.
 * Following functional style: prefer immutable creation over mutation.
 * ───────────────────────────────────────────────────────────────────────── */

/* Initialize an empty graph */
static inline Elab_Graph Elab_Graph_New(void) {
    Elab_Graph g = {0};
    return g;
}

/* Add a vertex, returning its ID (or 0 on failure) */
static uint32_t Elab_Add_Vertex(Elab_Graph *g, String_Slice name,
                                 Elab_Unit_Kind kind, Symbol *sym) {
    if (g->vertex_count >= ELAB_MAX_VERTICES) return 0;

    uint32_t id = ++g->vertex_count;  /* IDs are 1-based */
    Elab_Vertex *v = &g->vertices[id - 1];

    *v = (Elab_Vertex){
        .id              = id,
        .name            = name,
        .kind            = kind,
        .symbol          = sym,
        .tarjan_index    = -1,
        .tarjan_lowlink  = -1,
        .is_predefined   = (name.length >= 4 and
                           (strncasecmp(name.data, "Ada.", 4) == 0 or
                            strncasecmp(name.data, "System", 6) == 0 or
                            strncasecmp(name.data, "Interfaces", 10) == 0)),
        .is_internal     = (name.length >= 5 and
                           strncasecmp(name.data, "GNAT.", 5) == 0)
    };

    return id;
}

/* Find vertex by name, returning ID (or 0 if not found) */
static uint32_t Elab_Find_Vertex(const Elab_Graph *g, String_Slice name,
                                  Elab_Unit_Kind kind) {
    for (uint32_t i = 0; i < g->vertex_count; i++) {
        const Elab_Vertex *v = &g->vertices[i];
        if (v->kind == kind and v->name.length == name.length and
            strncasecmp(v->name.data, name.data, name.length) == 0) {
            return v->id;
        }
    }
    return 0;
}

/* Get vertex by ID (1-based), returns NULL if invalid */
static inline Elab_Vertex *Elab_Get_Vertex(Elab_Graph *g, uint32_t id) {
    return (id > 0 and id <= g->vertex_count) ? &g->vertices[id - 1] : NULL;
}

static inline const Elab_Vertex *Elab_Get_Vertex_Const(const Elab_Graph *g, uint32_t id) {
    return (id > 0 and id <= g->vertex_count) ? &g->vertices[id - 1] : NULL;
}

/* Add an edge from pred_id to succ_id, returning edge ID (or 0 on failure) */
static uint32_t Elab_Add_Edge(Elab_Graph *g, uint32_t pred_id, uint32_t succ_id,
                               Elab_Edge_Kind kind) {
    if (g->edge_count >= ELAB_MAX_EDGES) return 0;
    if (pred_id == 0 or succ_id == 0) return 0;
    if (pred_id == succ_id) return 0;  /* No self-loops */

    /* Check for duplicate edge */
    Elab_Vertex *pred = Elab_Get_Vertex(g, pred_id);
    if (pred) {
        for (uint32_t e = pred->first_succ_edge; e; ) {
            const Elab_Edge *edge = &g->edges[e - 1];
            if (edge->succ_vertex_id == succ_id and edge->kind == kind)
                return e;  /* Already exists */
            e = edge->next_pred_edge;
        }
    }

    uint32_t id = ++g->edge_count;
    Elab_Edge *e = &g->edges[id - 1];

    *e = (Elab_Edge){
        .id             = id,
        .kind           = kind,
        .is_strong      = Edge_Kind_Is_Strong(kind),
        .pred_vertex_id = pred_id,
        .succ_vertex_id = succ_id
    };

    /* Thread into predecessor's outgoing list */
    if (pred) {
        e->next_pred_edge = pred->first_succ_edge;
        pred->first_succ_edge = id;
    }

    /* Thread into successor's incoming list */
    Elab_Vertex *succ = Elab_Get_Vertex(g, succ_id);
    if (succ) {
        e->next_succ_edge = succ->first_pred_edge;
        succ->first_pred_edge = id;

        /* Update pending counts */
        if (e->is_strong) succ->pending_strong++;
        else              succ->pending_weak++;
    }

    return id;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §15.7.6 Tarjan's SCC Algorithm — Find strongly connected components
 *
 * Standard O(V+E) algorithm for finding SCCs. Each SCC becomes a component
 * that must be elaborated together (handles circular dependencies).
 *
 * Invariant: After completion, every vertex has a non-zero component_id.
 * ───────────────────────────────────────────────────────────────────────── */

typedef struct {
    uint32_t stack[ELAB_MAX_VERTICES];
    uint32_t stack_top;
    int32_t  index;
} Tarjan_State;

static void Tarjan_Strongconnect(Elab_Graph *g, Tarjan_State *s, uint32_t v_id) {
    Elab_Vertex *v = Elab_Get_Vertex(g, v_id);
    if (not v) return;

    v->tarjan_index = s->index;
    v->tarjan_lowlink = s->index;
    s->index++;

    /* Push onto stack */
    s->stack[s->stack_top++] = v_id;
    v->tarjan_on_stack = true;

    /* Visit all successors */
    for (uint32_t e_id = v->first_succ_edge; e_id; ) {
        const Elab_Edge *e = &g->edges[e_id - 1];
        Elab_Vertex *w = Elab_Get_Vertex(g, e->succ_vertex_id);

        if (w and w->tarjan_index < 0) {
            /* Successor not yet visited */
            Tarjan_Strongconnect(g, s, e->succ_vertex_id);
            v->tarjan_lowlink = (v->tarjan_lowlink < w->tarjan_lowlink)
                              ? v->tarjan_lowlink : w->tarjan_lowlink;
        } else if (w and w->tarjan_on_stack) {
            /* Successor is on stack, part of current SCC */
            v->tarjan_lowlink = (v->tarjan_lowlink < w->tarjan_index)
                              ? v->tarjan_lowlink : w->tarjan_index;
        }

        e_id = e->next_pred_edge;
    }

    /* If v is a root node, pop SCC from stack */
    if (v->tarjan_lowlink == v->tarjan_index) {
        uint32_t comp_id = ++g->component_count;

        uint32_t w_id;
        do {
            w_id = s->stack[--s->stack_top];
            Elab_Vertex *w = Elab_Get_Vertex(g, w_id);
            if (w) {
                w->tarjan_on_stack = false;
                w->component_id = comp_id;
            }
        } while (w_id != v_id);
    }
}

static void Elab_Find_Components(Elab_Graph *g) {
    Tarjan_State s = {.stack_top = 0, .index = 0};

    /* Reset Tarjan state */
    for (uint32_t i = 0; i < g->vertex_count; i++) {
        g->vertices[i].tarjan_index = -1;
        g->vertices[i].tarjan_lowlink = -1;
        g->vertices[i].tarjan_on_stack = false;
        g->vertices[i].component_id = 0;
    }
    g->component_count = 0;

    /* Run Tarjan's algorithm */
    for (uint32_t i = 1; i <= g->vertex_count; i++) {
        if (g->vertices[i - 1].tarjan_index < 0) {
            Tarjan_Strongconnect(g, &s, i);
        }
    }

    /* Compute component-level predecessor counts */
    memset(g->component_pending_strong, 0, sizeof(g->component_pending_strong));
    memset(g->component_pending_weak, 0, sizeof(g->component_pending_weak));

    for (uint32_t i = 0; i < g->edge_count; i++) {
        const Elab_Edge *e = &g->edges[i];
        const Elab_Vertex *pred = Elab_Get_Vertex_Const(g, e->pred_vertex_id);
        const Elab_Vertex *succ = Elab_Get_Vertex_Const(g, e->succ_vertex_id);

        if (pred and succ and pred->component_id != succ->component_id) {
            uint32_t c = succ->component_id;
            if (e->is_strong) g->component_pending_strong[c]++;
            else              g->component_pending_weak[c]++;

            /* Check for Elaborate_All edge in cycle (fatal) */
            if (e->kind == EDGE_ELABORATE_ALL and
                pred->component_id == succ->component_id) {
                g->has_elaborate_all_cycle = true;
            }
        }
    }
}

/* ─────────────────────────────────────────────────────────────────────────
 * §15.7.7 Vertex Predicates — Pure functions for elaboration decisions
 *
 * These predicates determine vertex eligibility and priority.
 * All are pure (no side effects) for functional composition.
 * ───────────────────────────────────────────────────────────────────────── */

/* Can this vertex be elaborated now? (all strong predecessors done) */
static inline bool Elab_Is_Elaborable(const Elab_Vertex *v) {
    return v and not v->in_elab_order and v->pending_strong == 0;
}

/* Can this vertex be weakly elaborated? (only weak predecessors remain) */
static inline bool Elab_Is_Weakly_Elaborable(const Elab_Vertex *v) {
    return v and not v->in_elab_order and
           v->pending_strong == 0 and v->pending_weak > 0;
}

/* Does this spec vertex have an elaborable body? */
static inline bool Elab_Has_Elaborable_Body(const Elab_Graph *g,
                                            const Elab_Vertex *v) {
    (void)g;  /* reserved for future use */
    if (not v or v->kind != UNIT_SPEC) return false;
    if (not v->body_vertex) return false;
    if (v->has_elab_body) return true;  /* pragma Elaborate_Body forces it */
    return Elab_Is_Elaborable(v->body_vertex);
}

/* Compare two vertices for elaboration priority.
 * Returns PREC_HIGHER if a should elaborate before b.
 * Per GNAT bindo-elaborators.adb Is_Better_Elaborable_Vertex. */
static Elab_Precedence Elab_Compare_Vertices(const Elab_Graph *g,
                                              const Elab_Vertex *a,
                                              const Elab_Vertex *b) {
    (void)g;  /* reserved for future use */
    if (not a or not b) return PREC_EQUAL;

    /* 1. Prefer spec with Elaborate_Body before its paired body */
    if (a->has_elab_body and b->spec_vertex == a) return PREC_HIGHER;
    if (b->has_elab_body and a->spec_vertex == b) return PREC_LOWER;

    /* 2. Prefer predefined units (Ada.*, System.*, Interfaces.*) */
    if (a->is_predefined and not b->is_predefined) return PREC_HIGHER;
    if (b->is_predefined and not a->is_predefined) return PREC_LOWER;

    /* 3. Prefer internal units (GNAT.*) */
    if (a->is_internal and not b->is_internal) return PREC_HIGHER;
    if (b->is_internal and not a->is_internal) return PREC_LOWER;

    /* 4. Prefer preelaborated units */
    if (a->is_preelaborate and not b->is_preelaborate) return PREC_HIGHER;
    if (b->is_preelaborate and not a->is_preelaborate) return PREC_LOWER;

    /* 5. Prefer pure units */
    if (a->is_pure and not b->is_pure) return PREC_HIGHER;
    if (b->is_pure and not a->is_pure) return PREC_LOWER;

    /* 6. Lexicographical tiebreaker for determinism */
    size_t min_len = (a->name.length < b->name.length)
                   ? a->name.length : b->name.length;
    int cmp = strncasecmp(a->name.data, b->name.data, min_len);
    if (cmp < 0) return PREC_HIGHER;
    if (cmp > 0) return PREC_LOWER;
    if (a->name.length < b->name.length) return PREC_HIGHER;
    if (a->name.length > b->name.length) return PREC_LOWER;

    return PREC_EQUAL;
}

/* Compare for weak elaboration: prefer fewer weak predecessors */
static Elab_Precedence Elab_Compare_Weak(const Elab_Graph *g,
                                          const Elab_Vertex *a,
                                          const Elab_Vertex *b) {
    if (not a or not b) return PREC_EQUAL;
    if (a->pending_weak < b->pending_weak) return PREC_HIGHER;
    if (a->pending_weak > b->pending_weak) return PREC_LOWER;
    return Elab_Compare_Vertices(g, a, b);
}

/* ─────────────────────────────────────────────────────────────────────────
 * §15.7.8 Vertex Set Operations — Functional set manipulation
 *
 * Uses bitmap representation for O(1) membership testing.
 * Pure functions that return new sets rather than mutating.
 * ───────────────────────────────────────────────────────────────────────── */

typedef struct {
    uint64_t bits[(ELAB_MAX_VERTICES + 63) / 64];
} Elab_Vertex_Set;

static inline Elab_Vertex_Set Elab_Set_Empty(void) {
    return (Elab_Vertex_Set){0};
}

static inline bool Elab_Set_Contains(const Elab_Vertex_Set *s, uint32_t id) {
    if (id == 0 or id > ELAB_MAX_VERTICES) return false;
    return (s->bits[(id - 1) / 64] >> ((id - 1) % 64)) & 1;
}

static inline void Elab_Set_Insert(Elab_Vertex_Set *s, uint32_t id) {
    if (id > 0 and id <= ELAB_MAX_VERTICES)
        s->bits[(id - 1) / 64] |= (1ULL << ((id - 1) % 64));
}

static inline void Elab_Set_Remove(Elab_Vertex_Set *s, uint32_t id) {
    if (id > 0 and id <= ELAB_MAX_VERTICES)
        s->bits[(id - 1) / 64] &= ~(1ULL << ((id - 1) % 64));
}

static inline uint32_t Elab_Set_Size(const Elab_Vertex_Set *s) {
    uint32_t count = 0;
    for (int i = 0; i < (ELAB_MAX_VERTICES + 63) / 64; i++) {
        uint64_t v = s->bits[i];
        while (v) { count++; v &= v - 1; }  /* Brian Kernighan's trick */
    }
    return count;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §15.7.9 Best Vertex Selection — Find optimal elaboration candidate
 *
 * Scans a vertex set to find the best candidate using a comparator.
 * Pure function with no side effects.
 * ───────────────────────────────────────────────────────────────────────── */

typedef bool (*Elab_Vertex_Pred)(const Elab_Vertex *v);
typedef Elab_Precedence (*Elab_Vertex_Cmp)(const Elab_Graph *,
                                           const Elab_Vertex *,
                                           const Elab_Vertex *);

static uint32_t Elab_Find_Best_Vertex(const Elab_Graph *g,
                                       const Elab_Vertex_Set *candidates,
                                       Elab_Vertex_Pred pred,
                                       Elab_Vertex_Cmp cmp) {
    uint32_t best_id = 0;
    const Elab_Vertex *best = NULL;

    for (uint32_t i = 1; i <= g->vertex_count; i++) {
        if (not Elab_Set_Contains(candidates, i)) continue;

        const Elab_Vertex *v = &g->vertices[i - 1];
        if (not pred(v)) continue;

        if (not best or cmp(g, v, best) == PREC_HIGHER) {
            best_id = i;
            best = v;
        }
    }

    return best_id;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §15.7.10 Elaboration Core — The main elaboration algorithm
 *
 * Implements the GNAT LLVM elaboration loop:
 *   1. Create elaborable/waiting vertex sets
 *   2. Repeatedly find best elaborable vertex
 *   3. Elaborate it and update successor counts
 *   4. Handle weak elaboration for cycles
 *
 * Per bindo-elaborators.adb Elaborate_Library_Graph.
 * ───────────────────────────────────────────────────────────────────────── */

/* Update successor when predecessor is elaborated */
static void Elab_Update_Successor(Elab_Graph *g, uint32_t edge_id,
                                   Elab_Vertex_Set *elaborable,
                                   Elab_Vertex_Set *waiting) {
    Elab_Edge *e = (edge_id > 0 and edge_id <= g->edge_count)
                 ? &g->edges[edge_id - 1] : NULL;
    if (not e) return;

    Elab_Vertex *succ = Elab_Get_Vertex(g, e->succ_vertex_id);
    Elab_Vertex *pred = Elab_Get_Vertex(g, e->pred_vertex_id);
    if (not succ or not pred) return;

    /* Decrement appropriate predecessor count */
    if (e->is_strong and succ->pending_strong > 0)
        succ->pending_strong--;
    else if (not e->is_strong and succ->pending_weak > 0)
        succ->pending_weak--;

    /* Update component counts if cross-component edge */
    if (pred->component_id != succ->component_id) {
        uint32_t c = succ->component_id;
        if (e->is_strong and g->component_pending_strong[c] > 0)
            g->component_pending_strong[c]--;
        else if (not e->is_strong and g->component_pending_weak[c] > 0)
            g->component_pending_weak[c]--;
    }

    /* Move successor from waiting to elaborable if now ready */
    if (Elab_Is_Elaborable(succ) and not succ->in_elab_order) {
        Elab_Set_Remove(waiting, succ->id);
        Elab_Set_Insert(elaborable, succ->id);

        /* Also update complement (spec/body pair) */
        Elab_Vertex *comp = succ->body_vertex ? succ->body_vertex
                          : succ->spec_vertex;
        if (comp and Elab_Is_Elaborable(comp) and not comp->in_elab_order) {
            Elab_Set_Remove(waiting, comp->id);
            Elab_Set_Insert(elaborable, comp->id);
        }
    }
}

/* Elaborate a single vertex */
static void Elab_Elaborate_Vertex(Elab_Graph *g, uint32_t v_id,
                                   Elab_Vertex_Set *elaborable,
                                   Elab_Vertex_Set *waiting) {
    Elab_Vertex *v = Elab_Get_Vertex(g, v_id);
    if (not v or v->in_elab_order) return;

    /* Mark as elaborated */
    v->in_elab_order = true;
    Elab_Set_Remove(elaborable, v_id);
    Elab_Set_Remove(waiting, v_id);

    /* Add to elaboration order */
    if (g->order_count < ELAB_MAX_VERTICES)
        g->order[g->order_count++] = v;

    /* Update all successors */
    for (uint32_t e_id = v->first_succ_edge; e_id; ) {
        Elab_Edge *e = &g->edges[e_id - 1];
        Elab_Update_Successor(g, e_id, elaborable, waiting);
        e_id = e->next_pred_edge;
    }

    /* If this is a spec with Elaborate_Body, immediately elaborate the body */
    if (v->has_elab_body and v->body_vertex and
        not v->body_vertex->in_elab_order) {
        Elab_Elaborate_Vertex(g, v->body_vertex->id, elaborable, waiting);
    }

    /* If this spec has an elaborable body, elaborate it too */
    if (Elab_Has_Elaborable_Body(g, v)) {
        Elab_Elaborate_Vertex(g, v->body_vertex->id, elaborable, waiting);
    }
}

/* Main elaboration algorithm */
static Elab_Order_Status Elab_Elaborate_Graph(Elab_Graph *g) {
    /* Initialize vertex sets */
    Elab_Vertex_Set elaborable = Elab_Set_Empty();
    Elab_Vertex_Set waiting = Elab_Set_Empty();

    for (uint32_t i = 1; i <= g->vertex_count; i++) {
        Elab_Vertex *v = &g->vertices[i - 1];
        v->in_elab_order = false;

        if (Elab_Is_Elaborable(v))
            Elab_Set_Insert(&elaborable, i);
        else
            Elab_Set_Insert(&waiting, i);
    }

    g->order_count = 0;

    /* Main elaboration loop */
    while (Elab_Set_Size(&elaborable) > 0 or Elab_Set_Size(&waiting) > 0) {
        /* Find best elaborable vertex */
        uint32_t best_id = Elab_Find_Best_Vertex(
            g, &elaborable, Elab_Is_Elaborable,
            (Elab_Vertex_Cmp)Elab_Compare_Vertices);

        /* If no strongly elaborable vertex, try weak elaboration */
        if (best_id == 0) {
            best_id = Elab_Find_Best_Vertex(
                g, &waiting, Elab_Is_Weakly_Elaborable,
                (Elab_Vertex_Cmp)Elab_Compare_Weak);
        }

        /* If still nothing, we have an unresolvable cycle */
        if (best_id == 0) {
            if (g->has_elaborate_all_cycle)
                return ELAB_ORDER_HAS_ELABORATE_ALL_CYCLE;
            return ELAB_ORDER_HAS_CYCLE;
        }

        Elab_Elaborate_Vertex(g, best_id, &elaborable, &waiting);
    }

    return ELAB_ORDER_OK;
}

/* Pair spec and body vertices after all vertices are added */
static void Elab_Pair_Specs_Bodies(Elab_Graph *g) {
    for (uint32_t i = 0; i < g->vertex_count; i++) {
        Elab_Vertex *v = &g->vertices[i];
        if (v->kind != UNIT_SPEC) continue;

        /* Find matching body */
        for (uint32_t j = 0; j < g->vertex_count; j++) {
            Elab_Vertex *b = &g->vertices[j];
            if (b->kind != UNIT_BODY) continue;
            if (b->name.length != v->name.length) continue;
            if (strncasecmp(b->name.data, v->name.data, v->name.length) != 0)
                continue;

            /* Found the pair */
            v->body_vertex = b;
            b->spec_vertex = v;

            /* Add spec-before-body edge */
            Elab_Add_Edge(g, v->id, b->id, EDGE_SPEC_BEFORE_BODY);
            break;
        }
    }
}

/* ─────────────────────────────────────────────────────────────────────────
 * §15.7.12 Elaboration Order API — Public interface
 *
 * These functions are called from the main driver (§17) and code generator
 * (§13) to determine and use the elaboration order.
 * ───────────────────────────────────────────────────────────────────────── */

/* Global elaboration graph (initialized during compilation) */
static Elab_Graph g_elab_graph;
static bool g_elab_graph_initialized = false;

/* Initialize the global elaboration graph */
static void Elab_Init(void) {
    if (not g_elab_graph_initialized) {
        g_elab_graph = Elab_Graph_New();
        g_elab_graph_initialized = true;
    }
}

/* Add a unit to the elaboration graph */
static uint32_t Elab_Register_Unit(String_Slice name, bool is_body,
                                    Symbol *sym, bool is_preelaborate,
                                    bool is_pure, bool has_elab_code) {
    Elab_Init();

    Elab_Unit_Kind kind = is_body ? UNIT_BODY : UNIT_SPEC;
    uint32_t id = Elab_Find_Vertex(&g_elab_graph, name, kind);

    if (id == 0) {
        id = Elab_Add_Vertex(&g_elab_graph, name, kind, sym);
    }

    Elab_Vertex *v = Elab_Get_Vertex(&g_elab_graph, id);
    if (v) {
        v->symbol = sym;
        v->is_preelaborate = is_preelaborate;
        v->is_pure = is_pure;
        v->needs_elab_code = has_elab_code;
    }

    return id;
}

/* Compute the elaboration order (call after all units registered) */
static Elab_Order_Status Elab_Compute_Order(void) {
    Elab_Init();

    /* Pair specs with their bodies */
    Elab_Pair_Specs_Bodies(&g_elab_graph);

    /* Find strongly connected components */
    Elab_Find_Components(&g_elab_graph);

    /* Compute elaboration order */
    return Elab_Elaborate_Graph(&g_elab_graph);
}

/* Get the computed elaboration order */
static uint32_t Elab_Get_Order_Count(void) {
    return g_elab_graph.order_count;
}

static Symbol *Elab_Get_Order_Symbol(uint32_t index) {
    if (index >= g_elab_graph.order_count) return NULL;
    const Elab_Vertex *v = g_elab_graph.order[index];
    return v ? v->symbol : NULL;
}

static bool Elab_Needs_Elab_Call(uint32_t index) {
    if (index >= g_elab_graph.order_count) return false;
    const Elab_Vertex *v = g_elab_graph.order[index];
    if (not v) return false;

    /* Pure units never need elaboration calls */
    if (v->is_pure) return false;

    /* Preelaborate units without explicit elab code don't need calls */
    if (v->is_preelaborate and not v->needs_elab_code) return false;

    /* Only bodies generate __elab functions */
    return v->kind == UNIT_BODY or v->kind == UNIT_BODY_ONLY;
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §15.8 BUILD-IN-PLACE — Limited Type Function Returns
 *
 * Ada limited types cannot be copied (RM 7.5). Functions returning limited
 * types must construct the result directly in caller-provided space—the
 * "Build-in-Place" (BIP) protocol. This eliminates intermediate temporaries.
 *
 * The protocol passes extra hidden parameters to BIP functions:
 *   __BIPalloc  - Allocation form selector (caller space, heap, pool, etc.)
 *   __BIPaccess - Pointer to destination where result is constructed
 *   __BIPfinal  - Finalization collection (for controlled components)
 *   __BIPmaster - Task master ID (for task components)
 *   __BIPchain  - Activation chain (for task components)
 *
 * Reference: Ada RM 7.5 (Limited Types), RM 6.5 (Return Statements)
 * ═══════════════════════════════════════════════════════════════════════════ */

/* ─────────────────────────────────────────────────────────────────────────
 * §15.8.1 Algebraic Types — Sum types for BIP protocol
 *
 * BIP_Alloc_Form determines where the function result is allocated:
 *   - CALLER: Caller provides stack/object space (most common)
 *   - SECONDARY_STACK: Use secondary stack for dynamic-sized returns
 *   - GLOBAL_HEAP: Allocate on heap (from 'new' expression)
 *   - USER_POOL: Use user-defined storage pool
 *
 * BIP_Formal_Kind identifies which extra formal parameter is being accessed.
 * ───────────────────────────────────────────────────────────────────────── */

typedef enum {
    BIP_ALLOC_UNSPECIFIED = 0,    /* Let callee decide (propagate)          */
    BIP_ALLOC_CALLER      = 1,    /* Build in caller-provided space         */
    BIP_ALLOC_SECONDARY   = 2,    /* Allocate on secondary stack            */
    BIP_ALLOC_GLOBAL_HEAP = 3,    /* Allocate on global heap                */
    BIP_ALLOC_USER_POOL   = 4     /* Allocate from user storage pool        */
} BIP_Alloc_Form;

typedef enum {
    BIP_FORMAL_ALLOC_FORM,        /* Allocation strategy selector           */
    BIP_FORMAL_STORAGE_POOL,      /* Storage pool access (for USER_POOL)    */
    BIP_FORMAL_FINALIZATION,      /* Finalization collection pointer        */
    BIP_FORMAL_TASK_MASTER,       /* Task master ID for task components     */
    BIP_FORMAL_ACTIVATION,        /* Activation chain for task components   */
    BIP_FORMAL_OBJECT_ACCESS      /* Pointer to result destination          */
} BIP_Formal_Kind;

/* ─────────────────────────────────────────────────────────────────────────
 * §15.8.2 BIP Context — State for call-site and return transformation
 *
 * Tracks the BIP state during code generation: what allocation form to use,
 * where to build the result, and whether task/finalization handling needed.
 * ───────────────────────────────────────────────────────────────────────── */

typedef struct {
    Symbol         *func;              /* Function being transformed         */
    Type_Info      *result_type;       /* Return type                        */
    BIP_Alloc_Form  alloc_form;        /* Determined allocation strategy     */
    uint32_t        dest_ptr;          /* Temp holding destination address   */
    bool            needs_finalization;/* Has controlled components          */
    bool            has_tasks;         /* Has task components                */
} BIP_Context;

/* ─────────────────────────────────────────────────────────────────────────
 * §15.8.3 Type Predicates — Pure functions for BIP decisions
 *
 * These predicates determine whether a type requires BIP handling.
 * Per Ada RM 7.5, limited types include:
 *   - Task types (always limited)
 *   - Types with "limited" in their declaration
 *   - Private types declared "limited private"
 *   - Composite types with limited components
 * ───────────────────────────────────────────────────────────────────────── */

/* Forward declaration - full Type_Info checking */
static bool BIP_Type_Has_Task_Component(const Type_Info *t);

/* Check if type is explicitly marked limited (not just by composition) */
static inline bool BIP_Is_Explicitly_Limited(const Type_Info *t) {
    if (not t) return false;
    return t->kind == TYPE_LIMITED_PRIVATE or t->kind == TYPE_TASK;
}

/* Check if type is a task type */
static inline bool BIP_Is_Task_Type(const Type_Info *t) {
    return t and t->kind == TYPE_TASK;
}

/* Check if record type has any limited components (recursive) */
static bool BIP_Record_Has_Limited_Component(const Type_Info *t) {
    if (not t or t->kind != TYPE_RECORD) return false;

    for (uint32_t i = 0; i < t->record.component_count; i++) {
        const Type_Info *ft = t->record.components[i].component_type;
        if (not ft) continue;

        /* Task component makes the record limited */
        if (ft->kind == TYPE_TASK) return true;

        /* Limited private component makes the record limited */
        if (ft->kind == TYPE_LIMITED_PRIVATE) return true;

        /* Recursively check nested records */
        if (ft->kind == TYPE_RECORD and BIP_Record_Has_Limited_Component(ft))
            return true;
    }
    return false;
}

/* Master predicate: Is this type limited? (RM 7.5) */
static bool BIP_Is_Limited_Type(const Type_Info *t) {
    if (not t) return false;

    /* Explicitly marked as limited (from type declaration) */
    if (t->is_limited) return true;

    /* Task types are always limited */
    if (t->kind == TYPE_TASK) return true;

    /* Limited private types */
    if (t->kind == TYPE_LIMITED_PRIVATE) return true;

    /* Records with limited components */
    if (t->kind == TYPE_RECORD and BIP_Record_Has_Limited_Component(t))
        return true;

    /* Arrays of limited element type */
    if (t->kind == TYPE_ARRAY and t->array.element_type and
        BIP_Is_Limited_Type(t->array.element_type))
        return true;

    return false;
}

/* Does this function return a type requiring BIP? */
static inline bool BIP_Is_BIP_Function(const Symbol *func) {
    if (not func or func->kind != SYMBOL_FUNCTION) return false;
    return func->return_type and BIP_Is_Limited_Type(func->return_type);
}

/* Does type have task components (needs activation chain)? */
static bool BIP_Type_Has_Task_Component(const Type_Info *t) {
    if (not t) return false;
    if (t->kind == TYPE_TASK) return true;

    if (t->kind == TYPE_RECORD) {
        for (uint32_t i = 0; i < t->record.component_count; i++) {
            if (BIP_Type_Has_Task_Component(t->record.components[i].component_type))
                return true;
        }
    }

    if (t->kind == TYPE_ARRAY and t->array.element_type)
        return BIP_Type_Has_Task_Component(t->array.element_type);

    return false;
}

/* Does function need allocation form parameter? (unconstrained result) */
static inline bool BIP_Needs_Alloc_Form(const Symbol *func) {
    if (not func or not func->return_type) return false;
    const Type_Info *rt = func->return_type;

    /* Unconstrained arrays need runtime size determination */
    if (rt->kind == TYPE_ARRAY and not rt->array.is_constrained)
        return true;

    return false;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §15.8.4 Extra Formal Parameters — Hidden BIP parameters
 *
 * BIP functions receive extra hidden parameters prepended to their formals:
 *   __BIPalloc  : i32     (BIP_Alloc_Form enum value)
 *   __BIPaccess : ptr     (pointer to result destination)
 *   __BIPmaster : i32     (task master ID, if tasks)
 *   __BIPchain  : ptr     (activation chain, if tasks)
 *
 * These are added during code generation, not during semantic analysis,
 * so the Symbol structure remains unchanged.
 * ───────────────────────────────────────────────────────────────────────── */

/* BIP extra formal names (matched by code generator) */
#define BIP_ALLOC_NAME   "__BIPalloc"
#define BIP_ACCESS_NAME  "__BIPaccess"
#define BIP_MASTER_NAME  "__BIPmaster"
#define BIP_CHAIN_NAME   "__BIPchain"
#define BIP_FINAL_NAME   "__BIPfinal"

/* Count of BIP extra formals for a given function */
static uint32_t BIP_Extra_Formal_Count(const Symbol *func) {
    if (not BIP_Is_BIP_Function(func)) return 0;

    uint32_t count = 2;  /* alloc_form + object_access always present */

    if (BIP_Type_Has_Task_Component(func->return_type))
        count += 2;  /* task_master + activation_chain */

    /* Future: finalization collection for controlled types */
    return count;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §15.8.5 Call-Site Transformation — Expanding BIP function calls
 *
 * When calling a BIP function, the caller must:
 *   1. Determine allocation form (usually CALLER for declarations)
 *   2. Allocate destination space if CALLER
 *   3. Pass extra BIP actuals before regular arguments
 *
 * Transform: X : Limited_Type := F(args);
 * Into:      space = alloca(sizeof(Limited_Type))
 *            F(__BIPalloc => CALLER, __BIPaccess => space, args)
 *            X = *space  (or X IS space if we alias)
 * ───────────────────────────────────────────────────────────────────────── */

/* Determine allocation form from call context */
static BIP_Alloc_Form BIP_Determine_Alloc_Form(bool is_allocator,
                                                bool in_return_stmt,
                                                bool has_target) {
    if (is_allocator)   return BIP_ALLOC_GLOBAL_HEAP;
    if (in_return_stmt) return BIP_ALLOC_UNSPECIFIED;  /* Propagate caller's */
    if (has_target)     return BIP_ALLOC_CALLER;
    return BIP_ALLOC_SECONDARY;  /* Temp needed */
}

/* ─────────────────────────────────────────────────────────────────────────
 * §15.8.6 Return Statement Expansion — Building result in place
 *
 * In a BIP function, return statements build directly into __BIPaccess:
 *
 *   return (Field1 => V1, Field2 => V2);
 *
 * Becomes (for CALLER allocation):
 *   __BIPaccess->Field1 = V1;
 *   __BIPaccess->Field2 = V2;
 *   return;
 *
 * For HEAP allocation, we allocate first then build:
 *   tmp = malloc(sizeof(T));
 *   tmp->Field1 = V1;
 *   tmp->Field2 = V2;
 *   *__BIPaccess = tmp;  // Return allocated pointer
 *   return;
 * ───────────────────────────────────────────────────────────────────────── */

/* BIP return state - tracks current function's BIP context */
typedef struct {
    bool     is_bip_function;     /* Current function uses BIP              */
    uint32_t bip_alloc_param;     /* Temp holding __BIPalloc value          */
    uint32_t bip_access_param;    /* Temp holding __BIPaccess pointer       */
    uint32_t bip_master_param;    /* Temp holding __BIPmaster (if tasks)    */
    uint32_t bip_chain_param;     /* Temp holding __BIPchain (if tasks)     */
    bool     has_task_components; /* Return type has tasks                  */
} BIP_Function_State;

/* Global BIP state for current function being generated */
static BIP_Function_State g_bip_state = {0};

/* Initialize BIP state for a new function */
static void BIP_Begin_Function(const Symbol *func) {
    g_bip_state = (BIP_Function_State){0};

    if (BIP_Is_BIP_Function(func)) {
        g_bip_state.is_bip_function = true;
        g_bip_state.has_task_components =
            BIP_Type_Has_Task_Component(func->return_type);
    }
}

/* Check if we're in a BIP function */
static inline bool BIP_In_BIP_Function(void) {
    return g_bip_state.is_bip_function;
}

/* End BIP state for function */
static void BIP_End_Function(void) {
    g_bip_state = (BIP_Function_State){0};
}

/* ─────────────────────────────────────────────────────────────────────────
 * §15.8.7 BIP Integration API — Called from code generator
 *
 * Public interface for the BIP subsystem:
 *   BIP_Begin_Function()   - Start generating a function
 *   BIP_In_BIP_Function()  - Check if current function is BIP
 *   BIP_Get_Access_Param() - Get destination pointer
 *   BIP_End_Function()     - End function generation
 *   BIP_Is_BIP_Function()  - Check if symbol is BIP function
 *   BIP_Is_Limited_Type()  - Check if type is limited
 * ───────────────────────────────────────────────────────────────────────── */

static const char *Include_Paths[32];
static uint32_t Include_Path_Count = 0;

/* Track loaded package bodies for code generation */
static Syntax_Node *Loaded_Package_Bodies[128];
static int Loaded_Body_Count = 0;

/* Track which package bodies have already been loaded (to avoid duplicates) */
static String_Slice Loaded_Body_Names[128];
static int Loaded_Body_Names_Count = 0;

static bool Body_Already_Loaded(String_Slice name) {
    for (int i = 0; i < Loaded_Body_Names_Count; i++) {
        if (Loaded_Body_Names[i].length == name.length and
            strncasecmp(Loaded_Body_Names[i].data, name.data, name.length) == 0) {
            return true;
        }
    }
    return false;
}

static void Mark_Body_Loaded(String_Slice name) {
    if (Loaded_Body_Names_Count < 128) {
        Loaded_Body_Names[Loaded_Body_Names_Count++] = name;
    }
}

/* Track packages currently being loaded to detect cycles */
typedef struct {
    String_Slice names[64];
    int count;
} Loading_Set;

static Loading_Set Loading_Packages = {0};

static bool Loading_Set_Contains(String_Slice name) {
    for (int i = 0; i < Loading_Packages.count; i++) {
        if (Loading_Packages.names[i].length == name.length and
            strncasecmp(Loading_Packages.names[i].data, name.data, name.length) == 0) {
            return true;
        }
    }
    return false;
}

static void Loading_Set_Add(String_Slice name) {
    if (Loading_Packages.count < 64) {
        Loading_Packages.names[Loading_Packages.count++] = name;
    }
}

static void Loading_Set_Remove(String_Slice name) {
    for (int i = 0; i < Loading_Packages.count; i++) {
        if (Loading_Packages.names[i].length == name.length and
            strncasecmp(Loading_Packages.names[i].data, name.data, name.length) == 0) {
            /* Swap with last and decrement count */
            Loading_Packages.names[i] = Loading_Packages.names[--Loading_Packages.count];
            return;
        }
    }
}

/* Forward declarations for functions defined after Load_Package_Spec */
static char *Lookup_Path(String_Slice name);
static bool Has_Precompiled_LL(String_Slice name);
static char *Lookup_Path_Body(String_Slice name);

/* Find ALI file for a unit name in include paths */
static char *ALI_Find(String_Slice unit_name) {
    static char path_buf[512];
    char file_buf[256];

    /* Convert unit name to file name (lowercase, dots to hyphens) */
    size_t j = 0;
    for (size_t i = 0; i < unit_name.length and j < sizeof(file_buf) - 5; i++) {
        char c = unit_name.data[i];
        if (c == '.') file_buf[j++] = '-';
        else if (c >= 'A' and c <= 'Z') file_buf[j++] = c - 'A' + 'a';
        else file_buf[j++] = c;
    }
    file_buf[j] = '\0';

    /* Try each include path */
    for (uint32_t i = 0; i < Include_Path_Count; i++) {
        snprintf(path_buf, sizeof(path_buf), "%s/%s.ali", Include_Paths[i], file_buf);
        if (access(path_buf, R_OK) == 0) {
            return path_buf;
        }
    }

    return NULL;
}

/* Load symbols from an ALI file into the symbol manager */
static void ALI_Load_Symbols(Symbol_Manager *sm, ALI_Cache_Entry *entry) {
    if (not entry or entry->loaded) return;
    entry->loaded = true;

    /* Recursively load dependencies first */
    for (uint32_t i = 0; i < entry->with_count; i++) {
        char *dep_ali = ALI_Find((String_Slice){entry->withs[i], strlen(entry->withs[i])});
        if (dep_ali) {
            ALI_Cache_Entry *dep = ALI_Read(dep_ali);
            if (dep) ALI_Load_Symbols(sm, dep);
        }
    }

    /* For specs, create package symbol and exports */
    if (not entry->is_spec or entry->export_count == 0) return;

    String_Slice pkg_name = {entry->unit_name, strlen(entry->unit_name)};

    /* Check if package already exists */
    Symbol *pkg_sym = Symbol_Find(sm, pkg_name);
    if (pkg_sym) return;

    /* Create package symbol */
    Source_Location loc = {entry->source_file, 1, 1};
    pkg_sym = Symbol_New(SYMBOL_PACKAGE, pkg_name, loc);
    pkg_sym->type = Type_New(TYPE_PACKAGE, pkg_name);
    Symbol_Add(sm, pkg_sym);

    /* Allocate exported array for qualified access */
    if (entry->export_count > 0) {
        pkg_sym->exported = Arena_Allocate(entry->export_count * sizeof(Symbol*));
        pkg_sym->exported_count = 0;
    }

    /* Push package scope to add exports */
    Symbol_Manager_Push_Scope(sm, pkg_sym);

    /* Create symbols from exports
     *
     * The mangled_name from ALI becomes external_name on Symbol,
     * enabling direct LLVM references without re-mangling.
     */
    for (uint32_t i = 0; i < entry->export_count; i++) {
        ALI_Export *exp = &entry->exports[i];
        String_Slice name = {exp->name, strlen(exp->name)};
        String_Slice mangled = exp->mangled_name ?
            (String_Slice){exp->mangled_name, strlen(exp->mangled_name)} : (String_Slice){0};
        Source_Location exp_loc = {entry->source_file, exp->line, 1};

        Symbol *sym = NULL;
        switch (exp->kind) {
            case 'T': {
                /* Type: create type symbol with size derived from exported LLVM type.
                 * Type_New defaults to 4 bytes (i32) which is wrong for smaller
                 * types like 3-value enumerations (i8).  Use the LLVM type
                 * signature from the ALI export to set the correct size so that
                 * cross-compilation-unit type widths are consistent. */
                sym = Symbol_New(SYMBOL_TYPE, name, exp_loc);
                Type_Info *t = Type_New(TYPE_INTEGER, name);
                if (exp->llvm_type and exp->llvm_type[0] == 'i') {
                    int bits = atoi(exp->llvm_type + 1);
                    if (bits > 0) t->size = (bits + 7) / 8;
                }
                sym->type = t;
                break;
            }
            case 'S': {
                /* Subtype: link to base type */
                sym = Symbol_New(SYMBOL_SUBTYPE, name, exp_loc);
                if (exp->type_name) {
                    String_Slice base = {exp->type_name, strlen(exp->type_name)};
                    Symbol *base_sym = Symbol_Find(sm, base);
                    sym->type = base_sym ? base_sym->type : Type_New(TYPE_INTEGER, base);
                } else {
                    sym->type = Type_New(TYPE_INTEGER, name);
                }
                break;
            }
            case 'V': {
                /* Variable: external reference */
                sym = Symbol_New(SYMBOL_VARIABLE, name, exp_loc);
                sym->is_imported = true;
                sym->external_name = mangled;
                if (exp->type_name) {
                    String_Slice tn = {exp->type_name, strlen(exp->type_name)};
                    Symbol *ts = Symbol_Find(sm, tn);
                    sym->type = ts ? ts->type : Type_New(TYPE_INTEGER, tn);
                }
                break;
            }
            case 'C': {
                /* Constant: external reference */
                sym = Symbol_New(SYMBOL_CONSTANT, name, exp_loc);
                sym->is_imported = true;
                sym->external_name = mangled;
                if (exp->type_name) {
                    String_Slice tn = {exp->type_name, strlen(exp->type_name)};
                    Symbol *ts = Symbol_Find(sm, tn);
                    sym->type = ts ? ts->type : Type_New(TYPE_INTEGER, tn);
                }
                break;
            }
            case 'P': {
                /* Procedure: external subprogram declaration */
                sym = Symbol_New(SYMBOL_PROCEDURE, name, exp_loc);
                sym->is_imported = true;
                sym->external_name = mangled;
                sym->parameter_count = exp->param_count;
                break;
            }
            case 'F': {
                /* Function: external subprogram declaration */
                sym = Symbol_New(SYMBOL_FUNCTION, name, exp_loc);
                sym->is_imported = true;
                sym->external_name = mangled;
                sym->parameter_count = exp->param_count;
                if (exp->type_name) {
                    String_Slice tn = {exp->type_name, strlen(exp->type_name)};
                    Symbol *ts = Symbol_Find(sm, tn);
                    sym->return_type = ts ? ts->type : Type_New(TYPE_INTEGER, tn);
                    sym->type = sym->return_type;  /* For consistency */
                }
                break;
            }
            case 'E': {
                /* Exception: external exception identity */
                sym = Symbol_New(SYMBOL_EXCEPTION, name, exp_loc);
                sym->is_imported = true;
                sym->external_name = mangled;
                break;
            }
        }

        if (sym) {
            sym->parent = pkg_sym;  /* Set parent for proper scoping */
            Symbol_Add(sm, sym);
            /* Also add to package exported list for qualified access */
            if (pkg_sym->exported_count < 256) {
                pkg_sym->exported[pkg_sym->exported_count++] = sym;
            }
        }
    }

    Symbol_Manager_Pop_Scope(sm);
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §14. INCLUDE PATH & PACKAGE LOADING
 * ═══════════════════════════════════════════════════════════════════════════
 */

/* Try_Load_From_ALI — Called by Load_Package_Spec to attempt ALI-based loading
 *
 * This is the entry point for ALI-based separate compilation:
 *   1. Look for ALI file in include paths
 *   2. Verify checksum against source
 *   3. Load symbols directly from ALI X lines
 *
 * Returns true if successful (caller should skip parsing).
 */
static bool Try_Load_From_ALI(Symbol_Manager *sm, String_Slice name) {
    char *ali_path = ALI_Find(name);
    if (not ali_path) return false;

    /* Build source path from unit name */
    char source_file[256];
    size_t j = 0;
    for (size_t i = 0; i < name.length and j < sizeof(source_file) - 5; i++) {
        char c = name.data[i];
        if (c == '.') source_file[j++] = '-';
        else if (c >= 'A' and c <= 'Z') source_file[j++] = c - 'A' + 'a';
        else source_file[j++] = c;
    }
    strcpy(source_file + j, ".ads");

    /* Find full source path in include paths */
    char full_source_path[512] = {0};
    for (uint32_t i = 0; i < Include_Path_Count; i++) {
        snprintf(full_source_path, sizeof(full_source_path), "%s/%s",
                 Include_Paths[i], source_file);
        if (access(full_source_path, R_OK) == 0) break;
        full_source_path[0] = '\0';
    }

    if (not full_source_path[0]) return false;

    /* Check if ALI is current */
    if (not ALI_Is_Current(ali_path, full_source_path)) {
        return false;  /* Stale - need to recompile */
    }

    /* Read ALI and check for exports */
    ALI_Cache_Entry *entry = ALI_Read(ali_path);
    if (not entry or entry->export_count == 0) return false;

    /* Load symbols from ALI */
    ALI_Load_Symbols(sm, entry);
    return true;
}


/* Load and resolve a package specification */
static void Load_Package_Spec(Symbol_Manager *sm, String_Slice name, char *src) {
    if (not src) return;

    /* Check if already loaded */
    Symbol *existing = Symbol_Find(sm, name);
    if (existing and existing->kind == SYMBOL_PACKAGE and existing->declaration) {
        return;  /* Already loaded */
    }

    /* Check for circular dependency (package currently being loaded) */
    if (Loading_Set_Contains(name)) {
        return;  /* Break cycle - package will be available when outer load completes */
    }

    /* Try to load from cached ALI file first.
     * If successful, we skip parsing entirely. */
    if (Try_Load_From_ALI(sm, name)) {
        return;
    }

    /* Mark package as loading to detect cycles */
    Loading_Set_Add(name);

    /* Parse the package (ALI not available or stale) */
    size_t fn_len = name.length + 4; /* ".ads" */
    char *filename = Arena_Allocate(fn_len + 1);
    snprintf(filename, fn_len + 1, "%.*s.ads", (int)name.length, name.data);
    Parser p = Parser_New(src, strlen(src), filename);
    Syntax_Node *cu = Parse_Compilation_Unit(&p);

    if (not cu) {
        Loading_Set_Remove(name);
        return;
    }

    /* Recursively load WITH'd packages */
    if (cu->compilation_unit.context) {
        Node_List *withs = &cu->compilation_unit.context->context.with_clauses;
        for (uint32_t i = 0; i < withs->count; i++) {
            Syntax_Node *with_node = withs->items[i];
            for (uint32_t j = 0; j < with_node->use_clause.names.count; j++) {
                Syntax_Node *pkg_name = with_node->use_clause.names.items[j];
                if (pkg_name->kind == NK_IDENTIFIER) {
                    char *pkg_src = Lookup_Path(pkg_name->string_val.text);
                    if (pkg_src) {
                        Load_Package_Spec(sm, pkg_name->string_val.text, pkg_src);
                    }
                }
            }
        }
    }

    /* Resolve the package declarations */
    if (cu->compilation_unit.unit) {
        Syntax_Node *unit = cu->compilation_unit.unit;

        if (unit->kind == NK_PACKAGE_SPEC) {
            Syntax_Node *pkg = unit;

            /* Create package symbol */
            Symbol *pkg_sym = Symbol_New(SYMBOL_PACKAGE, pkg->package_spec.name,
                                         pkg->location);
            Type_Info *pkg_type = Type_New(TYPE_PACKAGE, pkg->package_spec.name);
            pkg_sym->type = pkg_type;
            pkg_sym->declaration = pkg;
            Symbol_Add(sm, pkg_sym);
            pkg->symbol = pkg_sym;

            /* Push package scope */
            Symbol_Manager_Push_Scope(sm, pkg_sym);

            /* Resolve visible declarations */
            Resolve_Declaration_List(sm, &pkg->package_spec.visible_decls);

            /* Populate package exports for qualified access (e.g., SYSTEM.MAX_INT) */
            Populate_Package_Exports(pkg_sym, pkg);

            /* Resolve private declarations */
            Resolve_Declaration_List(sm, &pkg->package_spec.private_decls);

            Symbol_Manager_Pop_Scope(sm);

            /* SYSTEM.ADDRESS override (RM 13.7):
             * The SYSTEM package declares ADDRESS as NEW INTEGER (32-bit),
             * but on 64-bit targets, addresses require 64 bits.  Override
             * the parsed type to match the compiler's internal type_address. */
            if (Slice_Equal_Ignore_Case(name, S("SYSTEM")) and sm->type_address) {
                for (uint32_t ei = 0; ei < pkg_sym->exported_count; ei++) {
                    Symbol *esym = pkg_sym->exported[ei];
                    if (esym and esym->type and
                        Slice_Equal_Ignore_Case(esym->name, S("ADDRESS"))) {
                        esym->type->size = sm->type_address->size;
                        esym->type->alignment = sm->type_address->alignment;
                        esym->type->low_bound = sm->type_address->low_bound;
                        esym->type->high_bound = sm->type_address->high_bound;
                        break;
                    }
                }
            }
        }
        else if (unit->kind == NK_GENERIC_DECL) {
            /* Generic unit: create SYMBOL_GENERIC with the inner spec */
            Syntax_Node *inner = unit->generic_decl.unit;
            String_Slice unit_name = {0};

            if (inner and inner->kind == NK_PACKAGE_SPEC) {
                unit_name = inner->package_spec.name;
            } else if (inner and (inner->kind == NK_PROCEDURE_SPEC or
                                 inner->kind == NK_FUNCTION_SPEC)) {
                unit_name = inner->subprogram_spec.name;
            }

            if (unit_name.data) {
                /* Create generic symbol */
                Symbol *sym = Symbol_New(SYMBOL_GENERIC, unit_name, unit->location);
                sym->declaration = unit;
                sym->generic_unit = inner;

                /* Store formals list for later instantiation */
                if (unit->generic_decl.formals.count > 0) {
                    sym->generic_formals = unit->generic_decl.formals.items[0];
                }

                Symbol_Add(sm, sym);
                unit->symbol = sym;

                /* Resolve the generic package spec's declarations so type/exception
                 * names are available when the body is parsed. Push scope, install
                 * generic formals, then resolve visible/private declarations. */
                if (inner and inner->kind == NK_PACKAGE_SPEC) {
                    Symbol_Manager_Push_Scope(sm, sym);

                    /* Install generic formal parameters */
                    Node_List *formals = &unit->generic_decl.formals;
                    for (uint32_t i = 0; i < formals->count; i++) {
                        Syntax_Node *formal = formals->items[i];
                        if (formal->kind == NK_GENERIC_TYPE_PARAM) {
                            Symbol *type_sym = Symbol_New(SYMBOL_TYPE,
                                formal->generic_type_param.name, formal->location);
                            /* Map def_kind to appropriate Type_Kind */
                            Type_Kind tk = TYPE_PRIVATE;
                            switch (formal->generic_type_param.def_kind) {
                                case 2: tk = TYPE_ENUMERATION; break; /* DISCRETE */
                                case 3: tk = TYPE_INTEGER; break;     /* INTEGER */
                                case 4: tk = TYPE_FLOAT; break;       /* FLOAT */
                                case 5: tk = TYPE_FIXED; break;       /* FIXED */
                                case 6: tk = TYPE_ARRAY; break;       /* ARRAY */
                                case 7: tk = TYPE_ACCESS; break;      /* ACCESS */
                                default: tk = TYPE_PRIVATE; break;
                            }
                            Type_Info *type = Type_New(tk, formal->generic_type_param.name);
                            type_sym->type = type;
                            formal->symbol = type_sym;
                            Symbol_Add(sm, type_sym);
                        }
                    }

                    /* Resolve visible declarations */
                    Resolve_Declaration_List(sm, &inner->package_spec.visible_decls);

                    /* Populate package exports for qualified access */
                    Populate_Package_Exports(sym, inner);

                    /* Resolve private declarations */
                    Resolve_Declaration_List(sm, &inner->package_spec.private_decls);

                    Symbol_Manager_Pop_Scope(sm);
                }
            }
        }
    }

    /* Done loading this package */
    Loading_Set_Remove(name);

    /* Also try to load the package body if available.
     * Skip if a precompiled .ll file exists (package provided externally). */
    if (Body_Already_Loaded(name)) {
        return;  /* Body already loaded */
    }
    if (Has_Precompiled_LL(name)) {
        return;  /* Precompiled version will be linked in */
    }
    char *body_src = Lookup_Path_Body(name);
    if (body_src and Loaded_Body_Count < 128) {
        Mark_Body_Loaded(name);
        /* Parse the body — arena-allocate filename so AST Source_Locations stay valid */
        size_t bfn_len = name.length + 4;
        char *body_filename = Arena_Allocate(bfn_len + 1);
        snprintf(body_filename, bfn_len + 1, "%.*s.adb", (int)name.length, name.data);
        Parser body_parser = Parser_New(body_src, strlen(body_src), body_filename);
        Syntax_Node *body_cu = Parse_Compilation_Unit(&body_parser);

        if (body_cu and body_cu->compilation_unit.unit) {
            Syntax_Node *body_unit = body_cu->compilation_unit.unit;

            /* Recursively load WITH'd packages from body */
            if (body_cu->compilation_unit.context) {
                Node_List *withs = &body_cu->compilation_unit.context->context.with_clauses;
                for (uint32_t i = 0; i < withs->count; i++) {
                    Syntax_Node *with_node = withs->items[i];
                    for (uint32_t j = 0; j < with_node->use_clause.names.count; j++) {
                        Syntax_Node *pkg_name = with_node->use_clause.names.items[j];
                        if (pkg_name->kind == NK_IDENTIFIER) {
                            char *pkg_src = Lookup_Path(pkg_name->string_val.text);
                            if (pkg_src) {
                                Load_Package_Spec(sm, pkg_name->string_val.text, pkg_src);
                            }
                        }
                    }
                }
            }

            if (body_unit->kind == NK_PACKAGE_BODY) {
                /* Look up the package symbol */
                String_Slice body_name = body_unit->package_body.name;
                Symbol *pkg_sym = Symbol_Find(sm, body_name);

                if (pkg_sym and (pkg_sym->kind == SYMBOL_PACKAGE or pkg_sym->kind == SYMBOL_GENERIC)) {
                    /* Link body to spec */
                    body_unit->symbol = pkg_sym;

                    /* For generic packages, store the body for later instantiation */
                    if (pkg_sym->kind == SYMBOL_GENERIC) {
                        pkg_sym->generic_body = body_unit;
                    }

                    /* Resolve the body within package scope */
                    Symbol_Manager_Push_Scope(sm, pkg_sym);

                    /* Install visible and private declarations from package spec
                     * into the body's scope (RM 7.1, 7.2) */
                    Syntax_Node *spec = pkg_sym->declaration;
                    /* For generics, install formals first, then look at the unit */
                    if (spec and spec->kind == NK_GENERIC_DECL) {
                        Node_List *formals = &spec->generic_decl.formals;
                        for (uint32_t i = 0; i < formals->count; i++) {
                            Syntax_Node *formal = formals->items[i];
                            if (formal->symbol) Symbol_Add(sm, formal->symbol);
                            /* For generic type parameters, create type symbol if needed */
                            if (formal->kind == NK_GENERIC_TYPE_PARAM and not formal->symbol) {
                                Symbol *type_sym = Symbol_New(SYMBOL_TYPE,
                                    formal->generic_type_param.name, formal->location);
                                /* Map def_kind to appropriate Type_Kind */
                                Type_Kind tk = TYPE_PRIVATE;
                                switch (formal->generic_type_param.def_kind) {
                                    case 2: tk = TYPE_ENUMERATION; break; /* DISCRETE */
                                    case 3: tk = TYPE_INTEGER; break;     /* INTEGER */
                                    case 4: tk = TYPE_FLOAT; break;       /* FLOAT */
                                    case 5: tk = TYPE_FIXED; break;       /* FIXED */
                                    case 6: tk = TYPE_ARRAY; break;       /* ARRAY */
                                    case 7: tk = TYPE_ACCESS; break;      /* ACCESS */
                                    default: tk = TYPE_PRIVATE; break;
                                }
                                Type_Info *type = Type_New(tk, formal->generic_type_param.name);
                                type_sym->type = type;
                                formal->symbol = type_sym;
                                Symbol_Add(sm, type_sym);
                            }
                        }
                        spec = spec->generic_decl.unit;
                    }
                    if (spec and spec->kind == NK_PACKAGE_SPEC) {
                        /* Helper: install symbols from a declaration */
                        #define INSTALL_DECL_SYMBOLS(decl) do { \
                            if ((decl)->symbol) Symbol_Add(sm, (decl)->symbol); \
                            if ((decl)->kind == NK_OBJECT_DECL) { \
                                for (uint32_t k = 0; k < (decl)->object_decl.names.count; k++) { \
                                    Syntax_Node *n = (decl)->object_decl.names.items[k]; \
                                    if (n->symbol) Symbol_Add(sm, n->symbol); \
                                } \
                            } \
                            if ((decl)->kind == NK_EXCEPTION_DECL) { \
                                for (uint32_t k = 0; k < (decl)->exception_decl.names.count; k++) { \
                                    Syntax_Node *n = (decl)->exception_decl.names.items[k]; \
                                    if (n->symbol) Symbol_Add(sm, n->symbol); \
                                } \
                            } \
                            if ((decl)->kind == NK_TYPE_DECL and (decl)->type_decl.definition and \
                                (decl)->type_decl.definition->kind == NK_ENUMERATION_TYPE) { \
                                Node_List *lits = &(decl)->type_decl.definition->enum_type.literals; \
                                for (uint32_t k = 0; k < lits->count; k++) { \
                                    if (lits->items[k]->symbol) Symbol_Add(sm, lits->items[k]->symbol); \
                                } \
                            } \
                        } while(0)

                        /* Install visible declarations */
                        for (uint32_t i = 0; i < spec->package_spec.visible_decls.count; i++) {
                            Syntax_Node *decl = spec->package_spec.visible_decls.items[i];
                            INSTALL_DECL_SYMBOLS(decl);
                        }
                        /* Install private declarations */
                        for (uint32_t i = 0; i < spec->package_spec.private_decls.count; i++) {
                            Syntax_Node *decl = spec->package_spec.private_decls.items[i];
                            INSTALL_DECL_SYMBOLS(decl);
                        }
                        #undef INSTALL_DECL_SYMBOLS
                    }

                    Resolve_Declaration_List(sm, &body_unit->package_body.declarations);
                    Symbol_Manager_Pop_Scope(sm);

                    /* Store for code generation */
                    Loaded_Package_Bodies[Loaded_Body_Count++] = body_cu;
                }
            }
        }
    }
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §16. GENERIC EXPANSION - Macro-style instantiation
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * Generics via macro expansion:
 *   1. Parse generic declaration > store template AST
 *   2. On instantiation: clone template, substitute actuals
 *   3. Analyze cloned tree with actual types
 *   4. Generate code for each instantiation separately
 *
 * Key insight: We do NOT share code between instantiations. Each instance
 * gets its own copy with types fully substituted.
 */

/* ─────────────────────────────────────────────────────────────────────────
 * §16.1 Instantiation_Env — Formal-to-actual mapping
 *
 * Instead of mutating nodes, we carry substitution environment through.
 * ───────────────────────────────────────────────────────────────────────── */

typedef struct {
    String_Slice  formal_name;    /* Generic formal parameter name */
    Type_Info    *actual_type;    /* Substituted actual type */
    Symbol       *actual_symbol;  /* Actual symbol (for subprogram formals) */
    Syntax_Node  *actual_expr;    /* Actual expression (for object formals) */
} Generic_Mapping;

typedef struct {
    Generic_Mapping  mappings[32];
    uint32_t         count;
    Symbol          *instance_sym;   /* The instantiation symbol */
    Symbol          *template_sym;   /* The generic template symbol */
} Instantiation_Env;

/* ─────────────────────────────────────────────────────────────────────────
 * §16.2 Instantiation_Env helpers
 * ───────────────────────────────────────────────────────────────────────── */

static Type_Info *Env_Lookup_Type(Instantiation_Env *env, String_Slice name) {
    for (uint32_t i = 0; i < env->count; i++) {
        if (Slice_Equal_Ignore_Case(env->mappings[i].formal_name, name))
            return env->mappings[i].actual_type;
    }
    return NULL;
}

static Syntax_Node *Env_Lookup_Expr(Instantiation_Env *env, String_Slice name) {
    for (uint32_t i = 0; i < env->count; i++) {
        if (Slice_Equal_Ignore_Case(env->mappings[i].formal_name, name))
            return env->mappings[i].actual_expr;
    }
    return NULL;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §16.3 Node_Deep_Clone — Deep copy with environment substitution
 *
 * Unlike the existing node_clone_substitute, this:
 *   • ALWAYS allocates new nodes (no aliasing)
 *   • Uses recursion depth tracking with proper error
 *   • Carries environment for type substitution
 * ───────────────────────────────────────────────────────────────────────── */

static Syntax_Node *Node_Deep_Clone(Syntax_Node *node, Instantiation_Env *env,
                                    int depth);

/* Clone a node list */
static void Node_List_Clone(Node_List *dst, Node_List *src,
                            Instantiation_Env *env, int depth) {
    dst->count = 0;
    dst->capacity = 0;
    dst->items = NULL;
    for (uint32_t i = 0; i < src->count; i++) {
        Syntax_Node *cloned = Node_Deep_Clone(src->items[i], env, depth);
        Node_List_Push(dst, cloned);
    }
}

static Syntax_Node *Node_Deep_Clone(Syntax_Node *node, Instantiation_Env *env,
                                    int depth) {
    if (not node) return NULL;

    /* Depth limit with REAL error, not silent aliasing */
    if (depth > 500) {
        Report_Error(node->location, "generic instantiation too deeply nested");
        return NULL;
    }

    /* Allocate fresh node */
    Syntax_Node *n = Arena_Allocate(sizeof(Syntax_Node));
    memset(n, 0, sizeof(Syntax_Node));  /* Zero-init ALL fields */
    n->kind = node->kind;
    n->location = node->location;
    n->type = node->type;
    n->symbol = NULL;  /* Symbols will be re-resolved */

    /* Substitute generic formal types throughout the cloned tree.
     * When a node carries a TYPE_PRIVATE/TYPE_LIMITED_PRIVATE type whose
     * name matches a generic formal parameter, replace it with the actual
     * type.  This ensures that expressions, declarations, and statements
     * all use the concrete type (e.g., FLOAT) rather than the opaque
     * formal type (e.g., ELEMENT_TYPE). */
    if (env and n->type and Type_Is_Private(n->type) and n->type->name.data) {
        Type_Info *subst = Env_Lookup_Type(env, n->type->name);
        if (subst) n->type = subst;
    }

    switch (node->kind) {
        case NK_IDENTIFIER:
            /* Check for expression substitution (formal object parameters) */
            if (env) {
                Syntax_Node *expr_subst = Env_Lookup_Expr(env, node->string_val.text);
                if (expr_subst) {
                    /* Return a clone of the actual expression instead.
                     * The 'n' node becomes garbage but arena will reclaim it. */
                    return Node_Deep_Clone(expr_subst, env, depth + 1);
                }
            }
            n->string_val = node->string_val;
            /* Check for type substitution */
            if (env) {
                Type_Info *subst = Env_Lookup_Type(env, node->string_val.text);
                if (subst) n->type = subst;
            }
            break;

        case NK_INTEGER:
            n->integer_lit = node->integer_lit;
            break;

        case NK_REAL:
            n->real_lit = node->real_lit;
            break;

        case NK_STRING:
        case NK_CHARACTER:
            n->string_val = node->string_val;
            break;

        case NK_BINARY_OP:
            n->binary.op = node->binary.op;
            n->binary.left = Node_Deep_Clone(node->binary.left, env, depth + 1);
            n->binary.right = Node_Deep_Clone(node->binary.right, env, depth + 1);
            break;

        case NK_UNARY_OP:
            n->unary.op = node->unary.op;
            n->unary.operand = Node_Deep_Clone(node->unary.operand, env, depth + 1);
            break;

        case NK_ATTRIBUTE:
            n->attribute.prefix = Node_Deep_Clone(node->attribute.prefix, env, depth + 1);
            n->attribute.name = node->attribute.name;
            Node_List_Clone(&n->attribute.arguments, &node->attribute.arguments, env, depth + 1);
            break;

        case NK_APPLY:
            n->apply.prefix = Node_Deep_Clone(node->apply.prefix, env, depth + 1);
            Node_List_Clone(&n->apply.arguments, &node->apply.arguments, env, depth + 1);
            break;

        case NK_SELECTED:
            n->selected.prefix = Node_Deep_Clone(node->selected.prefix, env, depth + 1);
            n->selected.selector = node->selected.selector;  /* String_Slice, not a node */
            break;

        case NK_AGGREGATE:
            Node_List_Clone(&n->aggregate.items, &node->aggregate.items, env, depth + 1);
            n->aggregate.is_named = node->aggregate.is_named;
            break;

        case NK_ASSOCIATION:
            Node_List_Clone(&n->association.choices, &node->association.choices, env, depth + 1);
            n->association.expression = Node_Deep_Clone(node->association.expression, env, depth + 1);
            break;

        case NK_RANGE:
            n->range.low = Node_Deep_Clone(node->range.low, env, depth + 1);
            n->range.high = Node_Deep_Clone(node->range.high, env, depth + 1);
            break;

        case NK_OBJECT_DECL:
            Node_List_Clone(&n->object_decl.names, &node->object_decl.names, env, depth + 1);
            n->object_decl.object_type = Node_Deep_Clone(node->object_decl.object_type, env, depth + 1);
            n->object_decl.init = Node_Deep_Clone(node->object_decl.init, env, depth + 1);
            n->object_decl.is_constant = node->object_decl.is_constant;
            n->object_decl.is_rename = node->object_decl.is_rename;
            break;

        case NK_TYPE_DECL:
        case NK_SUBTYPE_DECL:
            n->type_decl.name = node->type_decl.name;
            n->type_decl.definition = Node_Deep_Clone(node->type_decl.definition, env, depth + 1);
            Node_List_Clone(&n->type_decl.discriminants, &node->type_decl.discriminants, env, depth + 1);
            break;

        case NK_PROCEDURE_BODY:
        case NK_FUNCTION_BODY:
            n->subprogram_body.specification = Node_Deep_Clone(node->subprogram_body.specification, env, depth + 1);
            Node_List_Clone(&n->subprogram_body.declarations, &node->subprogram_body.declarations, env, depth + 1);
            Node_List_Clone(&n->subprogram_body.statements, &node->subprogram_body.statements, env, depth + 1);
            Node_List_Clone(&n->subprogram_body.handlers, &node->subprogram_body.handlers, env, depth + 1);
            n->subprogram_body.is_separate = node->subprogram_body.is_separate;
            break;

        case NK_PROCEDURE_SPEC:
        case NK_FUNCTION_SPEC:
            n->subprogram_spec.name = node->subprogram_spec.name;
            Node_List_Clone(&n->subprogram_spec.parameters, &node->subprogram_spec.parameters, env, depth + 1);
            n->subprogram_spec.return_type = Node_Deep_Clone(node->subprogram_spec.return_type, env, depth + 1);
            n->subprogram_spec.renamed = Node_Deep_Clone(node->subprogram_spec.renamed, env, depth + 1);
            break;

        case NK_PARAM_SPEC:
            Node_List_Clone(&n->param_spec.names, &node->param_spec.names, env, depth + 1);
            n->param_spec.mode = node->param_spec.mode;
            n->param_spec.param_type = Node_Deep_Clone(node->param_spec.param_type, env, depth + 1);
            n->param_spec.default_expr = Node_Deep_Clone(node->param_spec.default_expr, env, depth + 1);
            break;

        case NK_PACKAGE_SPEC:
            n->package_spec.name = node->package_spec.name;
            Node_List_Clone(&n->package_spec.visible_decls, &node->package_spec.visible_decls, env, depth + 1);
            Node_List_Clone(&n->package_spec.private_decls, &node->package_spec.private_decls, env, depth + 1);
            break;

        case NK_PACKAGE_BODY:
            n->package_body.name = node->package_body.name;
            Node_List_Clone(&n->package_body.declarations, &node->package_body.declarations, env, depth + 1);
            Node_List_Clone(&n->package_body.statements, &node->package_body.statements, env, depth + 1);
            Node_List_Clone(&n->package_body.handlers, &node->package_body.handlers, env, depth + 1);
            break;

        case NK_ASSIGNMENT:
        case NK_CALL_STMT:  /* Reuses assignment.target field */
            n->assignment.target = Node_Deep_Clone(node->assignment.target, env, depth + 1);
            n->assignment.value = Node_Deep_Clone(node->assignment.value, env, depth + 1);
            break;

        case NK_IF:
            n->if_stmt.condition = Node_Deep_Clone(node->if_stmt.condition, env, depth + 1);
            Node_List_Clone(&n->if_stmt.then_stmts, &node->if_stmt.then_stmts, env, depth + 1);
            Node_List_Clone(&n->if_stmt.elsif_parts, &node->if_stmt.elsif_parts, env, depth + 1);
            Node_List_Clone(&n->if_stmt.else_stmts, &node->if_stmt.else_stmts, env, depth + 1);
            break;

        case NK_LOOP:
            n->loop_stmt.label = node->loop_stmt.label;
            n->loop_stmt.iteration_scheme = Node_Deep_Clone(node->loop_stmt.iteration_scheme, env, depth + 1);
            Node_List_Clone(&n->loop_stmt.statements, &node->loop_stmt.statements, env, depth + 1);
            n->loop_stmt.is_reverse = node->loop_stmt.is_reverse;
            break;

        case NK_RETURN:
            n->return_stmt.expression = Node_Deep_Clone(node->return_stmt.expression, env, depth + 1);
            break;

        case NK_BLOCK:
            n->block_stmt.label = node->block_stmt.label;
            Node_List_Clone(&n->block_stmt.declarations, &node->block_stmt.declarations, env, depth + 1);
            Node_List_Clone(&n->block_stmt.statements, &node->block_stmt.statements, env, depth + 1);
            Node_List_Clone(&n->block_stmt.handlers, &node->block_stmt.handlers, env, depth + 1);
            break;

        case NK_CASE:
            n->case_stmt.expression = Node_Deep_Clone(node->case_stmt.expression, env, depth + 1);
            Node_List_Clone(&n->case_stmt.alternatives, &node->case_stmt.alternatives, env, depth + 1);
            break;

        case NK_EXIT:
            n->exit_stmt.loop_name = node->exit_stmt.loop_name;
            n->exit_stmt.condition = Node_Deep_Clone(node->exit_stmt.condition, env, depth + 1);
            break;

        case NK_NULL_STMT:
        case NK_OTHERS:
            /* No fields to copy */
            break;

        default:
            /* For node kinds not explicitly handled, do shallow copy.
             * This is safer than the original which returned aliased nodes. */
            *n = *node;
            n->symbol = NULL;
            break;
    }

    return n;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §16.4 Build_Instantiation_Env — Create mapping from formals to actuals
 * ───────────────────────────────────────────────────────────────────────── */

static void Build_Instantiation_Env(Instantiation_Env *env,
                                    Symbol *template_sym,
                                    Symbol *instance_sym,
                                    Symbol_Manager *sm) {
    (void)sm;  /* reserved for future use */
    env->count = 0;
    env->template_sym = template_sym;
    env->instance_sym = instance_sym;

    if (not template_sym or not template_sym->declaration) return;

    Syntax_Node *gen_decl = template_sym->declaration;
    if (gen_decl->kind != NK_GENERIC_DECL) return;

    Node_List *formals = &gen_decl->generic_decl.formals;

    /* Use pre-resolved actuals from instance symbol */
    for (uint32_t i = 0; i < instance_sym->generic_actual_count and i < 32; i++) {
        Generic_Mapping *m = &env->mappings[env->count++];
        m->formal_name = instance_sym->generic_actuals[i].formal_name;
        m->actual_type = instance_sym->generic_actuals[i].actual_type;
        m->actual_symbol = NULL;
        m->actual_expr = NULL;

        /* For object/subprogram formals, populate additional fields */
        if (i < formals->count) {
            Syntax_Node *formal = formals->items[i];
            if (formal->kind == NK_GENERIC_OBJECT_PARAM) {
                /* Store expression for object formals */
                m->actual_expr = instance_sym->generic_actuals[i].actual_expr;
            } else if (formal->kind == NK_GENERIC_SUBPROGRAM_PARAM) {
                /* Store actual subprogram symbol for substitution during clone */
                m->actual_symbol = instance_sym->generic_actuals[i].actual_subprogram;
            }
        }
    }
}

/* ─────────────────────────────────────────────────────────────────────────
 * §16.5 Expand_Generic_Package — Full instantiation of generic package
 *
 *   1. Clone the package spec with type substitutions
 *   2. Clone the package body (if found)
 *   3. Resolve cloned trees with actual types
 *   4. Store expanded body for code generation
 * ───────────────────────────────────────────────────────────────────────── */

static void Expand_Generic_Package(Symbol_Manager *sm, Symbol *instance_sym) {
    if (not instance_sym or not instance_sym->generic_template) return;

    Symbol *template = instance_sym->generic_template;
    if (not template->generic_unit) return;

    /* Build substitution environment */
    Instantiation_Env env;
    Build_Instantiation_Env(&env, template, instance_sym, sm);

    /* Clone the package spec */
    Syntax_Node *spec_clone = Node_Deep_Clone(template->generic_unit, &env, 0);
    if (spec_clone) {
        /* Rename to instance name */
        if (spec_clone->kind == NK_PACKAGE_SPEC) {
            spec_clone->package_spec.name = instance_sym->name;
        }

        /* Store for later processing */
        instance_sym->expanded_spec = spec_clone;
    }

    /* Try to find and clone the package body */
    String_Slice pkg_name = template->generic_unit->kind == NK_PACKAGE_SPEC ?
                            template->generic_unit->package_spec.name :
                            template->name;

    char *body_src = Lookup_Path_Body(pkg_name);
    if (body_src) {
        /* Parse the body — arena-allocate filename for Source_Location stability */
        size_t bfn_len = pkg_name.length + 4;
        char *body_filename = Arena_Allocate(bfn_len + 1);
        snprintf(body_filename, bfn_len + 1, "%.*s.adb",
                 (int)pkg_name.length, pkg_name.data);
        Parser body_parser = Parser_New(body_src, strlen(body_src), body_filename);
        Syntax_Node *body_cu = Parse_Compilation_Unit(&body_parser);

        if (body_cu and body_cu->compilation_unit.unit and
            body_cu->compilation_unit.unit->kind == NK_PACKAGE_BODY) {

            /* Clone with substitutions */
            Syntax_Node *body_clone = Node_Deep_Clone(
                body_cu->compilation_unit.unit, &env, 0);

            if (body_clone) {
                /* Rename to instance name */
                body_clone->package_body.name = instance_sym->name;

                /* Store expanded body */
                instance_sym->expanded_body = body_clone;
            }
        }
    }
}

/* ─────────────────────────────────────────────────────────────────────────
 * §12.3 Declaration Resolution
 * ───────────────────────────────────────────────────────────────────────── */

static void Resolve_Declaration(Symbol_Manager *sm, Syntax_Node *node);
/* Install all exported symbols from a declaration list into the symbol table.
 * Handles objects, exceptions, and enumeration literals uniformly.
 * Extracted from two identical visible/private installation blocks. */
static void Install_Declaration_Symbols(Symbol_Manager *sm, Node_List *decls) {
    for (uint32_t i = 0; i < decls->count; i++) {
        Syntax_Node *decl = decls->items[i];
        /* For single task declarations (RM 9.1), both a type symbol and an
         * anonymous object variable were created during semantic analysis.
         * decl->symbol is the type; we must also install the variable so that
         * codegen can find it for global allocation and task start.
         * Grab the variable from the type's original defining_scope (the spec
         * scope) BEFORE Symbol_Add changes defining_scope to the body scope. */
        Symbol *task_obj_sym = NULL;
        if (decl->kind == NK_TASK_SPEC and not decl->task_spec.is_type and decl->symbol) {
            Scope *orig_scope = decl->symbol->defining_scope;
            if (orig_scope) {
                for (uint32_t j = 0; j < orig_scope->symbol_count; j++) {
                    Symbol *s = orig_scope->symbols[j];
                    if (s and s->kind == SYMBOL_VARIABLE and
                        Type_Is_Task(s->type) and
                        Slice_Equal_Ignore_Case(s->name, decl->task_spec.name)) {
                        task_obj_sym = s;
                        break;
                    }
                }
            }
        }
        if (decl->symbol) Symbol_Add(sm, decl->symbol);
        if (task_obj_sym) Symbol_Add(sm, task_obj_sym);
        /* Multi-name object declarations: install each named symbol */
        if (decl->kind == NK_OBJECT_DECL)
            for (uint32_t j = 0; j < decl->object_decl.names.count; j++) {
                Syntax_Node *name = decl->object_decl.names.items[j];
                if (name->symbol) Symbol_Add(sm, name->symbol);
            }
        /* Exception declarations: same multi-name pattern */
        if (decl->kind == NK_EXCEPTION_DECL)
            for (uint32_t j = 0; j < decl->exception_decl.names.count; j++) {
                Syntax_Node *name = decl->exception_decl.names.items[j];
                if (name->symbol) Symbol_Add(sm, name->symbol);
            }
        /* Enumeration type: install each literal as a separate symbol */
        if (decl->kind == NK_TYPE_DECL and decl->type_decl.definition and
            decl->type_decl.definition->kind == NK_ENUMERATION_TYPE) {
            Node_List *lits = &decl->type_decl.definition->enum_type.literals;
            for (uint32_t j = 0; j < lits->count; j++)
                if (lits->items[j]->symbol) Symbol_Add(sm, lits->items[j]->symbol);
        }
    }
}

static char *Read_File_Simple(const char *path) {
    FILE *f = fopen(path, "rb");
    if (not f) return NULL;

    fseek(f, 0, SEEK_END);
    long fsize = ftell(f);
    if (fsize < 0) { fclose(f); return NULL; }
    size_t size = (size_t)fsize;
    fseek(f, 0, SEEK_SET);

    char *buffer = malloc(size + 1);
    if (not buffer) { fclose(f); return NULL; }

    size_t read_size = fread(buffer, 1, size, f);
    fclose(f);
    buffer[read_size] = '\0';
    return buffer;
}

/* Find a package source file in include paths */
static char *Lookup_Path(String_Slice name) {
    char path[512], full_path[520];  /* full_path larger for .ads extension */

    for (uint32_t i = 0; i < Include_Path_Count; i++) {
        /* Build lowercase filename */
        size_t base_len = strlen(Include_Paths[i]);
        snprintf(path, sizeof(path), "%s%s%.*s",
                 Include_Paths[i],
                 (base_len > 0 and Include_Paths[i][base_len-1] != '/') ? "/" : "",
                 (int)name.length, name.data);

        /* Lowercase the filename part */
        for (char *p = path + base_len; *p; p++) {
            if (*p >= 'A' and *p <= 'Z') *p = *p - 'A' + 'a';
        }

        /* Try .ads extension */
        snprintf(full_path, sizeof(full_path), "%s.ads", path);
        char *src = Read_File_Simple(full_path);
        if (src) return src;

        /* Try .ada extension (ACATS naming convention) */
        snprintf(full_path, sizeof(full_path), "%s.ada", path);
        src = Read_File_Simple(full_path);
        if (src) return src;
    }
    return NULL;
}

/* Check if a precompiled .ll file exists for a package in include paths */
static bool Has_Precompiled_LL(String_Slice name) {
    char path[512], full_path[520];
    for (uint32_t i = 0; i < Include_Path_Count; i++) {
        size_t base_len = strlen(Include_Paths[i]);
        snprintf(path, sizeof(path), "%s%s%.*s",
                 Include_Paths[i],
                 (base_len > 0 and Include_Paths[i][base_len-1] != '/') ? "/" : "",
                 (int)name.length, name.data);
        for (char *p = path + base_len; *p; p++) {
            if (*p >= 'A' and *p <= 'Z') *p = *p - 'A' + 'a';
        }
        snprintf(full_path, sizeof(full_path), "%s.ll", path);
        FILE *f = fopen(full_path, "r");
        if (f) { fclose(f); return true; }
    }
    return false;
}

/* Find a package body source file in include paths */
static char *Lookup_Path_Body(String_Slice name) {
    char path[512], full_path[520];

    for (uint32_t i = 0; i < Include_Path_Count; i++) {
        size_t base_len = strlen(Include_Paths[i]);
        snprintf(path, sizeof(path), "%s%s%.*s",
                 Include_Paths[i],
                 (base_len > 0 and Include_Paths[i][base_len-1] != '/') ? "/" : "",
                 (int)name.length, name.data);

        /* Lowercase the filename part */
        for (char *p = path + base_len; *p; p++) {
            if (*p >= 'A' and *p <= 'Z') *p = *p - 'A' + 'a';
        }

        /* Try .adb extension */
        snprintf(full_path, sizeof(full_path), "%s.adb", path);
        char *src = Read_File_Simple(full_path);
        if (src) return src;

        /* Try .ada extension (ACATS uses .ada for both specs and bodies) */
        snprintf(full_path, sizeof(full_path), "%s.ada", path);
        src = Read_File_Simple(full_path);
        if (src) return src;
    }
    return NULL;
}

static void Resolve_Declaration_List(Symbol_Manager *sm, Node_List *list) {
    for (uint32_t i = 0; i < list->count; i++) {
        Resolve_Declaration(sm, list->items[i]);
    }
}

/* ─────────────────────────────────────────────────────────────────────────────
 * §12.4.1 Derived Type Operation Inheritance (RM 3.4)
 *
 * When TYPE T IS NEW PARENT is declared, T inherits primitive operations of
 * PARENT. A primitive operation is a subprogram declared in the same scope as
 * the type, with a parameter or return type of that type.
 *
 * The inherited operation has T substituted for PARENT in its profile. We create
 * a new symbol that wraps the parent's implementation with type conversions.
 * ───────────────────────────────────────────────────────────────────────────── */

/* Check if two types represent the same named type.
 * Handles private types where partial (visible) and full (private) views
 * have different Type_Info pointers but represent the same type. */
static bool Types_Same_Named(Type_Info *t1, Type_Info *t2) {
    if (not t1 or not t2) return false;
    if (t1 == t2) return true;
    /* For private types, partial and full views have same name but different Type_Info. */
    if (t1->name.data and t2->name.data and
        Slice_Equal_Ignore_Case(t1->name, t2->name)) {
        /* Same name: check if they share a defining symbol */
        if (t1->defining_symbol and t2->defining_symbol and
            t1->defining_symbol == t2->defining_symbol) return true;
        /* For types declared in the same package, same name = same type */
        if (t1->defining_symbol and t2->defining_symbol and
            t1->defining_symbol->defining_scope == t2->defining_symbol->defining_scope)
            return true;
    }
    return false;
}

/* Check if a subprogram has the given type in its profile (parameter or return) */
static bool Subprogram_Is_Primitive_Of(Symbol *sub, Type_Info *type) {
    if (not sub or not type) return false;
    if (sub->kind != SYMBOL_FUNCTION and sub->kind != SYMBOL_PROCEDURE) return false;

    /* Check return type for functions */
    if (sub->kind == SYMBOL_FUNCTION and Types_Same_Named(sub->return_type, type)) return true;

    /* Check parameter types */
    for (uint32_t i = 0; i < sub->parameter_count; i++) {
        if (Types_Same_Named(sub->parameters[i].param_type, type)) return true;
    }
    return false;
}

/* Helper to create a derived operation from a parent operation */
static void Create_Derived_Operation(Symbol_Manager *sm, Symbol *sub,
                                     Type_Info *derived_type, Type_Info *parent_type,
                                     Symbol *type_sym) {
    (void)type_sym;  /* reserved for future use */
    Symbol *derived_sub = Symbol_New(sub->kind, sub->name, sub->location);
    derived_sub->parameter_count = sub->parameter_count;
    derived_sub->parent_operation = sub;  /* Link to parent's implementation */
    derived_sub->derived_from_type = derived_type;
    derived_sub->is_overloaded = true;  /* Needs unique_id suffix */

    /* Copy and adjust parameters - substitute derived_type for parent_type */
    if (sub->parameter_count > 0) {
        derived_sub->parameters = Arena_Allocate(sub->parameter_count * sizeof(Parameter_Info));
        for (uint32_t j = 0; j < sub->parameter_count; j++) {
            derived_sub->parameters[j] = sub->parameters[j];
            if (Types_Same_Named(sub->parameters[j].param_type, parent_type)) {
                derived_sub->parameters[j].param_type = derived_type;
            }
        }
    }

    /* Adjust return type for functions */
    if (sub->kind == SYMBOL_FUNCTION) {
        derived_sub->return_type = Types_Same_Named(sub->return_type, parent_type)
                                   ? derived_type : sub->return_type;
    }

    /* Make visible so overload resolution can find it */
    derived_sub->visibility = VIS_IMMEDIATELY_VISIBLE;

    /* Add to current scope */
    Symbol_Add(sm, derived_sub);

    /* Set parent to match the parent operation's parent for proper name mangling
     * and to avoid false nested function detection. The derived operation
     * wraps the parent operation so should be at the same nesting level.
     * Done AFTER Symbol_Add since it overwrites parent. */
    derived_sub->parent = sub->parent;
}

/* Create inherited operations for a derived type (RM 3.4) */
static void Derive_Subprograms(Symbol_Manager *sm, Type_Info *derived_type,
                               Type_Info *parent_type, Symbol *type_sym) {
    if (not derived_type or not parent_type or not type_sym) return;

    /* Find the parent type's symbol and its owning scope/package */
    Symbol *parent_sym = parent_type->defining_symbol;
    if (not parent_sym) return;

    /* For private types in packages, look at the package's exported symbols.
     * The parent of the type symbol is the enclosing package/scope. */
    Symbol *pkg = parent_sym->parent;
    if (pkg and pkg->kind == SYMBOL_PACKAGE and pkg->exported_count > 0) {
        /* Search package exports for primitive operations */
        for (uint32_t i = 0; i < pkg->exported_count; i++) {
            Symbol *sub = pkg->exported[i];
            if (not sub) continue;
            if (sub->kind != SYMBOL_FUNCTION and sub->kind != SYMBOL_PROCEDURE) continue;
            if (not Subprogram_Is_Primitive_Of(sub, parent_type)) continue;
            Create_Derived_Operation(sm, sub, derived_type, parent_type, type_sym);
        }
        return;
    }

    /* Fallback: search the scope where the parent type is declared.
     * Iterate through hash buckets to find all symbols including overloads. */
    Scope *parent_scope = parent_sym->defining_scope;
    if (not parent_scope) return;

    for (uint32_t h = 0; h < SYMBOL_TABLE_SIZE; h++) {
        for (Symbol *sym = parent_scope->buckets[h]; sym; sym = sym->next_in_bucket) {
            /* Check this symbol and all in its overload chain */
            for (Symbol *sub = sym; sub; sub = sub->next_overload) {
                if (sub->kind != SYMBOL_FUNCTION and sub->kind != SYMBOL_PROCEDURE) continue;
                if (not Subprogram_Is_Primitive_Of(sub, parent_type)) continue;
                Create_Derived_Operation(sm, sub, derived_type, parent_type, type_sym);
            }
        }
    }
}

static void Resolve_Declaration(Symbol_Manager *sm, Syntax_Node *node) {
    if (not node) return;

    switch (node->kind) {
        case NK_OBJECT_DECL:
            /* Resolve type */
            if (node->object_decl.object_type) {
                Resolve_Expression(sm, node->object_decl.object_type);
                /* Object declarations freeze the type (RM 13.14) */
                if (node->object_decl.object_type->type) {
                    Freeze_Type(node->object_decl.object_type->type);
                }
            }
            /* Resolve initializer/renamed object - propagate type to aggregates first */
            if (node->object_decl.init) {
                /* Propagate type to aggregate initializer from declared type */
                if (node->object_decl.init->kind == NK_AGGREGATE and
                    node->object_decl.object_type and node->object_decl.object_type->type) {
                    node->object_decl.init->type = node->object_decl.object_type->type;
                }
                Resolve_Expression(sm, node->object_decl.init);
                /* Resolve character literal as enumeration literal (RM 3.5.1) */
                if (node->object_decl.init->kind == NK_CHARACTER and
                    node->object_decl.object_type and node->object_decl.object_type->type) {
                    Type_Info *et = node->object_decl.object_type->type;
                    while (et and et->kind != TYPE_ENUMERATION) {
                        if (et->parent_type) et = et->parent_type;
                        else if (et->base_type) et = et->base_type;
                        else break;
                    }
                    if (et and et->kind == TYPE_ENUMERATION)
                        Resolve_Char_As_Enum(sm, node->object_decl.init, et);
                }
            }
            /* Add symbols for each name */
            for (uint32_t i = 0; i < node->object_decl.names.count; i++) {
                Syntax_Node *name_node = node->object_decl.names.items[i];
                Symbol *sym = Symbol_New(
                    node->object_decl.is_constant ? SYMBOL_CONSTANT : SYMBOL_VARIABLE,
                    name_node->string_val.text,
                    name_node->location);
                /* Object renames: type comes from renamed object */
                if (node->object_decl.is_rename and node->object_decl.init) {
                    sym->type = node->object_decl.init->type;
                    sym->renamed_object = node->object_decl.init;  /* Point to renamed */
                    sym->is_named_number = false;
                }
                /* For named numbers (constant without type mark), use init expression's type */
                else if (node->object_decl.object_type) {
                    sym->type = node->object_decl.object_type->type;
                    sym->is_named_number = false;
                } else if (node->object_decl.is_constant and node->object_decl.init) {
                    /* Named number: use universal type from init expression */
                    sym->type = node->object_decl.init->type;
                    sym->is_named_number = true;  /* Mark as named number for inline generation */
                } else {
                    sym->type = NULL;
                    sym->is_named_number = node->object_decl.is_constant and not node->object_decl.object_type;
                }
                sym->declaration = node;
                Symbol_Add(sm, sym);
                name_node->symbol = sym;
            }
            break;

        case NK_TYPE_DECL:
            {
                /* Check for existing incomplete type to complete (RM 3.8.1)
                 * Must be in same declarative region (current scope) */
                Symbol *existing = Symbol_Find(sm, node->type_decl.name);
                Symbol *sym;
                Type_Info *type;
                if (existing and existing->kind == SYMBOL_TYPE and
                    existing->type and existing->type->kind == TYPE_UNKNOWN and
                    existing->defining_scope == sm->current_scope and
                    node->type_decl.definition) {
                    /* Complete the existing incomplete type */
                    sym = existing;
                    type = sym->type;
                } else {
                    /* Create new type symbol */
                    sym = Symbol_New(SYMBOL_TYPE, node->type_decl.name, node->location);
                    type = Type_New(TYPE_UNKNOWN, node->type_decl.name);
                    sym->type = type;
                    type->defining_symbol = sym;
                    Symbol_Add(sm, sym);
                }
                node->symbol = sym;

                /* For discriminated types, add discriminant symbols to scope first
                 * so they can be referenced in the type definition (e.g., CASE A IS) */
                bool has_discriminants = node->type_decl.discriminants.count > 0;
                if (has_discriminants) {
                    Symbol_Manager_Push_Scope(sm, sym);
                    for (uint32_t i = 0; i < node->type_decl.discriminants.count; i++) {
                        Syntax_Node *disc_spec = node->type_decl.discriminants.items[i];
                        if (disc_spec->kind == NK_DISCRIMINANT_SPEC) {
                            /* Resolve discriminant type first */
                            Type_Info *disc_type = sm->type_integer;
                            if (disc_spec->discriminant.disc_type) {
                                disc_type = Resolve_Expression(sm, disc_spec->discriminant.disc_type);
                            }
                            /* Resolve default expression if present (RM 3.7.1) */
                            if (disc_spec->discriminant.default_expr) {
                                Resolve_Expression(sm, disc_spec->discriminant.default_expr);
                            }
                            /* Add each discriminant name as a symbol (RM 3.7.1) */
                            for (uint32_t j = 0; j < disc_spec->discriminant.names.count; j++) {
                                Syntax_Node *name_node = disc_spec->discriminant.names.items[j];
                                Symbol *disc_sym = Symbol_New(SYMBOL_DISCRIMINANT, name_node->string_val.text,
                                                              name_node->location);
                                disc_sym->type = disc_type;
                                disc_sym->parent = sym;
                                Symbol_Add(sm, disc_sym);
                                name_node->symbol = disc_sym;
                            }
                        }
                    }
                }

                /* Resolve definition and copy type info */
                if (node->type_decl.definition) {
                    Type_Info *def_type = Resolve_Expression(sm, node->type_decl.definition);
                    if (def_type) {
                        /* Copy type info from definition to named type */
                        type->kind = def_type->kind;
                        type->size = def_type->size;
                        type->alignment = def_type->alignment;
                        type->low_bound = def_type->low_bound;
                        type->high_bound = def_type->high_bound;

                        /* For derived and subtype types, preserve base/parent chain */
                        type->base_type = def_type->base_type;
                        type->parent_type = def_type->parent_type;

                        /* For user-defined integer types (TYPE T IS RANGE L..R), the declared
                         * type is the "first subtype" and needs a base type (RM 3.5.4).
                         * Use INTEGER as the base type for constraint checking in 'PRED/'SUCC. */
                        if (def_type->kind == TYPE_INTEGER and type->base_type == NULL) {
                            type->base_type = sm->type_integer;
                        }

                        if (Type_Is_Array_Like(def_type)) {
                            type->array = def_type->array;
                        } else if (Type_Is_Fixed_Point(def_type)) {
                            type->fixed = def_type->fixed;
                        } else if (Type_Is_Float(def_type)) {
                            type->flt = def_type->flt;
                        } else if (Type_Is_Record(def_type)) {
                            type->record = def_type->record;

                            /* Add discriminants as accessible record components (RM 3.7.1)
                             * Discriminants can be accessed like normal components: R.D1 */
                            if (has_discriminants) {
                                /* Count total discriminant names and check for defaults */
                                uint32_t disc_count = 0;
                                bool all_have_defaults = true;
                                for (uint32_t i = 0; i < node->type_decl.discriminants.count; i++) {
                                    Syntax_Node *disc_spec = node->type_decl.discriminants.items[i];
                                    if (disc_spec->kind == NK_DISCRIMINANT_SPEC) {
                                        disc_count += disc_spec->discriminant.names.count;
                                        if (not disc_spec->discriminant.default_expr) {
                                            all_have_defaults = false;
                                        }
                                    }
                                }

                                /* Create new components array with discriminants at the start */
                                uint32_t old_count = type->record.component_count;
                                uint32_t new_count = old_count + disc_count;
                                Component_Info *new_comps = Arena_Allocate(
                                    new_count * sizeof(Component_Info));

                                /* Add discriminants first (they come before other components) */
                                uint32_t disc_idx = 0;
                                uint32_t disc_offset = 0;  /* Running offset for discriminants */
                                for (uint32_t i = 0; i < node->type_decl.discriminants.count; i++) {
                                    Syntax_Node *disc_spec = node->type_decl.discriminants.items[i];
                                    if (disc_spec->kind == NK_DISCRIMINANT_SPEC) {
                                        Type_Info *disc_type = sm->type_integer;
                                        if (disc_spec->discriminant.disc_type and
                                            disc_spec->discriminant.disc_type->type) {
                                            disc_type = disc_spec->discriminant.disc_type->type;
                                        }
                                        uint32_t disc_size = disc_type ? disc_type->size : 8;
                                        for (uint32_t j = 0; j < disc_spec->discriminant.names.count; j++) {
                                            Syntax_Node *name_node = disc_spec->discriminant.names.items[j];
                                            new_comps[disc_idx].name = name_node->string_val.text;
                                            new_comps[disc_idx].component_type = disc_type;
                                            new_comps[disc_idx].byte_offset = disc_offset;
                                            new_comps[disc_idx].bit_offset = 0;
                                            new_comps[disc_idx].bit_size = disc_size * 8;
                                            new_comps[disc_idx].default_expr = disc_spec->discriminant.default_expr;
                                            new_comps[disc_idx].is_discriminant = true;
                                            new_comps[disc_idx].variant_index = -1;  /* Fixed part */
                                            disc_offset += disc_size;
                                            disc_idx++;
                                        }
                                    }
                                }

                                /* Copy existing components after discriminants, adjusting offsets */
                                for (uint32_t i = 0; i < old_count; i++) {
                                    new_comps[disc_count + i] = type->record.components[i];
                                    new_comps[disc_count + i].byte_offset += disc_offset;
                                }

                                /* Adjust variant_offset to account for discriminant size */
                                if (type->record.variant_count > 0) {
                                    type->record.variant_offset += disc_offset;
                                    /* Also adjust variant component offsets */
                                    for (uint32_t i = 0; i < type->record.variant_count; i++) {
                                        type->record.variants[i].first_component += disc_count;
                                    }
                                }

                                /* Update record size to include discriminants */
                                type->size += disc_offset;

                                type->record.components = new_comps;
                                type->record.component_count = new_count;

                                /* Set discriminant tracking fields */
                                type->record.has_discriminants = true;
                                type->record.discriminant_count = disc_count;
                                type->record.all_defaults = all_have_defaults;
                            }
                        } else if (Type_Is_Access(def_type)) {
                            type->access = def_type->access;
                        } else if (Type_Is_Enumeration(def_type)) {
                            type->enumeration = def_type->enumeration;

                            /* Create symbols for enumeration literals
                             * They must reference the named type (type), not the anonymous def_type */
                            if (node->type_decl.definition and
                                node->type_decl.definition->kind == NK_ENUMERATION_TYPE) {
                                Node_List *lits = &node->type_decl.definition->enum_type.literals;
                                for (uint32_t i = 0; i < lits->count; i++) {
                                    Syntax_Node *lit = lits->items[i];
                                    Symbol *lit_sym = Symbol_New(SYMBOL_LITERAL, lit->string_val.text, lit->location);
                                    lit_sym->type = type;  /* Reference the named type */
                                    lit_sym->frame_offset = (int64_t)i;  /* Store ordinal position */
                                    Symbol_Add(sm, lit_sym);
                                    lit->symbol = lit_sym;
                                }
                            }
                            /* For derived enumeration types (TYPE T IS NEW BOOLEAN),
                             * create inherited literal symbols (RM 3.4(12)) */
                            if (node->type_decl.definition and
                                node->type_decl.definition->kind == NK_DERIVED_TYPE and
                                type->enumeration.literals and type->enumeration.literal_count > 0) {
                                for (uint32_t i = 0; i < type->enumeration.literal_count; i++) {
                                    String_Slice lit_name = type->enumeration.literals[i];
                                    Symbol *lit_sym = Symbol_New(SYMBOL_LITERAL, lit_name, node->location);
                                    lit_sym->type = type;
                                    lit_sym->frame_offset = (int64_t)i;
                                    Symbol_Add(sm, lit_sym);
                                }
                            }
                        }

                        /* Propagate limited flag from AST node (RM 7.5) */
                        if (node->type_decl.is_limited) {
                            type->is_limited = true;
                        }
                    }
                }

                /* For derived types (TYPE T IS NEW PARENT), inherit primitive
                 * subprograms from the parent type (RM 3.4) */
                if (type->parent_type) {
                    Derive_Subprograms(sm, type, type->parent_type, sym);
                }

                /* Pop discriminant scope if we pushed one */
                if (has_discriminants) {
                    Symbol_Manager_Pop_Scope(sm);
                }
            }
            break;

        case NK_SUBTYPE_DECL:
            {
                Symbol *sym = Symbol_New(SYMBOL_SUBTYPE, node->type_decl.name, node->location);
                Symbol_Add(sm, sym);
                node->symbol = sym;

                if (node->type_decl.definition) {
                    Resolve_Expression(sm, node->type_decl.definition);
                    sym->type = node->type_decl.definition->type;
                }
            }
            break;

        case NK_PROCEDURE_SPEC:
        case NK_FUNCTION_SPEC:
            {
                /* Count total parameters first (needed for overload matching) */
                Node_List *param_list = &node->subprogram_spec.parameters;
                uint32_t total_params = 0;
                for (uint32_t i = 0; i < param_list->count; i++) {
                    Syntax_Node *ps = param_list->items[i];
                    if (ps->kind == NK_PARAM_SPEC) {
                        total_params += ps->param_spec.names.count;
                    }
                }

                /* Check if there's already a matching symbol from package spec.
                 * This happens when resolving a subprogram body that completes a spec.
                 * For overloaded subprograms, must match parameter count AND types.
                 * Per RM 6.3, only match specs declared in the same scope — not
                 * USE-visible homographs from other packages (those are hidden). */
                Symbol_Kind expected_kind = node->kind == NK_PROCEDURE_SPEC ?
                                           SYMBOL_PROCEDURE : SYMBOL_FUNCTION;
                Symbol *scope_owner = sm->current_scope ? sm->current_scope->owner : NULL;
                Symbol *sym = Symbol_Find(sm, node->subprogram_spec.name);
                while (sym) {
                    /* Only match specs from the current declarative region */
                    if (sym->kind == expected_kind and sym->parameter_count == total_params
                        and sym->parent == scope_owner) {
                        /* Check parameter types match */
                        bool types_match = true;
                        uint32_t param_idx = 0;
                        for (uint32_t i = 0; i < param_list->count and types_match; i++) {
                            Syntax_Node *ps = param_list->items[i];
                            if (ps->kind == NK_PARAM_SPEC) {
                                /* Resolve param type first */
                                if (ps->param_spec.param_type) {
                                    Resolve_Expression(sm, ps->param_spec.param_type);
                                }
                                Type_Info *body_type = ps->param_spec.param_type ?
                                                       ps->param_spec.param_type->type : NULL;
                                for (uint32_t j = 0; j < ps->param_spec.names.count; j++) {
                                    if (param_idx < sym->parameter_count) {
                                        Type_Info *spec_type = sym->parameters[param_idx].param_type;
                                        if (not Types_Same_Named(body_type, spec_type)) {
                                            types_match = false;
                                            break;
                                        }
                                    }
                                    param_idx++;
                                }
                            }
                        }
                        if (types_match and expected_kind == SYMBOL_FUNCTION) {
                            if (node->subprogram_spec.return_type) {
                                Resolve_Expression(sm, node->subprogram_spec.return_type);
                                Type_Info *body_return = node->subprogram_spec.return_type->type;
                                if (not Types_Same_Named(body_return, sym->return_type)) {
                                    types_match = false;
                                }
                            }
                        }
                        /* Found matching spec - check it's not already claimed */
                        if (types_match and not sym->body_claimed) {
                            sym->body_claimed = true;
                            node->symbol = sym;
                            goto spec_matched;
                        }
                    }
                    sym = sym->next_overload;
                }

                /* No matching spec found - create new symbol */
                sym = Symbol_New(expected_kind, node->subprogram_spec.name, node->location);
                sym->parameter_count = total_params;
                if (total_params > 0) {
                    sym->parameters = Arena_Allocate(total_params * sizeof(Parameter_Info));
                    uint32_t param_idx = 0;
                    for (uint32_t i = 0; i < param_list->count; i++) {
                        Syntax_Node *ps = param_list->items[i];
                        if (ps->kind == NK_PARAM_SPEC) {
                            /* Resolve parameter type */
                            if (ps->param_spec.param_type) {
                                Resolve_Expression(sm, ps->param_spec.param_type);
                            }
                            Type_Info *pt = ps->param_spec.param_type ?
                                          ps->param_spec.param_type->type : NULL;
                            /* Resolve default expression, propagating param type
                             * to untyped aggregates (RM 6.1, 3.2.1) */
                            if (ps->param_spec.default_expr) {
                                if (ps->param_spec.default_expr->kind == NK_AGGREGATE and
                                    not ps->param_spec.default_expr->type and pt)
                                    ps->param_spec.default_expr->type = pt;
                                Resolve_Expression(sm, ps->param_spec.default_expr);
                            }
                            for (uint32_t j = 0; j < ps->param_spec.names.count; j++) {
                                Syntax_Node *name = ps->param_spec.names.items[j];
                                sym->parameters[param_idx].name = name->string_val.text;
                                sym->parameters[param_idx].param_type = pt;
                                sym->parameters[param_idx].mode = (Parameter_Mode)ps->param_spec.mode;
                                sym->parameters[param_idx].default_value = ps->param_spec.default_expr;
                                param_idx++;
                            }
                        }
                    }
                }

                if (node->subprogram_spec.return_type) {
                    Resolve_Expression(sm, node->subprogram_spec.return_type);
                    sym->return_type = node->subprogram_spec.return_type->type;
                }
                Symbol_Add(sm, sym);
                node->symbol = sym;
            spec_matched:;
            }
            break;

        case NK_SUBPROGRAM_RENAMING:
            /* PROCEDURE P RENAMES Q; or FUNCTION F RENAMES G; */
            {
                /* Resolve the renamed subprogram */
                if (node->subprogram_spec.renamed) {
                    Resolve_Expression(sm, node->subprogram_spec.renamed);
                }
                Symbol *renamed_sym = node->subprogram_spec.renamed ?
                                      node->subprogram_spec.renamed->symbol : NULL;

                /* Create new symbol for the rename */
                bool is_proc = not node->subprogram_spec.return_type;
                Symbol *sym = Symbol_New(
                    is_proc ? SYMBOL_PROCEDURE : SYMBOL_FUNCTION,
                    node->subprogram_spec.name, node->location);

                /* Copy info from renamed subprogram if available */
                if (renamed_sym) {
                    sym->parameters = renamed_sym->parameters;
                    sym->parameter_count = renamed_sym->parameter_count;
                    sym->return_type = renamed_sym->return_type;
                    sym->renamed_object = (Syntax_Node *)renamed_sym;  /* Store reference */
                } else {
                    /* Build parameter info from our own spec */
                    Node_List *param_list = &node->subprogram_spec.parameters;
                    uint32_t total_params = 0;
                    for (uint32_t i = 0; i < param_list->count; i++) {
                        Syntax_Node *ps = param_list->items[i];
                        if (ps->kind == NK_PARAM_SPEC)
                            total_params += ps->param_spec.names.count;
                    }
                    sym->parameter_count = total_params;
                    if (total_params > 0) {
                        sym->parameters = Arena_Allocate(total_params * sizeof(Parameter_Info));
                        uint32_t idx = 0;
                        for (uint32_t i = 0; i < param_list->count; i++) {
                            Syntax_Node *ps = param_list->items[i];
                            if (ps->kind == NK_PARAM_SPEC) {
                                if (ps->param_spec.param_type)
                                    Resolve_Expression(sm, ps->param_spec.param_type);
                                Type_Info *pt = ps->param_spec.param_type ?
                                              ps->param_spec.param_type->type : NULL;
                                for (uint32_t j = 0; j < ps->param_spec.names.count; j++) {
                                    Syntax_Node *nm = ps->param_spec.names.items[j];
                                    sym->parameters[idx].name = nm->string_val.text;
                                    sym->parameters[idx].param_type = pt;
                                    sym->parameters[idx].mode = (Parameter_Mode)ps->param_spec.mode;
                                    sym->parameters[idx].default_value = ps->param_spec.default_expr;
                                    idx++;
                                }
                            }
                        }
                    }
                    if (node->subprogram_spec.return_type) {
                        Resolve_Expression(sm, node->subprogram_spec.return_type);
                        sym->return_type = node->subprogram_spec.return_type->type;
                    }
                }
                Symbol_Add(sm, sym);
                node->symbol = sym;
            }
            break;

        case NK_PROCEDURE_BODY:
        case NK_FUNCTION_BODY:
            {
                /* Check if this body completes a generic declaration */
                Syntax_Node *spec = node->subprogram_body.specification;
                String_Slice body_name = spec ? spec->subprogram_spec.name : (String_Slice){0};

                Symbol *matching_generic = Symbol_Find(sm, body_name);
                if (matching_generic and matching_generic->kind == SYMBOL_GENERIC) {
                    /* This body completes a generic - store it and resolve it.
                     * Push scope with generic formals so T, F etc. are visible. */
                    matching_generic->generic_body = node;
                    node->symbol = matching_generic;

                    /* Push scope for generic body resolution */
                    Symbol_Manager_Push_Scope(sm, matching_generic);

                    /* Add generic formal parameters (types, objects, subprograms) to scope */
                    if (matching_generic->declaration and
                        matching_generic->declaration->kind == NK_GENERIC_DECL) {
                        Node_List *formals = &matching_generic->declaration->generic_decl.formals;
                        for (uint32_t i = 0; i < formals->count; i++) {
                            Syntax_Node *formal = formals->items[i];
                            if (not formal) continue;
                            if (formal->kind == NK_GENERIC_TYPE_PARAM) {
                                /* Map def_kind > Type_Kind so numeric formals
                                 * are recognised by Type_Is_Numeric (RM 12.1.2):
                                 * 0=PRIVATE, 1=LIMITED, 2=DISCRETE, 3=INTEGER,
                                 * 4=FLOAT, 5=FIXED, 6=ARRAY, 7=ACCESS */
                                Type_Kind tk = TYPE_PRIVATE;
                                switch (formal->generic_type_param.def_kind) {
                                    case 2: tk = TYPE_ENUMERATION; break;
                                    case 3: tk = TYPE_INTEGER;     break;
                                    case 4: tk = TYPE_FLOAT;       break;
                                    case 5: tk = TYPE_FIXED;       break;
                                    case 6: tk = TYPE_ARRAY;       break;
                                    case 7: tk = TYPE_ACCESS;      break;
                                    default: break;
                                }
                                Symbol *type_sym = Symbol_New(SYMBOL_TYPE,
                                    formal->generic_type_param.name, formal->location);
                                type_sym->type = Type_New(tk,
                                    formal->generic_type_param.name);
                                Symbol_Add(sm, type_sym);
                                formal->symbol = type_sym;
                            } else if (formal->kind == NK_GENERIC_SUBPROGRAM_PARAM) {
                                /* Create and add formal subprogram symbol if not exists */
                                if (not formal->symbol) {
                                    String_Slice name = formal->generic_subprog_param.name;
                                    Symbol_Kind sk = formal->generic_subprog_param.is_function ?
                                                     SYMBOL_FUNCTION : SYMBOL_PROCEDURE;
                                    Symbol *subprog_sym = Symbol_New(sk, name, formal->location);

                                    /* Set up parameter info */
                                    Node_List *fparams = &formal->generic_subprog_param.parameters;
                                    uint32_t total_params = 0;
                                    for (uint32_t j = 0; j < fparams->count; j++) {
                                        Syntax_Node *ps = fparams->items[j];
                                        if (ps and ps->kind == NK_PARAM_SPEC)
                                            total_params += ps->param_spec.names.count;
                                    }
                                    subprog_sym->parameter_count = total_params;
                                    if (total_params > 0) {
                                        subprog_sym->parameters = Arena_Allocate(
                                            total_params * sizeof(Parameter_Info));
                                        uint32_t idx = 0;
                                        for (uint32_t j = 0; j < fparams->count; j++) {
                                            Syntax_Node *ps = fparams->items[j];
                                            if (ps and ps->kind == NK_PARAM_SPEC) {
                                                Type_Info *pt = NULL;
                                                if (ps->param_spec.param_type) {
                                                    Resolve_Expression(sm, ps->param_spec.param_type);
                                                    pt = ps->param_spec.param_type->type;
                                                }
                                                for (uint32_t k = 0; k < ps->param_spec.names.count; k++) {
                                                    Syntax_Node *pn = ps->param_spec.names.items[k];
                                                    subprog_sym->parameters[idx].name = pn->string_val.text;
                                                    subprog_sym->parameters[idx].param_type = pt;
                                                    subprog_sym->parameters[idx].mode =
                                                        (Parameter_Mode)ps->param_spec.mode;
                                                    idx++;
                                                }
                                            }
                                        }
                                    }

                                    /* Set return type for functions */
                                    if (formal->generic_subprog_param.is_function and
                                        formal->generic_subprog_param.return_type) {
                                        Resolve_Expression(sm, formal->generic_subprog_param.return_type);
                                        subprog_sym->type = formal->generic_subprog_param.return_type->type;
                                        subprog_sym->return_type = subprog_sym->type;
                                    }
                                    formal->symbol = subprog_sym;
                                }
                                Symbol_Add(sm, formal->symbol);
                            } else if (formal->kind == NK_GENERIC_OBJECT_PARAM) {
                                /* Add formal object(s) as variable(s) with their declared type.
                                 * e.g., "I1, I2 : INTEGER" creates two symbols of type INTEGER */
                                Type_Info *obj_type = NULL;
                                if (formal->generic_object_param.object_type) {
                                    Resolve_Expression(sm, formal->generic_object_param.object_type);
                                    obj_type = formal->generic_object_param.object_type->type;
                                }
                                for (uint32_t j = 0; j < formal->generic_object_param.names.count; j++) {
                                    Syntax_Node *name_node = formal->generic_object_param.names.items[j];
                                    Symbol *obj_sym = Symbol_New(SYMBOL_VARIABLE,
                                        name_node->string_val.text, formal->location);
                                    obj_sym->type = obj_type;
                                    Symbol_Add(sm, obj_sym);
                                    name_node->symbol = obj_sym;
                                }
                            }
                        }
                    }

                    /* Add body parameters to scope */
                    if (spec) {
                        Node_List *params = &spec->subprogram_spec.parameters;
                        for (uint32_t i = 0; i < params->count; i++) {
                            Syntax_Node *param = params->items[i];
                            if (param and param->kind == NK_PARAM_SPEC) {
                                /* Resolve parameter type (may reference generic formals) */
                                if (param->param_spec.param_type)
                                    Resolve_Expression(sm, param->param_spec.param_type);
                                /* Add each parameter name as a symbol */
                                for (uint32_t j = 0; j < param->param_spec.names.count; j++) {
                                    Syntax_Node *name = param->param_spec.names.items[j];
                                    Symbol *param_sym = Symbol_New(SYMBOL_PARAMETER,
                                        name->string_val.text, name->location);
                                    if (param->param_spec.param_type)
                                        param_sym->type = param->param_spec.param_type->type;
                                    Symbol_Add(sm, param_sym);
                                    name->symbol = param_sym;
                                }
                            }
                        }
                    }

                    /* Resolve declarations and statements in the generic body */
                    Resolve_Declaration_List(sm, &node->subprogram_body.declarations);
                    Resolve_Statement_List(sm, &node->subprogram_body.statements);

                    /* Resolve exception handlers */
                    for (uint32_t i = 0; i < node->subprogram_body.handlers.count; i++) {
                        Resolve_Statement(sm, node->subprogram_body.handlers.items[i]);
                    }

                    Symbol_Manager_Pop_Scope(sm);
                    break;
                }

                /* Resolve spec if present */
                if (spec) {
                    Resolve_Declaration(sm, spec);
                    node->symbol = spec->symbol;
                }

                /* For stubs (IS SEPARATE), don't claim the symbol - the separate
                 * subunit will provide the actual body and should claim it. */
                if (node->subprogram_body.is_separate and node->symbol) {
                    node->symbol->body_claimed = false;
                }

                /* Push scope for body */
                Symbol_Manager_Push_Scope(sm, node->symbol);

                /* Link the scope to the symbol for static link access */
                if (node->symbol) {
                    node->symbol->scope = sm->current_scope;
                }

                /* Add parameters to scope and link to Parameter_Info */
                if (spec) {
                    Symbol *func_sym = node->symbol;
                    uint32_t param_idx = 0;
                    Node_List *params = &spec->subprogram_spec.parameters;
                    for (uint32_t i = 0; i < params->count; i++) {
                        Syntax_Node *param = params->items[i];
                        if (param->kind == NK_PARAM_SPEC) {
                            /* Resolve parameter type */
                            if (param->param_spec.param_type) {
                                Resolve_Expression(sm, param->param_spec.param_type);
                            }
                            /* Add each parameter name as a symbol */
                            for (uint32_t j = 0; j < param->param_spec.names.count; j++) {
                                Syntax_Node *name = param->param_spec.names.items[j];
                                Symbol *param_sym = Symbol_New(SYMBOL_PARAMETER,
                                    name->string_val.text, name->location);
                                if (param->param_spec.param_type) {
                                    param_sym->type = param->param_spec.param_type->type;
                                }
                                Symbol_Add(sm, param_sym);
                                name->symbol = param_sym;
                                /* Link to Parameter_Info for code generation */
                                if (func_sym and param_idx < func_sym->parameter_count) {
                                    func_sym->parameters[param_idx].param_sym = param_sym;
                                }
                                param_idx++;
                            }
                        }
                    }
                }

                /* Resolve declarations and statements */
                Resolve_Declaration_List(sm, &node->subprogram_body.declarations);
                /* Freeze all types at end of declarative part (RM 13.14) */
                Freeze_Declaration_List(&node->subprogram_body.declarations);
                Resolve_Statement_List(sm, &node->subprogram_body.statements);

                /* Resolve exception handlers */
                for (uint32_t i = 0; i < node->subprogram_body.handlers.count; i++) {
                    Resolve_Statement(sm, node->subprogram_body.handlers.items[i]);
                }

                Symbol_Manager_Pop_Scope(sm);
            }
            break;

        case NK_TASK_SPEC:
            {
                /* Task declaration creates a task type and optionally an object */
                Symbol *type_sym = Symbol_New(SYMBOL_TYPE, node->task_spec.name, node->location);
                Type_Info *type = Type_New(TYPE_TASK, node->task_spec.name);
                type_sym->type = type;
                type->defining_symbol = type_sym;
                type_sym->declaration = node;
                Symbol_Add(sm, type_sym);
                node->symbol = type_sym;

                /* If not a task TYPE, also create an object of that type */
                if (not node->task_spec.is_type) {
                    Symbol *obj_sym = Symbol_New(SYMBOL_VARIABLE, node->task_spec.name, node->location);
                    obj_sym->type = type;
                    obj_sym->declaration = node;
                    /* Add the object symbol - it will shadow the type for normal lookups */
                    Symbol_Add(sm, obj_sym);
                }

                /* Push scope for task entries */
                Symbol_Manager_Push_Scope(sm, type_sym);

                /* Resolve and add entry declarations */
                uint32_t entry_idx_counter = 0;  /* Counter for unique entry indices */
                for (uint32_t i = 0; i < node->task_spec.entries.count; i++) {
                    Syntax_Node *entry = node->task_spec.entries.items[i];
                    if (entry->kind == NK_ENTRY_DECL) {
                        Symbol *entry_sym = Symbol_New(SYMBOL_ENTRY,
                            entry->entry_decl.name, entry->location);
                        entry_sym->declaration = entry;
                        entry_sym->parent = type_sym;
                        entry_sym->entry_index = entry_idx_counter++;  /* Assign unique entry index */

                        /* Count entry parameters */
                        uint32_t param_count = 0;
                        for (uint32_t j = 0; j < entry->entry_decl.parameters.count; j++) {
                            Syntax_Node *ps = entry->entry_decl.parameters.items[j];
                            if (ps->kind == NK_PARAM_SPEC) {
                                param_count += ps->param_spec.names.count;
                            }
                        }
                        entry_sym->parameter_count = param_count;
                        if (param_count > 0) {
                            entry_sym->parameters = Arena_Allocate(param_count * sizeof(Parameter_Info));
                            uint32_t pi = 0;
                            for (uint32_t j = 0; j < entry->entry_decl.parameters.count; j++) {
                                Syntax_Node *ps = entry->entry_decl.parameters.items[j];
                                if (ps->kind == NK_PARAM_SPEC) {
                                    if (ps->param_spec.param_type) {
                                        Resolve_Expression(sm, ps->param_spec.param_type);
                                    }
                                    for (uint32_t k = 0; k < ps->param_spec.names.count; k++) {
                                        entry_sym->parameters[pi].name = ps->param_spec.names.items[k]->string_val.text;
                                        entry_sym->parameters[pi].param_type = ps->param_spec.param_type ?
                                            ps->param_spec.param_type->type : NULL;
                                        entry_sym->parameters[pi].mode = (Parameter_Mode)ps->param_spec.mode;
                                        pi++;
                                    }
                                }
                            }
                        }
                        Symbol_Add(sm, entry_sym);
                        entry->symbol = entry_sym;

                        /* Add entry to type's exported symbols */
                        if (type_sym->exported_count < 100) {
                            if (not type_sym->exported) {
                                type_sym->exported = Arena_Allocate(100 * sizeof(Symbol*));
                            }
                            type_sym->exported[type_sym->exported_count++] = entry_sym;
                        }
                    }
                }
                Symbol_Manager_Pop_Scope(sm);
            }
            break;

        case NK_TASK_BODY:
            {
                /* Find the task spec symbol */
                Symbol *task_sym = Symbol_Find(sm, node->task_body.name);
                if (not task_sym) {
                    /* Create a symbol for the task body if spec wasn't found */
                    task_sym = Symbol_New(SYMBOL_PROCEDURE, node->task_body.name, node->location);
                    task_sym->declaration = node;
                    Symbol_Add(sm, task_sym);
                }
                node->symbol = task_sym;

                /* Push scope for task body */
                Symbol_Manager_Push_Scope(sm, task_sym);

                /* Import entries from task spec into body scope (RM 9.1)
                 * Entries declared in the task spec are visible inside the task body.
                 * For single tasks, task_sym is SYMBOL_VARIABLE with TYPE_TASK;
                 * the entries are on the type's defining_symbol. */
                Symbol *type_sym = NULL;
                if (task_sym->kind == SYMBOL_TYPE and Type_Is_Task(task_sym->type)) {
                    /* task_sym is the type symbol directly (task type declaration) */
                    type_sym = task_sym;
                } else if (Type_Is_Task(task_sym->type) and
                           task_sym->type->defining_symbol) {
                    /* task_sym is the variable; get the type's defining symbol */
                    type_sym = task_sym->type->defining_symbol;
                }
                if (type_sym and type_sym->exported) {
                    for (uint32_t i = 0; i < type_sym->exported_count; i++) {
                        Symbol *entry_sym = type_sym->exported[i];
                        if (entry_sym) {
                            Symbol_Add(sm, entry_sym);
                        }
                    }
                }

                /* Resolve declarations and statements */
                Resolve_Declaration_List(sm, &node->task_body.declarations);
                Resolve_Statement_List(sm, &node->task_body.statements);

                /* Resolve exception handlers */
                for (uint32_t i = 0; i < node->task_body.handlers.count; i++) {
                    Resolve_Statement(sm, node->task_body.handlers.items[i]);
                }

                Symbol_Manager_Pop_Scope(sm);
            }
            break;

        case NK_PACKAGE_SPEC:
            {
                Symbol *sym = Symbol_New(SYMBOL_PACKAGE, node->package_spec.name, node->location);
                sym->declaration = node;  /* Store declaration for body to find */
                Symbol_Add(sm, sym);
                node->symbol = sym;

                Symbol_Manager_Push_Scope(sm, sym);
                sym->scope = sm->current_scope;  /* Link scope to symbol for P.X lookups */
                Resolve_Declaration_List(sm, &node->package_spec.visible_decls);
                Resolve_Declaration_List(sm, &node->package_spec.private_decls);
                /* End of package spec freezes all declared entities (RM 13.14) */
                Freeze_Declaration_List(&node->package_spec.visible_decls);
                Freeze_Declaration_List(&node->package_spec.private_decls);
                /* Populate exports for nested/inline package access (e.g., INNER.ACC) */
                Populate_Package_Exports(sym, node);
                Symbol_Manager_Pop_Scope(sm);
            }
            break;

        case NK_PACKAGE_BODY:
            {
                /* Find or create package symbol for proper name mangling */
                Symbol *pkg_sym = NULL;
                String_Slice pkg_name = node->package_body.name;
                if (pkg_name.length > 0) {
                    /* Mark this body as loaded BEFORE trying to load the spec.
                     * This prevents Load_Package_Spec from recursively loading
                     * the same body when we're compiling a .adb file directly. */
                    Mark_Body_Loaded(pkg_name);

                    pkg_sym = Symbol_Find(sm, pkg_name);
                    if (not pkg_sym) {
                        /* Try to load corresponding package spec first.
                         * This ensures body uses same symbol IDs as spec */
                        char *spec_src = Lookup_Path(pkg_name);
                        if (spec_src) {
                            Load_Package_Spec(sm, pkg_name, spec_src);
                            pkg_sym = Symbol_Find(sm, pkg_name);
                        }
                        if (not pkg_sym) {
                            /* Create package symbol if spec not found */
                            pkg_sym = Symbol_New(SYMBOL_PACKAGE, pkg_name, node->location);
                            Symbol_Add(sm, pkg_sym);
                        }
                    }
                    node->symbol = pkg_sym;
                }
                Symbol_Manager_Push_Scope(sm, pkg_sym);

                /* Set package symbol's scope for separate subunit resolution.
                 * This allows SEPARATE (Parent) subunits to find stub symbols. */
                if (pkg_sym) {
                    pkg_sym->scope = sm->current_scope;
                }

                /* Install visible and private declarations from package spec
                 * into the body's scope (RM 7.1, 7.2) */
                Syntax_Node *spec = NULL;

                /* Handle generic packages: formals and unit are in the generic declaration */
                if (pkg_sym and pkg_sym->kind == SYMBOL_GENERIC) {
                    /* Store this body as the generic's body for later instantiation */
                    pkg_sym->generic_body = node;

                    /* Install generic formal parameters first */
                    if (pkg_sym->declaration and
                        pkg_sym->declaration->kind == NK_GENERIC_DECL) {
                        Node_List *formals = &pkg_sym->declaration->generic_decl.formals;
                        for (uint32_t i = 0; i < formals->count; i++) {
                            Syntax_Node *formal = formals->items[i];
                            if (formal->symbol) {
                                Symbol_Add(sm, formal->symbol);
                            }
                            /* For generic type parameters, create/install a type symbol */
                            if (formal->kind == NK_GENERIC_TYPE_PARAM and not formal->symbol) {
                                Symbol *type_sym = Symbol_New(SYMBOL_TYPE,
                                    formal->generic_type_param.name, formal->location);
                                /* Map def_kind to appropriate Type_Kind:
                                 * 0=PRIVATE, 1=LIMITED_PRIVATE, 2=DISCRETE, 3=INTEGER,
                                 * 4=FLOAT, 5=FIXED, 6=ARRAY, 7=ACCESS */
                                Type_Kind tk = TYPE_PRIVATE;
                                switch (formal->generic_type_param.def_kind) {
                                    case 2: tk = TYPE_ENUMERATION; break; /* DISCRETE */
                                    case 3: tk = TYPE_INTEGER; break;     /* INTEGER (range <>) */
                                    case 4: tk = TYPE_FLOAT; break;       /* FLOAT (digits <>) */
                                    case 5: tk = TYPE_FIXED; break;       /* FIXED (delta <>) */
                                    case 6: tk = TYPE_ARRAY; break;       /* ARRAY */
                                    case 7: tk = TYPE_ACCESS; break;      /* ACCESS */
                                    default: tk = TYPE_PRIVATE; break;
                                }
                                Type_Info *type = Type_New(tk, formal->generic_type_param.name);
                                type_sym->type = type;
                                formal->symbol = type_sym;
                                Symbol_Add(sm, type_sym);
                            }
                            /* For generic object parameters, create/install object symbols */
                            if (formal->kind == NK_GENERIC_OBJECT_PARAM) {
                                /* Resolve the object type */
                                Type_Info *obj_type = NULL;
                                if (formal->generic_object_param.object_type) {
                                    Resolve_Expression(sm, formal->generic_object_param.object_type);
                                    obj_type = formal->generic_object_param.object_type->type;
                                }
                                /* Create symbols for each name */
                                for (uint32_t j = 0; j < formal->generic_object_param.names.count; j++) {
                                    Syntax_Node *name_node = formal->generic_object_param.names.items[j];
                                    if (name_node and name_node->kind == NK_IDENTIFIER) {
                                        Symbol *obj_sym = Symbol_New(SYMBOL_CONSTANT,
                                            name_node->string_val.text, name_node->location);
                                        obj_sym->type = obj_type;
                                        name_node->symbol = obj_sym;
                                        Symbol_Add(sm, obj_sym);
                                    }
                                }
                            }
                            /* For generic subprogram parameters, create procedure/function symbols
                             * so calls to formal subprograms resolve during generic body analysis */
                            if (formal->kind == NK_GENERIC_SUBPROGRAM_PARAM) {
                                String_Slice name = formal->generic_subprog_param.name;
                                Symbol_Kind sk = formal->generic_subprog_param.is_function ?
                                                 SYMBOL_FUNCTION : SYMBOL_PROCEDURE;
                                Symbol *subprog_sym = Symbol_New(sk, name, formal->location);

                                /* Count total parameters */
                                Node_List *params = &formal->generic_subprog_param.parameters;
                                uint32_t total_params = 0;
                                for (uint32_t j = 0; j < params->count; j++) {
                                    Syntax_Node *ps = params->items[j];
                                    if (ps->kind == NK_PARAM_SPEC) {
                                        total_params += ps->param_spec.names.count;
                                    }
                                }

                                /* Allocate and fill parameter info */
                                subprog_sym->parameter_count = total_params;
                                if (total_params > 0) {
                                    subprog_sym->parameters = Arena_Allocate(
                                        total_params * sizeof(Parameter_Info));
                                    uint32_t idx = 0;
                                    for (uint32_t j = 0; j < params->count; j++) {
                                        Syntax_Node *ps = params->items[j];
                                        if (ps->kind == NK_PARAM_SPEC) {
                                            /* Resolve param type - may reference earlier formal types */
                                            Type_Info *pt = NULL;
                                            if (ps->param_spec.param_type) {
                                                Resolve_Expression(sm, ps->param_spec.param_type);
                                                pt = ps->param_spec.param_type->type;
                                            }
                                            for (uint32_t k = 0; k < ps->param_spec.names.count; k++) {
                                                Syntax_Node *pn = ps->param_spec.names.items[k];
                                                subprog_sym->parameters[idx].name = pn->string_val.text;
                                                subprog_sym->parameters[idx].param_type = pt;
                                                subprog_sym->parameters[idx].mode =
                                                    (Parameter_Mode)ps->param_spec.mode;
                                                idx++;
                                            }
                                        }
                                    }
                                }

                                /* For functions, set return type */
                                if (formal->generic_subprog_param.is_function and
                                    formal->generic_subprog_param.return_type) {
                                    Resolve_Expression(sm, formal->generic_subprog_param.return_type);
                                    subprog_sym->type = formal->generic_subprog_param.return_type->type;
                                }

                                formal->symbol = subprog_sym;
                                Symbol_Add(sm, subprog_sym);
                            }
                        }
                    }
                    /* Get the package spec from the generic unit */
                    spec = pkg_sym->generic_unit;

                    /* For generic package body, resolve the spec first if not done */
                    if (spec and spec->kind == NK_PACKAGE_SPEC) {
                        Resolve_Declaration_List(sm, &spec->package_spec.visible_decls);
                        Resolve_Declaration_List(sm, &spec->package_spec.private_decls);
                    }
                } else if (pkg_sym and pkg_sym->declaration and
                           pkg_sym->declaration->kind == NK_PACKAGE_SPEC) {
                    spec = pkg_sym->declaration;
                }

                if (spec and spec->kind == NK_PACKAGE_SPEC) {
                    Install_Declaration_Symbols(sm, &spec->package_spec.visible_decls);
                    Install_Declaration_Symbols(sm, &spec->package_spec.private_decls);
                }

                Resolve_Declaration_List(sm, &node->package_body.declarations);
                /* Freeze all types at end of declarative part (RM 13.14) */
                Freeze_Declaration_List(&node->package_body.declarations);
                Resolve_Statement_List(sm, &node->package_body.statements);
                /* Resolve exception handlers (RM 11.4) — local variables and
                 * parameters remain visible in the handler body. */
                for (uint32_t hi = 0; hi < node->package_body.handlers.count; hi++) {
                    Syntax_Node *handler = node->package_body.handlers.items[hi];
                    if (handler) {
                        for (uint32_t ei = 0; ei < handler->handler.exceptions.count; ei++)
                            Resolve_Expression(sm, handler->handler.exceptions.items[ei]);
                        Resolve_Statement_List(sm, &handler->handler.statements);
                    }
                }
                Symbol_Manager_Pop_Scope(sm);
            }
            break;

        case NK_USE_CLAUSE:
            /* Make package contents directly visible (Ada 83 8.4)
             * "A use clause achieves direct visibility of declarations
             *  that appear in the visible parts of the named packages" */
            for (uint32_t i = 0; i < node->use_clause.names.count; i++) {
                Syntax_Node *pkg_name_node = node->use_clause.names.items[i];
                Resolve_Expression(sm, pkg_name_node);

                /* Find the package symbol */
                Symbol *pkg_sym = NULL;
                if (pkg_name_node->kind == NK_IDENTIFIER) {
                    pkg_sym = Symbol_Find(sm, pkg_name_node->string_val.text);
                } else if (pkg_name_node->symbol) {
                    pkg_sym = pkg_name_node->symbol;
                }

                if (pkg_sym and pkg_sym->kind == SYMBOL_PACKAGE) {
                    /* Helper macro: add use-visible alias for a symbol */
                    #define ADD_USE_ALIAS(orig) do { \
                        if (orig) { \
                            /* Check if alias already exists for this symbol */ \
                            uint32_t _hash = Symbol_Hash_Name((orig)->name); \
                            bool _already_aliased = false; \
                            for (Symbol *_ex = sm->current_scope->buckets[_hash]; _ex; _ex = _ex->next_in_bucket) { \
                                if (Slice_Equal_Ignore_Case(_ex->name, (orig)->name) and \
                                    _ex->visibility == VIS_USE_VISIBLE and \
                                    _ex->unique_id == (orig)->unique_id) { \
                                    _already_aliased = true; \
                                    break; \
                                } \
                            } \
                            if (not _already_aliased) { \
                                Symbol *alias = Symbol_New((orig)->kind, (orig)->name, (orig)->location); \
                                alias->type = (orig)->type; \
                                alias->declaration = (orig)->declaration; \
                                alias->visibility = VIS_USE_VISIBLE; \
                                alias->parameter_count = (orig)->parameter_count; \
                                alias->parameters = (orig)->parameters; \
                                alias->return_type = (orig)->return_type; \
                                alias->is_named_number = (orig)->is_named_number; \
                                alias->generic_unit = (orig)->generic_unit; \
                                alias->generic_body = (orig)->generic_body; \
                                alias->generic_formals = (orig)->generic_formals; \
                                Symbol_Add(sm, alias); \
                                alias->parent = (orig)->parent; \
                                alias->unique_id = (orig)->unique_id; \
                            } \
                        } \
                    } while(0)

                    /* For loaded packages with exported array, use it */
                    if (pkg_sym->exported_count > 0) {
                        for (uint32_t j = 0; j < pkg_sym->exported_count; j++)
                            ADD_USE_ALIAS(pkg_sym->exported[j]);
                    }
                    /* For inline packages, iterate visible declarations */
                    else if (pkg_sym->declaration and pkg_sym->declaration->kind == NK_PACKAGE_SPEC) {
                        Syntax_Node *pkg_decl = pkg_sym->declaration;
                        for (uint32_t j = 0; j < pkg_decl->package_spec.visible_decls.count; j++) {
                            Syntax_Node *decl = pkg_decl->package_spec.visible_decls.items[j];
                            if (not decl) continue;
                            if (decl->symbol) ADD_USE_ALIAS(decl->symbol);
                            /* Handle object_decl names (constants, variables) */
                            if (decl->kind == NK_OBJECT_DECL) {
                                for (uint32_t k = 0; k < decl->object_decl.names.count; k++) {
                                    Syntax_Node *nm = decl->object_decl.names.items[k];
                                    if (nm and nm->symbol) ADD_USE_ALIAS(nm->symbol);
                                }
                            }
                            /* Handle enumeration literals */
                            if ((decl->kind == NK_TYPE_DECL or decl->kind == NK_SUBTYPE_DECL) and
                                decl->type_decl.definition and
                                decl->type_decl.definition->kind == NK_ENUMERATION_TYPE) {
                                Node_List *lits = &decl->type_decl.definition->enum_type.literals;
                                for (uint32_t k = 0; k < lits->count; k++) {
                                    if (lits->items[k] and lits->items[k]->symbol)
                                        ADD_USE_ALIAS(lits->items[k]->symbol);
                                }
                            }
                            /* Handle exception declarations */
                            if (decl->kind == NK_EXCEPTION_DECL) {
                                for (uint32_t k = 0; k < decl->exception_decl.names.count; k++) {
                                    Syntax_Node *nm = decl->exception_decl.names.items[k];
                                    if (nm and nm->symbol) ADD_USE_ALIAS(nm->symbol);
                                }
                            }
                        }
                    }
                    #undef ADD_USE_ALIAS
                }
            }
            break;

        case NK_PRAGMA:
            /* Process pragma effects */
            {
                String_Slice pragma_name = node->pragma_node.name;

                /* pragma Inline(subprogram_name, ...) */
                if (Slice_Equal_Ignore_Case(pragma_name, S("INLINE"))) {
                    for (uint32_t i = 0; i < node->pragma_node.arguments.count; i++) {
                        Syntax_Node *arg = node->pragma_node.arguments.items[i];
                        Syntax_Node *name_node = (arg->kind == NK_ASSOCIATION) ?
                                                  arg->association.expression : arg;
                        if (name_node and name_node->kind == NK_IDENTIFIER) {
                            Symbol *sym = Symbol_Find(sm, name_node->string_val.text);
                            if (sym and (sym->kind == SYMBOL_PROCEDURE or
                                        sym->kind == SYMBOL_FUNCTION)) {
                                sym->is_inline = true;
                            }
                        }
                    }
                }

                /* pragma Pack(type_name) */
                else if (Slice_Equal_Ignore_Case(pragma_name, S("PACK"))) {
                    if (node->pragma_node.arguments.count > 0) {
                        Syntax_Node *arg = node->pragma_node.arguments.items[0];
                        Syntax_Node *name_node = (arg->kind == NK_ASSOCIATION) ?
                                                  arg->association.expression : arg;
                        if (name_node and name_node->kind == NK_IDENTIFIER) {
                            Symbol *sym = Symbol_Find(sm, name_node->string_val.text);
                            if (sym and sym->type) {
                                sym->type->is_packed = true;
                            }
                        }
                    }
                }

                /* pragma Suppress(check_name) or pragma Suppress(check_name, entity_name) */
                else if (Slice_Equal_Ignore_Case(pragma_name, S("SUPPRESS"))) {
                    uint32_t check_bit = 0;
                    if (node->pragma_node.arguments.count > 0) {
                        Syntax_Node *arg = node->pragma_node.arguments.items[0];
                        Syntax_Node *check_node = (arg->kind == NK_ASSOCIATION) ?
                                                   arg->association.expression : arg;
                        if (check_node and check_node->kind == NK_IDENTIFIER) {
                            String_Slice check = check_node->string_val.text;
                            if (Slice_Equal_Ignore_Case(check, S("RANGE_CHECK")))
                                check_bit = CHK_RANGE;
                            else if (Slice_Equal_Ignore_Case(check, S("OVERFLOW_CHECK")))
                                check_bit = CHK_OVERFLOW;
                            else if (Slice_Equal_Ignore_Case(check, S("INDEX_CHECK")))
                                check_bit = CHK_INDEX;
                            else if (Slice_Equal_Ignore_Case(check, S("LENGTH_CHECK")))
                                check_bit = CHK_LENGTH;
                            else if (Slice_Equal_Ignore_Case(check, S("DIVISION_CHECK")))
                                check_bit = CHK_DIVISION;
                            else if (Slice_Equal_Ignore_Case(check, S("ACCESS_CHECK")))
                                check_bit = CHK_ACCESS;
                            else if (Slice_Equal_Ignore_Case(check, S("DISCRIMINANT_CHECK")))
                                check_bit = CHK_DISCRIMINANT;
                            else if (Slice_Equal_Ignore_Case(check, S("ELABORATION_CHECK")))
                                check_bit = CHK_ELABORATION;
                            else if (Slice_Equal_Ignore_Case(check, S("STORAGE_CHECK")))
                                check_bit = CHK_STORAGE;
                            else if (Slice_Equal_Ignore_Case(check, S("ALL_CHECKS")))
                                check_bit = CHK_ALL;
                        }
                    }

                    /* Apply to specific entity or current scope */
                    if (node->pragma_node.arguments.count > 1) {
                        Syntax_Node *arg = node->pragma_node.arguments.items[1];
                        Syntax_Node *entity = (arg->kind == NK_ASSOCIATION) ?
                                               arg->association.expression : arg;
                        if (entity and entity->kind == NK_IDENTIFIER) {
                            Symbol *sym = Symbol_Find(sm, entity->string_val.text);
                            if (sym) sym->suppressed_checks |= check_bit;
                        }
                    }
                    /* else: would apply to enclosing scope */
                }

                /* pragma Import(Convention, Entity, External_Name, Link_Name) */
                else if (Slice_Equal_Ignore_Case(pragma_name, S("IMPORT"))) {
                    if (node->pragma_node.arguments.count >= 2) {
                        /* Get convention */
                        Syntax_Node *conv_arg = node->pragma_node.arguments.items[0];
                        Syntax_Node *conv_node = (conv_arg->kind == NK_ASSOCIATION) ?
                                                  conv_arg->association.expression : conv_arg;

                        /* Get entity */
                        Syntax_Node *ent_arg = node->pragma_node.arguments.items[1];
                        Syntax_Node *ent_node = (ent_arg->kind == NK_ASSOCIATION) ?
                                                 ent_arg->association.expression : ent_arg;

                        if (ent_node and ent_node->kind == NK_IDENTIFIER) {
                            Symbol *sym = Symbol_Find(sm, ent_node->string_val.text);
                            if (sym) {
                                sym->is_imported = true;

                                /* Set convention */
                                if (conv_node and conv_node->kind == NK_IDENTIFIER) {
                                    String_Slice conv = conv_node->string_val.text;
                                    if (Slice_Equal_Ignore_Case(conv, S("C")))
                                        sym->convention = CONVENTION_C;
                                    else if (Slice_Equal_Ignore_Case(conv, S("STDCALL")))
                                        sym->convention = CONVENTION_STDCALL;
                                    else if (Slice_Equal_Ignore_Case(conv, S("INTRINSIC")))
                                        sym->convention = CONVENTION_INTRINSIC;
                                }

                                /* Get external name if provided */
                                if (node->pragma_node.arguments.count >= 3) {
                                    Syntax_Node *name_arg = node->pragma_node.arguments.items[2];
                                    Syntax_Node *name_node = (name_arg->kind == NK_ASSOCIATION) ?
                                                              name_arg->association.expression : name_arg;
                                    if (name_node and name_node->kind == NK_STRING) {
                                        sym->external_name = name_node->string_val.text;
                                    }
                                }
                            }
                        }
                    }
                }

                /* pragma Export(Convention, Entity, External_Name) */
                else if (Slice_Equal_Ignore_Case(pragma_name, S("EXPORT"))) {
                    if (node->pragma_node.arguments.count >= 2) {
                        Syntax_Node *conv_arg = node->pragma_node.arguments.items[0];
                        Syntax_Node *conv_node = (conv_arg->kind == NK_ASSOCIATION) ?
                                                  conv_arg->association.expression : conv_arg;

                        Syntax_Node *ent_arg = node->pragma_node.arguments.items[1];
                        Syntax_Node *ent_node = (ent_arg->kind == NK_ASSOCIATION) ?
                                                 ent_arg->association.expression : ent_arg;

                        if (ent_node and ent_node->kind == NK_IDENTIFIER) {
                            Symbol *sym = Symbol_Find(sm, ent_node->string_val.text);
                            if (sym) {
                                sym->is_exported = true;

                                if (conv_node and conv_node->kind == NK_IDENTIFIER) {
                                    String_Slice conv = conv_node->string_val.text;
                                    if (Slice_Equal_Ignore_Case(conv, S("C")))
                                        sym->convention = CONVENTION_C;
                                }

                                if (node->pragma_node.arguments.count >= 3) {
                                    Syntax_Node *name_arg = node->pragma_node.arguments.items[2];
                                    Syntax_Node *name_node = (name_arg->kind == NK_ASSOCIATION) ?
                                                              name_arg->association.expression : name_arg;
                                    if (name_node and name_node->kind == NK_STRING) {
                                        sym->external_name = name_node->string_val.text;
                                    }
                                }
                            }
                        }
                    }
                }

                /* pragma Unreferenced(name, ...) */
                else if (Slice_Equal_Ignore_Case(pragma_name, S("UNREFERENCED"))) {
                    for (uint32_t i = 0; i < node->pragma_node.arguments.count; i++) {
                        Syntax_Node *arg = node->pragma_node.arguments.items[i];
                        Syntax_Node *name_node = (arg->kind == NK_ASSOCIATION) ?
                                                  arg->association.expression : arg;
                        if (name_node and name_node->kind == NK_IDENTIFIER) {
                            Symbol *sym = Symbol_Find(sm, name_node->string_val.text);
                            if (sym) sym->is_unreferenced = true;
                        }
                    }
                }

                /* pragma Convention(convention, entity) */
                else if (Slice_Equal_Ignore_Case(pragma_name, S("CONVENTION"))) {
                    if (node->pragma_node.arguments.count >= 2) {
                        Syntax_Node *conv_arg = node->pragma_node.arguments.items[0];
                        Syntax_Node *conv_node = (conv_arg->kind == NK_ASSOCIATION) ?
                                                  conv_arg->association.expression : conv_arg;

                        Syntax_Node *ent_arg = node->pragma_node.arguments.items[1];
                        Syntax_Node *ent_node = (ent_arg->kind == NK_ASSOCIATION) ?
                                                 ent_arg->association.expression : ent_arg;

                        if (ent_node and ent_node->kind == NK_IDENTIFIER) {
                            Symbol *sym = Symbol_Find(sm, ent_node->string_val.text);
                            if (sym and conv_node and conv_node->kind == NK_IDENTIFIER) {
                                String_Slice conv = conv_node->string_val.text;
                                if (Slice_Equal_Ignore_Case(conv, S("C")))
                                    sym->convention = CONVENTION_C;
                                else if (Slice_Equal_Ignore_Case(conv, S("STDCALL")))
                                    sym->convention = CONVENTION_STDCALL;
                            }
                        }
                    }
                }

                /* pragma Pure, pragma Preelaborate - informational only ??? */
                /* pragma Elaborate, pragma Elaborate_All - handled at link time ??? */
                /* pragma Restrictions - ??? */
            }
            break;

        case NK_EXCEPTION_DECL:
            /* Exception declaration: E : exception; */
            for (uint32_t i = 0; i < node->exception_decl.names.count; i++) {
                Syntax_Node *name_node = node->exception_decl.names.items[i];
                if (name_node and name_node->kind == NK_IDENTIFIER) {
                    Symbol *sym = Symbol_New(SYMBOL_EXCEPTION,
                                             name_node->string_val.text,
                                             name_node->location);
                    Symbol_Add(sm, sym);
                    name_node->symbol = sym;
                    /* Add to global exception list for codegen */
                    if (Exception_Symbol_Count < 256) {
                        Exception_Symbols[Exception_Symbol_Count++] = sym;
                    }
                }
            }
            break;

        case NK_GENERIC_DECL:
            /* Generic declaration: generic ... procedure/function/package spec */
            {
                Syntax_Node *unit = node->generic_decl.unit;
                if (not unit) break;

                /* Get name from the unit */
                String_Slice name = {0};
                if (unit->kind == NK_PROCEDURE_SPEC or unit->kind == NK_FUNCTION_SPEC) {
                    name = unit->subprogram_spec.name;
                } else if (unit->kind == NK_PACKAGE_SPEC) {
                    name = unit->package_spec.name;
                }

                /* Create generic symbol */
                Symbol *sym = Symbol_New(SYMBOL_GENERIC, name, node->location);
                sym->declaration = node;
                sym->generic_unit = unit;

                /* Store formals list for later */
                if (node->generic_decl.formals.count > 0) {
                    sym->generic_formals = node->generic_decl.formals.items[0];
                }

                Symbol_Add(sm, sym);
                node->symbol = sym;

                /* DON'T resolve the unit here - it contains generic formals
                   that need to be substituted during instantiation */
            }
            break;

        case NK_GENERIC_INST:
            /* Generic instantiation: procedure/function X is new GENERIC_NAME(actuals) */
            {
                /* Find the generic template */
                Syntax_Node *gen_name = node->generic_inst.generic_name;
                if (not gen_name) {
                    Report_Error(node->location, "expected a generic unit name");
                    break;
                }

                /* Resolve the generic name to find template */
                Resolve_Expression(sm, gen_name);
                Symbol *template = NULL;
                if (gen_name->kind == NK_IDENTIFIER) {
                    template = Symbol_Find(sm, gen_name->string_val.text);
                } else if (gen_name->symbol) {
                    /* Handle qualified names like P.PP (NK_SELECTED resolved to a symbol) */
                    template = gen_name->symbol;
                }

                if (not template or template->kind != SYMBOL_GENERIC) {
                    Report_Error(node->location, "expected a generic unit name");
                    break;
                }

                /* Create instance symbol */
                Symbol_Kind inst_kind;
                if (node->generic_inst.unit_kind == TK_FUNCTION)
                    inst_kind = SYMBOL_FUNCTION;
                else if (node->generic_inst.unit_kind == TK_PACKAGE)
                    inst_kind = SYMBOL_PACKAGE;
                else
                    inst_kind = SYMBOL_PROCEDURE;
                Symbol *inst_sym = Symbol_New(inst_kind,
                                              node->generic_inst.instance_name,
                                              node->location);
                inst_sym->declaration = node;
                inst_sym->generic_template = template;

                /* Process generic actuals and build mapping */
                Node_List *formals = &template->declaration->generic_decl.formals;
                Node_List *actuals = &node->generic_inst.actuals;

                /* Count total actual slots: multi-name object formals
                 * like "F, L : E" consume one actual per name.
                 * Type and subprogram formals consume one actual each. */
                uint32_t total_actual_slots = 0;
                for (uint32_t i = 0; i < formals->count; i++) {
                    Syntax_Node *formal = formals->items[i];
                    if (formal->kind == NK_GENERIC_OBJECT_PARAM)
                        total_actual_slots += formal->generic_object_param.names.count;
                    else
                        total_actual_slots++;
                }
                /* Use the larger of computed slots and actual params provided */
                if (total_actual_slots < actuals->count)
                    total_actual_slots = actuals->count;

                inst_sym->generic_actual_count = total_actual_slots;
                if (total_actual_slots > 0) {
                    inst_sym->generic_actuals = Arena_Allocate(
                        total_actual_slots * sizeof(*inst_sym->generic_actuals));

                    /* First pass: resolve type formals (using actual_idx to track
                     * position in the actuals list, since object formals with multiple
                     * names consume multiple actual slots). */
                    uint32_t actual_idx = 0;
                    for (uint32_t i = 0; i < formals->count; i++) {
                        Syntax_Node *formal = formals->items[i];

                        if (formal->kind == NK_GENERIC_TYPE_PARAM) {
                            Syntax_Node *actual = (actual_idx < actuals->count) ?
                                actuals->items[actual_idx] : NULL;
                            if (actual_idx < total_actual_slots) {
                                inst_sym->generic_actuals[actual_idx].formal_name =
                                    formal->generic_type_param.name;
                                if (actual) {
                                    Syntax_Node *type_node = actual;
                                    if (actual->kind == NK_ASSOCIATION)
                                        type_node = actual->association.expression;
                                    Resolve_Expression(sm, type_node);
                                    inst_sym->generic_actuals[actual_idx].actual_type = type_node->type;
                                }
                            }
                            actual_idx++;
                        } else if (formal->kind == NK_GENERIC_OBJECT_PARAM) {
                            actual_idx += formal->generic_object_param.names.count;
                        } else if (formal->kind == NK_GENERIC_SUBPROGRAM_PARAM) {
                            actual_idx++;
                        }
                    }

                    /* Second pass: resolve object formals with substituted types.
                     * Each name in a multi-name object formal gets its own actual slot. */
                    actual_idx = 0;
                    for (uint32_t i = 0; i < formals->count; i++) {
                        Syntax_Node *formal = formals->items[i];

                        if (formal->kind == NK_GENERIC_OBJECT_PARAM) {
                            /* Look up the formal's type, substituting any type formals */
                            Syntax_Node *obj_type_node = formal->generic_object_param.object_type;
                            Type_Info *obj_type = NULL;
                            if (obj_type_node and obj_type_node->kind == NK_IDENTIFIER) {
                                for (uint32_t k = 0; k < total_actual_slots; k++) {
                                    if (inst_sym->generic_actuals[k].actual_type and
                                        Slice_Equal_Ignore_Case(obj_type_node->string_val.text,
                                                  inst_sym->generic_actuals[k].formal_name)) {
                                        obj_type = inst_sym->generic_actuals[k].actual_type;
                                        break;
                                    }
                                }
                            }
                            /* Map each name to its own actual */
                            for (uint32_t j = 0; j < formal->generic_object_param.names.count; j++) {
                                Syntax_Node *actual = (actual_idx < actuals->count) ?
                                    actuals->items[actual_idx] : NULL;
                                if (actual and actual_idx < total_actual_slots) {
                                    Syntax_Node *expr = actual;
                                    if (actual->kind == NK_ASSOCIATION)
                                        expr = actual->association.expression;
                                    if (obj_type) {
                                        expr->type = obj_type;
                                        Resolve_Expression(sm, expr);
                                        if (not expr->type or expr->kind == NK_AGGREGATE)
                                            expr->type = obj_type;
                                        /* Character literal actuals for enum formal types need
                                         * explicit resolution to find their position (RM 3.5.1).
                                         * Resolve_Expression sets type to CHARACTER, losing the
                                         * enum context; restore and resolve as enum literal. */
                                        if (expr->kind == NK_CHARACTER)
                                            Resolve_Char_As_Enum(sm, expr, obj_type);
                                    } else {
                                        Resolve_Expression(sm, expr);
                                    }
                                    inst_sym->generic_actuals[actual_idx].actual_expr = expr;
                                    Syntax_Node *fname = formal->generic_object_param.names.items[j];
                                    if (fname)
                                        inst_sym->generic_actuals[actual_idx].formal_name =
                                            fname->string_val.text;
                                }
                                actual_idx++;
                            }
                        } else if (formal->kind == NK_GENERIC_TYPE_PARAM) {
                            actual_idx++;
                        } else if (formal->kind == NK_GENERIC_SUBPROGRAM_PARAM) {
                            actual_idx++;
                        }
                    }
                    /* Third pass: resolve subprogram formals to actual subprograms */
                    actual_idx = 0;
                    for (uint32_t i = 0; i < formals->count; i++) {
                        Syntax_Node *formal = formals->items[i];

                        if (formal->kind == NK_GENERIC_OBJECT_PARAM) {
                            actual_idx += formal->generic_object_param.names.count;
                            continue;
                        }
                        Syntax_Node *actual = (actual_idx < actuals->count) ?
                            actuals->items[actual_idx] : NULL;

                        if (formal->kind == NK_GENERIC_SUBPROGRAM_PARAM) {
                            if (actual_idx < total_actual_slots)
                                inst_sym->generic_actuals[actual_idx].formal_name =
                                    formal->generic_subprog_param.name;

                            /* Resolve actual subprogram name */
                            if (actual) {
                                Syntax_Node *name_node = actual;
                                if (actual->kind == NK_ASSOCIATION) {
                                    name_node = actual->association.expression;
                                }
                                if (not name_node) continue;

                                /* Handle operator designators: "&" is the "&" operator */
                                if (name_node->kind == NK_STRING) {
                                    /* Look up operator by name */
                                    if (name_node->string_val.text.data) {
                                        Symbol *op = Symbol_Find(sm, name_node->string_val.text);
                                        /* Check type profile matches: the formal's type parameter
                                         * must match the found operator's return type. Otherwise
                                         * fall through to built-in operator path. */
                                        bool type_matches = false;
                                        if (op and (op->kind == SYMBOL_FUNCTION or op->kind == SYMBOL_PROCEDURE)) {
                                            /* Find the actual type for the first type formal */
                                            Type_Info *expected_type = NULL;
                                            for (uint32_t k = 0; k < total_actual_slots; k++) {
                                                if (inst_sym->generic_actuals[k].actual_type) {
                                                    expected_type = inst_sym->generic_actuals[k].actual_type;
                                                    break;
                                                }
                                            }
                                            if (expected_type and op->return_type) {
                                                type_matches = (expected_type == op->return_type or
                                                    Type_Base(expected_type) == Type_Base(op->return_type));
                                            } else {
                                                type_matches = true; /* no type info to check */
                                            }
                                        }
                                        if (op and type_matches and
                                            (op->kind == SYMBOL_FUNCTION or op->kind == SYMBOL_PROCEDURE)) {
                                            name_node->symbol = op;
                                            inst_sym->generic_actuals[actual_idx].actual_subprogram = op;
                                        } else {
                                            /* Check for built-in operators */
                                            /* String lexer strips quotes: "&" becomes just & */
                                            String_Slice s = name_node->string_val.text;
                                            if (s.length == 1 and s.data[0] == '&')
                                                inst_sym->generic_actuals[actual_idx].builtin_operator = TK_AMPERSAND;
                                            else if (s.length == 1 and s.data[0] == '+')
                                                inst_sym->generic_actuals[actual_idx].builtin_operator = TK_PLUS;
                                            else if (s.length == 1 and s.data[0] == '-')
                                                inst_sym->generic_actuals[actual_idx].builtin_operator = TK_MINUS;
                                            else if (s.length == 1 and s.data[0] == '*')
                                                inst_sym->generic_actuals[actual_idx].builtin_operator = TK_STAR;
                                            else if (s.length == 1 and s.data[0] == '/')
                                                inst_sym->generic_actuals[actual_idx].builtin_operator = TK_SLASH;
                                        }
                                    }
                                }
                                /* Handle character literals as enum literals: '&' from ADD_OPS */
                                else if (name_node->kind == NK_CHARACTER) {
                                    /* Character literal as enum literal (parameterless function) */
                                    if (name_node->string_val.text.data) {
                                        Symbol *lit = Symbol_Find(sm, name_node->string_val.text);
                                        if (lit and lit->kind == SYMBOL_LITERAL) {
                                            name_node->symbol = lit;
                                            inst_sym->generic_actuals[actual_idx].actual_subprogram = lit;
                                        }
                                    }
                                }
                                else {
                                    /* Look up the actual subprogram symbol */
                                    Resolve_Expression(sm, name_node);
                                    if (name_node->symbol) {
                                        inst_sym->generic_actuals[actual_idx].actual_subprogram = name_node->symbol;
                                    }
                                }
                            }
                            actual_idx++;
                        } else if (formal->kind == NK_GENERIC_TYPE_PARAM) {
                            actual_idx++;
                        }
                    }
                }

                /* Copy parameter info from template unit */
                Syntax_Node *unit = template->generic_unit;
                if (unit and (unit->kind == NK_FUNCTION_SPEC or unit->kind == NK_PROCEDURE_SPEC)) {
                    Node_List *params = &unit->subprogram_spec.parameters;
                    uint32_t total_params = 0;
                    for (uint32_t i = 0; i < params->count; i++) {
                        Syntax_Node *ps = params->items[i];
                        if (ps->kind == NK_PARAM_SPEC) {
                            total_params += ps->param_spec.names.count;
                        }
                    }

                    inst_sym->parameter_count = total_params;
                    if (total_params > 0) {
                        inst_sym->parameters = Arena_Allocate(total_params * sizeof(Parameter_Info));
                        uint32_t idx = 0;
                        for (uint32_t i = 0; i < params->count; i++) {
                            Syntax_Node *ps = params->items[i];
                            if (ps->kind == NK_PARAM_SPEC) {
                                /* Resolve param type and substitute formals with actuals */
                                Type_Info *param_type = NULL;
                                if (ps->param_spec.param_type) {
                                    Syntax_Node *pt = ps->param_spec.param_type;
                                    if (pt->kind == NK_IDENTIFIER) {
                                        /* First check if formal type parameter > substitute */
                                        for (uint32_t k = 0; k < inst_sym->generic_actual_count; k++) {
                                            if (Slice_Equal_Ignore_Case(pt->string_val.text,
                                                          inst_sym->generic_actuals[k].formal_name)) {
                                                param_type = inst_sym->generic_actuals[k].actual_type;
                                                break;
                                            }
                                        }
                                        /* If not a formal, resolve actual type (e.g. STRING) */
                                        if (not param_type) {
                                            Symbol *type_sym = Symbol_Find(sm, pt->string_val.text);
                                            if (type_sym and type_sym->type)
                                                param_type = type_sym->type;
                                        }
                                    }
                                }

                                for (uint32_t j = 0; j < ps->param_spec.names.count; j++) {
                                    Syntax_Node *name = ps->param_spec.names.items[j];
                                    inst_sym->parameters[idx].name = name->string_val.text;
                                    inst_sym->parameters[idx].param_type = param_type;
                                    inst_sym->parameters[idx].mode = (Parameter_Mode)ps->param_spec.mode;
                                    idx++;
                                }
                            }
                        }
                    }

                    /* Handle return type for functions */
                    if (unit->kind == NK_FUNCTION_SPEC and unit->subprogram_spec.return_type) {
                        Syntax_Node *rt = unit->subprogram_spec.return_type;
                        if (rt->kind == NK_IDENTIFIER) {
                            /* Check if return type is a formal type parameter */
                            for (uint32_t k = 0; k < inst_sym->generic_actual_count; k++) {
                                if (Slice_Equal_Ignore_Case(rt->string_val.text,
                                              inst_sym->generic_actuals[k].formal_name)) {
                                    inst_sym->return_type = inst_sym->generic_actuals[k].actual_type;
                                    break;
                                }
                            }
                            /* If not a formal, look up the actual type (e.g. INTEGER) */
                            if (not inst_sym->return_type) {
                                Symbol *type_sym = Symbol_Find(sm, rt->string_val.text);
                                if (type_sym and type_sym->type)
                                    inst_sym->return_type = type_sym->type;
                            }
                        }
                    }
                }

                /* For package instantiations, copy and instantiate exported symbols */
                if (node->generic_inst.unit_kind == TK_PACKAGE) {
                    /* Look for exports from the template's generic_unit (package spec) */
                    Syntax_Node *pkg_spec = template->generic_unit;
                    if (pkg_spec and pkg_spec->kind == NK_PACKAGE_SPEC) {
                        /* Count visible declarations */
                        uint32_t export_count = 0;
                        for (uint32_t i = 0; i < pkg_spec->package_spec.visible_decls.count; i++) {
                            Syntax_Node *decl = pkg_spec->package_spec.visible_decls.items[i];
                            if (not decl) continue;
                            if (decl->kind == NK_TYPE_DECL or decl->kind == NK_SUBTYPE_DECL) {
                                export_count++;
                                /* Count enum literals too */
                                if (decl->type_decl.definition and
                                    decl->type_decl.definition->kind == NK_ENUMERATION_TYPE) {
                                    export_count += decl->type_decl.definition->enum_type.literals.count;
                                }
                            }
                            else if (decl->kind == NK_PROCEDURE_SPEC or decl->kind == NK_FUNCTION_SPEC)
                                export_count++;
                            else if (decl->kind == NK_EXCEPTION_DECL)
                                export_count += decl->exception_decl.names.count;
                            else if (decl->kind == NK_OBJECT_DECL)
                                export_count += decl->object_decl.names.count;
                            else if (decl->kind == NK_TASK_SPEC)
                                export_count++;
                        }

                        if (export_count > 0) {
                            inst_sym->exported = Arena_Allocate(export_count * sizeof(Symbol*));
                            inst_sym->exported_count = 0;

                            /* Helper: substitute generic formals with actuals in a type */
                            #define SUBSTITUTE_TYPE(ty) do { \
                                if (ty and ty->name.data) { \
                                    for (uint32_t k = 0; k < inst_sym->generic_actual_count; k++) { \
                                        if (Slice_Equal_Ignore_Case(ty->name, \
                                                      inst_sym->generic_actuals[k].formal_name)) { \
                                            ty = inst_sym->generic_actuals[k].actual_type; \
                                            break; \
                                        } \
                                    } \
                                } \
                            } while(0)

                            for (uint32_t i = 0; i < pkg_spec->package_spec.visible_decls.count; i++) {
                                Syntax_Node *decl = pkg_spec->package_spec.visible_decls.items[i];
                                if (not decl) continue;

                                if (decl->kind == NK_TYPE_DECL or decl->kind == NK_SUBTYPE_DECL) {
                                    /* Create type symbol for the instance */
                                    String_Slice name = decl->type_decl.name;
                                    Symbol *exp = Symbol_New(SYMBOL_TYPE, name, decl->location);
                                    /* Use the symbol's type (has the named type) if available */
                                    if (decl->symbol and decl->symbol->type)
                                        exp->type = decl->symbol->type;
                                    else if (decl->type)
                                        exp->type = decl->type;
                                    else if (decl->type_decl.definition)
                                        exp->type = decl->type_decl.definition->type;
                                    /* For subtypes, substitute formal type with actual */
                                    if (not exp->type and decl->kind == NK_SUBTYPE_DECL and
                                        decl->type_decl.definition) {
                                        Syntax_Node *def = decl->type_decl.definition;
                                        String_Slice def_name = {0};
                                        /* Handle plain identifier: SUBTYPE X IS GEN */
                                        if (def->kind == NK_IDENTIFIER) {
                                            def_name = def->string_val.text;
                                        }
                                        /* Handle constrained: SUBTYPE X IS GEN(4) */
                                        else if (def->kind == NK_APPLY and def->apply.prefix and
                                                 def->apply.prefix->kind == NK_IDENTIFIER) {
                                            def_name = def->apply.prefix->string_val.text;
                                        }
                                        /* Handle subtype indication: SUBTYPE X IS GEN RANGE ... */
                                        else if (def->kind == NK_SUBTYPE_INDICATION and
                                                 def->subtype_ind.subtype_mark and
                                                 def->subtype_ind.subtype_mark->kind == NK_IDENTIFIER) {
                                            def_name = def->subtype_ind.subtype_mark->string_val.text;
                                        }
                                        if (def_name.data) {
                                            for (uint32_t k = 0; k < inst_sym->generic_actual_count; k++) {
                                                Syntax_Node *formal_k = formals->items[k];
                                                if (formal_k->kind == NK_GENERIC_TYPE_PARAM and
                                                    Slice_Equal_Ignore_Case(def_name, formal_k->generic_type_param.name)) {
                                                    exp->type = inst_sym->generic_actuals[k].actual_type;
                                                    break;
                                                }
                                            }
                                        }
                                    }
                                    /* Create Type_Info for unresolved enum/range types */
                                    if (not exp->type and decl->type_decl.definition) {
                                        Syntax_Node *def = decl->type_decl.definition;
                                        if (def->kind == NK_ENUMERATION_TYPE) {
                                            Type_Info *ti = Type_New(TYPE_ENUMERATION, name);
                                            ti->size = 4;
                                            uint32_t lit_count = def->enum_type.literals.count;
                                            ti->enumeration.literal_count = lit_count;
                                            if (lit_count > 0) {
                                                ti->enumeration.literals = Arena_Allocate(
                                                    lit_count * sizeof(String_Slice));
                                                for (uint32_t j = 0; j < lit_count; j++) {
                                                    Syntax_Node *lit = def->enum_type.literals.items[j];
                                                    if (lit and lit->kind == NK_IDENTIFIER)
                                                        ti->enumeration.literals[j] = lit->string_val.text;
                                                }
                                            }
                                            exp->type = ti;
                                            def->type = ti;
                                            decl->type = ti;
                                        } else if (def->kind == NK_RANGE) {
                                            /* Integer type with range constraint */
                                            Type_Info *ti = Type_New(TYPE_INTEGER, name);
                                            ti->size = 4;
                                            exp->type = ti;
                                            def->type = ti;
                                            decl->type = ti;
                                        }
                                    }
                                    exp->declaration = decl;
                                    exp->parent = inst_sym;
                                    inst_sym->exported[inst_sym->exported_count++] = exp;

                                    /* Also export enum literals */
                                    if (decl->type_decl.definition and
                                        decl->type_decl.definition->kind == NK_ENUMERATION_TYPE) {
                                        Node_List *lits = &decl->type_decl.definition->enum_type.literals;
                                        for (uint32_t j = 0; j < lits->count; j++) {
                                            Syntax_Node *lit = lits->items[j];
                                            if (lit and lit->kind == NK_IDENTIFIER) {
                                                Symbol *lit_sym = Symbol_New(SYMBOL_LITERAL,
                                                    lit->string_val.text, lit->location);
                                                lit_sym->type = exp->type;
                                                lit_sym->parent = inst_sym;
                                                inst_sym->exported[inst_sym->exported_count++] = lit_sym;
                                            }
                                        }
                                    }
                                }
                                else if (decl->kind == NK_PROCEDURE_SPEC or
                                         decl->kind == NK_FUNCTION_SPEC) {
                                    /* Create subprogram symbol with instantiated types.
                                     * Assign unique_id immediately so homographs get distinct IDs. */
                                    String_Slice name = decl->subprogram_spec.name;
                                    Symbol_Kind sk = (decl->kind == NK_PROCEDURE_SPEC) ?
                                                     SYMBOL_PROCEDURE : SYMBOL_FUNCTION;
                                    Symbol *exp = Symbol_New(sk, name, decl->location);
                                    exp->unique_id = sm->next_unique_id++;
                                    exp->declaration = decl;
                                    exp->parent = inst_sym;
                                    exp->generic_template = template;

                                    /* Copy and substitute parameter types */
                                    Node_List *params = &decl->subprogram_spec.parameters;
                                    uint32_t total_params = 0;
                                    for (uint32_t j = 0; j < params->count; j++) {
                                        Syntax_Node *ps = params->items[j];
                                        if (ps->kind == NK_PARAM_SPEC)
                                            total_params += ps->param_spec.names.count;
                                    }
                                    exp->parameter_count = total_params;
                                    if (total_params > 0) {
                                        exp->parameters = Arena_Allocate(
                                            total_params * sizeof(Parameter_Info));
                                        uint32_t idx = 0;
                                        for (uint32_t j = 0; j < params->count; j++) {
                                            Syntax_Node *ps = params->items[j];
                                            if (ps->kind == NK_PARAM_SPEC) {
                                                Type_Info *ptype = ps->param_spec.param_type ?
                                                    ps->param_spec.param_type->type : NULL;
                                                /* If type not resolved, look up by name */
                                                if (not ptype and ps->param_spec.param_type and
                                                    ps->param_spec.param_type->kind == NK_IDENTIFIER) {
                                                    String_Slice pt_name = ps->param_spec.param_type->string_val.text;
                                                    /* First try instance's own exports */
                                                    for (uint32_t k = 0; k < inst_sym->exported_count; k++) {
                                                        Symbol *es = inst_sym->exported[k];
                                                        if (es and es->kind == SYMBOL_TYPE and
                                                            Slice_Equal_Ignore_Case(es->name, pt_name)) {
                                                            ptype = es->type;
                                                            break;
                                                        }
                                                    }
                                                    /* Then try global symbol table */
                                                    if (not ptype) {
                                                        Symbol *tsym = Symbol_Find(sm, pt_name);
                                                        if (tsym) ptype = tsym->type;
                                                    }
                                                }
                                                SUBSTITUTE_TYPE(ptype);
                                                for (uint32_t m = 0; m < ps->param_spec.names.count; m++) {
                                                    Syntax_Node *pname = ps->param_spec.names.items[m];
                                                    exp->parameters[idx].name = pname->string_val.text;
                                                    exp->parameters[idx].param_type = ptype;
                                                    exp->parameters[idx].mode =
                                                        (Parameter_Mode)ps->param_spec.mode;
                                                    /* Create param symbol if not present (specs don't have symbols) */
                                                    if (not pname->symbol) {
                                                        Symbol *ps_sym = Symbol_New(SYMBOL_PARAMETER,
                                                            pname->string_val.text, pname->location);
                                                        ps_sym->type = ptype;
                                                        ps_sym->unique_id = sm->next_unique_id++;
                                                        pname->symbol = ps_sym;
                                                    }
                                                    exp->parameters[idx].param_sym = pname->symbol;
                                                    idx++;
                                                }
                                            }
                                        }
                                    }

                                    /* Handle return type */
                                    if (decl->kind == NK_FUNCTION_SPEC and
                                        decl->subprogram_spec.return_type) {
                                        Type_Info *rtype = decl->subprogram_spec.return_type->type;
                                        /* If return type not resolved, look up by name */
                                        if (not rtype and decl->subprogram_spec.return_type->kind == NK_IDENTIFIER) {
                                            String_Slice rt_name = decl->subprogram_spec.return_type->string_val.text;
                                            /* First try instance's own exports (for types like FILE_MODE) */
                                            for (uint32_t k = 0; k < inst_sym->exported_count; k++) {
                                                Symbol *es = inst_sym->exported[k];
                                                if (es and es->kind == SYMBOL_TYPE and
                                                    Slice_Equal_Ignore_Case(es->name, rt_name)) {
                                                    rtype = es->type;
                                                    break;
                                                }
                                            }
                                            /* Then try global symbol table */
                                            if (not rtype) {
                                                Symbol *tsym = Symbol_Find(sm, rt_name);
                                                if (tsym) rtype = tsym->type;
                                            }
                                        }
                                        SUBSTITUTE_TYPE(rtype);
                                        exp->return_type = rtype;
                                    }

                                    inst_sym->exported[inst_sym->exported_count++] = exp;
                                }
                                else if (decl->kind == NK_EXCEPTION_DECL) {
                                    for (uint32_t j = 0; j < decl->exception_decl.names.count; j++) {
                                        Syntax_Node *nm = decl->exception_decl.names.items[j];
                                        Symbol *exp = Symbol_New(SYMBOL_EXCEPTION,
                                            nm->string_val.text, nm->location);
                                        exp->parent = inst_sym;
                                        inst_sym->exported[inst_sym->exported_count++] = exp;
                                    }
                                }
                                else if (decl->kind == NK_OBJECT_DECL) {
                                    /* Export object declarations (including renames) */
                                    Type_Info *obj_type = NULL;
                                    if (decl->object_decl.object_type) {
                                        obj_type = decl->object_decl.object_type->type;
                                        /* If type not resolved (generic template), look up by name */
                                        if (not obj_type and decl->object_decl.object_type->kind == NK_IDENTIFIER) {
                                            String_Slice type_name = decl->object_decl.object_type->string_val.text;
                                            Symbol *type_sym = Symbol_Find(sm, type_name);
                                            if (type_sym and type_sym->type)
                                                obj_type = type_sym->type;
                                        }
                                        /* Substitute generic formals with actuals */
                                        SUBSTITUTE_TYPE(obj_type);
                                    }
                                    for (uint32_t j = 0; j < decl->object_decl.names.count; j++) {
                                        Syntax_Node *nm = decl->object_decl.names.items[j];
                                        Symbol_Kind sk = decl->object_decl.is_constant ?
                                            SYMBOL_CONSTANT : SYMBOL_VARIABLE;
                                        Symbol *exp = Symbol_New(sk, nm->string_val.text, nm->location);
                                        exp->type = obj_type;
                                        exp->parent = inst_sym;
                                        /* For renames, store the renamed object expression */
                                        if (decl->object_decl.is_rename and decl->object_decl.init) {
                                            exp->renamed_object = decl->object_decl.init;
                                        }
                                        inst_sym->exported[inst_sym->exported_count++] = exp;
                                    }
                                }
                                else if (decl->kind == NK_TASK_SPEC) {
                                    /* Export task declarations from generic instantiation.
                                     * Create a type symbol with TYPE_TASK and populate its
                                     * entries from the task spec's entry declarations. */
                                    String_Slice name = decl->task_spec.name;
                                    Symbol *exp = Symbol_New(SYMBOL_TYPE, name, decl->location);
                                    Type_Info *type = Type_New(TYPE_TASK, name);
                                    exp->type = type;
                                    type->defining_symbol = exp;
                                    exp->declaration = decl;
                                    exp->parent = inst_sym;

                                    /* Add entries to the task type's exported list */
                                    for (uint32_t j = 0; j < decl->task_spec.entries.count; j++) {
                                        Syntax_Node *entry = decl->task_spec.entries.items[j];
                                        if (entry->kind == NK_ENTRY_DECL) {
                                            Symbol *entry_sym = Symbol_New(SYMBOL_ENTRY,
                                                entry->entry_decl.name, entry->location);
                                            entry_sym->declaration = entry;
                                            entry_sym->parent = exp;
                                            entry_sym->entry_index = j;
                                            if (not exp->exported) {
                                                exp->exported = Arena_Allocate(100 * sizeof(Symbol*));
                                            }
                                            exp->exported[exp->exported_count++] = entry_sym;
                                        }
                                    }
                                    inst_sym->exported[inst_sym->exported_count++] = exp;

                                    /* For single task declarations (not task types),
                                     * also create an object variable (RM 9.1) */
                                    if (not decl->task_spec.is_type) {
                                        Symbol *obj = Symbol_New(SYMBOL_VARIABLE,
                                            name, decl->location);
                                        obj->type = type;
                                        obj->declaration = decl;
                                        obj->parent = inst_sym;
                                        inst_sym->exported[inst_sym->exported_count++] = obj;
                                    }
                                }
                            }
                            #undef SUBSTITUTE_TYPE
                        }
                    }
                }

                Symbol_Add(sm, inst_sym);
                node->symbol = inst_sym;

                /* For package instantiations, expand the generic now
                 * so we have expanded_spec/expanded_body for codegen */
                if (node->generic_inst.unit_kind == TK_PACKAGE) {
                    Expand_Generic_Package(sm, inst_sym);
                }
            }
            break;

        case NK_REPRESENTATION_CLAUSE:
            /* Representation clause: FOR T'SIZE USE 32; or FOR T USE RECORD ... */
            {
                /* Resolve entity name */
                if (node->rep_clause.entity_name) {
                    Resolve_Expression(sm, node->rep_clause.entity_name);

                    /* Get target type or symbol */
                    Symbol *target_sym = NULL;
                    if (node->rep_clause.entity_name->kind == NK_IDENTIFIER) {
                        target_sym = Symbol_Find(sm, node->rep_clause.entity_name->string_val.text);
                    } else if (node->rep_clause.entity_name->symbol) {
                        target_sym = node->rep_clause.entity_name->symbol;
                    }

                    Type_Info *target_type = target_sym ? target_sym->type : NULL;

                    /* Process attribute clauses: FOR T'SIZE USE 32; */
                    if (node->rep_clause.attribute.data and target_type) {
                        String_Slice attr = node->rep_clause.attribute;

                        if (node->rep_clause.expression) {
                            Resolve_Expression(sm, node->rep_clause.expression);
                            /* Evaluate constant expression (handles T'SIZE/2 etc.) */
                            double dval = Eval_Const_Numeric(node->rep_clause.expression);
                            int64_t value = isnan(dval) ? 0 : (int64_t)dval;

                            /* Apply representation */
                            if (Slice_Equal_Ignore_Case(attr, S("SIZE"))) {
                                /* Size in bits - store exact and convert to bytes */
                                target_type->specified_bit_size = (uint32_t)value;
                                target_type->size = (uint32_t)((value + 7) / 8);
                            } else if (Slice_Equal_Ignore_Case(attr, S("ALIGNMENT"))) {
                                target_type->alignment = (uint32_t)value;
                            } else if (Slice_Equal_Ignore_Case(attr, S("STORAGE_SIZE"))) {
                                target_type->storage_size = value;
                            } else if (Slice_Equal_Ignore_Case(attr, S("SMALL"))) {
                                /* For fixed-point: set small value */
                                if (Type_Is_Fixed_Point(target_type) and
                                    node->rep_clause.expression->kind == NK_REAL) {
                                    target_type->fixed.small =
                                        node->rep_clause.expression->real_lit.value;
                                }
                            }
                        }
                    }

                    /* Process record representation: FOR T USE RECORD ... */
                    if (node->rep_clause.is_record_rep and
                        Type_Is_Record(target_type)) {
                        /* Process alignment clause */
                        if (node->rep_clause.expression) {
                            Resolve_Expression(sm, node->rep_clause.expression);
                            if (node->rep_clause.expression->kind == NK_INTEGER) {
                                target_type->alignment =
                                    (uint32_t)node->rep_clause.expression->integer_lit.value;
                            }
                        }

                        /* Process component clauses (record layout)
                         * Each clause: component_name AT byte_position [RANGE bits]; */
                        for (uint32_t i = 0; i < node->rep_clause.component_clauses.count; i++) {
                            Syntax_Node *cc = node->rep_clause.component_clauses.items[i];
                            if (cc->kind == NK_ASSOCIATION and cc->association.choices.count > 0) {
                                Syntax_Node *name_node = cc->association.choices.items[0];
                                if (name_node and name_node->kind == NK_IDENTIFIER) {
                                    String_Slice comp_name = name_node->string_val.text;
                                    /* Find matching component in record type */
                                    for (uint32_t j = 0; j < target_type->record.component_count; j++) {
                                        Component_Info *comp = &target_type->record.components[j];
                                        if (Slice_Equal_Ignore_Case(comp->name, comp_name)) {
                                            /* Get byte offset from expression */
                                            Syntax_Node *pos_expr = cc->association.expression;
                                            if (pos_expr and pos_expr->kind == NK_INTEGER) {
                                                comp->byte_offset = (uint32_t)pos_expr->integer_lit.value;
                                            }
                                            break;
                                        }
                                    }
                                }
                            }
                        }
                    }

                    /* Process enumeration representation: FOR T USE (val0, val1, ...); */
                    if (node->rep_clause.is_enum_rep and
                        Type_Is_Enumeration(target_type)) {
                        /* Store internal representation values for enum literals
                         * The component_clauses list contains the values in order */
                        uint32_t val_count = node->rep_clause.component_clauses.count;
                        if (val_count > 0 and val_count <= target_type->enumeration.literal_count) {
                            /* Allocate array for representation values */
                            target_type->enumeration.rep_values =
                                Arena_Allocate(val_count * sizeof(int64_t));
                            for (uint32_t i = 0; i < val_count; i++) {
                                Syntax_Node *val_node = node->rep_clause.component_clauses.items[i];
                                if (val_node and val_node->kind == NK_INTEGER) {
                                    target_type->enumeration.rep_values[i] =
                                        val_node->integer_lit.value;
                                } else {
                                    /* Default to position value */
                                    target_type->enumeration.rep_values[i] = (int64_t)i;
                                }
                            }
                        }
                    }
                }
            }
            break;

        default:
            break;
    }
}

/* ─────────────────────────────────────────────────────────────────────────
 * §12.4 Compilation Unit Resolution
 * ───────────────────────────────────────────────────────────────────────── */

static void Resolve_Compilation_Unit(Symbol_Manager *sm, Syntax_Node *node) {
    if (not node) return;

    /* Load WITH'd packages from include paths */
    if (node->compilation_unit.context) {
        Syntax_Node *ctx = node->compilation_unit.context;
        for (uint32_t i = 0; i < ctx->context.with_clauses.count; i++) {
            Syntax_Node *with_node = ctx->context.with_clauses.items[i];
            /* WITH clause contains a list of package names */
            for (uint32_t j = 0; j < with_node->use_clause.names.count; j++) {
                Syntax_Node *pkg_name = with_node->use_clause.names.items[j];
                if (pkg_name->kind == NK_IDENTIFIER) {
                    char *pkg_src = Lookup_Path(pkg_name->string_val.text);
                    if (pkg_src) {
                        Load_Package_Spec(sm, pkg_name->string_val.text, pkg_src);
                    }
                    /* Resolve the identifier to the package symbol */
                    Resolve_Expression(sm, pkg_name);
                }
            }
        }
        /* Resolve USE clauses (make package contents visible) */
        for (uint32_t i = 0; i < ctx->context.use_clauses.count; i++) {
            Resolve_Declaration(sm, ctx->context.use_clauses.items[i]);
        }
    }

    /* Handle separate subunits (SEPARATE (parent) ...) */
    Symbol *parent_sym = NULL;
    if (node->compilation_unit.separate_parent) {
        Syntax_Node *parent = node->compilation_unit.separate_parent;
        String_Slice parent_name = {0};
        if (parent->kind == NK_IDENTIFIER) {
            parent_name = parent->string_val.text;
        } else if (parent->kind == NK_SELECTED) {
            /* Handle qualified names like A.B - use the selector (rightmost part) */
            parent_name = parent->selected.selector;
        }
        if (parent_name.length > 0) {
            parent_sym = Symbol_Find(sm, parent_name);
            if (parent_sym and parent_sym->scope) {
                /* Push the parent's actual scope so we can find the stub symbol.
                 * This reuses the scope where the stub was declared. */
                Symbol_Manager_Push_Existing_Scope(sm, parent_sym->scope);
            }
        }
    }

    /* Resolve main unit */
    if (node->compilation_unit.unit) {
        Resolve_Declaration(sm, node->compilation_unit.unit);
    }

    /* Pop parent scope if we pushed it */
    if (parent_sym and parent_sym->scope) {
        Symbol_Manager_Pop_Scope(sm);
    }
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §13. LLVM IR CODE GENERATION
 * ═══════════════════════════════════════════════════════════════════════════
 *
 * The AST is semantic and the IR is operational, with translation bridging the gap.
 *
 * Generate LLVM IR from the resolved AST. Key principles:
 *
 * 1. Operate at native type width;
 *    convert only at explicit Ada type conversions and LLVM intrinsic
 *    boundaries (memcpy length, alloc size must be i64)
 * 2. All pointer types use opaque 'ptr' (LLVM 15+)
 * 3. Static links for nested subprogram access
 * 4. Fat pointers for unconstrained arrays (ptr + bounds)
 */

/* ─────────────────────────────────────────────────────────────────────────
 * §13.1 Code Generator State
 * ───────────────────────────────────────────────────────────────────────── */

typedef struct {
    FILE         *output;
    Symbol_Manager *sm;

    /* ID counters */
    uint32_t      temp_id;
    uint32_t      label_id;
    uint32_t      global_id;
    uint32_t      string_id;

    /* Current function context */
    Symbol       *current_function;
    uint32_t      current_nesting_level;

    /* Generic instance context for type substitution */
    Symbol       *current_instance;

    /* Loop/exit context */
    uint32_t      loop_exit_label;
    uint32_t      loop_continue_label;

    /* Function exit tracking */
    bool          has_return;
    bool          block_terminated;  /* True if current block has a terminator (ret/br) */

    /* Module header tracking for multi-unit files */
    bool          header_emitted;
    Symbol       *main_candidate;  /* Last parameterless library-level procedure */

    /* Deferred nested subprogram bodies */
    Syntax_Node  *deferred_bodies[64];
    uint32_t      deferred_count;

    /* Static link support for nested functions */
    Symbol       *enclosing_function;    /* Function containing current nested function */
    bool          is_nested;              /* True if current function is nested */

    /* Exception handling support */
    uint32_t      exception_handler_label;  /* Label of current exception handler */
    uint32_t      exception_jmp_buf;        /* Current setjmp buffer temp */
    bool          in_exception_region;      /* True if inside exception-handled block */

    /* String constant buffer (emitted at module level) */
    char         *string_const_buffer;
    size_t        string_const_size;
    size_t        string_const_capacity;

    /* Address markers needed for 'ADDRESS on packages/generics */
    Symbol       *address_markers[256];
    uint32_t      address_marker_count;

    /* Track emitted function unique_ids to prevent duplicate definitions */
    uint32_t      emitted_func_ids[1024];
    uint32_t      emitted_func_count;

    /* Task body context: task entry points return ptr (for pthread compat) */
    bool          in_task_body;

    /* Package elaboration functions to call before main (for task starts etc.) */
    Symbol       *elab_funcs[64];
    uint32_t      elab_func_count;

    /* Temp register type tracking: maps temp_id to actual LLVM type string.
     * Used to resolve divergence between Expression_Llvm_Type (Ada type) and
     * actual generated type (from 'VAL, 'POS, arithmetic, etc.).
     * Ring buffer: index = temp_id % capacity. */
    #define TEMP_TYPE_CAPACITY 4096
    uint32_t      temp_type_keys[TEMP_TYPE_CAPACITY];
    const char   *temp_types[TEMP_TYPE_CAPACITY];

    /* Track all exception global names referenced during codegen.
     * Stored as heap-allocated strings like "seq_io__status_error_s0".
     * Used by Generate_Exception_Globals to emit definitions for all. */
    #define EXC_REF_CAPACITY 512
    char         *exc_refs[EXC_REF_CAPACITY];
    uint32_t      exc_ref_count;
    bool          needs_trim_helpers;

    /* Counter for assigning unique runtime type elaboration IDs */
    uint32_t      rt_type_counter;
} Code_Generator;

static Code_Generator *Code_Generator_New(FILE *output, Symbol_Manager *sm) {
    Code_Generator *cg = Arena_Allocate(sizeof(Code_Generator));
    cg->output = output;
    cg->sm = sm;
    cg->temp_id = 1;
    cg->label_id = 1;
    cg->global_id = 1;
    cg->string_id = 1;
    cg->deferred_count = 0;
    /* Initialize string constant buffer */
    cg->string_const_capacity = 4096;
    cg->string_const_buffer = Arena_Allocate(cg->string_const_capacity);
    cg->string_const_size = 0;
    return cg;
}

/* Record the actual LLVM type for a generated temp register */
static inline void Temp_Set_Type(Code_Generator *cg, uint32_t temp_id, const char *ty) {
    uint32_t idx = temp_id % TEMP_TYPE_CAPACITY;
    cg->temp_type_keys[idx] = temp_id;
    cg->temp_types[idx] = ty;
}

/* Get the actual LLVM type for a temp register (returns NULL if unknown).
 * Verifies that the stored key matches to avoid hash collisions. */
static inline const char *Temp_Get_Type(Code_Generator *cg, uint32_t temp_id) {
    uint32_t idx = temp_id % TEMP_TYPE_CAPACITY;
    if (cg->temp_type_keys[idx] == temp_id)
        return cg->temp_types[idx];
    return NULL;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §13.1.1 Type-Derived Codegen Helpers
 *
 * GNAT LLVM never hardcodes type widths — it derives them from the front-end
 * type system (see GL_Type, Bound_Sub_GT).  These helpers do the same: they
 * query cg->sm to derive LLVM IR types from the Ada type system at the point
 * of emission, so every codegen site gets its types from a single source.
 * ───────────────────────────────────────────────────────────────────────── */

/* Derive the LLVM bound type for STRING from the type system.
 * Follows: STRING > index_type (POSITIVE) > Type_To_Llvm > Llvm_Int_Type.
 * This is GNAT LLVM's Bound_Sub_GT path. */
static inline const char *String_Bound_Type(const Code_Generator *cg) {
    return Array_Bound_Llvm_Type(cg->sm->type_string);
}

/* Derive the LLVM bounds struct type for STRING: "{ bt, bt }". */
static inline const char *String_Bounds_Struct(const Code_Generator *cg) {
    return Bounds_Type_For(String_Bound_Type(cg));
}

/* Derive the LLVM allocation size for STRING bounds struct. */
static inline int String_Bounds_Alloc(const Code_Generator *cg) {
    return Bounds_Alloc_Size(String_Bound_Type(cg));
}

/* Derive the LLVM type for Standard.INTEGER (the universal arithmetic type).
 * In GNAT LLVM, integer computation uses the GL_Type of Standard.Integer.
 * This replaces hardcoded "i64" in expression evaluation paths. */
static inline const char *Integer_Arith_Type(const Code_Generator *cg) {
    return Type_To_Llvm(cg->sm->type_integer);
}

/* Emit to string constant buffer instead of main output */
static void Emit_String_Const(Code_Generator *cg, const char *format, ...) {
    va_list args;
    va_start(args, format);
    char temp[1024];
    int len = vsnprintf(temp, sizeof(temp), format, args);
    va_end(args);
    if (len < 0) return;  /* Format error */
    size_t slen = (size_t)len;

    /* Expand buffer if needed */
    while (cg->string_const_size + slen + 1 > cg->string_const_capacity) {
        size_t new_cap = cg->string_const_capacity * 2;
        char *new_buf = Arena_Allocate(new_cap);
        memcpy(new_buf, cg->string_const_buffer, cg->string_const_size);
        cg->string_const_buffer = new_buf;
        cg->string_const_capacity = new_cap;
    }
    memcpy(cg->string_const_buffer + cg->string_const_size, temp, slen);
    cg->string_const_size += slen;
    cg->string_const_buffer[cg->string_const_size] = '\0';
}

/* Emit a single char to string constant buffer */
static void Emit_String_Const_Char(Code_Generator *cg, char c) {
    if (cg->string_const_size + 2 > cg->string_const_capacity) {
        size_t new_cap = cg->string_const_capacity * 2;
        char *new_buf = Arena_Allocate(new_cap);
        memcpy(new_buf, cg->string_const_buffer, cg->string_const_size);
        cg->string_const_buffer = new_buf;
        cg->string_const_capacity = new_cap;
    }
    cg->string_const_buffer[cg->string_const_size++] = c;
    cg->string_const_buffer[cg->string_const_size] = '\0';
}

/* ─────────────────────────────────────────────────────────────────────────
 * §13.2 IR Emission Helpers
 * ───────────────────────────────────────────────────────────────────────── */

static uint32_t Emit_Temp(Code_Generator *cg) {
    return cg->temp_id++;
}

static uint32_t Emit_Label(Code_Generator *cg) {
    return cg->label_id++;
}

static void Emit(Code_Generator *cg, const char *format, ...) {
    va_list args;
    va_start(args, format);
    vfprintf(cg->output, format, args);
    va_end(args);
}

/* Emit a source location comment for debugging: ; [filename:line:col] */
static void Emit_Location(Code_Generator *cg, Source_Location loc) {
    if (loc.line > 0) {
        const char *fname = loc.filename ? loc.filename : "?";
        /* Extract just the basename for brevity */
        const char *base = fname;
        for (const char *p = fname; *p; p++) {
            if (*p == '/' or *p == '\\') base = p + 1;
        }
        Emit(cg, "  ; [%s:%u:%u]\n", base, loc.line, loc.column);
    }
}

/* Emit a label, inserting a fallthrough branch if the prior block is open */
static void Emit_Label_Here(Code_Generator *cg, uint32_t label) {
    if (not cg->block_terminated) {
        Emit(cg, "  br label %%L%u\n", label);
    }
    Emit(cg, "L%u:\n", label);
    cg->block_terminated = false;
}

/* Emit a branch only if block is not already terminated */
static void Emit_Branch_If_Needed(Code_Generator *cg, uint32_t label) {
    if (not cg->block_terminated) {
        Emit(cg, "  br label %%L%u\n", label);
        cg->block_terminated = true;
    }
}

/* Emit a floating-point constant at the correct precision for the given
 * LLVM float type.  For "float" emits bitcast i32; for "double" emits
 * fadd double 0.0, 0x<hex>.  Replaces scattered hardcoded "fadd double" emissions. */
static void Emit_Float_Constant(Code_Generator *cg, uint32_t t,
                                 const char *fty, double value, const char *comment) {
    if (strcmp(fty, "float") == 0) {
        /* LLVM represents float hex as double-precision hex.
         * Convert to float, then back to double to get exact representation. */
        float fv = (float)value;
        double dv = (double)fv;
        uint64_t bits;
        memcpy(&bits, &dv, sizeof(bits));
        Emit(cg, "  %%t%u = fadd float 0.0, 0x%016llX  ; %s\n",
             t, (unsigned long long)bits, comment);
    } else {
        uint64_t bits;
        memcpy(&bits, &value, sizeof(bits));
        Emit(cg, "  %%t%u = fadd double 0.0, 0x%016llX  ; %s\n",
             t, (unsigned long long)bits, comment);
    }
}

/* Check if symbol is package-level (global storage with @ prefix in LLVM).
 * A symbol is global only if it's at package level AND no ancestor is a subprogram.
 * This handles nested packages inside subprogram bodies correctly. */
static inline bool Symbol_Is_Global(Symbol *sym) {
    if (not sym->parent) return true;  /* Top-level */
    /* Walk up parent chain - if any ancestor is a subprogram, symbol is local.
     * Also check for SYMBOL_GENERIC whose generic_unit is a subprogram spec
     * (not a package spec) — symbols inside generic subprogram bodies must be
     * treated as local when instantiated.  Generic package variables remain
     * global because they're allocated as package-level storage. */
    Symbol *p = sym->parent;
    while (p) {
        if (p->kind == SYMBOL_FUNCTION or p->kind == SYMBOL_PROCEDURE) {
            return false;  /* Inside a subprogram - use local (%) prefix */
        }
        if (p->kind == SYMBOL_GENERIC and p->generic_unit and
            p->generic_unit->kind != NK_PACKAGE_SPEC) {
            return false;  /* Inside a generic subprogram - local */
        }
        p = p->parent;
    }
    return true;  /* No subprogram ancestor - use global (@) prefix */
}

/* ─────────────────────────────────────────────────────────────────────────
 * Symbol_Mangle_Name — Unified LLVM-compatible name mangling
 *
 * Produces consistent mangled names for:
 *   1. Code generation (LLVM IR identifiers)
 *   2. ALI files (linkage names)
 *   3. Cross-compilation linking
 *
 * Format: parent__name[_SN] (all lowercase, special chars as _XX)
 *
 * This is the SINGLE SOURCE OF TRUTH for name mangling.
 * ───────────────────────────────────────────────────────────────────────── */

/* Internal recursive helper */
/* Mangle a name slice into buf at pos: lowercase, escape non-alphanum as _XX.
 * GNAT convention: operator symbols become _op_, special chars become _HH. */
static size_t Mangle_Slice_Into(char *buf, size_t pos, size_t max, String_Slice name) {
    for (uint32_t i = 0; i < name.length and pos < max - 4; i++) {
        char c = name.data[i];
        if (c >= 'A' and c <= 'Z') c = c - 'A' + 'a';
        if ((c >= 'a' and c <= 'z') or (c >= '0' and c <= '9') or c == '_') {
            buf[pos++] = c;
        } else if (c == '"') {
            if (pos + 4 < max) { buf[pos++] = '_'; buf[pos++] = 'o'; buf[pos++] = 'p'; buf[pos++] = '_'; }
        } else {
            if (pos + 3 < max) {
                buf[pos++] = '_';
                buf[pos++] = "0123456789abcdef"[(c >> 4) & 0xF];
                buf[pos++] = "0123456789abcdef"[c & 0xF];
            }
        }
    }
    return pos;
}

static size_t Mangle_Into_Buffer(char *buf, size_t pos, size_t max, Symbol *sym) {
    if (not sym) return pos;
    if (sym->parent and sym->parent->kind == SYMBOL_PACKAGE) {
        pos = Mangle_Into_Buffer(buf, pos, max, sym->parent);
        if (pos + 2 < max) { buf[pos++] = '_'; buf[pos++] = '_'; }
    }
    return Mangle_Slice_Into(buf, pos, max, sym->name);
}

/* Get mangled name for a symbol (thread-safe via rotation) */
static String_Slice Symbol_Mangle_Name(Symbol *sym) {
    static char bufs[4][512];
    static int buf_idx = 0;

    char *buf = bufs[buf_idx++ & 3];
    size_t pos = 0;

    /* Build mangled name from parent chain */
    pos = Mangle_Into_Buffer(buf, 0, 510, sym);

    /* Add unique_id suffix for local/overloaded symbols */
    if (sym and (not Symbol_Is_Global(sym) or sym->is_overloaded)) {
        pos += snprintf(buf + pos, 512 - pos, "_s%u", sym->unique_id);
    }

    buf[pos] = '\0';
    return (String_Slice){buf, pos};
}

/* Get mangled name for parent+name pair (for ALI generation before symbols exist).
 * Reuses Mangle_Slice_Into for consistent GNAT-style mangling. */
static String_Slice Mangle_Qualified_Name(String_Slice parent, String_Slice name) {
    static char bufs[4][512];
    static int buf_idx = 0;
    char *buf = bufs[buf_idx++ & 3];
    size_t pos = Mangle_Slice_Into(buf, 0, 510, parent);
    if (parent.length > 0) { buf[pos++] = '_'; buf[pos++] = '_'; }
    pos = Mangle_Slice_Into(buf, pos, 510, name);
    buf[pos] = '\0';
    return Slice_Duplicate((String_Slice){buf, pos});
}

/* Find the instance counterpart for a template symbol in the current function's
 * scope.  When generating a generic instance body, the AST references template
 * symbols (simple names, frame_offset 0) but the function scope contains the
 * properly-scoped instance symbols (qualified names, correct frame_offset).
 * Returns NULL if no match is found. */
static Symbol *Find_Instance_Local(const Code_Generator *cg, const Symbol *template_sym) {
    if (not cg->current_instance or not cg->current_function or
        not cg->current_function->scope)
        return NULL;
    /* Determine which instance (package) to match against */
    Symbol *inst = cg->current_instance;
    if ((inst->kind == SYMBOL_FUNCTION or inst->kind == SYMBOL_PROCEDURE) and
        inst->parent and inst->parent->kind == SYMBOL_PACKAGE and
        inst->parent->generic_template) {
        inst = inst->parent;
    }
    Scope *scope = cg->current_function->scope;
    for (uint32_t i = 0; i < scope->symbol_count; i++) {
        Symbol *s = scope->symbols[i];
        if (not s or s->kind != template_sym->kind) continue;
        if (s->name.length != template_sym->name.length) continue;
        if (s->parent != inst) continue;
        bool match = true;
        for (uint32_t j = 0; j < s->name.length; j++) {
            char a = s->name.data[j], b = template_sym->name.data[j];
            if (a >= 'A' and a <= 'Z') a = a - 'A' + 'a';
            if (b >= 'A' and b <= 'Z') b = b - 'A' + 'a';
            if (a != b) { match = false; break; }
        }
        if (match) return s;
    }
    /* Also check frame_vars (for symbols from child scopes) */
    for (uint32_t i = 0; i < scope->frame_var_count; i++) {
        Symbol *s = scope->frame_vars[i];
        if (not s or s->kind != template_sym->kind) continue;
        if (s->name.length != template_sym->name.length) continue;
        if (s->parent != inst) continue;
        bool match = true;
        for (uint32_t j = 0; j < s->name.length; j++) {
            char a = s->name.data[j], b = template_sym->name.data[j];
            if (a >= 'A' and a <= 'Z') a = a - 'A' + 'a';
            if (b >= 'A' and b <= 'Z') b = b - 'A' + 'a';
            if (a != b) { match = false; break; }
        }
        if (match) return s;
    }
    return NULL;
}

/* Emit symbol name for LLVM identifier (uses unified Symbol_Mangle_Name) */
static void Emit_Symbol_Name(Code_Generator *cg, Symbol *sym) {
    if (not sym) {
        Emit(cg, "unknown");
        return;
    }

    /* For imported symbols with external name, use that directly */
    if (sym->is_imported and sym->external_name.length > 0) {
        String_Slice name = sym->external_name;
        /* Strip quotes if present (from pragma Import) */
        if (name.length >= 2 and name.data[0] == '"' and name.data[name.length-1] == '"') {
            name.data++;
            name.length -= 2;
        }
        for (uint32_t i = 0; i < name.length; i++) {
            fputc(name.data[i], cg->output);
        }
        return;
    }

    /* For generic instance code generation: prefix global OBJECT symbols
     * (variables) from the template body with the instance name to avoid
     * collisions when multiple instances of the same generic are created.
     * Do NOT prefix exceptions, types, or subprograms. */
    if (cg->current_instance and sym->kind == SYMBOL_VARIABLE and Symbol_Is_Global(sym)) {
        /* Find the package instance - current_instance might be a procedure
         * within a package, in which case use the procedure's parent package */
        Symbol *inst = cg->current_instance;
        if ((inst->kind == SYMBOL_FUNCTION or inst->kind == SYMBOL_PROCEDURE) and
            inst->parent and inst->parent->kind == SYMBOL_PACKAGE and
            inst->parent->generic_template) {
            inst = inst->parent;  /* Use owning package instance for globals */
        }
        Symbol *tmpl = inst->generic_template;
        if (tmpl and sym->parent and sym->parent != inst and
            (sym->parent == tmpl or sym->parent->kind == SYMBOL_GENERIC)) {
            /* Emit instance name prefix */
            String_Slice inst_mangled = Symbol_Mangle_Name(inst);
            for (uint32_t i = 0; i < inst_mangled.length; i++) {
                fputc(inst_mangled.data[i], cg->output);
            }
            Emit(cg, "__");
            /* Emit just the symbol name (not parent chain) */
            for (uint32_t i = 0; i < sym->name.length; i++) {
                char c = sym->name.data[i];
                if (c >= 'A' and c <= 'Z') c = c - 'A' + 'a';
                fputc(c, cg->output);
            }
            return;
        }
    }

    /* For generic instance bodies: local variables/constants from the template
     * need instance-qualified names to avoid collisions between instances.
     * Find the instance counterpart in the function scope and use its name. */
    if (cg->current_instance and
        (sym->kind == SYMBOL_VARIABLE or sym->kind == SYMBOL_CONSTANT or
         sym->kind == SYMBOL_PARAMETER) and
        not sym->is_named_number) {
        Symbol *inst_sym = Find_Instance_Local(cg, sym);
        if (inst_sym) {
            String_Slice mangled = Symbol_Mangle_Name(inst_sym);
            for (uint32_t i = 0; i < mangled.length; i++) {
                fputc(mangled.data[i], cg->output);
            }
            return;
        }
    }

    /* Use unified mangling (lowercase, parent__name format, _sN suffix) */
    String_Slice mangled = Symbol_Mangle_Name(sym);
    for (uint32_t i = 0; i < mangled.length; i++) {
        fputc(mangled.data[i], cg->output);
    }
}

/* Emit symbol reference with appropriate prefix (@ for global, % for local) */
static void Emit_Symbol_Ref(Code_Generator *cg, Symbol *sym) {
    Emit(cg, Symbol_Is_Global(sym) ? "@" : "%%");
    Emit_Symbol_Name(cg, sym);
}

/* Emit @__exc.<name> reference for an exception symbol and track the name
 * so Generate_Exception_Globals can emit matching definitions. */
static void Emit_Exception_Ref(Code_Generator *cg, Symbol *exc) {
    /* Capture the exception name by temporarily redirecting output */
    FILE *real_out = cg->output;
    char buf[256];
    FILE *mem = fmemopen(buf, sizeof(buf) - 1, "w");
    cg->output = mem;
    Emit_Symbol_Name(cg, exc);
    fflush(mem);
    long len = ftell(mem);
    fclose(mem);
    buf[len] = '\0';
    cg->output = real_out;

    /* Emit the reference */
    Emit(cg, "@__exc.%s", buf);

    /* Record the name if not already tracked */
    for (uint32_t i = 0; i < cg->exc_ref_count; i++) {
        if (strcmp(cg->exc_refs[i], buf) == 0) return;
    }
    if (cg->exc_ref_count < EXC_REF_CAPACITY) {
        cg->exc_refs[cg->exc_ref_count] = strdup(buf);
        cg->exc_ref_count++;
    }
}

/* ─────────────────────────────────────────────────────────────────────────
 * §13.0.1 Codegen Predicates — Eliminate Duplicated Inline Checks
 * ───────────────────────────────────────────────────────────────────────── */

/* Find the nearest enclosing function/procedure by walking up the parent chain.
 * This handles nested packages: a procedure inside a package inside a procedure
 * needs access to the outermost procedure's frame.
 * Returns NULL if no enclosing function/procedure found. */
static Symbol *Find_Enclosing_Subprogram(Symbol *sym) {
    Symbol *p = sym ? sym->parent : NULL;
    while (p) {
        if (p->kind == SYMBOL_FUNCTION || p->kind == SYMBOL_PROCEDURE)
            return p;
        p = p->parent;
    }
    return NULL;
}

/* Check if a subprogram needs static chain (is nested transitively inside
 * another function/procedure). This handles package subprograms:
 *   procedure Outer is
 *     package P is
 *       procedure Inner;  -- Inner needs access to Outer's frame
 *     end P;
 *   ...
 */
static bool Subprogram_Needs_Static_Chain(Symbol *sym) {
    return Find_Enclosing_Subprogram(sym) != NULL;
}

/* Is sym an uplevel reference requiring access through __parent_frame?
 * This 4-line pattern previously appeared 10+ times throughout codegen. */
static inline bool Is_Uplevel_Access(const Code_Generator *cg, const Symbol *sym) {
    if (not cg->current_function or not sym) return false;
    Symbol *owner = sym->defining_scope ? sym->defining_scope->owner : NULL;
    return cg->is_nested and owner and
           owner != cg->current_function and
           owner != cg->current_function->generic_template;
}

/* Emit the storage location for a symbol, automatically handling uplevel
 * access through __frame.  This replaces 20+ manual Is_Uplevel_Access checks.
 * Emits either "%__frame.<name>" (uplevel) or the normal "%<name>"/"@<name>". */
static void Emit_Symbol_Storage(Code_Generator *cg, Symbol *sym) {
    if (Is_Uplevel_Access(cg, sym)) {
        Emit(cg, "%%__frame.");
        Emit_Symbol_Name(cg, sym);
    } else {
        Emit_Symbol_Ref(cg, sym);
    }
}

/* RM 8.3 Static Chain for Deeply Nested Calls — two-phase design.
 *
 * Phase 1 (Precompute_Nested_Frame_Arg): call BEFORE building the call
 *   instruction.  For depth ≥ 2 it emits GEP/load instructions to chase the
 *   static chain and returns the temp holding the ancestor frame pointer.
 *   For depth 0-1 it returns 0 (no precomputation needed).
 *
 * Phase 2 (Emit_Nested_Frame_Arg): call INSIDE the call instruction's
 *   argument list.  Emits "ptr %__frame_base", "ptr %__parent_frame", or
 *   "ptr %tN" depending on depth.
 *
 * Each intermediate frame stores its received __parent_frame at byte
 * offset scope->frame_size (see Generate_Subprogram_Body prologue). */

static int Nested_Frame_Depth(Code_Generator *cg, Symbol *proc) {
    /* Find the actual enclosing subprogram (skips packages) */
    Symbol *target = Find_Enclosing_Subprogram(proc);
    if (!target) return 0;
    int depth = 0;
    for (Symbol *w = cg->current_function; w; w = Find_Enclosing_Subprogram(w)) {
        if (w == target) return depth;
        depth++;
    }
    return depth;  /* shouldn't happen in valid code */
}

static uint32_t Precompute_Nested_Frame_Arg(Code_Generator *cg, Symbol *proc) {
    int depth = Nested_Frame_Depth(cg, proc);
    if (depth < 2) return 0;  /* no precomputation needed */
    Symbol *level = cg->current_function->parent;
    uint32_t prev = 0;
    for (int i = 1; i < depth; i++) {
        int64_t off = (level && level->scope) ? level->scope->frame_size : 0;
        uint32_t gep = Emit_Temp(cg);
        if (prev)
            Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %lld\n",
                 gep, prev, (long long)off);
        else
            Emit(cg, "  %%t%u = getelementptr i8, ptr %%__parent_frame, i64 %lld\n",
                 gep, (long long)off);
        prev = Emit_Temp(cg);
        Emit(cg, "  %%t%u = load ptr, ptr %%t%u\n", prev, gep);
        level = level->parent;
    }
    return prev;
}

static bool Emit_Nested_Frame_Arg(Code_Generator *cg, Symbol *proc, uint32_t precomp) {
    if (!cg->current_function || !proc->parent) return false;
    int depth = Nested_Frame_Depth(cg, proc);
    if (depth == 0)      Emit(cg, "ptr %%__frame_base");
    else if (depth == 1) Emit(cg, "ptr %%__parent_frame");
    else                 Emit(cg, "ptr %%t%u", precomp);
    return true;
}

/* Resolve generic formal type > actual type within an instance.
 * Called from attribute codegen, SUCC/PRED, and elsewhere.
 * Returns the substituted type, or the original if no match. */
static Type_Info *Resolve_Generic_Actual_Type(const Code_Generator *cg, Type_Info *type) {
    if (not type or not type->name.data) return type;
    Symbol *holder = cg->current_instance;
    /* Walk up: subprogram inside generic package uses package's actuals */
    if (holder and not holder->generic_actuals and holder->parent and
        holder->parent->kind == SYMBOL_PACKAGE and holder->parent->generic_actuals)
        holder = holder->parent;
    if (not holder or not holder->generic_actuals) return type;
    for (uint32_t i = 0; i < holder->generic_actual_count; i++)
        if (holder->generic_actuals[i].actual_type and
            Slice_Equal_Ignore_Case(type->name, holder->generic_actuals[i].formal_name))
            return holder->generic_actuals[i].actual_type;
    return type;
}

/* Emit raise sequence for a named exception: ptrtoint + call __ada_raise + unreachable. */
static void Emit_Raise_Exception(Code_Generator *cg, const char *exc_name, const char *comment) {
    uint32_t exc = Emit_Temp(cg);
    Emit(cg, "  %%t%u = ptrtoint ptr @__exc.%s to i64\n", exc, exc_name);
    Emit(cg, "  call void @__ada_raise(i64 %%t%u)  ; %s\n", exc, comment);
    Emit(cg, "  unreachable\n");
    cg->block_terminated = true;  /* unreachable terminates block */
}
#define Emit_Raise_Constraint_Error(cg, comment) Emit_Raise_Exception(cg, "constraint_error", comment)
#define Emit_Raise_Program_Error(cg, comment)    Emit_Raise_Exception(cg, "program_error", comment)

/* ─────────────────────────────────────────────────────────────────────────
 * §13.1.1a Granular Runtime Check Emission
 *
 * Each Emit_*_Check function:
 *   1. Consults Check_Is_Suppressed() — returns early if suppressed.
 *   2. Emits the check logic (comparison + conditional branch).
 *   3. On failure, branches to a block that calls Emit_Raise_Constraint_Error.
 *   4. On success, falls through to a continuation block.
 *
 * LLVM IR pattern for every check:
 *   %cmp = icmp <pred> <type> %val, <bound>
 *   br i1 %cmp, label %raise, label %cont
 *   raise:
 *     <raise constraint_error>
 *   cont:
 *     ; continue execution
 * ───────────────────────────────────────────────────────────────────────── */

/* Forward declaration for Emit_Check_With_Raise (defined in §13.2.4) */
static void Emit_Check_With_Raise(Code_Generator *cg, uint32_t cond,
                                   bool raise_on_true, const char *comment);

/* Emit_Overflow_Checked_Op — signed integer overflow check via LLVM intrinsics.
 * Uses llvm.sadd/ssub/smul.with.overflow.iN for signed types.
 * Modular (unsigned) types are exempt — they wrap (RM 3.5.4).
 * Returns the temp ID holding the checked result. */
static uint32_t Emit_Overflow_Checked_Op(
    Code_Generator *cg,
    uint32_t left, uint32_t right,
    const char *op,          /* "add", "sub", "mul" */
    const char *llvm_type,   /* "i8", "i16", "i32", "i64", "i128" */
    Type_Info *result_type)
{
    bool is_unsigned = Type_Is_Unsigned(result_type);
    bool suppressed = Check_Is_Suppressed(result_type, NULL, CHK_OVERFLOW);

    if (is_unsigned || suppressed) {
        /* Plain operation (wraps for modular, or check suppressed) */
        uint32_t t = Emit_Temp(cg);
        Emit(cg, "  %%t%u = %s %s %%t%u, %%t%u\n", t, op, llvm_type, left, right);
        Temp_Set_Type(cg, t, llvm_type);
        /* Modular non-power-of-2: caller handles urem wrapping */
        return t;
    }

    /* Signed overflow check via LLVM intrinsic */
    const char *intrinsic_op;
    if      (strcmp(op, "add") == 0) intrinsic_op = "sadd";
    else if (strcmp(op, "sub") == 0) intrinsic_op = "ssub";
    else if (strcmp(op, "mul") == 0) intrinsic_op = "smul";
    else {
        /* No intrinsic for div/rem — fall back to plain */
        uint32_t t = Emit_Temp(cg);
        Emit(cg, "  %%t%u = %s %s %%t%u, %%t%u\n", t, op, llvm_type, left, right);
        Temp_Set_Type(cg, t, llvm_type);
        return t;
    }

    /* Emit: %pair = call {iN, i1} @llvm.sOP.with.overflow.iN(iN %left, iN %right) */
    uint32_t pair = Emit_Temp(cg);
    Emit(cg, "  %%t%u = call {%s, i1} @llvm.%s.with.overflow.%s(%s %%t%u, %s %%t%u)\n",
         pair, llvm_type, intrinsic_op, llvm_type, llvm_type, left, llvm_type, right);

    /* Extract result and overflow flag */
    uint32_t result = Emit_Temp(cg);
    Emit(cg, "  %%t%u = extractvalue {%s, i1} %%t%u, 0\n", result, llvm_type, pair);
    Temp_Set_Type(cg, result, llvm_type);
    uint32_t ovf = Emit_Temp(cg);
    Emit(cg, "  %%t%u = extractvalue {%s, i1} %%t%u, 1\n", ovf, llvm_type, pair);

    /* Branch on overflow */
    Emit_Check_With_Raise(cg, ovf, true, "arithmetic overflow");

    return result;
}

/* Emit_Division_Check — division by zero check (RM 4.5.5).
 * Also checks for signed MIN_INT / -1 overflow on two's complement.
 * Emits before sdiv/udiv/srem/urem. */
static void Emit_Division_Check(Code_Generator *cg, uint32_t divisor,
                                 const char *llvm_type, Type_Info *type) {
    if (Check_Is_Suppressed(type, NULL, CHK_DIVISION)) return;

    /* Check divisor == 0 */
    uint32_t cmp = Emit_Temp(cg);
    Emit(cg, "  %%t%u = icmp eq %s %%t%u, 0\n", cmp, llvm_type, divisor);
    Emit_Check_With_Raise(cg, cmp, true, "division by zero");
}

/* Emit_Signed_Division_Overflow_Check — check for MIN_INT / -1.
 * Only for signed types: Integer'First / (-1) overflows on two's complement.
 * Emits after the division-by-zero check, before the actual sdiv. */
static void Emit_Signed_Division_Overflow_Check(Code_Generator *cg,
                                                  uint32_t dividend, uint32_t divisor,
                                                  const char *llvm_type, Type_Info *type) {
    if (Type_Is_Unsigned(type)) return;
    if (Check_Is_Suppressed(type, NULL, CHK_OVERFLOW)) return;

    /* Check: divisor == -1 AND dividend == type_min
     * type_min for iN is -(2^(N-1)) which is the LLVM representation of
     * the minimum signed value.  We use a two-step check. */
    int bits = 0;
    if (llvm_type[0] == 'i') bits = atoi(llvm_type + 1);
    if (bits == 0) return;

    /* Check divisor == -1 */
    uint32_t cmp_neg1 = Emit_Temp(cg);
    Emit(cg, "  %%t%u = icmp eq %s %%t%u, -1\n", cmp_neg1, llvm_type, divisor);

    /* Get type minimum: for iN, min = -(1 << (N-1)).
     * In LLVM, the min of i32 is -2147483648, i64 is -9223372036854775808.
     * We compute the min using shl + sign. */
    uint32_t min_val = Emit_Temp(cg);
    Emit(cg, "  %%t%u = shl %s 1, %d  ; type min magnitude\n", min_val, llvm_type, bits - 1);
    uint32_t neg_min = Emit_Temp(cg);
    Emit(cg, "  %%t%u = sub %s 0, %%t%u  ; negate to get actual min\n", neg_min, llvm_type, min_val);

    /* Check dividend == min */
    uint32_t cmp_min = Emit_Temp(cg);
    Emit(cg, "  %%t%u = icmp eq %s %%t%u, %%t%u\n", cmp_min, llvm_type, dividend, neg_min);

    /* Both conditions must be true for overflow */
    uint32_t both = Emit_Temp(cg);
    Emit(cg, "  %%t%u = and i1 %%t%u, %%t%u\n", both, cmp_neg1, cmp_min);

    Emit_Check_With_Raise(cg, both, true, "division overflow (MIN_INT / -1)");
}

static inline uint32_t Emit_Convert(Code_Generator *cg, uint32_t src,
    const char *src_type, const char *dst_type);
static inline uint32_t Emit_Coerce(Code_Generator *cg, uint32_t temp,
    const char *desired_type);
static inline uint32_t Emit_Coerce_Default_Int(Code_Generator *cg, uint32_t temp,
    const char *desired_type);

/* Emit_Index_Check — array index bounds check (RM 4.1.1).
 * Checks index against array low and high bounds.
 * Bounds are provided as temp IDs (may be static or dynamic). */
static uint32_t Emit_Index_Check(Code_Generator *cg, uint32_t index,
                                  uint32_t low_bound, uint32_t high_bound,
                                  const char *index_type, Type_Info *array_type) {
    if (Check_Is_Suppressed(array_type, NULL, CHK_INDEX)) return index;

    /* Ensure all operands match index_type */
    index = Emit_Coerce(cg, index, index_type);
    low_bound = Emit_Coerce(cg, low_bound, index_type);
    high_bound = Emit_Coerce(cg, high_bound, index_type);

    bool is_unsigned = Type_Is_Unsigned(array_type);
    const char *lt = is_unsigned ? "ult" : "slt";
    const char *gt = is_unsigned ? "ugt" : "sgt";

    /* index < low? */
    uint32_t cmp_lo = Emit_Temp(cg);
    Emit(cg, "  %%t%u = icmp %s %s %%t%u, %%t%u\n", cmp_lo, lt, index_type, index, low_bound);
    /* index > high? */
    uint32_t cmp_hi = Emit_Temp(cg);
    Emit(cg, "  %%t%u = icmp %s %s %%t%u, %%t%u\n", cmp_hi, gt, index_type, index, high_bound);
    uint32_t out_of_range = Emit_Temp(cg);
    Emit(cg, "  %%t%u = or i1 %%t%u, %%t%u\n", out_of_range, cmp_lo, cmp_hi);

    Emit_Check_With_Raise(cg, out_of_range, true, "index check failed");
    return index;
}

/* Emit_Length_Check — array length mismatch check (RM 4.5.2, 5.2.1).
 * Checks that source and destination arrays have matching lengths. */
static void Emit_Length_Check(Code_Generator *cg,
                               uint32_t src_length, uint32_t dst_length,
                               const char *len_type, Type_Info *array_type) {
    if (Check_Is_Suppressed(array_type, NULL, CHK_LENGTH)) return;

    /* Ensure both operands match len_type */
    src_length = Emit_Coerce(cg, src_length, len_type);
    dst_length = Emit_Coerce(cg, dst_length, len_type);

    uint32_t cmp = Emit_Temp(cg);
    Emit(cg, "  %%t%u = icmp ne %s %%t%u, %%t%u\n", cmp, len_type, src_length, dst_length);
    Emit_Check_With_Raise(cg, cmp, true, "length check failed");
}

/* Emit_Access_Check — null pointer dereference check (RM 4.1).
 * Emits before every .ALL dereference and implicit dereference. */
static void Emit_Access_Check(Code_Generator *cg, uint32_t ptr_val, Type_Info *acc_type) {
    if (Check_Is_Suppressed(acc_type, NULL, CHK_ACCESS)) return;

    /* If the value is a fat pointer { ptr, ptr }, extract the data pointer first */
    const char *actual_ty = Temp_Get_Type(cg, ptr_val);
    if (actual_ty and Llvm_Type_Is_Fat_Pointer(actual_ty)) {
        uint32_t data = Emit_Temp(cg);
        Emit(cg, "  %%t%u = extractvalue " FAT_PTR_TYPE " %%t%u, 0\n", data, ptr_val);
        ptr_val = data;
    }

    uint32_t cmp = Emit_Temp(cg);
    Emit(cg, "  %%t%u = icmp eq ptr %%t%u, null\n", cmp, ptr_val);
    Emit_Check_With_Raise(cg, cmp, true, "access check (null dereference)");
}

/* Emit_Discriminant_Check — variant record discriminant check (RM 3.7.1).
 * Verifies that a discriminant has the expected value before component access. */
static void Emit_Discriminant_Check(Code_Generator *cg,
                                      uint32_t actual, uint32_t expected,
                                      const char *disc_type, Type_Info *record_type) {
    if (Check_Is_Suppressed(record_type, NULL, CHK_DISCRIMINANT)) return;

    uint32_t cmp = Emit_Temp(cg);
    Emit(cg, "  %%t%u = icmp ne %s %%t%u, %%t%u\n", cmp, disc_type, actual, expected);
    Emit_Check_With_Raise(cg, cmp, true, "discriminant check failed");
}

/* Parse LLVM type width: "i64">64, "float">32, "double">64 */
static inline int Type_Bits(const char *ty) {
    if (ty[0] == 'i') return atoi(ty + 1);
    if (ty[0] == 'f') return 32;   /* float */
    if (ty[0] == 'd') return 64;   /* double */
    return 64;
}

/* Return the wider of two integer LLVM types.
 * Used for binary operations: both operands are widened to the wider type.
 * Example: Wider_Int_Type("i8", "i32") > "i32".
 * Both arguments MUST be integer types (i1, i8, i32, i64, etc.).
 * Non-integer types are a bug — use Integer_Arith_Type(cg) at call site. */
static inline const char *Wider_Int_Type(const Code_Generator *cg, const char *a, const char *b) {
    /* Non-integer types must not reach here; derive from INTEGER as error path */
    if (a[0] != 'i' or b[0] != 'i') {
        fprintf(stderr, "error: Wider_Int_Type called with non-integer type: \"%s\", \"%s\"\n", a, b);
        return Integer_Arith_Type(cg);
    }
    int ab = Type_Bits(a), bb = Type_Bits(b);
    return (ab >= bb) ? a : b;
}

/* Check if LLVM type is floating-point */
static inline bool Is_Float_Type(const char *ty) {
    return ty and (ty[0] == 'f' or ty[0] == 'd');
}

/* Return the LLVM fcmp predicate for a comparison operator.
 * Uses ordered predicates for relational ops, unordered for NE (IEEE NaN handling). */
static const char *Float_Cmp_Predicate(int op) {
    switch (op) {
        case TK_EQ: return "oeq";
        case TK_NE: return "une";
        case TK_LT: return "olt";
        case TK_LE: return "ole";
        case TK_GT: return "ogt";
        case TK_GE: return "oge";
        default:    return "oeq";
    }
}

/* Return the LLVM icmp predicate for a comparison operator.
 * Selects signed or unsigned predicate based on is_unsigned flag. */
static const char *Int_Cmp_Predicate(int op, bool is_unsigned) {
    switch (op) {
        case TK_EQ: return "eq";
        case TK_NE: return "ne";
        case TK_LT: return is_unsigned ? "ult" : "slt";
        case TK_LE: return is_unsigned ? "ule" : "sle";
        case TK_GT: return is_unsigned ? "ugt" : "sgt";
        case TK_GE: return is_unsigned ? "uge" : "sge";
        default:    return "eq";
    }
}

/* Check if expression produces boolean (i1) result directly.
 * Only comparisons and logical operators produce i1 - loaded variables
 * are widened to i64 even for BOOLEAN type. */
static inline bool Expression_Is_Boolean(Syntax_Node *node) {
    if (not node) return false;
    if (node->kind == NK_BINARY_OP) {
        switch (node->binary.op) {
            case TK_EQ: case TK_NE: case TK_LT: case TK_LE: case TK_GT: case TK_GE:
            case TK_AND: case TK_AND_THEN: case TK_OR: case TK_OR_ELSE: case TK_XOR:
            case TK_IN:   /* Membership test */
            case TK_NOT:  /* NOT IN (binary) is also a membership test */
                return true;
            default: break;
        }
    }
    if (node->kind == NK_UNARY_OP and node->unary.op == TK_NOT) {
        Type_Info *ty = node->unary.operand ? node->unary.operand->type : NULL;
        if (Type_Is_Boolean(ty)) return true;
    }
    /* Note: Boolean-valued attributes (CONSTRAINED, CALLABLE, TERMINATED) produce i8
     * (Boolean storage type), not i1.  Only comparisons/logical ops produce i1. */
    return false;
}

/* Check if expression produces float result */
static inline bool Expression_Is_Float(Syntax_Node *node) {
    if (not node) return false;
    /* Attributes that return floating-point (double) */
    if (node->kind == NK_ATTRIBUTE) {
        String_Slice attr = node->attribute.name;
        if (Slice_Equal_Ignore_Case(attr, S("EPSILON")) or
            Slice_Equal_Ignore_Case(attr, S("SMALL")) or
            Slice_Equal_Ignore_Case(attr, S("LARGE")) or
            Slice_Equal_Ignore_Case(attr, S("SAFE_SMALL")) or
            Slice_Equal_Ignore_Case(attr, S("SAFE_LARGE")) or
            Slice_Equal_Ignore_Case(attr, S("DELTA"))) {
            return true;
        }
        /* FIRST/LAST with float prefix type (not fixed-point) */
        if (Slice_Equal_Ignore_Case(attr, S("FIRST")) or
            Slice_Equal_Ignore_Case(attr, S("LAST"))) {
            Syntax_Node *prefix = node->attribute.prefix;
            if (prefix and prefix->type and
                not Type_Is_Fixed_Point(prefix->type) and
                (Type_Is_Float_Representation(prefix->type) or
                 prefix->type->low_bound.kind == BOUND_FLOAT)) {
                return true;
            }
        }
    }
    /* Check node type for general float expressions */
    return Type_Is_Float_Representation(node->type);
}

/* Get LLVM type string for expression result */
static inline const char *Expression_Llvm_Type(const Code_Generator *cg, Syntax_Node *node) {
    /* Boolean expressions (comparisons, logical ops) produce i1.
     * Widening to i8 (Boolean storage type) happens at store boundaries. */
    if (Expression_Is_Boolean(node)) {
        return "i1";
    }
    /* For float types, return the correct LLVM type based on actual size */
    if (node and Type_Is_Float_Representation(node->type)) {
        return Llvm_Float_Type((uint32_t)To_Bits(node->type->size));
    }
    /* Check for pointer/access types.
     * Access-to-unconstrained arrays use fat pointer { ptr, { bound, bound } }.
     * Access-to-constrained or scalar types use plain ptr.
     * Use Type_To_Llvm to get the correct representation. */
    if (node and Type_Is_Access(node->type))
        return Type_To_Llvm(node->type);
    if (node and node->kind == NK_ALLOCATOR and node->type)
        return Type_To_Llvm(node->type);
    if (node and node->kind == NK_NULL) return "ptr";
    /* Record types and aggregates return pointers (alloca addresses) */
    if (node and Type_Is_Record(node->type)) return "ptr";
    if (node and node->kind == NK_AGGREGATE and Type_Is_Record(node->type)) return "ptr";
    /* ALL array aggregates return ptr (alloca address), not fat pointers.
     * The aggregate creates stack storage and returns its address.
     * Fat pointers are only used when loading from unconstrained array variables. */
    if (node and node->kind == NK_AGGREGATE and node->type and
        (node->type->kind == TYPE_ARRAY or node->type->kind == TYPE_STRING)) return "ptr";
    /* Slices always produce fat pointers regardless of declared type.
     * Must check before array indexing since both are NK_APPLY. */
    if (node and Expression_Is_Slice(node)) {
        return FAT_PTR_TYPE;  /* Slices always produce fat pointers */
    }
    /* Array indexing (NK_APPLY) that returns non-i64 element types.
     * Now preserves native types for ALL element types, not just composites.
     * Must exclude function calls where prefix happens to have array-like return type. */
    if (node and node->kind == NK_APPLY and node->apply.prefix and
        node->apply.prefix->type and
        Type_Is_Array_Like(node->apply.prefix->type) and
        !(node->apply.prefix->symbol and
          (node->apply.prefix->symbol->kind == SYMBOL_FUNCTION or
           node->apply.prefix->symbol->kind == SYMBOL_PROCEDURE))) {
        Type_Info *elem_type = node->type;
        if (Type_Is_Record(elem_type) or Type_Is_String(elem_type) or
            Type_Is_Constrained_Array(elem_type)) {
            return "ptr";  /* Composite elements return ptr */
        }
        if (Type_Is_Access(elem_type)) {
            return "ptr";  /* Access elements loaded as ptr */
        }
        if (elem_type) return Type_To_Llvm(elem_type);
    }
    /* Check for string literals and unconstrained string types (fat pointers).
     * Constrained STRING subtypes (e.g., STRING(1..6)) are flat arrays > ptr. */
    if (node and node->kind == NK_STRING) return FAT_PTR_TYPE;
    if (node and Type_Is_String(node->type) and not Type_Is_Constrained_Array(node->type))
        return FAT_PTR_TYPE;
    /* Constrained arrays with dynamic bounds are stored as fat pointers */
    if (node and node->kind != NK_AGGREGATE and node->type and
        Type_Is_Constrained_Array(node->type) and Type_Has_Dynamic_Bounds(node->type))
        return FAT_PTR_TYPE;
    /* Identifiers stored as fat pointers (dynamic bounds at declaration time) */
    if (node and node->kind == NK_IDENTIFIER and node->symbol and
        node->symbol->needs_fat_ptr_storage)
        return FAT_PTR_TYPE;
    /* Check for unconstrained array types (fat pointers) - for variable references */
    if (node and node->kind != NK_AGGREGATE and
        Type_Is_Unconstrained_Array(node->type)) {
        return FAT_PTR_TYPE;
    }
    /* Binary integer arithmetic codegen produces result at
     * Wider_Int_Type(left, right), which may differ from Type_To_Llvm(node->type)
     * when the type resolver assigns a wider base type (e.g., INTEGER) to the
     * expression while operands are narrower (e.g., i8 for RANGE -10..10).
     * Must match Generate_Binary_Op's actual output type. */
    if (node and node->kind == NK_BINARY_OP and not Expression_Is_Boolean(node) and
        node->type and not Type_Is_Float_Representation(node->type) and
        not Type_Is_Fixed_Point(node->type)) {
        Token_Kind op = node->binary.op;
        if (op == TK_PLUS or op == TK_MINUS or op == TK_STAR or
            op == TK_SLASH or op == TK_MOD or op == TK_REM) {
            const char *lt = node->binary.left ?
                Expression_Llvm_Type(cg, node->binary.left) : Integer_Arith_Type(cg);
            const char *rt = node->binary.right ?
                Expression_Llvm_Type(cg, node->binary.right) : Integer_Arith_Type(cg);
            if (lt[0] == 'i' and rt[0] == 'i')
                return Wider_Int_Type(cg, lt, rt);
        }
    }
    /* Unary integer arithmetic codegen uses operand's native type. */
    if (node and node->kind == NK_UNARY_OP and
        node->type and not Type_Is_Float_Representation(node->type) and
        (node->unary.op == TK_MINUS or node->unary.op == TK_PLUS) and
        node->unary.operand) {
        return Expression_Llvm_Type(cg, node->unary.operand);
    }
    /* return the native LLVM type for the node's Ada type.
     * No widening to INTEGER — expressions stay at their natural width.
     * Only widen at explicit Ada type conversions and LLVM intrinsic boundaries.
     * Resolve generic formal types to their actuals so the predicted type
     * matches what codegen actually emits. */
    if (node and node->type) {
        Type_Info *resolved = node->type;
        if (cg->current_instance)
            resolved = Resolve_Generic_Actual_Type(cg, resolved);
        return Type_To_Llvm(resolved);
    }
    return Integer_Arith_Type(cg);
}

/* Emit type conversion if needed.
 * is_unsigned: when true, integer extensions use zext instead of sext,
 *              and float↔int conversions use unsigned variants (fptoui/uitofp).
 *              This is required for Ada modular (unsigned) types (RM 3.5.4). */
static uint32_t Emit_Convert_Ext(Code_Generator *cg, uint32_t src, const char *src_type,
                                 const char *dst_type, bool is_unsigned) {
    /* Check tracked actual type - Expression_Llvm_Type may disagree with
     * the actual generated type (e.g. after 'VAL, 'POS, arithmetic).
     * Use the tracked type if available to avoid invalid IR. */
    const char *actual = Temp_Get_Type(cg, src);
    if (actual and actual[0] != '\0' and strcmp(actual, src_type) != 0)
        src_type = actual;
    if (strcmp(src_type, dst_type) == 0) return src;

    bool src_is_float = Is_Float_Type(src_type);
    bool dst_is_float = Is_Float_Type(dst_type);
    int src_bits = Type_Bits(src_type), dst_bits = Type_Bits(dst_type);

    uint32_t t = Emit_Temp(cg);

    if (src_is_float and dst_is_float) {
        /* float ↔ double */
        if (dst_bits > src_bits) {
            Emit(cg, "  %%t%u = fpext %s %%t%u to %s\n", t, src_type, src, dst_type);
        } else {
            Emit(cg, "  %%t%u = fptrunc %s %%t%u to %s\n", t, src_type, src, dst_type);
        }
    } else if (src_is_float and not dst_is_float) {
        if (Llvm_Type_Is_Pointer(dst_type)) {
            /* float/double > ptr: fptosi to i64, then inttoptr */
            uint32_t i = Emit_Temp(cg);
            Emit(cg, "  %%t%u = fptosi %s %%t%u to i64\n", i, src_type, src);
            Emit(cg, "  %%t%u = inttoptr i64 %%t%u to ptr\n", t, i);
        } else {
            /* float/double > integer: round then fptosi (Ada RM 4.6) */
            uint32_t rounded = Emit_Temp(cg);
            Emit(cg, "  %%t%u = call %s @llvm.round.%s(%s %%t%u)\n",
                 rounded, src_type, src_type, src_type, src);
            Emit(cg, "  %%t%u = %s %s %%t%u to %s\n", t,
                 is_unsigned ? "fptoui" : "fptosi", src_type, rounded, dst_type);
        }
    } else if (not src_is_float and dst_is_float) {
        if (Llvm_Type_Is_Pointer(src_type)) {
            /* ptr > float/double: ptrtoint to i64, then sitofp */
            uint32_t i = Emit_Temp(cg);
            Emit(cg, "  %%t%u = ptrtoint ptr %%t%u to i64\n", i, src);
            Emit(cg, "  %%t%u = %s i64 %%t%u to %s\n", t,
                 is_unsigned ? "uitofp" : "sitofp", i, dst_type);
        } else {
            /* integer > float/double: sitofp for signed, uitofp for unsigned */
            Emit(cg, "  %%t%u = %s %s %%t%u to %s\n", t,
                 is_unsigned ? "uitofp" : "sitofp", src_type, src, dst_type);
        }
    } else if (Llvm_Type_Is_Pointer(src_type) and Llvm_Type_Is_Pointer(dst_type)) {
        /* ptr > ptr: no conversion needed */
        return src;
    } else if (Llvm_Type_Is_Pointer(src_type) and dst_type[0] == 'i') {
        /* ptr > integer: ptrtoint */
        Emit(cg, "  %%t%u = ptrtoint ptr %%t%u to %s\n", t, src, dst_type);
    } else if (src_type[0] == 'i' and Llvm_Type_Is_Pointer(dst_type)) {
        /* integer > ptr: inttoptr */
        Emit(cg, "  %%t%u = inttoptr %s %%t%u to ptr\n", t, src_type, src);
    } else if (Llvm_Type_Is_Fat_Pointer(src_type) and Llvm_Type_Is_Fat_Pointer(dst_type)) {
        /* fat pointer > fat pointer: no conversion needed */
        return src;
    } else if (Llvm_Type_Is_Fat_Pointer(src_type) and Llvm_Type_Is_Pointer(dst_type)) {
        /* fat pointer > ptr: extract data pointer (field 0).
         * Note: this loses bounds information, used when passing to constrained params
         * or assigning to access types */
        Emit(cg, "  %%t%u = extractvalue %s %%t%u, 0\n", t, src_type, src);
    } else if (Llvm_Type_Is_Pointer(src_type) and Llvm_Type_Is_Fat_Pointer(dst_type)) {
        /* ptr > fat pointer: pointer to unconstrained array storage, load it */
        Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", t, dst_type, src);
    } else if (Llvm_Type_Is_Fat_Pointer(src_type) and dst_type[0] == 'i') {
        /* fat pointer > integer: extract data pointer then ptrtoint */
        uint32_t data = Emit_Temp(cg);
        Emit(cg, "  %%t%u = extractvalue %s %%t%u, 0\n", data, src_type, src);
        Emit(cg, "  %%t%u = ptrtoint ptr %%t%u to %s\n", t, data, dst_type);
    } else if (src_type[0] == 'i' and Llvm_Type_Is_Fat_Pointer(dst_type)) {
        /* integer > fat pointer: likely an access value, inttoptr then load */
        uint32_t p = Emit_Temp(cg);
        Emit(cg, "  %%t%u = inttoptr %s %%t%u to ptr\n", p, src_type, src);
        Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", t, dst_type, p);
    } else if (Llvm_Type_Is_Fat_Pointer(src_type) or Llvm_Type_Is_Fat_Pointer(dst_type)) {
        /* One is fat pointer, other is something else - best effort */
        return src;
    } else {
        /* integer conversions */
        if (src_bits == dst_bits) return src;
        if (dst_bits > src_bits) {
            /* Use zext for boolean (i1) and unsigned/modular types,
             * sext for signed integer extensions */
            if (src_bits == 1 or is_unsigned) {
                Emit(cg, "  %%t%u = zext %s %%t%u to %s\n", t, src_type, src, dst_type);
            } else {
                Emit(cg, "  %%t%u = sext %s %%t%u to %s\n", t, src_type, src, dst_type);
            }
        } else if (dst_bits == 1) {
            /* Boolean: icmp ne 0 preserves semantics (any non-zero > true) */
            Emit(cg, "  %%t%u = icmp ne %s %%t%u, 0\n", t, src_type, src);
        } else {
            Emit(cg, "  %%t%u = trunc %s %%t%u to %s\n", t, src_type, src, dst_type);
        }
    }
    Temp_Set_Type(cg, t, dst_type);
    return t;
}

/* Signed (default) conversion — backward-compatible wrapper */
static inline uint32_t Emit_Convert(Code_Generator *cg, uint32_t src,
                                    const char *src_type, const char *dst_type) {
    return Emit_Convert_Ext(cg, src, src_type, dst_type, false);
}

/* Coerce a temp to the desired LLVM type, using Temp_Get_Type to discover
 * its current type.  If the type is already correct or unknown, returns the
 * temp unchanged.  This replaces scattered Temp_Get_Type/strcmp/Emit_Convert
 * boilerplate throughout the emitter. */
static inline uint32_t Emit_Coerce(Code_Generator *cg, uint32_t temp,
                                    const char *desired_type) {
    const char *cur = Temp_Get_Type(cg, temp);
    if (not cur or cur[0] == '\0') return temp;  /* Unknown type — no conversion */
    if (strcmp(cur, desired_type) == 0) return temp;
    return Emit_Convert(cg, temp, cur, desired_type);
}

/* Like Emit_Coerce, but assumes Integer_Arith_Type when the temp's type is
 * unknown.  Use only in contexts where untracked temps are known to be i32
 * (e.g. bound arithmetic). */
static inline uint32_t Emit_Coerce_Default_Int(Code_Generator *cg, uint32_t temp,
                                                const char *desired_type) {
    const char *cur = Temp_Get_Type(cg, temp);
    if (not cur or cur[0] == '\0') cur = Integer_Arith_Type(cg);
    if (strcmp(cur, desired_type) == 0) return temp;
    return Emit_Convert(cg, temp, cur, desired_type);
}

/* Forward declaration for use in bound evaluation */
static uint32_t Generate_Expression(Code_Generator *cg, Syntax_Node *node);

/* ─────────────────────────────────────────────────────────────────────────
 * §13.1.2 Constraint Checks
 *
 * Per RM 3.5.4: CONSTRAINT_ERROR raised when value falls outside subtype range.
 * Handles both static (BOUND_INTEGER) and dynamic (BOUND_EXPR) bounds.
 * Generates: if (val < low or val > high) __ada_raise(CONSTRAINT_ERROR)
 * ───────────────────────────────────────────────────────────────────────── */
static uint32_t Emit_Bound_Value_Typed(Code_Generator *cg, Type_Bound *bound,
                                       const char **out_type) {
    const char *iat = Integer_Arith_Type(cg);
    if (bound->kind == BOUND_INTEGER) {
        /* Use i64 if the value exceeds i32 range */
        const char *bt = iat;
        int128_t v = bound->int_value;
        if (v < (int128_t)INT32_MIN || v > (int128_t)INT32_MAX) bt = "i64";
        uint32_t t = Emit_Temp(cg);
        Emit(cg, "  %%t%u = add %s 0, %s  ; literal bound\n", t, bt, I128_Decimal(v));
        Temp_Set_Type(cg, t, bt);
        if (out_type) *out_type = bt;
        return t;
    } else if (bound->kind == BOUND_FLOAT) {
        int128_t ival = (int128_t)bound->float_value;
        const char *bt = iat;
        if (ival < (int128_t)INT32_MIN || ival > (int128_t)INT32_MAX) bt = "i64";
        uint32_t t = Emit_Temp(cg);
        Emit(cg, "  %%t%u = add %s 0, %s  ; float-to-int bound (%g)\n",
             t, bt, I128_Decimal(ival), bound->float_value);
        Temp_Set_Type(cg, t, bt);
        if (out_type) *out_type = bt;
        return t;
    } else if (bound->kind == BOUND_EXPR and bound->expr) {
        /* BOUND_EXPR: generate the expression and report its actual LLVM type.
         * Do NOT convert here — the caller will unify types. */
        uint32_t val = Generate_Expression(cg, bound->expr);
        if (out_type) *out_type = Expression_Llvm_Type(cg, bound->expr);
        return val;
    }
    if (out_type) *out_type = iat;
    return 0;  /* Cannot determine bound */
}

static uint32_t Emit_Bound_Value(Code_Generator *cg, Type_Bound *bound) {
    return Emit_Bound_Value_Typed(cg, bound, NULL);
}

/* RM 3.5: General scalar constraint check — dispatches to integer or
 * float path based on the target type's kind.  Covers:
 *   Integer, enumeration, character > icmp slt/sgt on native type (Integer_Arith_Type)
 *   Float, fixed, universal_real    > fcmp olt/ogt on double
 */
static uint32_t Emit_Constraint_Check_With_Type(Code_Generator *cg, uint32_t val,
                                       Type_Info *target, Type_Info *source,
                                       const char *actual_val_type) {
    if (not target) return val;

    /* Respect pragma Suppress(Range_Check) on the target type */
    if (Check_Is_Suppressed(target, NULL, CHK_RANGE)) return val;

    bool is_int_like = (target->kind == TYPE_INTEGER or
                        target->kind == TYPE_MODULAR or
                        target->kind == TYPE_ENUMERATION or
                        target->kind == TYPE_BOOLEAN or
                        target->kind == TYPE_CHARACTER or
                        target->kind == TYPE_FIXED);  /* scaled integer repr */
    bool is_flt_like = (target->kind == TYPE_FLOAT);

    if (not is_int_like and not is_flt_like) return val;

    /* Need either static or dynamic bounds */
    bool lo_ok = (target->low_bound.kind == BOUND_INTEGER or
                  target->low_bound.kind == BOUND_FLOAT or
                  target->low_bound.kind == BOUND_EXPR);
    bool hi_ok = (target->high_bound.kind == BOUND_INTEGER or
                  target->high_bound.kind == BOUND_FLOAT or
                  target->high_bound.kind == BOUND_EXPR);
    if (not lo_ok or not hi_ok) return val;

    uint32_t raise_label = cg->label_id++;
    uint32_t ok_label    = cg->label_id++;
    uint32_t cont_label  = cg->label_id++;

    if (is_flt_like) {
        /* Float/fixed path — compare at the target's native float type */
        const char *flt_type = Float_Llvm_Type_Of(target);
        /* Convert value to comparison type if needed.
         * Use actual_val_type when provided (value may already be converted). */
        const char *src_flt = actual_val_type ? actual_val_type :
                              (source ? Float_Llvm_Type_Of(source) : flt_type);
        if (strcmp(src_flt, flt_type) != 0) {
            val = Emit_Convert(cg, val, src_flt, flt_type);
        }
        uint32_t lo = 0, hi = 0;
        if (target->low_bound.kind == BOUND_FLOAT) {
            uint64_t bits; double v = target->low_bound.float_value;
            memcpy(&bits, &v, sizeof(bits));
            lo = Emit_Temp(cg);
            if (strcmp(flt_type, "float") == 0) {
                float fv = (float)v; uint32_t fb;
                memcpy(&fb, &fv, sizeof(fb));
                Emit(cg, "  %%t%u = bitcast i32 %u to float  ; low bound %g\n",
                     lo, fb, v);
            } else {
                Emit(cg, "  %%t%u = fadd double 0.0, 0x%016llX  ; low bound %g\n",
                     lo, (unsigned long long)bits, v);
            }
        } else if (target->low_bound.kind == BOUND_INTEGER) {
            lo = Emit_Temp(cg);
            Emit(cg, "  %%t%u = sitofp %s %s to %s  ; low bound\n",
                 lo, Integer_Arith_Type(cg), I128_Decimal(target->low_bound.int_value), flt_type);
        } else {
            lo = Generate_Expression(cg, target->low_bound.expr);
            const char *lo_expr_ty = Expression_Llvm_Type(cg, target->low_bound.expr);
            lo = Emit_Convert(cg, lo, lo_expr_ty, flt_type);
        }
        if (target->high_bound.kind == BOUND_FLOAT) {
            uint64_t bits; double v = target->high_bound.float_value;
            memcpy(&bits, &v, sizeof(bits));
            hi = Emit_Temp(cg);
            if (strcmp(flt_type, "float") == 0) {
                float fv = (float)v; uint32_t fb;
                memcpy(&fb, &fv, sizeof(fb));
                Emit(cg, "  %%t%u = bitcast i32 %u to float  ; high bound %g\n",
                     hi, fb, v);
            } else {
                Emit(cg, "  %%t%u = fadd double 0.0, 0x%016llX  ; high bound %g\n",
                     hi, (unsigned long long)bits, v);
            }
        } else if (target->high_bound.kind == BOUND_INTEGER) {
            hi = Emit_Temp(cg);
            Emit(cg, "  %%t%u = sitofp %s %s to %s  ; high bound\n",
                 hi, Integer_Arith_Type(cg), I128_Decimal(target->high_bound.int_value), flt_type);
        } else {
            hi = Generate_Expression(cg, target->high_bound.expr);
            const char *hi_expr_ty = Expression_Llvm_Type(cg, target->high_bound.expr);
            hi = Emit_Convert(cg, hi, hi_expr_ty, flt_type);
        }
        if (not lo or not hi) return val;

        /* val < low? */
        uint32_t cmp_lo = Emit_Temp(cg);
        Emit(cg, "  %%t%u = fcmp olt %s %%t%u, %%t%u\n", cmp_lo, flt_type, val, lo);
        Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n", cmp_lo, raise_label, ok_label);
        cg->block_terminated = true;
        Emit_Label_Here(cg, ok_label);
        /* val > high? */
        uint32_t cmp_hi = Emit_Temp(cg);
        Emit(cg, "  %%t%u = fcmp ogt %s %%t%u, %%t%u\n", cmp_hi, flt_type, val, hi);
        Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n", cmp_hi, raise_label, cont_label);
        cg->block_terminated = true;
    } else {
        /* Integer/enum/char/fixed path — all compare as i64.
         * For TYPE_FIXED, bounds may be BOUND_FLOAT or BOUND_EXPR
         * (e.g. subtype F is Fix range -101.0..0.0).  Scale float
         * bounds to match the mantissa repr: scaled = bound / small.
         * BOUND_EXPR bounds are generated as double then fptosi'd. */
        uint32_t lo, hi;
        const char *lo_type = NULL, *hi_type = NULL;
        if (target->kind == TYPE_FIXED) {
            double small = target->fixed.small;
            if (small <= 0) small = target->fixed.delta > 0 ? target->fixed.delta : 1.0;
            /* Fixed-point bounds must use the fixed type's native width (i64)
             * to avoid overflow when mantissa approaches MAX_MANTISSA.
             * Integer_Arith_Type is only i32 which overflows at 2^31. */
            const char *fix_bnd_ty = Type_To_Llvm(target);
            if (not fix_bnd_ty or fix_bnd_ty[0] != 'i') fix_bnd_ty = "i64";
            #define FIXED_BOUND_TO_I64(bnd, out) do {                     \
                if ((bnd)->kind == BOUND_FLOAT) {                         \
                    int128_t iv = (int128_t)((bnd)->float_value / small); \
                    (out) = Emit_Temp(cg);                                \
                    Emit(cg, "  %%t%u = add %s 0, %s  ; fixed bound"     \
                         " (%g/small)\n", (out), fix_bnd_ty,              \
                         I128_Decimal(iv), (bnd)->float_value);           \
                } else if ((bnd)->kind == BOUND_EXPR) {                   \
                    uint32_t fv = Generate_Expression(cg, (bnd)->expr);   \
                    const char *fv_ty = Temp_Get_Type(cg, fv);            \
                    bool fv_float = (fv_ty && Is_Float_Type(fv_ty)) ||    \
                        Type_Is_Float_Representation((bnd)->expr->type) ||\
                        ((bnd)->expr->type &&                             \
                         (bnd)->expr->type->kind == TYPE_UNIVERSAL_REAL); \
                    if (fv_float) {                                       \
                        /* Float expression: divide by SMALL, fptosi */   \
                        uint64_t sb; memcpy(&sb, &small, sizeof(sb));     \
                        uint32_t st = Emit_Temp(cg);                      \
                        Emit(cg, "  %%t%u = fadd double 0.0, 0x%016llX\n",\
                             st, (unsigned long long)sb);                 \
                        uint32_t dv = Emit_Temp(cg);                      \
                        Emit(cg, "  %%t%u = fdiv double %%t%u, %%t%u\n", \
                             dv, fv, st);                                 \
                        (out) = Emit_Temp(cg);                            \
                        Emit(cg, "  %%t%u = fptosi double %%t%u to %s\n",\
                             (out), dv, fix_bnd_ty);                      \
                    } else {                                              \
                        /* Already scaled integer (fixed-point value) */  \
                        const char *fv_src = fv_ty ? fv_ty :              \
                            Type_To_Llvm((bnd)->expr->type);              \
                        (out) = Emit_Convert(cg, fv,                      \
                            fv_src, fix_bnd_ty);                          \
                    }                                                     \
                    Temp_Set_Type(cg, (out), fix_bnd_ty);                 \
                } else {                                                  \
                    (out) = Emit_Bound_Value(cg, (bnd));                  \
                }                                                         \
            } while(0)
            FIXED_BOUND_TO_I64(&target->low_bound, lo);
            FIXED_BOUND_TO_I64(&target->high_bound, hi);
            #undef FIXED_BOUND_TO_I64
            lo_type = fix_bnd_ty;
            hi_type = fix_bnd_ty;
        } else {
            lo = Emit_Bound_Value_Typed(cg, &target->low_bound, &lo_type);
            hi = Emit_Bound_Value_Typed(cg, &target->high_bound, &hi_type);
        }
        if (not lo or not hi) return val;

        /* val < low? - Compare at wider of source/target type width.
         * Modular (unsigned) types use unsigned predicates (RM 3.5.4). */
        const char *target_llvm = Type_To_Llvm(target);
        const char *source_llvm = source ? Type_To_Llvm(source) : target_llvm;
        /* Use actual LLVM type if provided (may differ from Ada type info) */
        const char *effective_source = actual_val_type ? actual_val_type : source_llvm;
        const char *chk_type;
        if (target_llvm[0] == 'i' and effective_source[0] == 'i') {
            chk_type = Wider_Int_Type(cg, target_llvm, effective_source);
        } else {
            chk_type = Integer_Arith_Type(cg);
        }
        bool chk_unsigned = Type_Is_Unsigned(target);
        const char *lt_pred = chk_unsigned ? "ult" : "slt";
        const char *gt_pred = chk_unsigned ? "ugt" : "sgt";
        /* Widen val and bounds to chk_type for comparison only.
         * Use temporary widened values — original val is returned unchanged
         * so the caller's value stays at its original LLVM type. */
        const char *val_type = actual_val_type ? actual_val_type : source_llvm;
        /* Determine actual bound types.  BOUND_INTEGER/BOUND_FLOAT always produce
         * at Integer_Arith_Type.  BOUND_EXPR produces at Expression_Llvm_Type.
         * lo_type/hi_type are set above for the non-FIXED path; for FIXED they
         * come from the macro which always uses Integer_Arith_Type. */
        if (not lo_type) lo_type = Integer_Arith_Type(cg);
        if (not hi_type) hi_type = Integer_Arith_Type(cg);
        /* Ensure chk_type is wide enough for value and both bounds */
        if (chk_type[0] == 'i' and lo_type[0] == 'i')
            chk_type = Wider_Int_Type(cg, chk_type, lo_type);
        if (chk_type[0] == 'i' and hi_type[0] == 'i')
            chk_type = Wider_Int_Type(cg, chk_type, hi_type);
        uint32_t wval, wlo, whi;
        if (chk_unsigned) {
            wval = Emit_Convert_Ext(cg, val, val_type, chk_type, true);
            wlo  = Emit_Convert_Ext(cg, lo, lo_type, chk_type, true);
            whi  = Emit_Convert_Ext(cg, hi, hi_type, chk_type, true);
        } else {
            wval = Emit_Convert(cg, val, val_type, chk_type);
            wlo  = Emit_Convert(cg, lo, lo_type, chk_type);
            whi  = Emit_Convert(cg, hi, hi_type, chk_type);
        }
        uint32_t cmp_lo = Emit_Temp(cg);
        Emit(cg, "  %%t%u = icmp %s %s %%t%u, %%t%u\n", cmp_lo, lt_pred, chk_type, wval, wlo);
        Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n", cmp_lo, raise_label, ok_label);
        cg->block_terminated = true;
        Emit_Label_Here(cg, ok_label);
        /* val > high? */
        uint32_t cmp_hi = Emit_Temp(cg);
        Emit(cg, "  %%t%u = icmp %s %s %%t%u, %%t%u\n", cmp_hi, gt_pred, chk_type, wval, whi);
        Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n", cmp_hi, raise_label, cont_label);
        cg->block_terminated = true;
    }

    Emit_Label_Here(cg, raise_label); /* raise CONSTRAINT_ERROR */
    Emit_Raise_Constraint_Error(cg, "bound check");

    Emit_Label_Here(cg, cont_label);
    cg->block_terminated = false;
    return val;
}

/* Backward-compatible wrapper — derives val_type from source Type_Info */
static uint32_t Emit_Constraint_Check(Code_Generator *cg, uint32_t val,
                                       Type_Info *target, Type_Info *source) {
    return Emit_Constraint_Check_With_Type(cg, val, target, source, NULL);
}

/* RM 3.5(3): When a subtype_indication includes a range constraint
 * (e.g. I5 RANGE 0..P), the constraint bounds must lie within the
 * base type's range.  Emit runtime checks for any BOUND_EXPR bound. */
static void Emit_Subtype_Constraint_Compat_Check(Code_Generator *cg, Type_Info *ty) {
    if (!ty || !ty->base_type || !Type_Is_Scalar(ty)) return;
    Type_Info *base = ty->base_type;
    if (Check_Is_Suppressed(ty, NULL, CHK_RANGE)) return;
    bool lo_dyn = (ty->low_bound.kind == BOUND_EXPR);
    bool hi_dyn = (ty->high_bound.kind == BOUND_EXPR);
    if (!lo_dyn && !hi_dyn) return;  /* purely static — checked at compile time */
    bool base_lo_ok = (base->low_bound.kind == BOUND_INTEGER ||
                       base->low_bound.kind == BOUND_EXPR);
    bool base_hi_ok = (base->high_bound.kind == BOUND_INTEGER ||
                       base->high_bound.kind == BOUND_EXPR);
    if (!base_lo_ok || !base_hi_ok) return;
    const char *iat = Integer_Arith_Type(cg);
    /* Emit base type bounds */
    uint32_t blo = Emit_Bound_Value(cg, &base->low_bound);
    uint32_t bhi = Emit_Bound_Value(cg, &base->high_bound);
    /* Check each dynamic constraint bound against base range */
    if (lo_dyn) {
        uint32_t clo = Emit_Bound_Value(cg, &ty->low_bound);
        uint32_t c = Emit_Temp(cg);
        Emit(cg, "  %%t%u = icmp slt %s %%t%u, %%t%u\n", c, iat, clo, blo);
        Emit_Check_With_Raise(cg, c, true, "subtype low bound");
    }
    if (hi_dyn) {
        uint32_t chi = Emit_Bound_Value(cg, &ty->high_bound);
        uint32_t c = Emit_Temp(cg);
        Emit(cg, "  %%t%u = icmp sgt %s %%t%u, %%t%u\n", c, iat, chi, bhi);
        Emit_Check_With_Raise(cg, c, true, "subtype high bound");
    }
}

/* ─────────────────────────────────────────────────────────────────────────
 * §13.2.1 Fat Pointer Support for Unconstrained Arrays
 *
 * fat pointer = { data_ptr, bounds_ptr } = { ptr, ptr }.
 * Bounds live behind the second pointer as a struct { bt, bt } where
 * bt = native index type (i32 for STRING, i8 for CHARACTER, etc.).
 *
 * All helpers take a `bt` (bound type) parameter — the LLVM type string
 * for the bounds (e.g., "i32", "i8").  The bounds struct type is derived
 * from bt via Bounds_Type_For().
 * ───────────────────────────────────────────────────────────────────────── */

/* Create a fat pointer from data pointer and constant bounds.
 * bt = bound LLVM type (e.g., "i32").
 * Allocates bounds struct on stack, stores lo/hi, builds { ptr, ptr }. */
static uint32_t Emit_Fat_Pointer(Code_Generator *cg, uint32_t data_ptr,
                                  int128_t low, int128_t high, const char *bt) {
    const char *bst = Bounds_Type_For(bt);
    /* Allocate bounds struct { bt, bt } on stack — native type */
    uint32_t bounds_alloca = Emit_Temp(cg);
    Emit(cg, "  %%t%u = alloca %s\n", bounds_alloca, bst);

    /* Store low bound in native bt */
    uint32_t low_gep = Emit_Temp(cg);
    Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, i32 0, i32 0\n",
         low_gep, bst, bounds_alloca);
    Emit(cg, "  store %s %s, ptr %%t%u\n", bt, I128_Decimal(low), low_gep);

    /* Store high bound in native bt */
    uint32_t high_gep = Emit_Temp(cg);
    Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, i32 0, i32 1\n",
         high_gep, bst, bounds_alloca);
    Emit(cg, "  store %s %s, ptr %%t%u\n", bt, I128_Decimal(high), high_gep);

    /* Build fat pointer { ptr, ptr } via insertvalue */
    uint32_t t1 = Emit_Temp(cg);
    Emit(cg, "  %%t%u = insertvalue " FAT_PTR_TYPE " undef, ptr %%t%u, 0\n",
         t1, data_ptr);
    uint32_t t2 = Emit_Temp(cg);
    Emit(cg, "  %%t%u = insertvalue " FAT_PTR_TYPE " %%t%u, ptr %%t%u, 1\n",
         t2, t1, bounds_alloca);
    Temp_Set_Type(cg, t2, FAT_PTR_TYPE);
    return t2;
}

/* Widen a value to INTEGER width (Integer_Arith_Type) for use at
 * LLVM intrinsic boundaries (memcpy length, alloca size, malloc size, RTS ABI).
 * Uses sext for signed types, zext for unsigned (modular) types.
 * No-op if from_type is already at INTEGER width. */
static uint32_t Emit_Widen_For_Intrinsic(Code_Generator *cg, uint32_t val,
                                    const char *from_type) {
    const char *actual = Temp_Get_Type(cg, val);
    if (actual and actual[0] != '\0') from_type = actual;
    const char *iat = Integer_Arith_Type(cg);
    if (strcmp(from_type, iat) == 0) return val;
    uint32_t w = Emit_Temp(cg);
    Emit(cg, "  %%t%u = sext %s %%t%u to %s\n", w, from_type, val, iat);
    Temp_Set_Type(cg, w, iat);
    return w;
}

/* Extend value to i64 for C-level operations (memcpy, alloca, malloc, sec_stack_alloc).
 * These always require i64 on 64-bit targets regardless of Ada INTEGER width. */
static uint32_t Emit_Extend_To_I64(Code_Generator *cg, uint32_t val, const char *from_type) {
    const char *actual = Temp_Get_Type(cg, val);
    if (actual and actual[0] != '\0') from_type = actual;
    if (strcmp(from_type, "i64") == 0) return val;
    uint32_t w = Emit_Temp(cg);
    Emit(cg, "  %%t%u = sext %s %%t%u to i64\n", w, from_type, val);
    Temp_Set_Type(cg, w, "i64");
    return w;
}

/* Extract data pointer from fat pointer.
 * bt parameter retained for API compatibility but unused. */
static uint32_t Emit_Fat_Pointer_Data(Code_Generator *cg, uint32_t fat_ptr,
                                       const char *bt) {
    (void)bt;
    uint32_t t = Emit_Temp(cg);
    Emit(cg, "  %%t%u = extractvalue " FAT_PTR_TYPE " %%t%u, 0\n", t, fat_ptr);
    Temp_Set_Type(cg, t, "ptr");
    return t;
}

/* Extract bound at field_index from fat pointer's bounds struct.
 * Parametric over index: 0 = low, 1 = high */
static uint32_t Emit_Fat_Pointer_Bound(Code_Generator *cg, uint32_t fat_ptr,
                                        const char *bt, uint32_t field_index) {
    const char *bst = Bounds_Type_For(bt);
    uint32_t bptr = Emit_Temp(cg);
    Emit(cg, "  %%t%u = extractvalue " FAT_PTR_TYPE " %%t%u, 1\n", bptr, fat_ptr);
    uint32_t gep = Emit_Temp(cg);
    Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, i32 0, i32 %u\n",
         gep, bst, bptr, field_index);
    uint32_t val = Emit_Temp(cg);
    Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", val, bt, gep);
    Temp_Set_Type(cg, val, bt);
    return val;
}
#define Emit_Fat_Pointer_Low(cg, fp, bt)  Emit_Fat_Pointer_Bound(cg, fp, bt, 0)
#define Emit_Fat_Pointer_High(cg, fp, bt) Emit_Fat_Pointer_Bound(cg, fp, bt, 1)

/* Extract low bound for dimension `dim` from fat pointer.
 * Bounds are stored as flat pairs: [low0, high0, low1, high1, ...].
 * Uses flat GEP with index 2*dim for low, 2*dim+1 for high. */
static uint32_t Emit_Fat_Pointer_Low_Dim(Code_Generator *cg, uint32_t fat_ptr,
                                          const char *bt, uint32_t dim) {
    uint32_t bptr = Emit_Temp(cg);
    Emit(cg, "  %%t%u = extractvalue " FAT_PTR_TYPE " %%t%u, 1\n", bptr, fat_ptr);
    uint32_t gep = Emit_Temp(cg);
    Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, i32 %u\n",
         gep, bt, bptr, dim * 2);
    uint32_t val = Emit_Temp(cg);
    Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", val, bt, gep);
    Temp_Set_Type(cg, val, bt);
    return val;
}

static uint32_t Emit_Fat_Pointer_High_Dim(Code_Generator *cg, uint32_t fat_ptr,
                                            const char *bt, uint32_t dim) {
    uint32_t bptr = Emit_Temp(cg);
    Emit(cg, "  %%t%u = extractvalue " FAT_PTR_TYPE " %%t%u, 1\n", bptr, fat_ptr);
    uint32_t gep = Emit_Temp(cg);
    Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, i32 %u\n",
         gep, bt, bptr, dim * 2 + 1);
    uint32_t val = Emit_Temp(cg);
    Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", val, bt, gep);
    Temp_Set_Type(cg, val, bt);
    return val;
}

/* Consolidated helpers (defined in §13.2.1, §13.2.3) */
static uint32_t Emit_Length_Clamped(Code_Generator *cg, uint32_t low, uint32_t high, const char *bt);
static uint32_t Emit_Length_From_Bounds(Code_Generator *cg, uint32_t low, uint32_t high, const char *bt);
static uint32_t Emit_Static_Int(Code_Generator *cg, int128_t value, const char *ty);
static uint32_t Emit_Memcmp_Eq(Code_Generator *cg, uint32_t left_ptr, uint32_t right_ptr,
    uint32_t byte_size_temp, int64_t byte_size_static, bool is_dynamic);
static uint32_t Emit_Type_Bound(Code_Generator *cg, Type_Bound *bound, const char *ty);
static uint32_t Emit_Min_Value(Code_Generator *cg, uint32_t a, uint32_t b, const char *ty);
static uint32_t Emit_Array_Lex_Compare(Code_Generator *cg, uint32_t left_ptr, uint32_t right_ptr,
    uint32_t elem_size, const char *bt);

/* Compute length for dimension `dim` from fat pointer: high - low + 1
 * with null-array clamping (RM 3.6.2). */
static uint32_t Emit_Fat_Pointer_Length_Dim(Code_Generator *cg, uint32_t fat_ptr,
                                             const char *bt, uint32_t dim) {
    uint32_t low = Emit_Fat_Pointer_Low_Dim(cg, fat_ptr, bt, dim);
    uint32_t high = Emit_Fat_Pointer_High_Dim(cg, fat_ptr, bt, dim);
    return Emit_Length_Clamped(cg, low, high, bt);
}

/* Allocate a multi-dimension bounds block on the stack.
 * Layout: [low0, high0, low1, high1, ...] as flat array of 2*ndims values.
 * bounds_lo/bounds_hi are arrays of ndims temp IDs.
 * Returns the alloca temp ID (ptr to the bounds memory). */
static uint32_t Emit_Alloc_Bounds_MultiDim(Code_Generator *cg,
    uint32_t *bounds_lo, uint32_t *bounds_hi, uint32_t ndims, const char *bt)
{
    uint32_t bounds_alloca = Emit_Temp(cg);
    Emit(cg, "  %%t%u = alloca [%u x %s]  ; bounds for %u dims\n",
         bounds_alloca, ndims * 2, bt, ndims);
    for (uint32_t d = 0; d < ndims; d++) {
        uint32_t lo_coerced = Emit_Coerce(cg, bounds_lo[d], bt);
        uint32_t hi_coerced = Emit_Coerce(cg, bounds_hi[d], bt);
        uint32_t lo_gep = Emit_Temp(cg);
        Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, i32 %u\n",
             lo_gep, bt, bounds_alloca, d * 2);
        Emit(cg, "  store %s %%t%u, ptr %%t%u\n", bt, lo_coerced, lo_gep);
        uint32_t hi_gep = Emit_Temp(cg);
        Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, i32 %u\n",
             hi_gep, bt, bounds_alloca, d * 2 + 1);
        Emit(cg, "  store %s %%t%u, ptr %%t%u\n", bt, hi_coerced, hi_gep);
    }
    return bounds_alloca;
}

/* Create a fat pointer with multi-dim bounds.
 * bounds_lo/bounds_hi are arrays of ndims temp IDs. */
static uint32_t Emit_Fat_Pointer_MultiDim(Code_Generator *cg, uint32_t data_ptr,
    uint32_t *bounds_lo, uint32_t *bounds_hi, uint32_t ndims, const char *bt)
{
    uint32_t bounds_alloca = Emit_Alloc_Bounds_MultiDim(cg, bounds_lo, bounds_hi, ndims, bt);
    uint32_t t1 = Emit_Temp(cg);
    Emit(cg, "  %%t%u = insertvalue " FAT_PTR_TYPE " undef, ptr %%t%u, 0\n",
         t1, data_ptr);
    uint32_t t2 = Emit_Temp(cg);
    Emit(cg, "  %%t%u = insertvalue " FAT_PTR_TYPE " %%t%u, ptr %%t%u, 1\n",
         t2, t1, bounds_alloca);
    Temp_Set_Type(cg, t2, FAT_PTR_TYPE);
    return t2;
}

/* Create a fat pointer from data pointer and dynamic bounds (temp IDs).
 * bt = bound LLVM type of the input temps (already in native type).
 * Allocates bounds struct on stack, stores in native bt, builds { ptr, ptr }. */
/* Allocate a bounds struct { bt, bt } on the stack and store lo/hi into it.
 * Returns the alloca temp ID (a ptr to the bounds struct). */
static uint32_t Emit_Alloc_Bounds_Struct(Code_Generator *cg,
    uint32_t low_temp, uint32_t high_temp, const char *bt)
{
    const char *bst = Bounds_Type_For(bt);
    uint32_t bounds_alloca = Emit_Temp(cg);
    Emit(cg, "  %%t%u = alloca %s\n", bounds_alloca, bst);

    /* Convert bounds to target type if needed */
    low_temp = Emit_Coerce(cg, low_temp, bt);
    high_temp = Emit_Coerce(cg, high_temp, bt);

    uint32_t low_gep = Emit_Temp(cg);
    Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, i32 0, i32 0\n",
         low_gep, bst, bounds_alloca);
    Emit(cg, "  store %s %%t%u, ptr %%t%u\n", bt, low_temp, low_gep);

    uint32_t high_gep = Emit_Temp(cg);
    Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, i32 0, i32 1\n",
         high_gep, bst, bounds_alloca);
    Emit(cg, "  store %s %%t%u, ptr %%t%u\n", bt, high_temp, high_gep);

    return bounds_alloca;
}

static uint32_t Emit_Fat_Pointer_Dynamic(Code_Generator *cg, uint32_t data_ptr,
                                          uint32_t low_temp, uint32_t high_temp,
                                          const char *bt) {
    uint32_t bounds_alloca = Emit_Alloc_Bounds_Struct(cg, low_temp, high_temp, bt);
    uint32_t t1 = Emit_Temp(cg);
    Emit(cg, "  %%t%u = insertvalue " FAT_PTR_TYPE " undef, ptr %%t%u, 0\n",
         t1, data_ptr);
    uint32_t t2 = Emit_Temp(cg);
    Emit(cg, "  %%t%u = insertvalue " FAT_PTR_TYPE " %%t%u, ptr %%t%u, 1\n",
         t2, t1, bounds_alloca);
    Temp_Set_Type(cg, t2, FAT_PTR_TYPE);
    return t2;
}

/* Compute length from fat pointer bounds: high - low + 1
 * Returns temp ID holding the length in native bound type (bt). */
static uint32_t Emit_Fat_Pointer_Length(Code_Generator *cg, uint32_t fat_ptr,
                                         const char *bt) {
    uint32_t low = Emit_Fat_Pointer_Low(cg, fat_ptr, bt);
    uint32_t high = Emit_Fat_Pointer_High(cg, fat_ptr, bt);
    uint32_t diff = Emit_Temp(cg);
    Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", diff, bt, high, low);
    Temp_Set_Type(cg, diff, bt);
    uint32_t len = Emit_Temp(cg);
    Emit(cg, "  %%t%u = add %s %%t%u, 1\n", len, bt, diff);
    Temp_Set_Type(cg, len, bt);
    return len;
}

/* Emit length from two temp IDs (raw bounds, not from fat pointer):
 *   result = high - low + 1
 * Lighter than Emit_Fat_Pointer_Length when you already have low/high. */
static uint32_t Emit_Length_From_Bounds(Code_Generator *cg,
    uint32_t low, uint32_t high, const char *bt)
{
    uint32_t diff = Emit_Temp(cg);
    Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", diff, bt, high, low);
    uint32_t len = Emit_Temp(cg);
    Emit(cg, "  %%t%u = add %s %%t%u, 1\n", len, bt, diff);
    Temp_Set_Type(cg, len, bt);
    return len;
}

/* Emit_Fat_To_Array_Memcpy: Copy data from a fat pointer source to a destination.
 * Extracts data pointer, computes byte length from bounds * element size, emits memcpy.
 * Used when assigning fat pointer (unconstrained string/array) to constrained component. */
static void Emit_Fat_To_Array_Memcpy(Code_Generator *cg, uint32_t fat_val,
                                      uint32_t dest_ptr, Type_Info *array_type) {
    const char *bnd_type = Array_Bound_Llvm_Type(array_type);
    uint32_t data_ptr = Emit_Fat_Pointer_Data(cg, fat_val, bnd_type);
    uint32_t fat_lo = Emit_Fat_Pointer_Low(cg, fat_val, bnd_type);
    uint32_t fat_hi = Emit_Fat_Pointer_High(cg, fat_val, bnd_type);
    uint32_t len = Emit_Length_From_Bounds(cg, fat_lo, fat_hi, bnd_type);
    uint32_t elem_sz = (array_type->array.element_type &&
                        array_type->array.element_type->size > 0) ?
                        array_type->array.element_type->size : 1;
    uint32_t byte_len = len;
    if (elem_sz > 1) {
        byte_len = Emit_Temp(cg);
        Emit(cg, "  %%t%u = mul %s %%t%u, %u\n", byte_len, bnd_type, len, elem_sz);
    }
    uint32_t byte_len_64 = Emit_Extend_To_I64(cg, byte_len, bnd_type);
    Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)\n",
         dest_ptr, data_ptr, byte_len_64);
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §13.2.1 DRY-Consolidated Helpers (Phase 1 Refactoring)
 *
 * These helpers eliminate repetitive patterns identified across the codegen:
 *   - Length computation with null-array clamping (RM 3.6.2)
 *   - Static integer constant emission
 *   - Memcmp-based array comparison
 *   - Conditional check + raise sequences
 * ═══════════════════════════════════════════════════════════════════════════ */

/* Emit length from bounds with null-array clamping (RM 3.6.2):
 *   result = (low > high) ? 0 : (high - low + 1)
 * Handles the Ada rule that arrays with first > last have length 0. */
static uint32_t Emit_Length_Clamped(Code_Generator *cg,
    uint32_t low, uint32_t high, const char *bt)
{
    uint32_t diff = Emit_Temp(cg);
    Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", diff, bt, high, low);
    uint32_t unclamped = Emit_Temp(cg);
    Emit(cg, "  %%t%u = add %s %%t%u, 1\n", unclamped, bt, diff);
    uint32_t is_null = Emit_Temp(cg);
    Emit(cg, "  %%t%u = icmp sgt %s %%t%u, %%t%u\n", is_null, bt, low, high);
    uint32_t len = Emit_Temp(cg);
    Emit(cg, "  %%t%u = select i1 %%t%u, %s 0, %s %%t%u\n", len, is_null, bt, bt, unclamped);
    Temp_Set_Type(cg, len, bt);
    return len;
}

/* Emit a static integer constant using the add idiom:
 *   %tN = add <type> 0, <value>
 * This is the standard LLVM IR pattern for loading constants. */
static uint32_t Emit_Static_Int(Code_Generator *cg, int128_t value, const char *ty) {
    uint32_t t = Emit_Temp(cg);
    Emit(cg, "  %%t%u = add %s 0, %s\n", t, ty, I128_Decimal(value));
    Temp_Set_Type(cg, t, ty);
    return t;
}

/* Emit memcmp and return i1 equality result (true if arrays equal).
 * Handles both static (literal size) and dynamic (temp size) cases. */
static uint32_t Emit_Memcmp_Eq(Code_Generator *cg,
    uint32_t left_ptr, uint32_t right_ptr, uint32_t byte_size_temp,
    int64_t byte_size_static, bool is_dynamic)
{
    uint32_t memcmp_res = Emit_Temp(cg);
    if (is_dynamic) {
        Emit(cg, "  %%t%u = call i32 @memcmp(ptr %%t%u, ptr %%t%u, i64 %%t%u)\n",
             memcmp_res, left_ptr, right_ptr, byte_size_temp);
    } else {
        Emit(cg, "  %%t%u = call i32 @memcmp(ptr %%t%u, ptr %%t%u, i64 %lld)\n",
             memcmp_res, left_ptr, right_ptr, (long long)byte_size_static);
    }
    uint32_t eq = Emit_Temp(cg);
    Emit(cg, "  %%t%u = icmp eq i32 %%t%u, 0\n", eq, memcmp_res);
    Temp_Set_Type(cg, eq, "i1");
    return eq;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §13.2.2 Bound Extraction Helpers (DRY Pattern: 20+ locations)
 *
 * Ada types carry bounds as either:
 *   - BOUND_INTEGER: compile-time constant
 *   - BOUND_EXPR: runtime expression (dynamic subtypes)
 *   - BOUND_FLOAT: floating-point constant (for float types)
 *
 * These helpers consolidate the ~600 lines of repeated bound extraction.
 * ───────────────────────────────────────────────────────────────────────── */

/* Bound_Temps: Holds emitted temps for a dimension's low and high bounds.
 * The bound_type field records the LLVM type used (e.g., "i32", "i64"). */
typedef struct {
    uint32_t low_temp;      /* Temp ID holding low bound value  */
    uint32_t high_temp;     /* Temp ID holding high bound value */
    const char *bound_type; /* LLVM type of bounds (e.g., "i32") */
} Bound_Temps;

/* Emit a single bound (low or high) from a Type_Bound structure.
 * Handles all three bound kinds: INTEGER, EXPR, FLOAT. */
static uint32_t Emit_Single_Bound(Code_Generator *cg, Type_Bound *bound,
                                   const char *target_type) {
    if (bound->kind == BOUND_INTEGER) {
        return Emit_Static_Int(cg, bound->int_value, target_type);
    } else if (bound->kind == BOUND_FLOAT) {
        return Emit_Static_Int(cg, (int128_t)bound->float_value, target_type);
    } else if (bound->kind == BOUND_EXPR and bound->expr) {
        uint32_t val = Generate_Expression(cg, bound->expr);
        const char *expr_ty = Expression_Llvm_Type(cg, bound->expr);
        if (expr_ty and strcmp(expr_ty, target_type) != 0 and
            expr_ty[0] == 'i' and target_type[0] == 'i') {
            val = Emit_Convert(cg, val, expr_ty, target_type);
        }
        return val;
    }
    return Emit_Static_Int(cg, 0, target_type);  /* Fallback for unset bounds */
}

/* Emit_Bounds: Extract both bounds from a Type_Info for a specific dimension.
 * For arrays: uses indices[dim].low_bound/high_bound
 * For scalars: uses type->low_bound/high_bound (dim ignored)
 * Returns Bound_Temps with both temps and the bound type string. */
static Bound_Temps Emit_Bounds(Code_Generator *cg, Type_Info *type, uint32_t dim) {
    Bound_Temps result = {0, 0, Integer_Arith_Type(cg)};
    if (not type) return result;

    Type_Bound *lb = &type->low_bound;
    Type_Bound *hb = &type->high_bound;

    /* For array types, use the appropriate dimension's bounds */
    if (Type_Is_Array_Like(type) and dim < type->array.index_count) {
        lb = &type->array.indices[dim].low_bound;
        hb = &type->array.indices[dim].high_bound;
        /* Determine bound type from index type if available */
        if (type->array.indices[dim].index_type) {
            const char *idx_llvm = Type_To_Llvm(type->array.indices[dim].index_type);
            if (idx_llvm and idx_llvm[0] == 'i') result.bound_type = idx_llvm;
        }
    }

    /* Use array bound LLVM type if this is an array */
    if (Type_Is_Array_Like(type)) {
        const char *abt = Array_Bound_Llvm_Type(type);
        if (abt and abt[0] == 'i') result.bound_type = abt;
    }

    result.low_temp = Emit_Single_Bound(cg, lb, result.bound_type);
    result.high_temp = Emit_Single_Bound(cg, hb, result.bound_type);
    return result;
}

/* Emit_Bounds_From_Fat: Extract bounds from a fat pointer value.
 * Fat pointers have structure { ptr data, ptr bounds } where bounds
 * points to a { low, high } pair. Uses existing Emit_Fat_Pointer_Low/High. */
static Bound_Temps Emit_Bounds_From_Fat(Code_Generator *cg, uint32_t fat_ptr,
                                         const char *bt) {
    Bound_Temps result;
    result.bound_type = bt;
    result.low_temp = Emit_Fat_Pointer_Low(cg, fat_ptr, bt);
    result.high_temp = Emit_Fat_Pointer_High(cg, fat_ptr, bt);
    return result;
}

/* Emit_Bounds_From_Fat_Dim: Extract bounds from fat pointer for specific dimension.
 * Supports multi-dimensional unconstrained arrays (RM 3.6.1). */
static Bound_Temps Emit_Bounds_From_Fat_Dim(Code_Generator *cg, uint32_t fat_ptr,
                                             const char *bt, uint32_t dim) {
    Bound_Temps result;
    result.bound_type = bt;
    result.low_temp = Emit_Fat_Pointer_Low_Dim(cg, fat_ptr, bt, dim);
    result.high_temp = Emit_Fat_Pointer_High_Dim(cg, fat_ptr, bt, dim);
    return result;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §13.2.4 Conditional Check + Raise (DRY Pattern: 50+ locations)
 *
 * Ada runtime checks follow a common pattern:
 *   1. Emit comparison (icmp/fcmp)
 *   2. Branch to raise block if check fails
 *   3. Raise CONSTRAINT_ERROR (or other exception)
 *   4. Continue to next instruction
 *
 * This helper consolidates the branch + raise + continue sequence.
 * ───────────────────────────────────────────────────────────────────────── */

/* Emit_Check_With_Raise: Conditional branch + raise + continue.
 * If raise_on_true is true: raises when cond is true, continues when false.
 * If raise_on_true is false: raises when cond is false, continues when true. */
static void Emit_Check_With_Raise(Code_Generator *cg, uint32_t cond,
                                   bool raise_on_true, const char *comment) {
    uint32_t raise_label = cg->label_id++;
    uint32_t cont_label = cg->label_id++;
    if (raise_on_true) {
        Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n",
             cond, raise_label, cont_label);
    } else {
        Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n",
             cond, cont_label, raise_label);
    }
    cg->block_terminated = true;  /* conditional branch terminates block */
    Emit_Label_Here(cg, raise_label);
    Emit_Raise_Constraint_Error(cg, comment);
    Emit_Label_Here(cg, cont_label);
    cg->block_terminated = false;
}

/* Emit_Range_Check_With_Raise: Checks val in [lo_val, hi_val], raises if not.
 * Emits two icmp + br with shared raise label for efficiency.  */
static void Emit_Range_Check_With_Raise(Code_Generator *cg, uint32_t val,
                                         int64_t lo_val, int64_t hi_val,
                                         const char *type, const char *comment) {
    uint32_t lo_ok = cg->label_id++;
    uint32_t hi_ok = cg->label_id++;
    uint32_t raise_label = cg->label_id++;
    uint32_t cmp_lo = Emit_Temp(cg);
    Emit(cg, "  %%t%u = icmp slt %s %%t%u, %lld\n", cmp_lo, type, val, (long long)lo_val);
    Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n", cmp_lo, raise_label, lo_ok);
    cg->block_terminated = true;
    Emit_Label_Here(cg, lo_ok);
    uint32_t cmp_hi = Emit_Temp(cg);
    Emit(cg, "  %%t%u = icmp sgt %s %%t%u, %lld\n", cmp_hi, type, val, (long long)hi_val);
    Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n", cmp_hi, raise_label, hi_ok);
    cg->block_terminated = true;
    Emit_Label_Here(cg, raise_label);
    Emit_Raise_Constraint_Error(cg, comment);
    Emit_Label_Here(cg, hi_ok);
    cg->block_terminated = false;
}

/* Emit a type bound as a temp: handles BOUND_INTEGER, BOUND_EXPR, BOUND_FLOAT.
 * Returns temp ID with value at specified type width. */
static uint32_t Emit_Type_Bound(Code_Generator *cg, Type_Bound *bound, const char *ty) {
    if (bound->kind == BOUND_INTEGER) {
        return Emit_Static_Int(cg, bound->int_value, ty);
    } else if (bound->kind == BOUND_FLOAT) {
        return Emit_Static_Int(cg, (int128_t)bound->float_value, ty);
    } else if (bound->kind == BOUND_EXPR && bound->expr) {
        uint32_t val = Generate_Expression(cg, bound->expr);
        const char *expr_ty = Expression_Llvm_Type(cg, bound->expr);
        if (strcmp(expr_ty, ty) != 0 && expr_ty[0] == 'i' && ty[0] == 'i') {
            val = Emit_Convert(cg, val, expr_ty, ty);
        }
        return val;
    }
    return Emit_Static_Int(cg, 0, ty);  /* Fallback */
}

/* Copy data from fat pointer to a named destination.
 * Emits: memcpy(dst, src_data, length).  bt = bound type. */
static void Emit_Fat_Pointer_Copy_To_Name(Code_Generator *cg, uint32_t fat_ptr,
                                            Symbol *dst, const char *bt) {
    uint32_t src_ptr = Emit_Fat_Pointer_Data(cg, fat_ptr, bt);
    uint32_t len = Emit_Fat_Pointer_Length(cg, fat_ptr, bt);
    uint32_t len64 = Emit_Extend_To_I64(cg, len, bt);
    Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%");
    Emit_Symbol_Name(cg, dst);
    Emit(cg, ", ptr %%t%u, i64 %%t%u, i1 false)\n", src_ptr, len64);
}

/* Load fat pointer from a symbol's storage.  bt = bound type (unused for load). */
static uint32_t Emit_Load_Fat_Pointer(Code_Generator *cg, Symbol *sym,
                                       const char *bt) {
    (void)bt;
    uint32_t fat = Emit_Temp(cg);
    Emit(cg, "  %%t%u = load " FAT_PTR_TYPE ", ptr ", fat);
    Emit_Symbol_Storage(cg, sym);
    Emit(cg, "\n");
    Temp_Set_Type(cg, fat, FAT_PTR_TYPE);
    return fat;
}

/* Load fat pointer from a temp pointer (%%t<N>).  bt = bound type (unused for load). */
static uint32_t Emit_Load_Fat_Pointer_From_Temp(Code_Generator *cg,
                                                  uint32_t ptr_temp,
                                                  const char *bt) {
    (void)bt;
    uint32_t fat = Emit_Temp(cg);
    Emit(cg, "  %%t%u = load " FAT_PTR_TYPE ", ptr %%t%u\n", fat, ptr_temp);
    Temp_Set_Type(cg, fat, FAT_PTR_TYPE);
    return fat;
}


/* Store a fat pointer value into a symbol's storage.  bt = bound type (unused). */
static void Emit_Store_Fat_Pointer_To_Symbol(Code_Generator *cg,
                                              uint32_t fat_val, Symbol *sym,
                                              const char *bt) {
    (void)bt;
    Emit(cg, "  store " FAT_PTR_TYPE " %%t%u, ptr ", fat_val);
    Emit_Symbol_Storage(cg, sym);
    Emit(cg, "\n");
}

/* Store fat pointer fields (data ptr, low, high) into a symbol using GEP+store.
 * Allocates bounds struct, stores lo/hi, then stores { ptr, ptr } fields.
 * bt = bound type. */
static void Emit_Store_Fat_Pointer_Fields_To_Symbol(Code_Generator *cg,
    uint32_t data_ptr, uint32_t low_temp, uint32_t high_temp, Symbol *sym,
    const char *bt)
{
    uint32_t bounds_alloca = Emit_Alloc_Bounds_Struct(cg, low_temp, high_temp, bt);

    /* Store data ptr (field 0 of { ptr, ptr }) */
    uint32_t data_slot = Emit_Temp(cg);
    Emit(cg, "  %%t%u = getelementptr " FAT_PTR_TYPE ", ptr ", data_slot);
    Emit_Symbol_Storage(cg, sym);
    Emit(cg, ", i32 0, i32 0\n");
    Emit(cg, "  store ptr %%t%u, ptr %%t%u\n", data_ptr, data_slot);

    /* Store bounds ptr (field 1 of { ptr, ptr }) */
    uint32_t bounds_slot = Emit_Temp(cg);
    Emit(cg, "  %%t%u = getelementptr " FAT_PTR_TYPE ", ptr ", bounds_slot);
    Emit_Symbol_Storage(cg, sym);
    Emit(cg, ", i32 0, i32 1\n");
    Emit(cg, "  store ptr %%t%u, ptr %%t%u\n", bounds_alloca, bounds_slot);
}

/* Store fat pointer fields (data ptr, low, high) into a temp alloca using GEP+store.
 * bt = bound type. */
static void Emit_Store_Fat_Pointer_Fields_To_Temp(Code_Generator *cg,
    uint32_t data_ptr, uint32_t low_temp, uint32_t high_temp,
    uint32_t fat_alloca, const char *bt)
{
    uint32_t bounds_alloca = Emit_Alloc_Bounds_Struct(cg, low_temp, high_temp, bt);

    /* Store data ptr (field 0 of { ptr, ptr }) */
    uint32_t data_slot = Emit_Temp(cg);
    Emit(cg, "  %%t%u = getelementptr " FAT_PTR_TYPE ", ptr %%t%u, i32 0, i32 0\n",
         data_slot, fat_alloca);
    Emit(cg, "  store ptr %%t%u, ptr %%t%u\n", data_ptr, data_slot);

    /* Store bounds ptr (field 1 of { ptr, ptr }) */
    uint32_t bounds_slot = Emit_Temp(cg);
    Emit(cg, "  %%t%u = getelementptr " FAT_PTR_TYPE ", ptr %%t%u, i32 0, i32 1\n",
         bounds_slot, fat_alloca);
    Emit(cg, "  store ptr %%t%u, ptr %%t%u\n", bounds_alloca, bounds_slot);
}

/* Compare two fat pointers for identity equality (data ptr + both bounds).
 * Returns temp ID holding i1 result.  bt = bound type. */
static uint32_t Emit_Fat_Pointer_Compare(Code_Generator *cg,
    uint32_t left_fat, uint32_t right_fat, const char *bt)
{
    uint32_t lp = Emit_Fat_Pointer_Data(cg, left_fat, bt);
    uint32_t rp = Emit_Fat_Pointer_Data(cg, right_fat, bt);
    uint32_t ll = Emit_Fat_Pointer_Low(cg, left_fat, bt);
    uint32_t rl = Emit_Fat_Pointer_Low(cg, right_fat, bt);
    uint32_t lh = Emit_Fat_Pointer_High(cg, left_fat, bt);
    uint32_t rh = Emit_Fat_Pointer_High(cg, right_fat, bt);

    uint32_t cmp_p = Emit_Temp(cg);
    Emit(cg, "  %%t%u = icmp eq ptr %%t%u, %%t%u\n", cmp_p, lp, rp);
    uint32_t cmp_l = Emit_Temp(cg);
    Emit(cg, "  %%t%u = icmp eq %s %%t%u, %%t%u\n", cmp_l, bt, ll, rl);
    uint32_t cmp_h = Emit_Temp(cg);
    Emit(cg, "  %%t%u = icmp eq %s %%t%u, %%t%u\n", cmp_h, bt, lh, rh);

    uint32_t and1 = Emit_Temp(cg);
    Emit(cg, "  %%t%u = and i1 %%t%u, %%t%u\n", and1, cmp_p, cmp_l);
    uint32_t result = Emit_Temp(cg);
    Emit(cg, "  %%t%u = and i1 %%t%u, %%t%u\n", result, and1, cmp_h);
    return result;
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §13.2.3 DRY-Consolidated Helpers - Phase 1 (Additional)
 * ═══════════════════════════════════════════════════════════════════════════ */

/* Emit minimum of two values:  result = (a < b) ? a : b */
static uint32_t Emit_Min_Value(Code_Generator *cg, uint32_t a, uint32_t b, const char *ty) {
    uint32_t cmp = Emit_Temp(cg);
    Emit(cg, "  %%t%u = icmp slt %s %%t%u, %%t%u\n", cmp, ty, a, b);
    uint32_t result = Emit_Temp(cg);
    Emit(cg, "  %%t%u = select i1 %%t%u, %s %%t%u, %s %%t%u\n", result, cmp, ty, a, ty, b);
    Temp_Set_Type(cg, result, ty);
    return result;
}

/* Structure returned by Emit_Exception_Handler_Setup */
typedef struct {
    uint32_t handler_frame;   /* Alloca for { ptr, [200 x i8] } */
    uint32_t jmp_buf;         /* GEP to jmp_buf field */
    uint32_t normal_label;    /* Label for normal execution path */
    uint32_t handler_label;   /* Label for exception handler path */
} Exception_Setup;

/* Setup exception handler with setjmp. Emits alloca, push_handler, setjmp, branch.
 * Caller must emit labels and code for normal/handler paths.
 * Returns structure with handler_frame, jmp_buf temps, and label IDs. */
static Exception_Setup Emit_Exception_Handler_Setup(Code_Generator *cg) {
    Exception_Setup setup;
    setup.handler_frame = Emit_Temp(cg);
    Emit(cg, "  %%t%u = alloca { ptr, [200 x i8] }, align 16  ; handler frame\n", setup.handler_frame);
    Emit(cg, "  call void @__ada_push_handler(ptr %%t%u)\n", setup.handler_frame);
    setup.jmp_buf = Emit_Temp(cg);
    Emit(cg, "  %%t%u = getelementptr { ptr, [200 x i8] }, ptr %%t%u, i32 0, i32 1\n",
         setup.jmp_buf, setup.handler_frame);
    uint32_t setjmp_result = Emit_Temp(cg);
    Emit(cg, "  %%t%u = call i32 @setjmp(ptr %%t%u)\n", setjmp_result, setup.jmp_buf);
    uint32_t is_normal = Emit_Temp(cg);
    Emit(cg, "  %%t%u = icmp eq i32 %%t%u, 0\n", is_normal, setjmp_result);
    setup.normal_label = Emit_Label(cg);
    setup.handler_label = Emit_Label(cg);
    Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n",
         is_normal, setup.normal_label, setup.handler_label);
    cg->block_terminated = true;  /* conditional branch terminates block */
    return setup;
}

/* Emit code to get current exception identity (after exception raised).
 * Returns temp holding i64 exception ID. */
static uint32_t Emit_Current_Exception_Id(Code_Generator *cg) {
    uint32_t exc_id = Emit_Temp(cg);
    Emit(cg, "  %%t%u = call i64 @__ada_current_exception()\n", exc_id);
    return exc_id;
}

/* Forward declarations for exception handler dispatch */
static void Generate_Statement_List(Code_Generator *cg, Node_List *list);
static void Emit_Branch_If_Needed(Code_Generator *cg, uint32_t label);
static void Emit_Exception_Ref(Code_Generator *cg, Symbol *sym);

/* Generate exception handler dispatch code for a list of handlers.
 * exc_id = temp holding current exception identity (i64)
 * end_label = label to branch to after handler completes
 * handlers = list of NK_EXCEPTION_HANDLER nodes */
static void Generate_Exception_Dispatch(Code_Generator *cg, Node_List *handlers,
                                         uint32_t exc_id, uint32_t end_label)
{
    uint32_t next_handler = 0;
    for (uint32_t i = 0; i < handlers->count; i++) {
        Syntax_Node *handler = handlers->items[i];
        if (not handler) continue;

        if (next_handler != 0) {
            Emit_Label_Here(cg, next_handler);
            cg->block_terminated = false;
        }
        next_handler = Emit_Label(cg);
        uint32_t handler_body = Emit_Label(cg);

        /* Check each exception name in the handler */
        bool has_others = false;
        for (uint32_t j = 0; j < handler->handler.exceptions.count; j++) {
            Syntax_Node *exc_name = handler->handler.exceptions.items[j];
            if (exc_name->kind == NK_OTHERS) {
                has_others = true;
                break;
            }
        }

        if (has_others) {
            Emit(cg, "  br label %%L%u\n", handler_body);
        } else {
            for (uint32_t j = 0; j < handler->handler.exceptions.count; j++) {
                Syntax_Node *exc_name = handler->handler.exceptions.items[j];
                if (exc_name->symbol) {
                    uint32_t exc_ptr = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = ptrtoint ptr ", exc_ptr);
                    Emit_Exception_Ref(cg, exc_name->symbol);
                    Emit(cg, " to i64\n");
                    uint32_t match = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = icmp eq i64 %%t%u, %%t%u\n", match, exc_id, exc_ptr);
                    bool is_last = true;
                    for (uint32_t k = j + 1; k < handler->handler.exceptions.count; k++) {
                        if (handler->handler.exceptions.items[k]->symbol) { is_last = false; break; }
                    }
                    uint32_t fail_label = is_last ? next_handler : Emit_Label(cg);
                    Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n", match, handler_body, fail_label);
                    if (not is_last) {
                        Emit_Label_Here(cg, fail_label);
                        cg->block_terminated = false;
                    }
                }
            }
        }
        cg->block_terminated = true;

        /* Handler body */
        Emit_Label_Here(cg, handler_body);
        cg->block_terminated = false;
        Generate_Statement_List(cg, &handler->handler.statements);
        Emit_Branch_If_Needed(cg, end_label);
    }

    /* If no handler matched, reraise */
    if (next_handler != 0) {
        Emit_Label_Here(cg, next_handler);
        cg->block_terminated = false;
        Emit(cg, "  call void @__ada_reraise()\n");
        Emit(cg, "  unreachable\n");
        cg->block_terminated = true;
    }
}

/* Emit lexicographic array comparison for unconstrained arrays.
 * Compares common prefix via memcmp, then compares lengths.
 * Returns i32 result: <0 if left<right, 0 if equal, >0 if left>right.
 * left_ptr/right_ptr are fat pointers, bt = bound type. */
static uint32_t Emit_Array_Lex_Compare(Code_Generator *cg,
    uint32_t left_ptr, uint32_t right_ptr, uint32_t elem_size, const char *bt)
{
    /* Extract bounds and data pointers */
    uint32_t left_low = Emit_Fat_Pointer_Low(cg, left_ptr, bt);
    uint32_t left_high = Emit_Fat_Pointer_High(cg, left_ptr, bt);
    uint32_t right_low = Emit_Fat_Pointer_Low(cg, right_ptr, bt);
    uint32_t right_high = Emit_Fat_Pointer_High(cg, right_ptr, bt);
    uint32_t left_len = Emit_Length_From_Bounds(cg, left_low, left_high, bt);
    uint32_t right_len = Emit_Length_From_Bounds(cg, right_low, right_high, bt);
    uint32_t left_data = Emit_Fat_Pointer_Data(cg, left_ptr, bt);
    uint32_t right_data = Emit_Fat_Pointer_Data(cg, right_ptr, bt);

    /* min_len = min(left_len, right_len) */
    uint32_t min_len = Emit_Min_Value(cg, left_len, right_len, bt);

    /* byte_size = min_len * elem_size */
    uint32_t byte_size_nat = Emit_Temp(cg);
    Emit(cg, "  %%t%u = mul %s %%t%u, %u\n", byte_size_nat, bt, min_len, elem_size);
    uint32_t byte_size = Emit_Extend_To_I64(cg, byte_size_nat, bt);

    /* prefix_cmp = memcmp(left_data, right_data, byte_size) */
    uint32_t prefix_cmp = Emit_Temp(cg);
    Emit(cg, "  %%t%u = call i32 @memcmp(ptr %%t%u, ptr %%t%u, i64 %%t%u)\n",
         prefix_cmp, left_data, right_data, byte_size);

    /* If prefix differs, return prefix_cmp; otherwise return len_diff */
    uint32_t len_diff = Emit_Temp(cg);
    Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", len_diff, bt, left_len, right_len);
    uint32_t len_diff32 = Emit_Temp(cg);
    Emit(cg, "  %%t%u = trunc %s %%t%u to i32\n", len_diff32, bt, len_diff);
    uint32_t prefix_zero = Emit_Temp(cg);
    Emit(cg, "  %%t%u = icmp eq i32 %%t%u, 0\n", prefix_zero, prefix_cmp);
    uint32_t result = Emit_Temp(cg);
    Emit(cg, "  %%t%u = select i1 %%t%u, i32 %%t%u, i32 %%t%u\n",
         result, prefix_zero, len_diff32, prefix_cmp);
    return result;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §13.2.2 Named-SSA Fat Pointer Helpers for RTS Functions
 *
 * RTS function bodies (emitted as LLVM IR text with named registers like
 * %fat1, %data, etc.) cannot use the temp-ID helpers above.  These helpers
 * emit the same patterns but with caller-supplied named SSA prefixes.
 *
 * With { ptr, ptr } layout, bounds must be allocated and filled first,
 * then the fat pointer is built as { data_ptr, bounds_ptr }.
 * ───────────────────────────────────────────────────────────────────────── */

/* Build a fat pointer { ptr, ptr } from named SSA values.
 * Allocates a bounds struct on the secondary stack (not allocanot ) so the
 * bounds pointer remains valid after the function returns.  This is critical
 * for RTS functions that return fat pointers.
 * Emits: %<prefix>_bnd = call ptr @__ada_sec_stack_alloc(i64 N)
 *        %<prefix>_lo_gep, %<prefix>_hi_gep = GEP + store
 *        %<prefix>1 = insertvalue { ptr, ptr } undef, <data_expr>, 0
 *        %<prefix>2 = insertvalue { ptr, ptr } %<prefix>1, ptr %<prefix>_bnd, 1
 * The result value is %<prefix>2.
 */
static void Emit_Fat_Pointer_Insertvalue_Named(Code_Generator *cg,
    const char *prefix, const char *data_expr,
    const char *low_expr, const char *high_expr, const char *bt)
{
    const char *bst = Bounds_Type_For(bt);
    /* Allocate bounds struct { bt, bt } on secondary stack (survives function return) */
    Emit(cg, "  %%%s_bnd = call ptr @__ada_sec_stack_alloc(i64 %d)\n",
         prefix, Bounds_Alloc_Size(bt));
    /* Store low bound in native bt */
    Emit(cg, "  %%%s_lo_gep = getelementptr %s, ptr %%%s_bnd, i32 0, i32 0\n",
         prefix, bst, prefix);
    Emit(cg, "  store %s, ptr %%%s_lo_gep\n", low_expr, prefix);
    /* Store high bound in native bt */
    Emit(cg, "  %%%s_hi_gep = getelementptr %s, ptr %%%s_bnd, i32 0, i32 1\n",
         prefix, bst, prefix);
    Emit(cg, "  store %s, ptr %%%s_hi_gep\n", high_expr, prefix);
    /* Build { ptr, ptr } via insertvalue */
    Emit(cg, "  %%%s1 = insertvalue " FAT_PTR_TYPE " undef, %s, 0\n", prefix, data_expr);
    Emit(cg, "  %%%s2 = insertvalue " FAT_PTR_TYPE " %%%s1, ptr %%%s_bnd, 1\n",
         prefix, prefix, prefix);
}

/* Extract data pointer, low bound, and high bound from a named SSA fat pointer.
 * Extracts bounds_ptr (field 1), then GEP+load for low and high.
 * src_name:       name of the source fat pointer SSA value  (e.g., "str" for %str)
 * data_name:      name for extracted data pointer            (e.g., "data")
 * low_name:       name for extracted low bound               (e.g., "low32")
 * high_name:      name for extracted high bound              (e.g., "high32")
 * bt:             bound type string                           (e.g., "i32")
 */
static void Emit_Fat_Pointer_Extractvalue_Named(Code_Generator *cg,
    const char *src_name, const char *data_name,
    const char *low_name, const char *high_name, const char *bt)
{
    const char *bst = Bounds_Type_For(bt);
    /* Extract data pointer (field 0) */
    Emit(cg, "  %%%s = extractvalue " FAT_PTR_TYPE " %%%s, 0\n", data_name, src_name);
    /* Extract bounds pointer (field 1) */
    Emit(cg, "  %%%s_bptr = extractvalue " FAT_PTR_TYPE " %%%s, 1\n", src_name, src_name);
    /* GEP + load low bound in native bt */
    Emit(cg, "  %%%s_gep = getelementptr %s, ptr %%%s_bptr, i32 0, i32 0\n",
         low_name, bst, src_name);
    Emit(cg, "  %%%s = load %s, ptr %%%s_gep\n", low_name, bt, low_name);
    /* GEP + load high bound in native bt */
    Emit(cg, "  %%%s_gep = getelementptr %s, ptr %%%s_bptr, i32 0, i32 1\n",
         high_name, bst, src_name);
    Emit(cg, "  %%%s = load %s, ptr %%%s_gep\n", high_name, bt, high_name);
}

/* Emit a named-SSA widen from bound type to INTEGER width for intrinsic/RTS use.
 * If bt is already at INTEGER width, emits a no-op copy (add 0).
 * src_name:  name of the source SSA value (in bt)
 * dst_name:  name for the widened value
 * bt:        the bound type string
 * Uses sext (signed extension) — for unsigned types use the _Unsigned variant. */
static void Emit_Widen_Named_For_Intrinsic(Code_Generator *cg,
    const char *src_name, const char *dst_name, const char *bt)
{
    const char *iat = Integer_Arith_Type(cg);
    if (strcmp(bt, iat) == 0) {
        /* Already at INTEGER width — emit a trivial add-0 to create the alias */
        Emit(cg, "  %%%s = add %s %%%s, 0\n", dst_name, iat, src_name);
    } else {
        Emit(cg, "  %%%s = sext %s %%%s to %s\n", dst_name, bt, src_name, iat);
    }
}

/* Emit a named-SSA narrow from INTEGER width to bound type after intrinsic/RTS.
 * If bt is already at INTEGER width, emits a no-op copy.
 * src_name:  name of the source SSA value (INTEGER width)
 * dst_name:  name for the narrowed bt value
 * bt:        the target bound type string */
static void Emit_Narrow_Named_From_Intrinsic(Code_Generator *cg,
    const char *src_name, const char *dst_name, const char *bt)
{
    const char *iat = Integer_Arith_Type(cg);
    if (strcmp(bt, iat) == 0) {
        Emit(cg, "  %%%s = add %s %%%s, 0\n", dst_name, iat, src_name);
    } else {
        Emit(cg, "  %%%s = trunc %s %%%s to %s\n", dst_name, iat, src_name, bt);
    }
}

/* Build a null fat pointer value: { ptr null, ptr null }.
 * Returns temp ID of the constructed value.  bt = bound type (unused). */
static uint32_t Emit_Fat_Pointer_Null(Code_Generator *cg, const char *bt) {
    (void)bt;
    uint32_t t1 = Emit_Temp(cg);
    uint32_t t2 = Emit_Temp(cg);
    Emit(cg, "  %%t%u = insertvalue " FAT_PTR_TYPE " undef, ptr null, 0\n", t1);
    Emit(cg, "  %%t%u = insertvalue " FAT_PTR_TYPE " %%t%u, ptr null, 1\n", t2, t1);
    return t2;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §13.3 Expression Code Generation
 *
 * Returns the LLVM SSA value ID holding the expression result.
 * Every expression yields a value, and in SSA form every value has one definition.
 * ───────────────────────────────────────────────────────────────────────── */


/* ─────────────────────────────────────────────────────────────────────────
 * Generate_Lvalue — Return a ptr to the storage location of an lvalue.
 *
 * Handles:
 *   NK_IDENTIFIER   — symbol storage (local, global, or uplevel)
 *   NK_SELECTED     — record field offset from base address
 *   NK_APPLY        — array element address (indexed component)
 *   NK_UNARY_OP/ALL — .ALL dereference (load pointer value)
 *
 * Returns a temp holding ptr to the storage.  Caller can then:
 *   - load from it  (expression context)
 *   - store to it   (assignment context)
 * ───────────────────────────────────────────────────────────────────────── */
static uint32_t Generate_Lvalue(Code_Generator *cg, Syntax_Node *node) {
    if (not node) return 0;

    /* NK_IDENTIFIER: return ptr to the symbol's storage */
    if (node->kind == NK_IDENTIFIER) {
        Symbol *sym = node->symbol;
        if (not sym) return 0;

        /* For RENAMES: redirect to renamed object */
        if (sym->renamed_object) {
            return Generate_Lvalue(cg, sym->renamed_object);
        }

        uint32_t t = Emit_Temp(cg);
        Emit(cg, "  %%t%u = getelementptr i8, ptr ", t);
        Emit_Symbol_Storage(cg, sym);
        Emit(cg, ", i64 0  ; lvalue of %.*s\n",
             (int)sym->name.length, sym->name.data);
        return t;
    }

    /* NK_SELECTED: record field access — compute base + field offset */
    if (node->kind == NK_SELECTED) {
        Type_Info *prefix_type = node->selected.prefix ? node->selected.prefix->type : NULL;

        /* Explicit .ALL dereference: load pointer value */
        if (Type_Is_Access(prefix_type) and
            Slice_Equal_Ignore_Case(node->selected.selector, S("ALL"))) {
            /* The pointer IS the lvalue target */
            uint32_t ptr = Generate_Expression(cg, node->selected.prefix);
            Emit_Access_Check(cg, ptr, prefix_type);
            return ptr;
        }

        /* Determine effective record type (handle implicit dereference) */
        Type_Info *record_type = prefix_type;
        bool implicit_deref = false;
        if (Type_Is_Access(prefix_type) and
            Type_Is_Record(prefix_type->access.designated_type)) {
            record_type = prefix_type->access.designated_type;
            implicit_deref = true;
        }

        if (Type_Is_Record(record_type)) {
            /* Find field offset and component index */
            uint32_t byte_offset = 0;
            uint32_t comp_idx = 0;
            for (uint32_t i = 0; i < record_type->record.component_count; i++) {
                if (Slice_Equal_Ignore_Case(
                        record_type->record.components[i].name,
                        node->selected.selector)) {
                    byte_offset = record_type->record.components[i].byte_offset;
                    comp_idx = i;
                    break;
                }
            }

            /* Get base pointer */
            uint32_t base;
            if (implicit_deref) {
                base = Generate_Expression(cg, node->selected.prefix);
                Emit_Access_Check(cg, base, prefix_type);
            } else {
                base = Generate_Lvalue(cg, node->selected.prefix);
            }

            /* GEP to field offset — use runtime offset for dynamic records */
            uint32_t field_ptr = Emit_Temp(cg);
            /* Walk base/parent chain to find rt_global_id (covers subtypes) */
            uint32_t rec_rt_id = record_type->rt_global_id;
            if (rec_rt_id == 0) {
                Type_Info *walk = record_type->base_type ? record_type->base_type
                                                         : record_type->parent_type;
                for (int depth = 0; walk and depth < 10; depth++) {
                    if (walk->rt_global_id > 0) { rec_rt_id = walk->rt_global_id; break; }
                    walk = walk->base_type ? walk->base_type : walk->parent_type;
                }
            }
            if (rec_rt_id > 0) {
                uint32_t off_r = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load i64, ptr @__rt_rec_%u_off%u\n",
                     off_r, rec_rt_id, comp_idx);
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %%t%u"
                     "  ; rt field lvalue\n", field_ptr, base, off_r);
            } else {
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %u"
                     "  ; field lvalue\n", field_ptr, base, byte_offset);
            }
            return field_ptr;
        }

        /* Package-qualified name: return lvalue (address) of the resolved symbol.
         * E.g. PACK1.ARG1 where PACK1 is a package and ARG1 is a variable inside it.
         * We must NOT fall through to Generate_Expression which would load the value. */
        if (node->symbol) {
            uint32_t t = Emit_Temp(cg);
            Emit(cg, "  %%t%u = getelementptr i8, ptr ", t);
            Emit_Symbol_Storage(cg, node->symbol);
            Emit(cg, ", i64 0  ; lvalue of pkg-qualified %.*s\n",
                 (int)node->symbol->name.length, node->symbol->name.data);
            return t;
        }
    }

    /* NK_UNARY_OP with TK_ALL: .ALL dereference — load the pointer value */
    if (node->kind == NK_UNARY_OP and node->unary.op == TK_ALL) {
        uint32_t ptr = Generate_Expression(cg, node->unary.operand);
        return ptr;
    }

    /* NK_APPLY: array indexed component — compute element address */
    if (node->kind == NK_APPLY and node->apply.prefix) {
        Type_Info *prefix_type = node->apply.prefix->type;
        bool implicit_access_deref = false;
        if (Type_Is_Access(prefix_type) and prefix_type->access.designated_type) {
            Type_Info *desig = prefix_type->access.designated_type;
            if (desig->kind == TYPE_ARRAY or desig->kind == TYPE_STRING) {
                implicit_access_deref = true;
                prefix_type = desig;
            }
        }
        if (prefix_type and (prefix_type->kind == TYPE_ARRAY or
                            prefix_type->kind == TYPE_STRING)) {
            /* Get array base pointer */
            Symbol *array_sym = node->apply.prefix->symbol;
            uint32_t base;
            bool has_dynamic_low = false;
            uint32_t dynamic_low = 0, dyn_fat = 0;
            const char *dyn_lv_bt = NULL;

            uint32_t dynamic_high = 0;

            if (implicit_access_deref) {
                /* Access-to-array: load the access value to get array data pointer */
                base = Generate_Expression(cg, node->apply.prefix);
            } else if (array_sym and (Type_Is_Unconstrained_Array(prefix_type) or
                              Type_Has_Dynamic_Bounds(prefix_type))) {
                /* Unconstrained array: load fat pointer, extract data ptr */
                const char *bt = Array_Bound_Llvm_Type(prefix_type);
                dyn_lv_bt = bt;
                uint32_t fat = Emit_Load_Fat_Pointer(cg, array_sym, bt);
                dyn_fat = fat;
                base = Emit_Fat_Pointer_Data(cg, fat, bt);
                dynamic_low = Emit_Fat_Pointer_Low(cg, fat, bt);
                dynamic_high = Emit_Fat_Pointer_High(cg, fat, bt);
                has_dynamic_low = true;
            } else if (array_sym) {
                base = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr i8, ptr ", base);
                Emit_Symbol_Storage(cg, array_sym);
                Emit(cg, ", i64 0  ; array base\n");
            } else {
                base = Generate_Expression(cg, node->apply.prefix);
            }

            /* Generate index expression (supports multi-dimensional arrays) */
            if (node->apply.arguments.count > 0) {
                const char *idx_lv_iat = Integer_Arith_Type(cg);
                uint32_t ndims = prefix_type->array.index_count;
                uint32_t nargs = node->apply.arguments.count;
                uint32_t flat_idx;

                if (ndims > 1 and nargs >= ndims) {
                    /* Multi-dimensional: linearize indices.
                     * flat_idx = sum over d of (idx[d] - lo[d]) * stride[d]
                     * where stride[d] = product of lengths of dims d+1..ndims-1 */
                    for (uint32_t d = 0; d < ndims; d++) {
                        Syntax_Node *arg_d = node->apply.arguments.items[d];
                        uint32_t dim_idx = Generate_Expression(cg, arg_d);
                        const char *dim_src = Expression_Llvm_Type(cg, arg_d);
                        if (dim_src and dim_src[0] == 'i' and strcmp(dim_src, idx_lv_iat) != 0)
                            dim_idx = Emit_Convert(cg, dim_idx, dim_src, idx_lv_iat);
                        /* Subtract low bound for dimension d */
                        if (has_dynamic_low and dyn_fat) {
                            uint32_t lo_d = Emit_Fat_Pointer_Low_Dim(cg, dyn_fat, dyn_lv_bt, d);
                            lo_d = Emit_Convert(cg, lo_d, dyn_lv_bt, idx_lv_iat);
                            uint32_t adj = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u  ; lv dim %u dyn low adj\n",
                                 adj, idx_lv_iat, dim_idx, lo_d, d);
                            dim_idx = adj;
                        } else {
                            int128_t lo_d = Type_Bound_Value(prefix_type->array.indices[d].low_bound);
                            if (lo_d != 0) {
                                uint32_t adj = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = sub %s %%t%u, %s  ; lv dim %u low adj\n",
                                     adj, idx_lv_iat, dim_idx, I128_Decimal(lo_d), d);
                                dim_idx = adj;
                            }
                        }
                        /* Compute stride: product of inner dimension lengths */
                        if (has_dynamic_low and dyn_fat) {
                            uint32_t stride_val = 0;
                            for (uint32_t d2 = d + 1; d2 < ndims; d2++) {
                                uint32_t len_d2 = Emit_Fat_Pointer_Length_Dim(cg, dyn_fat, dyn_lv_bt, d2);
                                len_d2 = Emit_Convert(cg, len_d2, dyn_lv_bt, idx_lv_iat);
                                if (stride_val == 0) {
                                    stride_val = len_d2;
                                } else {
                                    uint32_t product = Emit_Temp(cg);
                                    Emit(cg, "  %%t%u = mul %s %%t%u, %%t%u\n",
                                         product, idx_lv_iat, stride_val, len_d2);
                                    stride_val = product;
                                }
                            }
                            if (stride_val != 0) {
                                uint32_t scaled = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = mul %s %%t%u, %%t%u  ; lv dim %u dyn stride\n",
                                     scaled, idx_lv_iat, dim_idx, stride_val, d);
                                dim_idx = scaled;
                            }
                        } else {
                            uint32_t stride = 1;
                            for (uint32_t d2 = d + 1; d2 < ndims; d2++) {
                                int128_t lo2 = Type_Bound_Value(prefix_type->array.indices[d2].low_bound);
                                int128_t hi2 = Type_Bound_Value(prefix_type->array.indices[d2].high_bound);
                                int128_t cnt2 = hi2 - lo2 + 1;
                                if (cnt2 > 0) stride *= (uint32_t)cnt2;
                            }
                            if (stride > 1) {
                                uint32_t scaled = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = mul %s %%t%u, %u  ; lv dim %u stride\n",
                                     scaled, idx_lv_iat, dim_idx, stride, d);
                                dim_idx = scaled;
                            }
                        }
                        if (d == 0) {
                            flat_idx = dim_idx;
                        } else {
                            uint32_t sum = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add %s %%t%u, %%t%u\n",
                                 sum, idx_lv_iat, flat_idx, dim_idx);
                            flat_idx = sum;
                        }
                    }
                } else {
                    /* Single-dimension indexing */
                    Syntax_Node *arg = node->apply.arguments.items[0];
                    uint32_t idx = Generate_Expression(cg, arg);
                    const char *idx_src = Expression_Llvm_Type(cg, arg);
                    if (idx_src and idx_src[0] == 'i' and strcmp(idx_src, idx_lv_iat) != 0)
                        idx = Emit_Convert(cg, idx, idx_src, idx_lv_iat);

                    if (has_dynamic_low and dynamic_high) {
                        uint32_t lo_chk = Emit_Convert(cg, dynamic_low, dyn_lv_bt, idx_lv_iat);
                        uint32_t hi_chk = Emit_Convert(cg, dynamic_high, dyn_lv_bt, idx_lv_iat);
                        idx = Emit_Index_Check(cg, idx, lo_chk, hi_chk, idx_lv_iat, prefix_type);
                    } else if (prefix_type->array.index_count > 0) {
                        int128_t lo = Type_Bound_Value(prefix_type->array.indices[0].low_bound);
                        int128_t hi = Type_Bound_Value(prefix_type->array.indices[0].high_bound);
                        if (lo != hi || lo != 0) {
                            uint32_t lo_t = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add %s 0, %s  ; lv low bound\n", lo_t, idx_lv_iat, I128_Decimal(lo));
                            uint32_t hi_t = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add %s 0, %s  ; lv high bound\n", hi_t, idx_lv_iat, I128_Decimal(hi));
                            idx = Emit_Index_Check(cg, idx, lo_t, hi_t, idx_lv_iat, prefix_type);
                        }
                    }
                    if (has_dynamic_low) {
                        uint32_t dynamic_low_conv = Emit_Convert(cg, dynamic_low, dyn_lv_bt, idx_lv_iat);
                        uint32_t adj = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", adj, idx_lv_iat, idx, dynamic_low_conv);
                        idx = adj;
                    } else {
                        int128_t low_bound = Array_Low_Bound(prefix_type);
                        if (low_bound != 0) {
                            uint32_t adj = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = sub %s %%t%u, %s\n",
                                 adj, idx_lv_iat, idx, I128_Decimal(low_bound));
                            idx = adj;
                        }
                    }
                    flat_idx = idx;
                }

                /* Compute element address */
                Type_Info *elem_type_info = prefix_type->array.element_type;
                const char *elem_type = Type_To_Llvm(elem_type_info);
                uint32_t ptr = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, %s %%t%u  ; elem lvalue\n",
                     ptr, elem_type, base, idx_lv_iat, flat_idx);
                return ptr;
            }
        }
    }

    /* Fallback: treat expression result as pointer (for composite types
     * that Generate_Expression already returns as ptr) */
    return Generate_Expression(cg, node);
}

/* Generate code to evaluate a type bound at runtime.
 * Returns the temp register containing the bound value. */
static uint32_t Generate_Bound_Value(Code_Generator *cg, Type_Bound b, const char *target_type) {
    uint32_t t = cg->temp_id++;
    const char *bt = target_type ? target_type : Integer_Arith_Type(cg);
    if (b.kind == BOUND_INTEGER) {
        Emit(cg, "  %%t%u = add %s 0, %s  ; bound (integer)\n", t, bt, I128_Decimal(b.int_value));
        Temp_Set_Type(cg, t, bt);
        return t;
    }
    if (b.kind == BOUND_FLOAT) {
        /* Note: "double" here is intentional — %e produces a double-precision
         * LLVM IR literal, matching the fptosi source type.  This converts a
         * real-valued bound constant to integer, not a typed expression. */
        Emit(cg, "  %%t%u = fptosi double %e to %s  ; bound (float)\n", t, b.float_value, bt);
        Temp_Set_Type(cg, t, bt);
        return t;
    }
    if (b.kind == BOUND_EXPR and b.expr) {
        /* First try compile-time evaluation */
        double val = Eval_Const_Numeric(b.expr);
        if (val == val) {  /* Not NaN */
            Emit(cg, "  %%t%u = add %s 0, %lld  ; bound (const expr)\n", t, bt, (long long)val);
            Temp_Set_Type(cg, t, bt);
            return t;
        }
        /* Must evaluate expression at runtime */
        uint32_t expr_t = Generate_Expression(cg, b.expr);
        if (bt) {
            const char *expr_llvm = Expression_Llvm_Type(cg, b.expr);
            if (expr_llvm and strcmp(expr_llvm, bt) != 0)
                expr_t = Emit_Convert(cg, expr_t, expr_llvm, bt);
            Temp_Set_Type(cg, expr_t, bt);
        }
        return expr_t;
    }
    Emit(cg, "  %%t%u = add %s 0, 0  ; bound (unknown)\n", t, bt);
    Temp_Set_Type(cg, t, bt);
    return t;
}

static uint32_t Generate_Integer_Literal(Code_Generator *cg, Syntax_Node *node) {
    uint32_t t = Emit_Temp(cg);
    /* Emit literal at the expression's native type width */
    const char *lit_type = node->type ? Type_To_Llvm(node->type) : Integer_Arith_Type(cg);
    if (node->integer_lit.big_value) {
        /* Value may exceed int64_t range — use Big_Integer_To_Int128 */
        int128_t val128;
        if (Big_Integer_To_Int128(node->integer_lit.big_value, &val128)) {
            Emit(cg, "  %%t%u = add %s 0, %s\n", t, lit_type, I128_Decimal(val128));
        } else {
            /* Value doesn't fit in int128 — fall back to int64 (shouldn't happen) */
            Emit(cg, "  %%t%u = add %s 0, %lld\n", t, lit_type, (long long)node->integer_lit.value);
        }
    } else {
        Emit(cg, "  %%t%u = add %s 0, %lld\n", t, lit_type, (long long)node->integer_lit.value);
    }
    Temp_Set_Type(cg, t, lit_type);
    return t;
}

static uint32_t Generate_Real_Literal(Code_Generator *cg, Syntax_Node *node) {
    uint32_t t = Emit_Temp(cg);
    /* Use IEEE 754 hex encoding for full precision
     * This preserves all 53 bits of mantissa (vs %f which loses precision)
     * The double value was computed from Big_Real during parsing */
    double d = node->real_lit.value;
    uint64_t bits;
    memcpy(&bits, &d, sizeof(bits));
    Emit(cg, "  %%t%u = fadd double 0.0, 0x%016llX\n", t, (unsigned long long)bits);
    Temp_Set_Type(cg, t, "double");
    return t;
}

static uint32_t Generate_String_Literal(Code_Generator *cg, Syntax_Node *node) {
    /* Allocate string constant */
    uint32_t str_id = cg->string_id++;
    uint32_t len = node->string_val.text.length;

    /* Generate global constant to buffer (without null terminator for Ada strings)
     * Use linkonce_odr to allow merging of duplicate string constants across units */
    Emit_String_Const(cg, "@.str%u = linkonce_odr unnamed_addr constant [%u x i8] c\"", str_id, len);
    for (uint32_t i = 0; i < len; i++) {
        char c = node->string_val.text.data[i];
        if (c >= 32 and c < 127 and c != '"' and c != '\\') {
            Emit_String_Const_Char(cg, c);
        } else {
            Emit_String_Const(cg, "\\%02X", (unsigned char)c);
        }
    }
    Emit_String_Const(cg, "\"\n");

    /* Get pointer to string data */
    uint32_t data_ptr = Emit_Temp(cg);
    Emit(cg, "  %%t%u = getelementptr [%u x i8], ptr @.str%u, i64 0, i64 0\n",
         data_ptr, len, str_id);

    /* Return fat pointer with Ada STRING bounds (1..length) */
    return Emit_Fat_Pointer(cg, data_ptr, 1, (int128_t)len, Array_Bound_Llvm_Type(node->type));
}

static uint32_t Generate_Identifier(Code_Generator *cg, Syntax_Node *node) {
    Symbol *sym = node->symbol;
    if (not sym) {
        Report_Error(node->location, "unresolved identifier in codegen");
        return 0;
    }
    /* Generic formal object substitution: if this is a formal object inside
     * a generic instantiation, generate code for the actual expression. */
    if (cg->current_instance and cg->current_instance->generic_actuals) {
        for (uint32_t i = 0; i < cg->current_instance->generic_actual_count; i++) {
            if (cg->current_instance->generic_actuals[i].actual_expr and
                Slice_Equal_Ignore_Case(sym->name,
                    cg->current_instance->generic_actuals[i].formal_name)) {
                return Generate_Expression(cg,
                    cg->current_instance->generic_actuals[i].actual_expr);
            }
        }
    }

    /* For RENAMES: redirect to the renamed object */
    if (sym->renamed_object) {
        return Generate_Expression(cg, sym->renamed_object);
    }

    uint32_t t = Emit_Temp(cg);
    Type_Info *ty = sym->type;

    /* Resolve generic formal types to their actuals for correct LLVM type sizing.
     * E.g. generic formal T (<>) mapped to COLOR (i8) — must load as i8, not i32. */
    if (cg->current_instance and ty)
        ty = Resolve_Generic_Actual_Type(cg, ty);

    switch (sym->kind) {
        case SYMBOL_VARIABLE:
        case SYMBOL_PARAMETER:
        case SYMBOL_DISCRIMINANT: {
            /* Check if symbol is stored as a fat pointer (dynamic/unconstrained arrays).
             * This flag is set at symbol creation time when bounds were dynamic.
             * Must take priority over Type_Is_Constrained_Array which may change
             * after bounds are resolved to static values. */
            if (sym->needs_fat_ptr_storage) {
                const char *dbt = Array_Bound_Llvm_Type(ty);
                uint32_t fat = Emit_Load_Fat_Pointer(cg, sym, dbt);
                return fat;
            }
            /* Also check at codegen time in case symbol was created via a path
             * that doesn't go through Symbol_Add (e.g., semantic pass creates
             * constrained subtypes with dynamic bounds). */
            if (ty and (Type_Has_Dynamic_Bounds(ty) or Type_Is_Unconstrained_Array(ty)) and
                (sym->kind == SYMBOL_VARIABLE or sym->kind == SYMBOL_PARAMETER)) {
                const char *dbt = Array_Bound_Llvm_Type(ty);
                uint32_t fat = Emit_Load_Fat_Pointer(cg, sym, dbt);
                return fat;
            }
            /* Constrained arrays with static bounds are flat allocas.
             * The alloca address IS the value — no load needed. */
            if (Type_Is_Constrained_Array(ty)) {
                /* Return pointer to the alloca directly (no load) */
                Emit(cg, "  %%t%u = getelementptr i8, ptr ", t);
                Emit_Symbol_Storage(cg, sym);
                Emit(cg, ", i64 0  ; constrained array ref\n");
                break;
            }
            /* Records are composite types stored as [N x i8] allocas.
             * Like constrained arrays, the alloca address IS the value —
             * no load needed. */
            if (Type_Is_Record(ty)) {
                Emit(cg, "  %%t%u = getelementptr i8, ptr ", t);
                Emit_Symbol_Storage(cg, sym);
                Emit(cg, ", i64 0  ; record ref\n");
                break;
            }
            const char *type_str = Type_To_Llvm(ty);
            Emit(cg, "  %%t%u = load %s, ptr ", t, type_str);
            Emit_Symbol_Storage(cg, sym);
            Emit(cg, "\n");
            Temp_Set_Type(cg, t, type_str);
            /* No widening — value stays at native type width.
             * Expression_Llvm_Type returns the native type, and Emit_Convert
             * handles any needed conversions at use sites. */
        } break;

        case SYMBOL_CONSTANT:
        case SYMBOL_LITERAL:
            /* Enumeration literal or constant */
            if (sym->kind == SYMBOL_LITERAL and Type_Is_Enumeration(sym->type)) {
                /* Find position in enumeration */
                int64_t pos = 0;
                for (uint32_t i = 0; i < sym->type->enumeration.literal_count; i++) {
                    if (Slice_Equal_Ignore_Case(sym->type->enumeration.literals[i], sym->name)) {
                        pos = i;
                        break;
                    }
                }
                { const char *ety = Type_To_Llvm(sym->type);
                Emit(cg, "  %%t%u = add %s 0, %lld\n", t, ety, (long long)pos);
                Temp_Set_Type(cg, t, ety); }
            } else if (sym->kind == SYMBOL_LITERAL and Type_Is_Boolean(ty)) {
                /* Boolean literal: TRUE=1, FALSE=0 — native type width */
                int64_t pos = Slice_Equal_Ignore_Case(sym->name, S("TRUE")) ? 1 : 0;
                { const char *bty = Type_To_Llvm(ty);
                Emit(cg, "  %%t%u = add %s 0, %lld\n", t, bty, (long long)pos);
                Temp_Set_Type(cg, t, bty); }
            } else if (sym->kind == SYMBOL_LITERAL and Type_Is_Character(ty)) {
                /* Character literal — native type width */
                { const char *cty = Type_To_Llvm(ty);
                Emit(cg, "  %%t%u = add %s 0, 0  ; character literal\n", t, cty);
                Temp_Set_Type(cg, t, cty); }
            } else if (sym->needs_fat_ptr_storage) {
                /* Constant stored as fat pointer (dynamic bounds at declaration) */
                const char *dbt = Array_Bound_Llvm_Type(ty);
                uint32_t fat = Emit_Load_Fat_Pointer(cg, sym, dbt);
                return fat;
            } else if (Type_Is_Constrained_Array(ty)) {
                /* Constrained array constant - return pointer to data.
                 * Fat pointer wrapping is handled at call sites when needed. */
                Emit(cg, "  %%t%u = getelementptr i8, ptr ", t);
                Emit_Symbol_Storage(cg, sym);
                Emit(cg, ", i64 0\n");
                return t;
            } else if (sym->kind == SYMBOL_CONSTANT and sym->is_named_number) {
                /* Named number (constant without explicit type) - evaluate initializer
                 * Named numbers in Ada are compile-time constants with no storage.
                 * Per RM 3.2.2: "A named number provides a name for a numeric value
                 * known at compile time." */
                Syntax_Node *decl = sym->declaration;
                if (decl and decl->kind == NK_OBJECT_DECL and decl->object_decl.init) {
                    /* Try compile-time evaluation first.  Named numbers are
                     * UNIVERSAL_INTEGER / UNIVERSAL_REAL and may involve
                     * expressions like 2**31 that overflow i32 at runtime. */
                    double cv = Eval_Const_Numeric(decl->object_decl.init);
                    const char *named_t = ty ? Type_To_Llvm(ty) : Integer_Arith_Type(cg);
                    if (cv == cv) {  /* not NaN — constant evaluation succeeded */
                        if (Type_Is_Float_Representation(ty)) {
                            uint64_t bits; memcpy(&bits, &cv, sizeof(bits));
                            Emit(cg, "  %%t%u = fadd double 0.0, 0x%016llX  ; named number %g\n",
                                 t, (unsigned long long)bits, cv);
                            Temp_Set_Type(cg, t, "double");
                        } else {
                            Emit(cg, "  %%t%u = add %s 0, %lld  ; named number\n",
                                 t, named_t, (long long)(int64_t)cv);
                            Temp_Set_Type(cg, t, named_t);
                        }
                    } else {
                        /* Fallback to codegen for initializer expression */
                        uint32_t result = Generate_Expression(cg, decl->object_decl.init);
                        const char *init_t = Expression_Llvm_Type(cg, decl->object_decl.init);
                        return Emit_Convert(cg, result, init_t, named_t);
                    }
                } else if (sym->frame_offset != 0 or Type_Is_Character(ty)) {
                    /* Predefined constant (e.g. ASCII.NUL) with value in frame_offset */
                    const char *named_t = ty ? Type_To_Llvm(ty) : Integer_Arith_Type(cg);
                    Emit(cg, "  %%t%u = add %s 0, %lld  ; predefined constant\n",
                         t, named_t, (long long)sym->frame_offset);
                    Temp_Set_Type(cg, t, named_t);
                } else {
                    /* ??? Fallback if no initializer found */
                    Emit(cg, "  %%t%u = add %s 0, 0  ; named number without init\n", t, Integer_Arith_Type(cg));
                    Temp_Set_Type(cg, t, Integer_Arith_Type(cg));
                }
            } else if (sym->kind == SYMBOL_CONSTANT and not sym->is_named_number and
                       Type_Is_Record(ty)) {
                /* Record constant: return pointer to storage (no load) */
                Emit(cg, "  %%t%u = getelementptr i8, ptr ", t);
                Emit_Symbol_Storage(cg, sym);
                Emit(cg, ", i64 0  ; record constant ref\n");
            } else if (sym->kind == SYMBOL_CONSTANT and not sym->is_named_number) {
                /* Typed constant: try compile-time evaluation first.
                 * Constants from WITHed packages (e.g. TEXT_IO.UNBOUNDED)
                 * may not have global definitions if the package body was
                 * separately compiled.  Inlining avoids unresolved symbols. */
                Syntax_Node *cdecl = sym->declaration;
                double cv = (cdecl and cdecl->kind == NK_OBJECT_DECL and cdecl->object_decl.init)
                    ? Eval_Const_Numeric(cdecl->object_decl.init) : __builtin_nan("");
                const char *type_str = Type_To_Llvm(ty);
                if (cv == cv and not Type_Is_Float_Representation(ty)) {
                    /* Integer constant with known value - inline it */
                    Emit(cg, "  %%t%u = add %s 0, %lld  ; typed constant\n",
                         t, type_str, (long long)(int64_t)cv);
                    Temp_Set_Type(cg, t, type_str);
                } else if (cv == cv and Type_Is_Float_Representation(ty)) {
                    const char *ftype = type_str;  /* float or double from Type_To_Llvm */
                    char comment[64];
                    snprintf(comment, sizeof(comment), "typed constant %g", cv);
                    Emit_Float_Constant(cg, t, ftype, cv, comment);
                    Temp_Set_Type(cg, t, ftype);
                } else {
                    /* Cannot evaluate at compile time - load from storage */
                    Emit(cg, "  %%t%u = load %s, ptr ", t, type_str);
                    Emit_Symbol_Storage(cg, sym);
                    Emit(cg, "\n");
                    Temp_Set_Type(cg, t, type_str);
                }
            } else {
                /* ??? Unknown literal type - emit 0 as fallback */
                Emit(cg, "  %%t%u = add %s 0, 0  ; unknown literal\n", t, Integer_Arith_Type(cg));
            }
            break;

        case SYMBOL_FUNCTION: {
            /* Parameterless function call: F is syntactically an identifier
             * but semantically a function call with zero arguments.
             * Generic formal subprogram substitution: if this is a formal subprogram
             * inside a generic instantiation, substitute with actual. */
            Symbol *actual = sym;
            if (cg->current_instance and cg->current_instance->generic_actuals) {
                for (uint32_t i = 0; i < cg->current_instance->generic_actual_count; i++) {
                    if (cg->current_instance->generic_actuals[i].actual_subprogram and
                        Slice_Equal_Ignore_Case(sym->name,
                            cg->current_instance->generic_actuals[i].formal_name)) {
                        actual = cg->current_instance->generic_actuals[i].actual_subprogram;
                        break;
                    }
                }
            }

            /* Check if actual is an enumeration literal (e.g., RED, YELLOW) */
            if (actual->kind == SYMBOL_LITERAL and Type_Is_Enumeration(actual->type)) {
                int64_t pos = 0;
                for (uint32_t i = 0; i < actual->type->enumeration.literal_count; i++) {
                    if (Slice_Equal_Ignore_Case(actual->type->enumeration.literals[i],
                                                actual->name)) {
                        pos = i;
                        break;
                    }
                }
                { const char *efty = Type_To_Llvm(actual->type);
                Emit(cg, "  %%t%u = add %s 0, %lld  ; enum literal as function\n",
                     t, efty, (long long)pos);
                Temp_Set_Type(cg, t, efty); }
            } else if (actual->kind == SYMBOL_FUNCTION) {
                /* Generate actual function call */
                const char *ret_type = actual->return_type ?
                    Type_To_Llvm_Sig(actual->return_type) : Integer_Arith_Type(cg);
                bool callee_is_nested = Subprogram_Needs_Static_Chain(actual);
                uint32_t frame_pre = callee_is_nested ?
                    Precompute_Nested_Frame_Arg(cg, actual) : 0;
                Emit(cg, "  %%t%u = call %s @", t, ret_type);
                Emit_Symbol_Name(cg, actual);
                if (callee_is_nested) {
                    Emit(cg, "(");
                    Emit_Nested_Frame_Arg(cg, actual, frame_pre);
                    Emit(cg, ")\n");
                } else {
                    Emit(cg, "()\n");
                }
                /* No widening — return value stays at native type width. */
                Temp_Set_Type(cg, t, ret_type);
            } else {
                /* Fallback for other symbol kinds */
                Emit(cg, "  %%t%u = add %s 0, 0  ; unhandled function symbol\n", t, Integer_Arith_Type(cg));
            }
        } break;

        default:
            /* ??? */
            Emit(cg, "  %%t%u = add %s 0, 0  ; unhandled symbol kind\n", t, Integer_Arith_Type(cg));
    }

    return t;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §13.3.1 Implicit Operators for Composite Types
 *
 * Ada requires equality operators for all non-limited types. For composite
 * types (records, arrays), equality is defined component-wise.
 * ───────────────────────────────────────────────────────────────────────── */

/* Forward declaration for mutual recursion */
static uint32_t Generate_Array_Equality(Code_Generator *cg, uint32_t left_ptr,
                                        uint32_t right_ptr, Type_Info *array_type);

/* Generate equality comparison for record types (component-by-component) */
static uint32_t Generate_Record_Equality(Code_Generator *cg, uint32_t left_ptr,
                                         uint32_t right_ptr, Type_Info *record_type) {
    if (not Type_Is_Record(record_type) or
        record_type->record.component_count == 0) {
        /* Empty record or invalid - always equal */
        if (not Type_Is_Record(record_type))
            fprintf(stderr, "warning: record equality called on non-record type\n");
        uint32_t t = Emit_Temp(cg);
        Emit(cg, "  %%t%u = add i1 0, 1  ; empty record equality\n", t);
        return t;
    }

    uint32_t result = 0;
    for (uint32_t i = 0; i < record_type->record.component_count; i++) {
        Component_Info *comp = &record_type->record.components[i];
        const char *comp_llvm_type = Type_To_Llvm(comp->component_type);

        /* Get pointers to components */
        uint32_t left_gep = Emit_Temp(cg);
        uint32_t right_gep = Emit_Temp(cg);
        Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %u\n",
             left_gep, left_ptr, comp->byte_offset);
        Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %u\n",
             right_gep, right_ptr, comp->byte_offset);

        /* Compare component - handle arrays/strings specially */
        uint32_t cmp;
        Type_Info *ct = comp->component_type;
        bool is_fat_ptr_access = Type_Is_Access(ct) and
            Type_Needs_Fat_Pointer(ct);

        if (Type_Is_Unconstrained_Array(ct) or
            (not Type_Is_Constrained_Array(ct) and Type_Is_String(ct))) {
            /* Unconstrained array/string - load fat pointer values from storage */
            const char *ct_bt = Array_Bound_Llvm_Type(ct);
            uint32_t left_fat = Emit_Load_Fat_Pointer_From_Temp(cg, left_gep, ct_bt);
            uint32_t right_fat = Emit_Load_Fat_Pointer_From_Temp(cg, right_gep, ct_bt);
            cmp = Generate_Array_Equality(cg, left_fat, right_fat, ct);
        } else if (Type_Is_Constrained_Array(ct) and Type_Has_Dynamic_Bounds(ct)) {
            /* Constrained array with dynamic bounds (discriminant-dependent).
             * Data stored inline; compute runtime byte size from discriminant.
             * For ARRAY(LOW..DISC) OF ELEM: size = max(0, disc - low + 1) * elem_size */
            uint32_t elem_size = ct->array.element_type ? ct->array.element_type->size : 1;
            if (elem_size == 0) elem_size = 1;
            int64_t low_val = 1;
            if (ct->array.index_count > 0 and ct->array.indices[0].low_bound.kind == BOUND_INTEGER)
                low_val = (int64_t)ct->array.indices[0].low_bound.int_value;
            /* Find the discriminant that controls the high bound.
             * Match the bound expression's symbol against the record's discriminant components. */
            uint32_t disc_offset = 0;
            const char *disc_llvm = "i32";
            if (ct->array.index_count > 0 and ct->array.indices[0].high_bound.kind == BOUND_EXPR
                and ct->array.indices[0].high_bound.expr) {
                Symbol *bsym = ct->array.indices[0].high_bound.expr->symbol;
                for (uint32_t d = 0; d < record_type->record.discriminant_count; d++) {
                    Component_Info *dc = &record_type->record.components[d];
                    if (bsym and Slice_Equal_Ignore_Case(dc->name, bsym->name)) {
                        disc_offset = dc->byte_offset;
                        disc_llvm = Type_To_Llvm(dc->component_type);
                        if (not disc_llvm) disc_llvm = "i32";
                        break;
                    }
                }
            }
            /* Load discriminant from left record and compute memcmp size */
            uint32_t dp = Emit_Temp(cg), dv = Emit_Temp(cg);
            Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %u\n", dp, left_ptr, disc_offset);
            Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", dv, disc_llvm, dp);
            uint32_t cnt = Emit_Temp(cg), sz64 = Emit_Temp(cg);
            Emit(cg, "  %%t%u = sub %s %%t%u, %lld\n", cnt, disc_llvm, dv, (long long)(low_val - 1));
            if (elem_size > 1) {
                uint32_t mul = Emit_Temp(cg);
                Emit(cg, "  %%t%u = mul %s %%t%u, %u\n", mul, disc_llvm, cnt, elem_size);
                cnt = mul;
            }
            /* Clamp to 0 for null arrays */
            uint32_t is_neg = Emit_Temp(cg), clamped = Emit_Temp(cg);
            Emit(cg, "  %%t%u = icmp slt %s %%t%u, 0\n", is_neg, disc_llvm, cnt);
            Emit(cg, "  %%t%u = select i1 %%t%u, %s 0, %s %%t%u\n", clamped, is_neg, disc_llvm, disc_llvm, cnt);
            Emit(cg, "  %%t%u = sext %s %%t%u to i64\n", sz64, disc_llvm, clamped);
            uint32_t mc_r = Emit_Temp(cg), mc_c = Emit_Temp(cg);
            Emit(cg, "  %%t%u = call i32 @memcmp(ptr %%t%u, ptr %%t%u, i64 %%t%u)\n",
                 mc_r, left_gep, right_gep, sz64);
            Emit(cg, "  %%t%u = icmp eq i32 %%t%u, 0\n", mc_c, mc_r);
            cmp = mc_c;
        } else if (Type_Is_Constrained_Array(ct)) {
            /* Constrained array with static bounds - use array equality directly on pointers */
            cmp = Generate_Array_Equality(cg, left_gep, right_gep, ct);
        } else if (Type_Is_Record(ct)) {
            /* Nested record - recurse */
            cmp = Generate_Record_Equality(cg, left_gep, right_gep, ct);
        } else if (is_fat_ptr_access) {
            /* ACCESS to unconstrained array - compare fat pointer identity */
            const char *acc_bt = Array_Bound_Llvm_Type(ct->access.designated_type);
            uint32_t left_val = Emit_Load_Fat_Pointer_From_Temp(cg, left_gep, acc_bt);
            uint32_t right_val = Emit_Load_Fat_Pointer_From_Temp(cg, right_gep, acc_bt);
            cmp = Emit_Fat_Pointer_Compare(cg, left_val, right_val, acc_bt);
        } else {
            /* Scalar type - load and compare */
            uint32_t left_val = Emit_Temp(cg);
            uint32_t right_val = Emit_Temp(cg);
            Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", left_val, comp_llvm_type, left_gep);
            Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", right_val, comp_llvm_type, right_gep);

            cmp = Emit_Temp(cg);
            if (Type_Is_Float_Representation(ct)) {
                Emit(cg, "  %%t%u = fcmp oeq %s %%t%u, %%t%u\n",
                     cmp, comp_llvm_type, left_val, right_val);
            } else {
                Emit(cg, "  %%t%u = icmp eq %s %%t%u, %%t%u\n",
                     cmp, comp_llvm_type, left_val, right_val);
            }
        }

        /* AND with previous results */
        if (i == 0) {
            result = cmp;
        } else {
            uint32_t and_result = Emit_Temp(cg);
            Emit(cg, "  %%t%u = and i1 %%t%u, %%t%u\n", and_result, result, cmp);
            result = and_result;
        }
    }

    return result;
}

/* Generate equality comparison for constrained array types (element-by-element) */
static uint32_t Generate_Array_Equality(Code_Generator *cg, uint32_t left_ptr,
                                        uint32_t right_ptr, Type_Info *array_type) {
    if (not Type_Is_Array_Like(array_type)) {
        fprintf(stderr, "warning: array equality called on non-array type\n");
        uint32_t t = Emit_Temp(cg);
        Emit(cg, "  %%t%u = add i1 0, 1  ; invalid array equality\n", t);
        return t;
    }

    /* For constrained arrays with static bounds, use memcmp.
     * Dynamic-bounds constrained arrays use fat pointers at runtime,
     * so fall through to the unconstrained path. */
    if (array_type->array.is_constrained and not Type_Has_Dynamic_Bounds(array_type)) {
        int128_t count = Array_Element_Count(array_type);
        uint32_t elem_size = array_type->array.element_type ?
                             array_type->array.element_type->size : 4;
        int64_t total_size = count * elem_size;

        /* If inputs are actually fat pointers, extract data pointers */
        const char *lty = Temp_Get_Type(cg, left_ptr);
        if (lty and Llvm_Type_Is_Fat_Pointer(lty)) {
            const char *bt = Array_Bound_Llvm_Type(array_type);
            left_ptr = Emit_Fat_Pointer_Data(cg, left_ptr, bt);
        }
        const char *rty = Temp_Get_Type(cg, right_ptr);
        if (rty and Llvm_Type_Is_Fat_Pointer(rty)) {
            const char *bt = Array_Bound_Llvm_Type(array_type);
            right_ptr = Emit_Fat_Pointer_Data(cg, right_ptr, bt);
        }

        /* Use memcmp for byte-by-byte comparison */
        return Emit_Memcmp_Eq(cg, left_ptr, right_ptr, 0, total_size, false);
    }

    /*
     * Unconstrained array equality (per RM 4.5.2):
     * Two arrays are equal iff they have the same length and matching components.
     * Bounds themselves need not match—only length and content.
     *
     * For fat pointers: compare lengths, then data if lengths match.
     * Use select instead of phi to avoid block label complications.
     */

    /*
     * For unconstrained arrays, left_ptr/right_ptr are fat pointer VALUES
     * (not pointers to storage).  All callers must ensure they pass loaded
     * fat pointer values: { ptr, { bound, bound } }.
     */

    /* Extract bounds and compute lengths for ALL dimensions (RM 4.5.2).
     * For multidimensional arrays, each dimension's length must match and
     * the total byte count is the product of all dimension lengths × elem_size. */
    const char *aeq_bt = Array_Bound_Llvm_Type(array_type);
    const char *aeq_iat = Integer_Arith_Type(cg);
    uint32_t ndims = array_type->array.index_count;
    if (ndims < 1) ndims = 1;

    /* Compare lengths for each dimension and accumulate total element count */
    uint32_t all_len_eq = 0;          /* AND of all dimension length comparisons */
    uint32_t total_elems = 0;          /* product of all dimension lengths */
    for (uint32_t d = 0; d < ndims; d++) {
        uint32_t ll = Emit_Fat_Pointer_Low_Dim(cg, left_ptr, aeq_bt, d);
        uint32_t lh = Emit_Fat_Pointer_High_Dim(cg, left_ptr, aeq_bt, d);
        uint32_t rl = Emit_Fat_Pointer_Low_Dim(cg, right_ptr, aeq_bt, d);
        uint32_t rh = Emit_Fat_Pointer_High_Dim(cg, right_ptr, aeq_bt, d);
        uint32_t l_len = Emit_Length_From_Bounds(cg, ll, lh, aeq_bt);
        uint32_t r_len = Emit_Length_From_Bounds(cg, rl, rh, aeq_bt);
        uint32_t dim_eq = Emit_Temp(cg);
        Emit(cg, "  %%t%u = icmp eq %s %%t%u, %%t%u\n", dim_eq, aeq_bt, l_len, r_len);
        if (d == 0) {
            all_len_eq = dim_eq;
            total_elems = Emit_Convert(cg, l_len, aeq_bt, aeq_iat);
        } else {
            uint32_t merged = Emit_Temp(cg);
            Emit(cg, "  %%t%u = and i1 %%t%u, %%t%u\n", merged, all_len_eq, dim_eq);
            all_len_eq = merged;
            uint32_t l_conv = Emit_Convert(cg, l_len, aeq_bt, aeq_iat);
            uint32_t prod = Emit_Temp(cg);
            Emit(cg, "  %%t%u = mul %s %%t%u, %%t%u\n", prod, aeq_iat, total_elems, l_conv);
            total_elems = prod;
        }
    }

    /* Extract data pointers */
    uint32_t left_data = Emit_Fat_Pointer_Data(cg, left_ptr, aeq_bt);
    uint32_t right_data = Emit_Fat_Pointer_Data(cg, right_ptr, aeq_bt);

    /* Compute byte size for memcmp: total_elems * scalar_elem_size */
    uint32_t elem_size = array_type->array.element_type ?
                         array_type->array.element_type->size : 1;
    uint32_t byte_size = Emit_Temp(cg);
    Emit(cg, "  %%t%u = mul %s %%t%u, %u\n", byte_size, aeq_iat, total_elems, elem_size);
    uint32_t byte_size_64 = Emit_Extend_To_I64(cg, byte_size, aeq_iat);

    /* Call memcmp */
    uint32_t data_eq = Emit_Memcmp_Eq(cg, left_data, right_data, byte_size_64, 0, true);

    /* Result: all dimension lengths match AND data matches */
    uint32_t result = Emit_Temp(cg);
    Emit(cg, "  %%t%u = and i1 %%t%u, %%t%u\n", result, all_len_eq, data_eq);

    return result;
}

/* Generate the address of a composite type expression (for equality comparison) */
static uint32_t Generate_Composite_Address(Code_Generator *cg, Syntax_Node *node) {
    /* Generate the ADDRESS of an lvalue (identifier, selected, indexed) */
    if (node->kind == NK_IDENTIFIER) {
        Symbol *sym = node->symbol;
        if (sym) {
            uint32_t t = Emit_Temp(cg);
            Emit(cg, "  %%t%u = getelementptr i8, ptr ", t);
            Emit_Symbol_Storage(cg, sym);
            Emit(cg, ", i64 0\n");
            return t;
        }
    }

    if (node->kind == NK_SELECTED) {
        /* Field access: Rec.Field - compute address of field */
        Type_Info *prefix_type = node->selected.prefix ? node->selected.prefix->type : NULL;

        /* Handle implicit dereference: U.A where U is access-to-record.
         * First load the pointer, then compute field address. */
        Type_Info *record_type = prefix_type;
        bool implicit_deref = false;
        if (Type_Is_Access(prefix_type) and
            Type_Is_Record(prefix_type->access.designated_type)) {
            record_type = prefix_type->access.designated_type;
            implicit_deref = true;
        }

        if (Type_Is_Record(record_type)) {
            uint32_t base;
            if (implicit_deref) {
                /* Load the access value (pointer to record) */
                Symbol *access_sym = node->selected.prefix->symbol;
                base = Emit_Temp(cg);
                if (access_sym) {
                    Emit(cg, "  %%t%u = load ptr, ptr ", base);
                    Emit_Symbol_Storage(cg, access_sym);
                    Emit(cg, "  ; implicit deref for field address\n");
                } else {
                    uint32_t ptr = Generate_Expression(cg, node->selected.prefix);
                    base = ptr;  /* Already a ptr from access expr */
                }
                Emit_Access_Check(cg, base, prefix_type);
            } else {
                base = Generate_Composite_Address(cg, node->selected.prefix);
            }
            /* Find field offset and component index */
            uint32_t offset = 0;
            uint32_t comp_idx = 0;
            for (uint32_t i = 0; i < record_type->record.component_count; i++) {
                if (Slice_Equal_Ignore_Case(
                        record_type->record.components[i].name, node->selected.selector)) {
                    offset = record_type->record.components[i].byte_offset;
                    comp_idx = i;
                    break;
                }
            }
            /* Walk base/parent chain to find rt_global_id (covers subtypes) */
            uint32_t rec_rt_id = record_type->rt_global_id;
            if (rec_rt_id == 0) {
                Type_Info *walk = record_type->base_type ? record_type->base_type
                                                         : record_type->parent_type;
                for (int depth = 0; walk and depth < 10; depth++) {
                    if (walk->rt_global_id > 0) { rec_rt_id = walk->rt_global_id; break; }
                    walk = walk->base_type ? walk->base_type : walk->parent_type;
                }
            }
            uint32_t addr = Emit_Temp(cg);
            if (rec_rt_id > 0) {
                uint32_t off_r = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load i64, ptr @__rt_rec_%u_off%u\n",
                     off_r, rec_rt_id, comp_idx);
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %%t%u"
                     "  ; rt composite addr\n", addr, base, off_r);
            } else {
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %u\n", addr, base, offset);
            }
            return addr;
        }
    }

    /* .ALL dereference: address of P.ALL = value of P (the pointer itself) */
    if (node->kind == NK_UNARY_OP and node->unary.op == TK_ALL and node->unary.operand) {
        Symbol *access_sym = node->unary.operand->symbol;
        if (access_sym) {
            uint32_t t = Emit_Temp(cg);
            Emit(cg, "  %%t%u = load ptr, ptr ", t);
            Emit_Symbol_Storage(cg, access_sym);
            Emit(cg, "  ; .ALL address (deref access)\n");
            return t;
        }
        /* For non-symbol expressions, evaluate to get the pointer */
        return Generate_Expression(cg, node->unary.operand);
    }

    if (node->kind == NK_APPLY and node->apply.arguments.count == 1) {
        /* Array indexing or slice: Arr(I) or Arr(low..high) */
        Type_Info *prefix_type = node->apply.prefix ? node->apply.prefix->type : NULL;
        /* Handle implicit dereference: PT(I) where PT is access-to-array (RM 4.1) */
        Type_Info *array_type = prefix_type;
        bool access_to_array = false;
        if (Type_Is_Access(prefix_type) and prefix_type->access.designated_type and
            prefix_type->access.designated_type->kind == TYPE_ARRAY) {
            array_type = prefix_type->access.designated_type;
            access_to_array = true;
        }
        if (array_type and array_type->kind == TYPE_ARRAY) {
            uint32_t elem_size = array_type->array.element_type
                                 ? array_type->array.element_type->size : 1;
            if (elem_size == 0) elem_size = 1;
            int128_t low = Array_Low_Bound(array_type);

            /* Slice: ARR(low..high) — return address at slice start (RM 4.1.2) */
            Syntax_Node *arg0 = node->apply.arguments.items[0];
            if (arg0->kind == NK_RANGE) {
                uint32_t base;
                if (access_to_array) {
                    base = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = load ptr, ptr ", base);
                    Emit_Symbol_Storage(cg, node->apply.prefix->symbol);
                    Emit(cg, "  ; deref access-to-array for slice\n");
                } else {
                    base = Generate_Composite_Address(cg, node->apply.prefix);
                }
                uint32_t slice_low = Generate_Expression(cg, arg0->range.low);
                uint32_t adj = slice_low;
                const char *slice_idx_t = Integer_Arith_Type(cg);
                if (low != 0) {
                    adj = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = sub %s %%t%u, %s\n", adj, slice_idx_t, slice_low, I128_Decimal(low));
                }
                uint32_t byte_off = adj;
                if (elem_size != 1) {
                    byte_off = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = mul %s %%t%u, %u\n", byte_off, slice_idx_t, adj, elem_size);
                }
                uint32_t addr = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s %%t%u\n", addr, base, slice_idx_t, byte_off);
                return addr;
            }

            uint32_t base;
            if (access_to_array) {
                /* Dereference access-to-array: load pointer then index */
                base = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load ptr, ptr ", base);
                Emit_Symbol_Storage(cg, node->apply.prefix->symbol);
                Emit(cg, "  ; deref access-to-array\n");
            } else {
                base = Generate_Composite_Address(cg, node->apply.prefix);
            }
            uint32_t idx = Generate_Expression(cg, arg0);

            /* Adjust index: byte_offset = (idx - low) * elem_size */
            const char *comp_idx_t = Integer_Arith_Type(cg);
            /* Widen index to native integer (enum/bool indices may be i8/i1) */
            {
                const char *idx_src = Expression_Llvm_Type(cg, arg0);
                if (idx_src and idx_src[0] == 'i' and strcmp(idx_src, comp_idx_t) != 0)
                    idx = Emit_Convert(cg, idx, idx_src, comp_idx_t);
            }
            uint32_t adj_idx = idx;
            if (low != 0) {
                adj_idx = Emit_Temp(cg);
                Emit(cg, "  %%t%u = sub %s %%t%u, %lld\n", adj_idx, comp_idx_t, idx, (long long)low);
            }
            uint32_t byte_off = Emit_Temp(cg);
            if (elem_size == 1) {
                byte_off = adj_idx;
            } else {
                Emit(cg, "  %%t%u = mul %s %%t%u, %u\n", byte_off, comp_idx_t, adj_idx, elem_size);
            }
            uint32_t addr = Emit_Temp(cg);
            Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s %%t%u\n", addr, base, comp_idx_t, byte_off);
            return addr;
        }
        /* Handle unconstrained arrays passed as fat pointers */
        if (not Type_Is_Constrained_Array(prefix_type) and Type_Is_String(prefix_type)) {
            /* Fat pointer - extract data and compute element address */
            const char *str_bt = Array_Bound_Llvm_Type(prefix_type);
            uint32_t fat = Generate_Expression(cg, node->apply.prefix);
            uint32_t data = Emit_Fat_Pointer_Data(cg, fat, str_bt);
            uint32_t low = Emit_Fat_Pointer_Low(cg, fat, str_bt);
            const char *str_idx_t = Integer_Arith_Type(cg);
            uint32_t low_conv = Emit_Convert(cg, low, str_bt, str_idx_t);
            uint32_t idx = Generate_Expression(cg, node->apply.arguments.items[0]);
            uint32_t adj_idx = Emit_Temp(cg);
            Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", adj_idx, str_idx_t, idx, low_conv);
            uint32_t addr = Emit_Temp(cg);
            Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s %%t%u\n", addr, data, str_idx_t, adj_idx);
            return addr;
        }
    }

    /* Fallback: for expressions that return a pointer (like composite values) */
    return Generate_Expression(cg, node);
}

/* ─── Boolean Array Elementwise Op (RM 4.5.1) ───
 * Unrolled loop applying `ir_op` (and/or/xor) byte-by-byte.
 * Returns alloca ptr to result.  Binary variant (two operands). */
static uint32_t Emit_Bool_Array_Binop(Code_Generator *cg,
    uint32_t left, uint32_t right, Type_Info *result_type, const char *ir_op)
{
    int128_t count = Array_Element_Count(result_type);
    uint32_t n = (count > 0) ? (uint32_t)count
               : (result_type->size > 0 ? result_type->size : 1);
    uint32_t dst = Emit_Temp(cg);
    Emit(cg, "  %%t%u = alloca [%u x i8]  ; bool array %s result\n", dst, n, ir_op);
    for (uint32_t i = 0; i < n; i++) {
        uint32_t lp = Emit_Temp(cg), rp = Emit_Temp(cg);
        uint32_t lv = Emit_Temp(cg), rv = Emit_Temp(cg);
        uint32_t ov = Emit_Temp(cg), dp = Emit_Temp(cg);
        Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i32 %u\n", lp, left, i);
        Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i32 %u\n", rp, right, i);
        Emit(cg, "  %%t%u = load i8, ptr %%t%u\n", lv, lp);
        Emit(cg, "  %%t%u = load i8, ptr %%t%u\n", rv, rp);
        Emit(cg, "  %%t%u = %s i8 %%t%u, %%t%u\n", ov, ir_op, lv, rv);
        Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i32 %u\n", dp, dst, i);
        Emit(cg, "  store i8 %%t%u, ptr %%t%u\n", ov, dp);
    }
    Temp_Set_Type(cg, dst, "ptr");
    return dst;
}

/* Unary NOT for boolean arrays: xor each byte with 1. */
static uint32_t Emit_Bool_Array_Not(Code_Generator *cg,
    uint32_t operand, Type_Info *result_type)
{
    int128_t count = Array_Element_Count(result_type);
    uint32_t n = (count > 0) ? (uint32_t)count
               : (result_type->size > 0 ? result_type->size : 1);
    uint32_t dst = Emit_Temp(cg);
    Emit(cg, "  %%t%u = alloca [%u x i8]  ; bool array NOT result\n", dst, n);
    for (uint32_t i = 0; i < n; i++) {
        uint32_t sp = Emit_Temp(cg), sv = Emit_Temp(cg);
        uint32_t nv = Emit_Temp(cg), dp = Emit_Temp(cg);
        Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i32 %u\n", sp, operand, i);
        Emit(cg, "  %%t%u = load i8, ptr %%t%u\n", sv, sp);
        Emit(cg, "  %%t%u = xor i8 %%t%u, 1\n", nv, sv);
        Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i32 %u\n", dp, dst, i);
        Emit(cg, "  store i8 %%t%u, ptr %%t%u\n", nv, dp);
    }
    Temp_Set_Type(cg, dst, "ptr");
    return dst;
}

/* Test whether a type is a boolean array (for AND/OR/XOR/NOT dispatch). */
static inline bool Type_Is_Bool_Array(const Type_Info *t) {
    return t and Type_Is_Array_Like(t) and t->array.element_type
           and Type_Is_Boolean(t->array.element_type);
}

/* ─── Normalize Expression to Fat Pointer ───
 * Given an expression and its type, produce a fat pointer value.
 * Handles: already-fat, CHARACTER (alloca+store+wrap), constrained array (wrap). */
static uint32_t Normalize_To_Fat_Pointer(Code_Generator *cg,
    Syntax_Node *expr, uint32_t raw, Type_Info *type, const char *bt)
{
    if (Expression_Produces_Fat_Pointer(expr, type))
        return raw;
    if (Type_Is_Character(type)) {
        uint32_t ca = Emit_Temp(cg);
        Emit(cg, "  %%t%u = alloca i8\n", ca);
        uint32_t ct = Emit_Convert(cg, raw, Integer_Arith_Type(cg), "i8");
        Emit(cg, "  store i8 %%t%u, ptr %%t%u\n", ct, ca);
        return Emit_Fat_Pointer(cg, ca, 1, 1, bt);
    }
    if (Type_Is_Constrained_Array(type) and type->array.index_count > 0) {
        int128_t lo = Type_Bound_Value(type->array.indices[0].low_bound);
        int128_t hi = Type_Bound_Value(type->array.indices[0].high_bound);
        /* Discriminant-dependent bounds: Type_Bound_Value returns 0 for
         * BOUND_EXPR.  For aggregates, derive bounds from positional count.
         * For non-aggregates, load the discriminant at runtime. (RM 3.7.1) */
        if (Type_Has_Dynamic_Bounds(type) and expr and
            expr->kind == NK_AGGREGATE) {
            uint32_t n_pos = 0;
            for (uint32_t ai = 0; ai < expr->aggregate.items.count; ai++) {
                if (expr->aggregate.items.items[ai]->kind != NK_ASSOCIATION)
                    n_pos++;
            }
            if (n_pos > 0) hi = lo + (int128_t)n_pos - 1;
        }
        return Emit_Fat_Pointer(cg, raw, lo, hi, bt);
    }
    return raw;  /* fallback: assume already fat */
}

/* Check whether a positional aggregate of the given constrained array type
 * will produce a fat pointer from Generate_Aggregate.  Generate_Aggregate
 * overrides dim_hi[d] with a BOUND_INTEGER when dim_lo[d] is BOUND_INTEGER,
 * collapsing dynamic bounds to static.  So an aggregate only stays dynamic
 * when at least one dimension has a BOUND_EXPR lower bound (typically from
 * runtime expressions like IDENT_INT, NOT from discriminant references whose
 * low bound is a literal).  Returns false for non-array / non-dynamic types. */
static inline bool Aggregate_Produces_Fat_Pointer(const Type_Info *t) {
    if (not t or not Type_Has_Dynamic_Bounds(t) or not Type_Is_Array_Like(t))
        return false;
    for (uint32_t d = 0; d < t->array.index_count; d++) {
        Type_Bound lo = t->array.indices[d].low_bound;
        if (lo.kind == BOUND_NONE and t->array.indices[d].index_type)
            lo = t->array.indices[d].index_type->low_bound;
        if (lo.kind == BOUND_EXPR)
            return true;
    }
    return false;
}

/* Assign a runtime elaboration ID to a constrained array type with
 * BOUND_EXPR bounds and emit its LLVM globals (@__rt_type_<id>_size,
 * per-dimension _lo/_hi).  Idempotent: returns immediately if ID
 * already assigned or if the type has only static bounds. */
static void Ensure_Runtime_Type_Globals(Code_Generator *cg, Type_Info *t) {
    if (not t or t->rt_global_id > 0) return;
    if (not Type_Is_Array_Like(t) or not t->array.is_constrained) return;
    bool needs = false;
    for (uint32_t d = 0; d < t->array.index_count; d++) {
        Type_Bound lo = t->array.indices[d].low_bound;
        Type_Bound hi = t->array.indices[d].high_bound;
        if (lo.kind == BOUND_NONE and t->array.indices[d].index_type)
            lo = t->array.indices[d].index_type->low_bound;
        if (hi.kind == BOUND_NONE and t->array.indices[d].index_type)
            hi = t->array.indices[d].index_type->high_bound;
        /* Only trigger for non-discriminant BOUND_EXPR (function calls like
         * IDENT_INT(-3)).  Discriminant-dependent bounds (expr->symbol points
         * to a discriminant) are handled by the existing disc_dep path. */
        bool lo_rt = (lo.kind == BOUND_EXPR and
                      not (lo.expr and lo.expr->kind == NK_IDENTIFIER and lo.expr->symbol));
        bool hi_rt = (hi.kind == BOUND_EXPR and
                      not (hi.expr and hi.expr->kind == NK_IDENTIFIER and hi.expr->symbol));
        if (lo_rt or hi_rt)
            { needs = true; break; }
    }
    if (not needs) return;
    uint32_t id = ++cg->rt_type_counter;
    t->rt_global_id = id;
    Emit_String_Const(cg, "@__rt_type_%u_size = internal global i64 0\n", id);
    for (uint32_t d = 0; d < t->array.index_count; d++) {
        Emit_String_Const(cg, "@__rt_type_%u_lo%u = internal global i64 0\n", id, d);
        Emit_String_Const(cg, "@__rt_type_%u_hi%u = internal global i64 0\n", id, d);
    }
}

/* Generate expression and wrap as fat pointer if needed.
 * Like Normalize_To_Fat_Pointer but generates the expression internally.
 * Handles aggregates of unconstrained types specially (load pre-built fat ptr). */
static uint32_t Wrap_Constrained_As_Fat(Code_Generator *cg,
    Syntax_Node *expr, Type_Info *type, const char *bt)
{
    if (Expression_Produces_Fat_Pointer(expr, type))
        return Generate_Expression(cg, expr);
    /* Aggregates of unconstrained or truly-dynamic array types already build
     * their own fat pointer alloca in Generate_Aggregate.  Load it.
     * NOTE: Generate_Aggregate overrides dim_hi from positional element count
     * when dim_lo is BOUND_INTEGER, converting bounds to static.  So only
     * aggregates whose type has a BOUND_EXPR *lower* bound (in any dimension)
     * actually produce a fat pointer.  Discriminant-dependent bounds like
     * TB(1..A) have static lower bound → positional override → static array. */
    if (expr->kind == NK_AGGREGATE and type and Type_Is_Array_Like(type) and
        (Type_Is_Unconstrained_Array(type) or Aggregate_Produces_Fat_Pointer(type))) {
        uint32_t agg_ptr = Generate_Expression(cg, expr);
        uint32_t loaded = Emit_Temp(cg);
        Emit(cg, "  %%t%u = load " FAT_PTR_TYPE ", ptr %%t%u  ; load agg fat ptr\n",
             loaded, agg_ptr);
        return loaded;
    }
    uint32_t ptr = Generate_Composite_Address(cg, expr);
    int128_t lo = 1, hi = 0;
    if (Type_Is_Array_Like(type) and type->array.index_count > 0) {
        lo = Type_Bound_Value(type->array.indices[0].low_bound);
        hi = Type_Bound_Value(type->array.indices[0].high_bound);
        /* Discriminant-dependent bounds: for aggregates, use positional count */
        if (Type_Has_Dynamic_Bounds(type) and expr and
            expr->kind == NK_AGGREGATE) {
            uint32_t n_pos = 0;
            for (uint32_t ai = 0; ai < expr->aggregate.items.count; ai++) {
                if (expr->aggregate.items.items[ai]->kind != NK_ASSOCIATION)
                    n_pos++;
            }
            if (n_pos > 0) hi = lo + (int128_t)n_pos - 1;
        }
    }
    return Emit_Fat_Pointer(cg, ptr, lo, hi, bt);
}

/* ─── Convert Universal_Real to Fixed-Point Scaled Integer ───
 * For fixed type with small S, value V converts to: fptosi(V / S). */
static uint32_t Convert_Real_To_Fixed(Code_Generator *cg,
    uint32_t val, double small, const char *fix_type)
{
    uint64_t small_bits;
    memcpy(&small_bits, &small, sizeof(small_bits));
    uint32_t small_val = Emit_Temp(cg);
    Emit(cg, "  %%t%u = fadd double 0.0, 0x%016llX  ; small=%g\n",
         small_val, (unsigned long long)small_bits, small);
    uint32_t divided = Emit_Temp(cg);
    Emit(cg, "  %%t%u = fdiv double %%t%u, %%t%u\n", divided, val, small_val);
    uint32_t scaled = Emit_Temp(cg);
    Emit(cg, "  %%t%u = fptosi double %%t%u to %s\n", scaled, divided, fix_type);
    Temp_Set_Type(cg, scaled, fix_type);
    return scaled;
}

static uint32_t Get_Dimension_Index(Syntax_Node *arg);  /* forward decl */
static uint32_t Generate_Binary_Op(Code_Generator *cg, Syntax_Node *node) {
    /* User-defined operator: generate function call (RM 6.7) */
    if (node->symbol && node->symbol->kind == SYMBOL_FUNCTION &&
        !node->symbol->is_predefined) {
        uint32_t left = Generate_Expression(cg, node->binary.left);
        uint32_t right = Generate_Expression(cg, node->binary.right);
        const char *left_llvm = Expression_Llvm_Type(cg, node->binary.left);
        const char *right_llvm = Expression_Llvm_Type(cg, node->binary.right);
        Type_Info *p0_type = (node->symbol->parameter_count > 0) ?
            node->symbol->parameters[0].param_type : NULL;
        Type_Info *p1_type = (node->symbol->parameter_count > 1) ?
            node->symbol->parameters[1].param_type : NULL;
        const char *p0_llvm = p0_type ? Type_To_Llvm(p0_type) : left_llvm;
        const char *p1_llvm = p1_type ? Type_To_Llvm(p1_type) : right_llvm;
        left = Emit_Convert(cg, left, left_llvm, p0_llvm);
        right = Emit_Convert(cg, right, right_llvm, p1_llvm);
        const char *ret_type = node->symbol->return_type ?
            Type_To_Llvm(node->symbol->return_type) : "i32";
        bool callee_is_nested = Subprogram_Needs_Static_Chain(node->symbol);
        uint32_t frame_pre = callee_is_nested ?
            Precompute_Nested_Frame_Arg(cg, node->symbol) : 0;
        uint32_t result = Emit_Temp(cg);
        Emit(cg, "  %%t%u = call %s @", result, ret_type);
        Emit_Symbol_Name(cg, node->symbol);
        Emit(cg, "(");
        if (callee_is_nested) {
            Emit_Nested_Frame_Arg(cg, node->symbol, frame_pre);
            Emit(cg, ", ");
        }
        Emit(cg, "%s %%t%u, %s %%t%u)\n", p0_llvm, left, p1_llvm, right);
        return result;
    }

    /* Check if this is equality/inequality on composite types */
    Type_Info *left_type = node->binary.left ? node->binary.left->type : NULL;

    if ((node->binary.op == TK_EQ or node->binary.op == TK_NE) and
        left_type and Type_Is_Composite(left_type)) {
        /* Composite type comparison */
        uint32_t eq_result;

        bool left_is_slice = Expression_Is_Slice(node->binary.left);
        bool right_is_slice = Expression_Is_Slice(node->binary.right);
        Type_Info *right_type = node->binary.right ? node->binary.right->type : NULL;
        bool left_is_fat = Expression_Produces_Fat_Pointer(node->binary.left, left_type);
        bool right_is_fat = Expression_Produces_Fat_Pointer(node->binary.right, right_type);
        bool is_unconstrained = left_is_fat or right_is_fat;

        /* Handle slice comparisons specially - they have mixed representations */
        if ((left_is_slice or right_is_slice) and not is_unconstrained) {
            /* At least one slice with constrained type - generate inline comparison */
            uint32_t left_data, right_data;
            uint32_t left_low, left_high, right_low, right_high;
            uint32_t elem_size = left_type->array.element_type ?
                                 left_type->array.element_type->size : 8;

            const char *slice_bt = Array_Bound_Llvm_Type(left_type);
            /* Generate left operand */
            if (left_is_slice) {
                uint32_t left_fat = Generate_Expression(cg, node->binary.left);
                left_data = Emit_Fat_Pointer_Data(cg, left_fat, slice_bt);
                Bound_Temps lb = Emit_Bounds_From_Fat(cg, left_fat, slice_bt);
                left_low = lb.low_temp;
                left_high = lb.high_temp;
            } else {
                left_data = Generate_Composite_Address(cg, node->binary.left);
                Bound_Temps lb = Emit_Bounds(cg, left_type, 0);
                left_low = lb.low_temp;
                left_high = lb.high_temp;
            }

            /* Generate right operand */
            if (right_is_slice) {
                uint32_t right_fat = Generate_Expression(cg, node->binary.right);
                right_data = Emit_Fat_Pointer_Data(cg, right_fat, slice_bt);
                Bound_Temps rb = Emit_Bounds_From_Fat(cg, right_fat, slice_bt);
                right_low = rb.low_temp;
                right_high = rb.high_temp;
            } else {
                right_data = Generate_Composite_Address(cg, node->binary.right);
                Type_Info *rtype = node->binary.right->type ? node->binary.right->type : left_type;
                Bound_Temps rb = Emit_Bounds(cg, rtype, 0);
                right_low = rb.low_temp;
                right_high = rb.high_temp;
            }

            /* Compute lengths and compare */
            uint32_t left_len = Emit_Length_From_Bounds(cg, left_low, left_high, slice_bt);
            uint32_t right_len = Emit_Length_From_Bounds(cg, right_low, right_high, slice_bt);
            uint32_t len_eq = Emit_Temp(cg);
            Emit(cg, "  %%t%u = icmp eq %s %%t%u, %%t%u\n", len_eq, slice_bt, left_len, right_len);

            /* Compare data with memcmp */
            uint32_t byte_size_nat = Emit_Temp(cg);
            Emit(cg, "  %%t%u = mul %s %%t%u, %u\n", byte_size_nat, slice_bt, left_len, elem_size);
            uint32_t byte_size = Emit_Extend_To_I64(cg, byte_size_nat, slice_bt);
            uint32_t data_eq = Emit_Memcmp_Eq(cg, left_data, right_data, byte_size, 0, true);

            /* Result: lengths match AND data matches */
            eq_result = Emit_Temp(cg);
            Emit(cg, "  %%t%u = and i1 %%t%u, %%t%u\n", eq_result, len_eq, data_eq);
        } else if (left_is_fat or right_is_fat) {
            /* At least one operand produces a fat pointer.
             * Normalize both to fat pointers for uniform comparison. */
            uint32_t left_val, right_val;

            const char *eq_bt = Array_Bound_Llvm_Type(left_type);
            /* Normalize both operands to fat pointers for uniform comparison.
             * Constrained arrays get wrapped with static bounds. */
            left_val  = Wrap_Constrained_As_Fat(cg, node->binary.left,  left_type, eq_bt);
            right_val = Wrap_Constrained_As_Fat(cg, node->binary.right,
                node->binary.right->type ? node->binary.right->type : left_type, eq_bt);

            /* Use the unconstrained array equality path (compares lengths then data) */
            Type_Info *cmp_type = left_type;
            if (Type_Is_Constrained_Array(cmp_type) and (Type_Is_String(right_type) or
                Type_Is_Unconstrained_Array(right_type))) {
                cmp_type = right_type;  /* Use unconstrained type for comparison */
            }
            /* Ensure comparison uses unconstrained path */
            eq_result = Generate_Array_Equality(cg, left_val, right_val, cmp_type);
        } else {
            /* Standard path: both operands are constrained (same representation).
             * However, some expressions (concatenation, function calls) may still
             * produce fat pointers.  Extract data ptr if needed. */

            /* If both are constrained arrays but with different static sizes,
             * they cannot be equal (RM 4.5.2(9)).  Emit constant false. */
            if (right_type and Type_Is_Array_Like(left_type) and Type_Is_Array_Like(right_type) and
                left_type->size > 0 and right_type->size > 0 and
                left_type->size != right_type->size) {
                eq_result = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add i1 0, 0  ; arrays of different size\n", eq_result);
                goto eq_done;
            }

            uint32_t left_ptr, right_ptr;
            bool l_produces_fat = Expression_Produces_Fat_Pointer(node->binary.left, left_type);
            bool r_produces_fat = Expression_Produces_Fat_Pointer(node->binary.right, right_type);
            if (l_produces_fat) {
                uint32_t lfat = Generate_Expression(cg, node->binary.left);
                const char *lbt = Array_Bound_Llvm_Type(left_type);
                left_ptr = Emit_Fat_Pointer_Data(cg, lfat, lbt);
            } else {
                left_ptr = Generate_Composite_Address(cg, node->binary.left);
            }
            if (r_produces_fat) {
                uint32_t rfat = Generate_Expression(cg, node->binary.right);
                const char *rbt = Array_Bound_Llvm_Type(right_type ? right_type : left_type);
                right_ptr = Emit_Fat_Pointer_Data(cg, rfat, rbt);
            } else {
                right_ptr = Generate_Composite_Address(cg, node->binary.right);
            }
            eq_result = Emit_Temp(cg);

            if (left_type->equality_func_name) {
                const char *arg_type = Type_To_Llvm(left_type);
                Emit(cg, "  %%t%u = call i1 @%s(%s %%t%u, %s %%t%u)\n",
                     eq_result, left_type->equality_func_name, arg_type, left_ptr, arg_type, right_ptr);
            } else {
                if (Type_Is_Record(left_type)) {
                    eq_result = Generate_Record_Equality(cg, left_ptr, right_ptr, left_type);
                } else {
                    eq_result = Generate_Array_Equality(cg, left_ptr, right_ptr, left_type);
                }
            }
        }

        eq_done:
        /* For /= operator, negate the result */
        if (node->binary.op == TK_NE) {
            uint32_t ne_result = Emit_Temp(cg);
            Emit(cg, "  %%t%u = xor i1 %%t%u, 1\n", ne_result, eq_result);
            eq_result = ne_result;
        }
        /* Comparisons stay as i1 (Boolean_Data relationship) */
        return eq_result;
    }

    /* Array relational comparisons (lexicographic) */
    if ((node->binary.op == TK_LT or node->binary.op == TK_LE or
         node->binary.op == TK_GT or node->binary.op == TK_GE) and
        Type_Is_Array_Like(left_type)) {
        /* Get addresses of both arrays for comparison */
        uint32_t left_ptr, right_ptr;
        Type_Info *rhs_cmp_type = node->binary.right ? node->binary.right->type : NULL;
        /* An aggregate of an unconstrained type already builds its own fat
         * pointer alloca inside Generate_Aggregate.  Detect this so we can
         * just load it instead of double-wrapping with wrong bounds. */
        bool l_is_uncon_agg = (node->binary.left->kind == NK_AGGREGATE and
            node->binary.left->type and Type_Is_Unconstrained_Array(node->binary.left->type));
        bool r_is_uncon_agg = (node->binary.right and
            node->binary.right->kind == NK_AGGREGATE and
            node->binary.right->type and Type_Is_Unconstrained_Array(node->binary.right->type));
        bool is_unconstrained = Expression_Produces_Fat_Pointer(node->binary.left, left_type) or
                                Expression_Produces_Fat_Pointer(node->binary.right, rhs_cmp_type) or
                                l_is_uncon_agg or r_is_uncon_agg;
        const char *rel_bt = Array_Bound_Llvm_Type(left_type);
        if (is_unconstrained) {
            /* Generate each operand as fat pointer, wrapping constrained if needed */
            left_ptr = Wrap_Constrained_As_Fat(cg, node->binary.left, left_type, rel_bt);
            right_ptr = Wrap_Constrained_As_Fat(cg, node->binary.right, rhs_cmp_type, rel_bt);
        } else {
            left_ptr = Generate_Composite_Address(cg, node->binary.left);
            right_ptr = Generate_Composite_Address(cg, node->binary.right);
        }

        uint32_t memcmp_result, cmp_result;

        if (left_type->array.is_constrained and not is_unconstrained) {
            /* Constrained array: same size, use memcmp directly */
            int128_t count = Array_Element_Count(left_type);
            uint32_t elem_size = left_type->array.element_type ?
                                 left_type->array.element_type->size : 1;
            int64_t total_size = count * elem_size;

            memcmp_result = Emit_Temp(cg);
            Emit(cg, "  %%t%u = call i32 @memcmp(ptr %%t%u, ptr %%t%u, i64 %lld)\n",
                 memcmp_result, left_ptr, right_ptr, (long long)total_size);
        } else {
            /* Unconstrained array: lexicographic comparison via helper */
            uint32_t elem_size = left_type->array.element_type ?
                                 left_type->array.element_type->size : 1;
            memcmp_result = Emit_Array_Lex_Compare(cg, left_ptr, right_ptr, elem_size, rel_bt);
        }

        /* Compare memcmp result with 0 based on operator */
        cmp_result = Emit_Temp(cg);
        switch (node->binary.op) {
            case TK_LT:
                Emit(cg, "  %%t%u = icmp slt i32 %%t%u, 0\n", cmp_result, memcmp_result);
                break;
            case TK_LE:
                Emit(cg, "  %%t%u = icmp sle i32 %%t%u, 0\n", cmp_result, memcmp_result);
                break;
            case TK_GT:
                Emit(cg, "  %%t%u = icmp sgt i32 %%t%u, 0\n", cmp_result, memcmp_result);
                break;
            case TK_GE:
                Emit(cg, "  %%t%u = icmp sge i32 %%t%u, 0\n", cmp_result, memcmp_result);
                break;
            default:
                fprintf(stderr, "warning: unhandled array comparison operator, defaulting to equality\n");
                Emit(cg, "  %%t%u = icmp eq i32 %%t%u, 0\n", cmp_result, memcmp_result);
        }
        /* Comparisons stay as i1 */
        return cmp_result;
    }

    /* Short-circuit boolean operators: AND THEN, OR ELSE
     * These must NOT evaluate the right operand if the left operand
     * determines the result (Ada RM 4.5.1). */
    if (node->binary.op == TK_AND_THEN) {
        /* AND THEN: if left is false, result is false (don't evaluate right)
         *           if left is true, result is right */
        uint32_t left = Generate_Expression(cg, node->binary.left);
        const char *left_llvm = Expression_Llvm_Type(cg, node->binary.left);
        uint32_t left_i1 = Emit_Convert(cg, left, left_llvm, "i1");

        uint32_t eval_right_label = cg->label_id++;
        uint32_t done_label = cg->label_id++;
        uint32_t left_block_label = cg->label_id++;

        /* Save current block for phi */
        Emit(cg, "  br label %%Landthen_check%u\n", left_block_label);
        Emit(cg, "Landthen_check%u:\n", left_block_label);
        Emit(cg, "  br i1 %%t%u, label %%Landthen_right%u, label %%Landthen_done%u\n",
             left_i1, eval_right_label, done_label);

        /* Evaluate right if left was true */
        Emit(cg, "Landthen_right%u:\n", eval_right_label);
        uint32_t right = Generate_Expression(cg, node->binary.right);
        const char *right_llvm = Expression_Llvm_Type(cg, node->binary.right);
        uint32_t right_i1 = Emit_Convert(cg, right, right_llvm, "i1");
        uint32_t right_done_label = cg->label_id++;
        Emit(cg, "  br label %%Landthen_merge%u\n", right_done_label);
        Emit(cg, "Landthen_merge%u:\n", right_done_label);
        Emit(cg, "  br label %%Landthen_done%u\n", done_label);

        /* Merge point */
        Emit(cg, "Landthen_done%u:\n", done_label);
        uint32_t phi = Emit_Temp(cg);
        Emit(cg, "  %%t%u = phi i1 [ false, %%Landthen_check%u ], [ %%t%u, %%Landthen_merge%u ]\n",
             phi, left_block_label, right_i1, right_done_label);
        return phi;  /* Stays as i1 */
    }

    if (node->binary.op == TK_OR_ELSE) {
        /* OR ELSE: if left is true, result is true (don't evaluate right)
         *          if left is false, result is right */
        uint32_t left = Generate_Expression(cg, node->binary.left);
        const char *left_llvm = Expression_Llvm_Type(cg, node->binary.left);
        uint32_t left_i1 = Emit_Convert(cg, left, left_llvm, "i1");

        uint32_t eval_right_label = cg->label_id++;
        uint32_t done_label = cg->label_id++;
        uint32_t left_block_label = cg->label_id++;

        /* Save current block for phi */
        Emit(cg, "  br label %%Lorelse_check%u\n", left_block_label);
        Emit(cg, "Lorelse_check%u:\n", left_block_label);
        Emit(cg, "  br i1 %%t%u, label %%Lorelse_done%u, label %%Lorelse_right%u\n",
             left_i1, done_label, eval_right_label);

        /* Evaluate right if left was false */
        Emit(cg, "Lorelse_right%u:\n", eval_right_label);
        uint32_t right = Generate_Expression(cg, node->binary.right);
        const char *right_llvm = Expression_Llvm_Type(cg, node->binary.right);
        uint32_t right_i1 = Emit_Convert(cg, right, right_llvm, "i1");
        uint32_t right_done_label = cg->label_id++;
        Emit(cg, "  br label %%Lorelse_merge%u\n", right_done_label);
        Emit(cg, "Lorelse_merge%u:\n", right_done_label);
        Emit(cg, "  br label %%Lorelse_done%u\n", done_label);

        /* Merge point */
        Emit(cg, "Lorelse_done%u:\n", done_label);
        uint32_t phi = Emit_Temp(cg);
        Emit(cg, "  %%t%u = phi i1 [ true, %%Lorelse_check%u ], [ %%t%u, %%Lorelse_merge%u ]\n",
             phi, left_block_label, right_i1, right_done_label);
        return phi;  /* stays as i1 */
    }

    /* String/array concatenation */
    if (node->binary.op == TK_AMPERSAND and
        (Type_Is_Array_Like(left_type) or Type_Is_Array_Like(node->type) or
         Type_Is_String(left_type) or Type_Is_String(node->type))) {

        /* Generate both operands.
         * Each operand may be: fat pointer (STRING/unconstrained/literal/slice/concat),
         * ptr (constrained array), or i64 (CHARACTER).
         * We normalize each to a fat pointer before proceeding. */
        uint32_t left_raw = Generate_Expression(cg, node->binary.left);
        uint32_t right_raw = Generate_Expression(cg, node->binary.right);

        /* Normalize both operands to fat pointers (handles character, constrained, already-fat) */
        const char *cat_bt = Array_Bound_Llvm_Type(left_type);
        Type_Info *rhs_type = node->binary.right ? node->binary.right->type : NULL;
        uint32_t left_fat  = Normalize_To_Fat_Pointer(cg, node->binary.left,  left_raw, left_type, cat_bt);
        uint32_t right_fat = Normalize_To_Fat_Pointer(cg, node->binary.right, right_raw, rhs_type, cat_bt);

        /* Extract data pointers and bounds */
        uint32_t left_data = Emit_Fat_Pointer_Data(cg, left_fat, cat_bt);
        uint32_t left_low = Emit_Fat_Pointer_Low(cg, left_fat, cat_bt);
        uint32_t left_high = Emit_Fat_Pointer_High(cg, left_fat, cat_bt);

        uint32_t right_data = Emit_Fat_Pointer_Data(cg, right_fat, cat_bt);
        uint32_t right_low = Emit_Fat_Pointer_Low(cg, right_fat, cat_bt);
        uint32_t right_high = Emit_Fat_Pointer_High(cg, right_fat, cat_bt);

        /* Calculate lengths: high - low + 1 */
        uint32_t left_len1  = Emit_Length_From_Bounds(cg, left_low,  left_high,  cat_bt);
        uint32_t right_len1 = Emit_Length_From_Bounds(cg, right_low, right_high, cat_bt);

        /* Total length */
        uint32_t total_len = Emit_Temp(cg);
        Emit(cg, "  %%t%u = add %s %%t%u, %%t%u\n", total_len, cat_bt, left_len1, right_len1);

        /* Check result length against index SUBTYPE bounds (RM 4.5.3(7)).
         * The check is against the index subtype (e.g., POSITIVE for STRING),
         * NOT the specific constraint on a variable. For STRING, the index
         * subtype is POSITIVE (1..INTEGER'LAST), so almost any length is valid. */
        Type_Info *result_type = node->type;
        if (result_type and (result_type->kind == TYPE_ARRAY or result_type->kind == TYPE_STRING) and
            result_type->array.index_count > 0) {
            /* Always use index_type bounds (the index subtype), not Index_Info
             * bounds which represent a specific constraint on a variable. */
            Index_Info *idx_info = &result_type->array.indices[0];
            Type_Bound low_b = {0}, high_b = {0};
            if (idx_info->index_type) {
                low_b = idx_info->index_type->low_bound;
                high_b = idx_info->index_type->high_bound;
            }
            if (low_b.kind == BOUND_INTEGER and high_b.kind == BOUND_INTEGER) {
                /* Max length = index_high - index_low + 1 */
                int128_t max_len = high_b.int_value - low_b.int_value + 1;
                if (max_len > 0) {
                    uint32_t max_const = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s 0, %lld  ; max index length\n", max_const, cat_bt, (long long)max_len);
                    uint32_t overflow = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = icmp sgt %s %%t%u, %%t%u\n", overflow, cat_bt, total_len, max_const);
                    Emit_Check_With_Raise(cg, overflow, true, "concatenation length exceeds index subtype");
                }
            }
        }

        /* Extend to i64 for C-level calls (memcpy, sec_stack_alloc) */
        uint32_t total_len_64 = Emit_Extend_To_I64(cg, total_len, cat_bt);
        uint32_t left_len1_64 = Emit_Extend_To_I64(cg, left_len1, cat_bt);
        uint32_t right_len1_64 = Emit_Extend_To_I64(cg, right_len1, cat_bt);

        /* Allocate space on secondary stack */
        uint32_t result_data = Emit_Temp(cg);
        Emit(cg, "  %%t%u = call ptr @__ada_sec_stack_alloc(i64 %%t%u)\n",
             result_data, total_len_64);

        /* Copy left string using llvm.memcpy */
        Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)\n",
             result_data, left_data, left_len1_64);

        /* Calculate destination for right string */
        uint32_t right_dest = Emit_Temp(cg);
        Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %%t%u\n",
             right_dest, result_data, left_len1_64);

        /* Copy right string */
        Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)\n",
             right_dest, right_data, right_len1_64);

        /* Result bounds: 1..total_len (Ada STRING convention) */
        uint32_t one = Emit_Temp(cg);
        Emit(cg, "  %%t%u = add %s 0, 1\n", one, cat_bt);

        /* Return fat pointer to result */
        return Emit_Fat_Pointer_Dynamic(cg, result_data, one, total_len, cat_bt);
    }

    uint32_t left = Generate_Expression(cg, node->binary.left);
    /* NK_RANGE right operand is generated inside the IN/NOT IN handler.
     * For membership tests (IN/NOT IN), type names are also handled specially
     * and should not be evaluated as expressions. */
    bool right_is_range = node->binary.right and node->binary.right->kind == NK_RANGE;
    bool is_membership = (node->binary.op == TK_IN) or
                         (node->binary.op == TK_NOT and node->binary.right and
                          (node->binary.right->kind == NK_IDENTIFIER or
                           node->binary.right->kind == NK_QUALIFIED) and
                          node->binary.right->symbol and
                          node->binary.right->symbol->kind == SYMBOL_TYPE);
    uint32_t right = (right_is_range or is_membership) ? 0 : Generate_Expression(cg, node->binary.right);
    uint32_t t = Emit_Temp(cg);

    const char *op;
    Type_Info *result_type = node->type;

    /* track actual LLVM types for native-width integer operations. */
    const char *left_int_type = Expression_Llvm_Type(cg, node->binary.left);
    const char *right_int_type = (right_is_range or is_membership) ? Integer_Arith_Type(cg) :
                                  Expression_Llvm_Type(cg, node->binary.right);
    Type_Info *lhs_type = node->binary.left ? node->binary.left->type : NULL;
    Type_Info *rhs_type = node->binary.right ? node->binary.right->type : NULL;
    bool is_float = Type_Is_Float_Representation(result_type);
    bool is_fixed = Type_Is_Fixed_Point(result_type);

    /* Determine LLVM float type from result type (float vs double) */
    const char *float_type_str = Float_Llvm_Type_Of(result_type);

    /* Mixed-mode arithmetic: when result is float but operands are integer,
     * convert integer operands to float for proper arithmetic (RM 4.5.5) */
    if (is_float) {
        bool lhs_is_float = Type_Is_Float_Representation(lhs_type);
        bool rhs_is_float = Type_Is_Float_Representation(rhs_type);
        /* Determine actual types for left and right operands */
        const char *lhs_float_type = Float_Llvm_Type_Of(lhs_type);
        const char *rhs_float_type = Float_Llvm_Type_Of(rhs_type);

        if (not lhs_is_float) {
            /* Integer > float: use uitofp for modular (unsigned) types */
            uint32_t conv = Emit_Temp(cg);
            const char *itof = Type_Is_Unsigned(lhs_type) ? "uitofp" : "sitofp";
            Emit(cg, "  %%t%u = %s %s %%t%u to %s\n", conv, itof, left_int_type, left, float_type_str);
            left = conv;
        } else if (strcmp(lhs_float_type, float_type_str) != 0) {
            /* Convert left operand to result float type */
            left = Emit_Convert(cg, left, lhs_float_type, float_type_str);
        }
        /* For exponentiation, skip RHS conversion - TK_EXPON handles it */
        if (not rhs_is_float and node->binary.op != TK_EXPON) {
            /* Integer > float: use uitofp for modular (unsigned) types */
            uint32_t conv = Emit_Temp(cg);
            const char *itof = Type_Is_Unsigned(rhs_type) ? "uitofp" : "sitofp";
            Emit(cg, "  %%t%u = %s %s %%t%u to %s\n", conv, itof, right_int_type, right, float_type_str);
            right = conv;
        } else if (rhs_is_float and strcmp(rhs_float_type, float_type_str) != 0 and
                   node->binary.op != TK_EXPON) {
            /* Convert right operand to result float type */
            right = Emit_Convert(cg, right, rhs_float_type, float_type_str);
        }
    }

    /* Fixed-point uses scaled integer representation at the
     * result type's native width.  Widen operands to match.
     * Skip universal_real operands — they'll be handled below via
     * the fdiv/fptosi path which produces the correct scaled integer. */
    if (is_fixed and not is_float) {
        const char *fixed_arith = Type_To_Llvm(result_type);
        if (not Type_Is_Universal_Real(lhs_type))
            left = Emit_Convert(cg, left, left_int_type, fixed_arith);
        if (not right_is_range and not is_membership and not Type_Is_Universal_Real(rhs_type))
            right = Emit_Convert(cg, right, right_int_type, fixed_arith);
        left_int_type = fixed_arith;
        right_int_type = fixed_arith;
    }

    /* Mixed fixed-point / universal_real arithmetic (RM 4.5.5, 4.10):
     * When result is fixed-point but an operand is universal_real, convert
     * the universal_real to the fixed-point's scaled integer representation.
     * For fixed type with small S, value V converts to: floor(V / S)
     * Skip for exponentiation which has its own special handling. */
    if (is_fixed and node->binary.op != TK_EXPON) {
        double small = result_type->fixed.small;
        if (small <= 0) small = result_type->fixed.delta > 0 ? result_type->fixed.delta : 1.0;

        const char *fix_arith = Type_To_Llvm(result_type);
        if (Type_Is_Universal_Real(rhs_type))
            right = Convert_Real_To_Fixed(cg, right, small, fix_arith);
        if (Type_Is_Universal_Real(lhs_type))
            left = Convert_Real_To_Fixed(cg, left, small, fix_arith);
    }

    /* Fixed-point multiplication/division needs scaling (RM 4.5.5)
     * Only when BOTH operands are fixed-point. Integer × Fixed (or v.v.)
     * already yields a correctly scaled result — no shift needed. */
    bool both_fixed = is_fixed
        and Type_Is_Fixed_Point(lhs_type) and Type_Is_Fixed_Point(rhs_type);
    if (both_fixed and (node->binary.op == TK_STAR or node->binary.op == TK_SLASH)) {
        const char *fix_type = Type_To_Llvm(result_type);
        int scale = result_type->fixed.scale;
        if (node->binary.op == TK_STAR) {
            /* Fixed * Fixed: result = (a * b) >> abs(scale) */
            uint32_t mul = Emit_Temp(cg);
            Emit(cg, "  %%t%u = mul %s %%t%u, %%t%u\n", mul, fix_type, left, right);
            if (scale < 0) {
                /* Negative scale = right shift by |scale| */
                Emit(cg, "  %%t%u = ashr %s %%t%u, %d\n", t, fix_type, mul, -scale);
                Temp_Set_Type(cg, t, fix_type);
            } else if (scale > 0) {
                /* Positive scale = left shift (uncommon) */
                Emit(cg, "  %%t%u = shl %s %%t%u, %d\n", t, fix_type, mul, scale);
                Temp_Set_Type(cg, t, fix_type);
            } else {
                t = mul;
                Temp_Set_Type(cg, t, fix_type);
            }
            return t;
        } else {
            /* Fixed / Fixed: result = (a << abs(scale)) / b */
            uint32_t shifted = Emit_Temp(cg);
            if (scale < 0) {
                Emit(cg, "  %%t%u = shl %s %%t%u, %d\n", shifted, fix_type, left, -scale);
            } else if (scale > 0) {
                Emit(cg, "  %%t%u = ashr %s %%t%u, %d\n", shifted, fix_type, left, scale);
            } else {
                shifted = left;
            }
            Emit(cg, "  %%t%u = sdiv %s %%t%u, %%t%u\n", t, fix_type, shifted, right);
            Temp_Set_Type(cg, t, fix_type);
            return t;
        }
    }

    /* modular (unsigned) types use unsigned division/remainder.
     * Ada MOD vs REM differ for signed types (RM 4.5.5), but for modular
     * types both map to urem since all values are non-negative. */
    bool lhs_unsigned = Type_Is_Unsigned(lhs_type);

    switch (node->binary.op) {
        case TK_PLUS:  op = is_float ? "fadd" : "add"; break;
        case TK_MINUS: op = is_float ? "fsub" : "sub"; break;
        case TK_STAR:  op = is_float ? "fmul" : "mul"; break;
        case TK_SLASH: op = is_float ? "fdiv" : (lhs_unsigned ? "udiv" : "sdiv"); break;
        case TK_MOD:   op = lhs_unsigned ? "urem" : "srem"; break;
        case TK_REM:   op = lhs_unsigned ? "urem" : "srem"; break;

        case TK_EXPON:
            /* Exponentiation: base ** exponent
             * For floating-point: use llvm.pow.f64 intrinsic (requires double)
             * For integer: use __ada_integer_pow */
            {
                bool left_is_float = Type_Is_Float_Representation(left_type);
                if (left_is_float) {
                    /* Float ** Integer: use native-precision pow intrinsic.
                     * LLVM provides llvm.pow.f32 and llvm.pow.f64.
                     * RM 4.5.6(12): 0.0 ** negative must raise CONSTRAINT_ERROR. */
                    const char *lhs_ftype = Float_Llvm_Type_Of(left_type);
                    const char *pow_intrinsic = (lhs_ftype[0] == 'f')
                        ? "llvm.pow.f32" : "llvm.pow.f64";
                    /* Check: if base == 0.0 and exponent < 0, raise CONSTRAINT_ERROR */
                    uint32_t is_zero = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = fcmp oeq %s %%t%u, 0.0\n",
                         is_zero, lhs_ftype, left);
                    uint32_t is_neg = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = icmp slt %s %%t%u, 0\n", is_neg, right_int_type, right);
                    uint32_t bad = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = and i1 %%t%u, %%t%u\n", bad, is_zero, is_neg);
                    uint32_t ok_label = Emit_Label(cg);
                    uint32_t bad_label = Emit_Label(cg);
                    Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n", bad, bad_label, ok_label);
                    cg->block_terminated = true;
                    Emit_Label_Here(cg, bad_label);
                    cg->block_terminated = false;
                    Emit_Raise_Constraint_Error(cg, "0.0 ** negative (RM 4.5.6)");
                    Emit_Label_Here(cg, ok_label);
                    cg->block_terminated = false;
                    /* Convert integer exponent to matching float type */
                    uint32_t exp_float = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = sitofp %s %%t%u to %s\n",
                         exp_float, right_int_type, right, lhs_ftype);
                    Emit(cg, "  %%t%u = call %s @%s(%s %%t%u, %s %%t%u)\n",
                         t, lhs_ftype, pow_intrinsic, lhs_ftype, left, lhs_ftype, exp_float);
                } else {
                    /* Integer ** Integer: use integer power function.
                     * Signed types use overflow-checked __ada_integer_pow.
                     * Modular types use wrapping __ada_modular_pow (RM 3.5.4). */
                    const char *iat = Integer_Arith_Type(cg);
                    left = Emit_Convert(cg, left, left_int_type, iat);
                    right = Emit_Convert(cg, right, right_int_type, iat);
                    bool pow_unsigned = Type_Is_Unsigned(result_type);
                    bool pow_suppressed = Check_Is_Suppressed(result_type, NULL, CHK_OVERFLOW);
                    const char *pow_fn = (pow_unsigned || pow_suppressed)
                        ? "__ada_modular_pow" : "__ada_integer_pow";
                    Emit(cg, "  %%t%u = call %s @%s(%s %%t%u, %s %%t%u)\n",
                         t, iat, pow_fn, iat, left, iat, right);
                    Temp_Set_Type(cg, t, iat);
                }
                return t;
            }

        case TK_AND:
        case TK_AND_THEN:
        case TK_OR:
        case TK_OR_ELSE:
        case TK_XOR:
            {
                /* Bitwise/logical operations (RM 4.5.1):
                 * - Modular types: bitwise at native width
                 * - Boolean arrays: element-wise
                 * - Boolean scalars: convert to i1, operate, widen back */
                const char *llvm_op = (node->binary.op == TK_AND || node->binary.op == TK_AND_THEN) ? "and" :
                                      (node->binary.op == TK_OR  || node->binary.op == TK_OR_ELSE)  ? "or" : "xor";
                if (Type_Is_Bool_Array(result_type)) {
                    return Emit_Bool_Array_Binop(cg, left, right, result_type, llvm_op);
                } else if (Type_Is_Unsigned(result_type)) {
                    const char *common_t = Wider_Int_Type(cg, left_int_type, right_int_type);
                    left = Emit_Convert_Ext(cg, left, left_int_type, common_t, true);
                    right = Emit_Convert_Ext(cg, right, right_int_type, common_t, true);
                    Emit(cg, "  %%t%u = %s %s %%t%u, %%t%u\n", t, llvm_op, common_t, left, right);
                } else {
                    left = Emit_Convert(cg, left, Expression_Llvm_Type(cg, node->binary.left), "i1");
                    right = Emit_Convert(cg, right, Expression_Llvm_Type(cg, node->binary.right), "i1");
                    Emit(cg, "  %%t%u = %s i1 %%t%u, %%t%u\n", t, llvm_op, left, right);
                    Temp_Set_Type(cg, t, "i1");
                }
                return t;
            }

        case TK_EQ:
        case TK_NE:
        case TK_LT:
        case TK_LE:
        case TK_GT:
        case TK_GE:
            {
                /* Check operand types for typed comparisons */
                Type_Info *right_type = node->binary.right ? node->binary.right->type : NULL;
                bool left_is_float = Type_Is_Float_Representation(left_type);
                bool right_is_float = Type_Is_Float_Representation(right_type);
                bool left_is_bool = Type_Is_Boolean(left_type);
                bool right_is_bool = Type_Is_Boolean(right_type);
                /* Determine actual LLVM types of operands for type-safe comparison.
                 * Access types produce ptr, arrays produce ptr or fat_ptr,
                 * integers/enums produce i64. Use Expression_Llvm_Type to
                 * get the actual type each operand produces. */
                const char *left_llvm_type = Expression_Llvm_Type(cg, node->binary.left);
                const char *right_llvm_type = Expression_Llvm_Type(cg, node->binary.right);

                /* Boolean sub-expressions may produce i1 (raw comparisons) or
                 * i64 (widened booleans).  Use actual expression type to avoid
                 * double-widening when the value is already i64. */
                if (not left_is_float and not right_is_float) {
                    const char *int_arith = Integer_Arith_Type(cg);
                    if (Expression_Is_Boolean(node->binary.left)) {
                        left = Emit_Convert(cg, left, left_llvm_type, int_arith);
                        left_llvm_type = int_arith;
                    }
                    if (Expression_Is_Boolean(node->binary.right)) {
                        right = Emit_Convert(cg, right, right_llvm_type, int_arith);
                        right_llvm_type = int_arith;
                    }
                }

                /* For non-float, non-boolean: ensure operands are same type.
                 * If one is ptr and other is i64, convert to common type.
                 * Fat pointers: extract data pointer for comparison. */
                if (not left_is_float and not right_is_float and
                    not left_is_bool and not right_is_bool) {
                    /* Handle fat pointer operands - extract data pointer */
                    if (Llvm_Type_Is_Fat_Pointer(left_llvm_type)) {
                        left = Emit_Convert(cg, left, left_llvm_type, "ptr");
                        left_llvm_type = "ptr";
                    }
                    if (Llvm_Type_Is_Fat_Pointer(right_llvm_type)) {
                        right = Emit_Convert(cg, right, right_llvm_type, "ptr");
                        right_llvm_type = "ptr";
                    }
                    /* Normalize: if one is ptr and other is integer, convert ptr to integer.
                     * integer side may be native type (i8/i16/i32/i64). */
                    if (Llvm_Type_Is_Pointer(left_llvm_type) and
                        right_llvm_type[0] == 'i') {
                        const char *ptr_int = Integer_Arith_Type(cg);
                        left = Emit_Convert(cg, left, "ptr", ptr_int);
                        left_llvm_type = ptr_int;
                    } else if (left_llvm_type[0] == 'i' and
                               Llvm_Type_Is_Pointer(right_llvm_type)) {
                        const char *ptr_int = Integer_Arith_Type(cg);
                        right = Emit_Convert(cg, right, "ptr", ptr_int);
                        right_llvm_type = ptr_int;
                    }
                    /* Both ptr: will use icmp eq ptr below */
                    /* Both integer: will use common type below */
                }

                /* Determine float type based on left operand */
                const char *float_type = Float_Llvm_Type_Of(left_type);

                /* Get the right operand's float type (if it is float) */
                const char *right_float_type = Float_Llvm_Type_Of(right_type);
                /* UNIVERSAL_REAL always uses double (Generate_Real_Literal produces double) */

                /* Convert operands to same type if needed */
                if (left_is_float and not right_is_float) {
                    /* Convert right to float. If it's fixed-point, multiply by SMALL.
                     * use actual integer type; uitofp for unsigned. */
                    uint32_t conv = Emit_Temp(cg);
                    const char *itof_cmp = Type_Is_Unsigned(right_type) ? "uitofp" : "sitofp";
                    Emit(cg, "  %%t%u = %s %s %%t%u to %s\n", conv, itof_cmp, right_llvm_type, right, float_type);
                    right = conv;
                    if (Type_Is_Fixed_Point(right_type)) {
                        /* Fixed-point: scale by SMALL to get actual value.
                         * Resolve generic formal type to get actual SMALL. */
                        Type_Info *resolved_right = cg->current_instance ?
                            Resolve_Generic_Actual_Type(cg, right_type) : right_type;
                        double small = resolved_right->fixed.small;
                        if (small <= 0) small = resolved_right->fixed.delta > 0 ? resolved_right->fixed.delta : 1.0;
                        uint64_t bits; memcpy(&bits, &small, sizeof(bits));
                        uint32_t small_t = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = fadd %s 0.0, 0x%016llX\n", small_t, float_type, (unsigned long long)bits);
                        uint32_t scaled = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = fmul %s %%t%u, %%t%u\n", scaled, float_type, right, small_t);
                        right = scaled;
                    }
                    right_is_float = true;
                } else if (not left_is_float and right_is_float) {
                    /* Convert right float to integer for fixed-point comparison.
                     * If left is fixed-point, divide by SMALL first */
                    if (Type_Is_Fixed_Point(left_type)) {
                        /* Resolve generic formal type to get actual SMALL value */
                        Type_Info *resolved_left = cg->current_instance ?
                            Resolve_Generic_Actual_Type(cg, left_type) : left_type;
                        double small = resolved_left->fixed.small;
                        if (small <= 0) small = resolved_left->fixed.delta > 0 ? resolved_left->fixed.delta : 1.0;
                        uint64_t bits; memcpy(&bits, &small, sizeof(bits));
                        uint32_t small_t = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = fadd %s 0.0, 0x%016llX\n", small_t, right_float_type, (unsigned long long)bits);
                        uint32_t div_t = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = fdiv %s %%t%u, %%t%u\n", div_t, right_float_type, right, small_t);
                        right = div_t;
                    }
                    uint32_t conv = Emit_Temp(cg);
                    const char *ftoi_cmp = Type_Is_Unsigned(left_type) ? "fptoui" : "fptosi";
                    Emit(cg, "  %%t%u = %s %s %%t%u to %s\n", conv, ftoi_cmp, right_float_type, right, Integer_Arith_Type(cg));
                    right = conv;
                    right_is_float = false;
                    right_llvm_type = Integer_Arith_Type(cg);
                } else if (left_is_float and right_is_float) {
                    /* Both floats — use Emit_Convert which handles fpext/fptrunc
                     * based on bit widths, no hardcoded type string matching needed */
                    if (strcmp(float_type, right_float_type) != 0) {
                        right = Emit_Convert(cg, right, right_float_type, float_type);
                    }
                }

                /* RM 4.10: If both sides are static universal_real, fold
                 * the comparison at compile time using exact rationals. */
                if (left_is_float and right_is_float) {
                    Rational lq, rq;
                    bool l_ok = Eval_Const_Rational(node->binary.left, &lq);
                    bool r_ok = Eval_Const_Rational(node->binary.right, &rq);
                    if (l_ok and r_ok) {
                        int cmp = Rational_Compare(lq, rq);
                        bool result;
                        switch (node->binary.op) {
                            case TK_EQ: result = (cmp == 0); break;
                            case TK_NE: result = (cmp != 0); break;
                            case TK_LT: result = (cmp < 0);  break;
                            case TK_LE: result = (cmp <= 0); break;
                            case TK_GT: result = (cmp > 0);  break;
                            case TK_GE: result = (cmp >= 0); break;
                            default:    goto no_fold;
                        }
                        Emit(cg, "  %%t%u = add i1 0, %d  ; folded universal_real cmp\n",
                             t, result ? 1 : 0);
                        Temp_Set_Type(cg, t, "i1");
                        return t;
                    }
                }
                no_fold: ;

                const char *cmp_op;
                char cmp_buf[64];
                if (left_is_float and right_is_float) {
                    snprintf(cmp_buf, sizeof(cmp_buf), "fcmp %s %s",
                             Float_Cmp_Predicate(node->binary.op), float_type);
                    cmp_op = cmp_buf;
                } else if (Llvm_Type_Is_Pointer(left_llvm_type) and
                           Llvm_Type_Is_Pointer(right_llvm_type)) {
                    if (node->binary.op == TK_EQ or node->binary.op == TK_NE) {
                        snprintf(cmp_buf, sizeof(cmp_buf), "icmp %s ptr",
                                 Int_Cmp_Predicate(node->binary.op, false));
                        cmp_op = cmp_buf;
                    } else {
                        /* Ordered comparisons on pointers: convert to integer first */
                        const char *iat = Integer_Arith_Type(cg);
                        left = Emit_Convert(cg, left, "ptr", iat);
                        right = Emit_Convert(cg, right, "ptr", iat);
                        snprintf(cmp_buf, sizeof(cmp_buf), "icmp %s %s",
                                 Int_Cmp_Predicate(node->binary.op, false), iat);
                        cmp_op = cmp_buf;
                    }
                } else if (Is_Float_Type(left_llvm_type) or Is_Float_Type(right_llvm_type)) {
                    /* Float comparison that wasn't caught by left_is_float/right_is_float
                     * (e.g., derived float types, universal real) */
                    const char *fty = Is_Float_Type(left_llvm_type) ? left_llvm_type : right_llvm_type;
                    if (not Is_Float_Type(left_llvm_type)) {
                        uint32_t cv = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = sitofp %s %%t%u to %s\n", cv, left_llvm_type, left, fty);
                        left = cv;
                    }
                    if (not Is_Float_Type(right_llvm_type)) {
                        uint32_t cv = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = sitofp %s %%t%u to %s\n", cv, right_llvm_type, right, fty);
                        right = cv;
                    }
                    snprintf(cmp_buf, sizeof(cmp_buf), "fcmp %s %s",
                             Float_Cmp_Predicate(node->binary.op), fty);
                    cmp_op = cmp_buf;
                } else {
                    /* integer comparison using common native type.
                     * Modular (unsigned) types use unsigned predicates. */
                    const char *cmp_int_t = Wider_Int_Type(cg, left_llvm_type, right_llvm_type);
                    bool cmp_unsigned = Type_Is_Unsigned(left_type) or Type_Is_Unsigned(right_type);
                    left = Emit_Convert_Ext(cg, left, left_llvm_type, cmp_int_t, cmp_unsigned);
                    right = Emit_Convert_Ext(cg, right, right_llvm_type, cmp_int_t, cmp_unsigned);
                    snprintf(cmp_buf, sizeof(cmp_buf), "icmp %s %s",
                             Int_Cmp_Predicate(node->binary.op, cmp_unsigned), cmp_int_t);
                    cmp_op = cmp_buf;
                }
                Emit(cg, "  %%t%u = %s %%t%u, %%t%u\n", t, cmp_op, left, right);
                Temp_Set_Type(cg, t, "i1");
                /* comparison result stays as i1; widened at store boundary */
                return t;
            }

        case TK_IN:
        case TK_NOT:  /* NOT IN encoded as TK_NOT binary (RM 4.4) */
            {
                /* Membership test — two forms:
                 *   X IN  low .. high   >  low <= X <= high
                 *   X IN  T             >  T'FIRST <= X <= T'LAST */
                bool negate = (node->binary.op == TK_NOT);
                bool left_is_flt = Type_Is_Float_Representation(lhs_type);
                const char *mem_float_type = Float_Llvm_Type_Of(lhs_type);

                if (node->binary.right and node->binary.right->kind == NK_RANGE) {
                    /* Dynamic range: generate both bounds from AST */
                    uint32_t lo = Generate_Expression(cg, node->binary.right->range.low);
                    uint32_t hi = Generate_Expression(cg, node->binary.right->range.high);
                    uint32_t ge = Emit_Temp(cg), le = Emit_Temp(cg), in_range = Emit_Temp(cg);
                    if (left_is_flt) {
                        /* Ensure all operands have the same float type.
                         * Use Expression_Llvm_Type to get the actual LLVM type, which
                         * accounts for any conversions done during expression generation. */
                        const char *lo_ftype = Expression_Llvm_Type(cg, node->binary.right->range.low);
                        const char *hi_ftype = Expression_Llvm_Type(cg, node->binary.right->range.high);
                        /* Convert bounds to match left operand type if different */
                        if (strcmp(lo_ftype, mem_float_type) != 0) {
                            lo = Emit_Convert(cg, lo, lo_ftype, mem_float_type);
                        }
                        if (strcmp(hi_ftype, mem_float_type) != 0) {
                            hi = Emit_Convert(cg, hi, hi_ftype, mem_float_type);
                        }
                        Emit(cg, "  %%t%u = fcmp oge %s %%t%u, %%t%u\n", ge, mem_float_type, left, lo);
                        Emit(cg, "  %%t%u = fcmp ole %s %%t%u, %%t%u\n", le, mem_float_type, left, hi);
                    } else if (Is_Float_Type(left_int_type)) {
                        /* Float membership: left is float, use fcmp */
                        const char *lo_type = Expression_Llvm_Type(cg, node->binary.right->range.low);
                        const char *hi_type = Expression_Llvm_Type(cg, node->binary.right->range.high);
                        if (not Is_Float_Type(lo_type)) {
                            uint32_t cv = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = sitofp %s %%t%u to %s\n", cv, lo_type, lo, left_int_type);
                            lo = cv;
                        } else if (strcmp(lo_type, left_int_type) != 0) {
                            lo = Emit_Convert(cg, lo, lo_type, left_int_type);
                        }
                        if (not Is_Float_Type(hi_type)) {
                            uint32_t cv = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = sitofp %s %%t%u to %s\n", cv, hi_type, hi, left_int_type);
                            hi = cv;
                        } else if (strcmp(hi_type, left_int_type) != 0) {
                            hi = Emit_Convert(cg, hi, hi_type, left_int_type);
                        }
                        Emit(cg, "  %%t%u = fcmp oge %s %%t%u, %%t%u\n", ge, left_int_type, left, lo);
                        Emit(cg, "  %%t%u = fcmp ole %s %%t%u, %%t%u\n", le, left_int_type, left, hi);
                    } else {
                        /* use common native type for integer membership.
                         * Modular (unsigned) types use unsigned predicates. */
                        bool mem_unsigned = Type_Is_Unsigned(lhs_type);
                        const char *lo_type = Expression_Llvm_Type(cg, node->binary.right->range.low);
                        const char *hi_type = Expression_Llvm_Type(cg, node->binary.right->range.high);
                        /* Guard: if any types are float, convert to integer first.
                         * For fixed-point types, float bounds must be divided by
                         * SMALL before fptosi to match the scaled representation
                         * (RM 3.5.9: fixed_value = mantissa * SMALL). */
                        bool fp_scale = (lhs_type and lhs_type->kind == TYPE_FIXED);
                        double fp_small = 1.0;
                        if (fp_scale) {
                            fp_small = lhs_type->fixed.small;
                            if (fp_small <= 0) fp_small = lhs_type->fixed.delta > 0
                                                        ? lhs_type->fixed.delta : 1.0;
                        }
                        if (Is_Float_Type(lo_type)) {
                            uint32_t cv = Emit_Temp(cg); const char *iat2 = Integer_Arith_Type(cg);
                            if (fp_scale) {
                                uint64_t sb; memcpy(&sb, &fp_small, sizeof(sb));
                                uint32_t st = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = fadd double 0.0, 0x%016llX  ; small\n",
                                     st, (unsigned long long)sb);
                                uint32_t dv = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = fdiv %s %%t%u, %%t%u  ; bound/small\n",
                                     dv, lo_type, lo, st);
                                Emit(cg, "  %%t%u = fptosi %s %%t%u to %s\n", cv, lo_type, dv, iat2);
                            } else {
                                Emit(cg, "  %%t%u = fptosi %s %%t%u to %s\n", cv, lo_type, lo, iat2);
                            }
                            lo = cv; lo_type = iat2;
                        }
                        if (Is_Float_Type(hi_type)) {
                            uint32_t cv = Emit_Temp(cg); const char *iat2 = Integer_Arith_Type(cg);
                            if (fp_scale) {
                                uint64_t sb; memcpy(&sb, &fp_small, sizeof(sb));
                                uint32_t st = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = fadd double 0.0, 0x%016llX  ; small\n",
                                     st, (unsigned long long)sb);
                                uint32_t dv = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = fdiv %s %%t%u, %%t%u  ; bound/small\n",
                                     dv, hi_type, hi, st);
                                Emit(cg, "  %%t%u = fptosi %s %%t%u to %s\n", cv, hi_type, dv, iat2);
                            } else {
                                Emit(cg, "  %%t%u = fptosi %s %%t%u to %s\n", cv, hi_type, hi, iat2);
                            }
                            hi = cv; hi_type = iat2;
                        }
                        if (Is_Float_Type(left_int_type)) {
                            uint32_t cv = Emit_Temp(cg); const char *iat2 = Integer_Arith_Type(cg);
                            Emit(cg, "  %%t%u = fptosi %s %%t%u to %s\n", cv, left_int_type, left, iat2);
                            left = cv; left_int_type = iat2;
                        }
                        const char *mem_ct = Wider_Int_Type(cg, left_int_type, Wider_Int_Type(cg, lo_type, hi_type));
                        uint32_t ml = Emit_Convert_Ext(cg, left, left_int_type, mem_ct, mem_unsigned);
                        lo = Emit_Convert_Ext(cg, lo, lo_type, mem_ct, mem_unsigned);
                        hi = Emit_Convert_Ext(cg, hi, hi_type, mem_ct, mem_unsigned);
                        const char *ge_pred = mem_unsigned ? "uge" : "sge";
                        const char *le_pred = mem_unsigned ? "ule" : "sle";
                        Emit(cg, "  %%t%u = icmp %s %s %%t%u, %%t%u\n", ge, ge_pred, mem_ct, ml, lo);
                        Emit(cg, "  %%t%u = icmp %s %s %%t%u, %%t%u\n", le, le_pred, mem_ct, ml, hi);
                    }
                    Emit(cg, "  %%t%u = and i1 %%t%u, %%t%u\n", in_range, ge, le);
                    if (negate) { Emit(cg, "  %%t%u = xor i1 %%t%u, 1\n", t, in_range); }
                    else        { t = in_range; }
                } else if (node->binary.right and node->binary.right->kind == NK_ATTRIBUTE and
                           Slice_Equal_Ignore_Case(node->binary.right->attribute.name, S("RANGE"))) {
                    /* X IN A'RANGE or X IN A'RANGE(N) — expand to A'FIRST(N) <= X <= A'LAST(N) */
                    Syntax_Node *attr_node = node->binary.right;
                    Type_Info *arr_type = attr_node->attribute.prefix->type;
                    Symbol *arr_sym = attr_node->attribute.prefix->symbol;
                    Syntax_Node *range_dim_arg = attr_node->attribute.arguments.count > 0
                                               ? attr_node->attribute.arguments.items[0] : NULL;
                    uint32_t rdim = Get_Dimension_Index(range_dim_arg);

                    uint32_t lo, hi;
                    bool arr_needs_rt = false;
                    if (arr_type and (Type_Is_Unconstrained_Array(arr_type) or Type_Has_Dynamic_Bounds(arr_type)) and
                        arr_sym and (arr_sym->kind == SYMBOL_PARAMETER or arr_sym->kind == SYMBOL_VARIABLE or
                                    arr_sym->kind == SYMBOL_CONSTANT or arr_sym->kind == SYMBOL_DISCRIMINANT))
                        arr_needs_rt = true;
                    if (arr_needs_rt) {
                        const char *rbt = Array_Bound_Llvm_Type(arr_type);
                        uint32_t fat = Emit_Load_Fat_Pointer(cg, arr_sym, rbt);
                        lo = Emit_Fat_Pointer_Low_Dim(cg, fat, rbt, rdim);
                        hi = Emit_Fat_Pointer_High_Dim(cg, fat, rbt, rdim);
                    } else if (arr_type and Type_Is_Array_Like(arr_type) and rdim < arr_type->array.index_count) {
                        const char *iat = Integer_Arith_Type(cg);
                        Type_Bound lb = arr_type->array.indices[rdim].low_bound;
                        Type_Bound hb = arr_type->array.indices[rdim].high_bound;
                        /* If bounds not set on array, derive from index type */
                        if (lb.kind != BOUND_INTEGER and lb.kind != BOUND_EXPR and
                            arr_type->array.indices[rdim].index_type) {
                            Type_Info *idx_ty = arr_type->array.indices[rdim].index_type;
                            lb = idx_ty->low_bound;
                            hb = idx_ty->high_bound;
                        }
                        lo = Emit_Single_Bound(cg, &lb, iat);
                        hi = Emit_Single_Bound(cg, &hb, iat);
                    } else {
                        /* Fallback - can't determine bounds */
                        uint32_t always = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = add i1 0, 1  ; range membership fallback\n", always);
                        if (negate) { Emit(cg, "  %%t%u = xor i1 %%t%u, 1\n", t, always); }
                        else        { t = always; }
                        return t;
                    }
                    /* Compare left IN lo..hi */
                    const char *rng_iat = Integer_Arith_Type(cg);
                    uint32_t ml = Emit_Convert(cg, left, left_int_type, rng_iat);
                    lo = Emit_Convert(cg, lo, rng_iat, rng_iat); /* ensure same type */
                    hi = Emit_Convert(cg, hi, rng_iat, rng_iat);
                    uint32_t ge = Emit_Temp(cg), le = Emit_Temp(cg), in_range = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = icmp sge %s %%t%u, %%t%u\n", ge, rng_iat, ml, lo);
                    Emit(cg, "  %%t%u = icmp sle %s %%t%u, %%t%u\n", le, rng_iat, ml, hi);
                    Emit(cg, "  %%t%u = and i1 %%t%u, %%t%u\n", in_range, ge, le);
                    if (negate) { Emit(cg, "  %%t%u = xor i1 %%t%u, 1\n", t, in_range); }
                    else        { t = in_range; }
                } else {
                    /* Type or subtype name: generate bounds at runtime (RM 4.4) */
                    Type_Info *rt = node->binary.right ? node->binary.right->type : NULL;
                    /* Composite types (records, arrays) and access/task types:
                     * membership is always TRUE since the value is already of
                     * that type (RM 4.5.2). Access types have no range. */
                    if (rt and (Type_Is_Composite(rt) or Type_Is_Access(rt) or
                                rt->kind == TYPE_TASK)) {
                        uint32_t always = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = add i1 0, 1  ; composite IN is always true\n", always);
                        if (negate) { Emit(cg, "  %%t%u = xor i1 %%t%u, 1\n", t, always); }
                        else        { t = always; }
                        return t;
                    }
                    if (rt and (rt->low_bound.kind == BOUND_INTEGER or rt->low_bound.kind == BOUND_EXPR) and
                              (rt->high_bound.kind == BOUND_INTEGER or rt->high_bound.kind == BOUND_EXPR)) {
                        const char *lo_bt = NULL, *hi_bt = NULL;
                        uint32_t lo = Emit_Bound_Value_Typed(cg, &rt->low_bound, &lo_bt);
                        uint32_t hi = Emit_Bound_Value_Typed(cg, &rt->high_bound, &hi_bt);
                        if (lo == 0 || hi == 0) {
                            /* Bounds could not be determined — assume always in range */
                            uint32_t always = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add i1 0, 1  ; membership fallback (no bounds)\n", always);
                            if (negate) { Emit(cg, "  %%t%u = xor i1 %%t%u, 1\n", t, always); }
                            else        { t = always; }
                            return t;
                        }
                        if (not lo_bt) lo_bt = Integer_Arith_Type(cg);
                        if (not hi_bt) hi_bt = Integer_Arith_Type(cg);
                        uint32_t ge = Emit_Temp(cg), le = Emit_Temp(cg), in_range = Emit_Temp(cg);
                        if (left_is_flt) {
                            /* For float membership tests, determine bound types and convert if needed.
                             * BOUND_INTEGER may produce i32 or i64, BOUND_EXPR for float types produces float. */
                            const char *lo_src_type = lo_bt;
                            const char *hi_src_type = hi_bt;
                            /* Convert bounds to match left operand's float type */
                            uint32_t lo_f = lo, hi_f = hi;
                            if (strcmp(lo_src_type, mem_float_type) != 0) {
                                lo_f = Emit_Convert(cg, lo, lo_src_type, mem_float_type);
                            }
                            if (strcmp(hi_src_type, mem_float_type) != 0) {
                                hi_f = Emit_Convert(cg, hi, hi_src_type, mem_float_type);
                            }
                            Emit(cg, "  %%t%u = fcmp oge %s %%t%u, %%t%u\n", ge, mem_float_type, left, lo_f);
                            Emit(cg, "  %%t%u = fcmp ole %s %%t%u, %%t%u\n", le, mem_float_type, left, hi_f);
                        } else {
                            /* widen left and bounds to widest type for comparison.
                             * Modular (unsigned) types use unsigned predicates. */
                            bool mem_u = Type_Is_Unsigned(lhs_type);
                            const char *cmp_t = Integer_Arith_Type(cg);
                            if (left_int_type[0] == 'i') cmp_t = Wider_Int_Type(cg, cmp_t, left_int_type);
                            if (lo_bt[0] == 'i') cmp_t = Wider_Int_Type(cg, cmp_t, lo_bt);
                            if (hi_bt[0] == 'i') cmp_t = Wider_Int_Type(cg, cmp_t, hi_bt);
                            uint32_t ml = Emit_Convert_Ext(cg, left, left_int_type, cmp_t, mem_u);
                            uint32_t wlo = Emit_Convert_Ext(cg, lo, lo_bt, cmp_t, mem_u);
                            uint32_t whi = Emit_Convert_Ext(cg, hi, hi_bt, cmp_t, mem_u);
                            const char *ge_p = mem_u ? "uge" : "sge";
                            const char *le_p = mem_u ? "ule" : "sle";
                            Emit(cg, "  %%t%u = icmp %s %s %%t%u, %%t%u\n", ge, ge_p, cmp_t, ml, wlo);
                            Emit(cg, "  %%t%u = icmp %s %s %%t%u, %%t%u\n", le, le_p, cmp_t, ml, whi);
                        }
                        Emit(cg, "  %%t%u = and i1 %%t%u, %%t%u\n", in_range, ge, le);
                        if (negate) { Emit(cg, "  %%t%u = xor i1 %%t%u, 1\n", t, in_range); }
                        else        { t = in_range; }
                    } else {
                        /* Fallback: equality with right operand value */
                        if (left_is_flt) {
                            Emit(cg, "  %%t%u = fcmp oeq %s %%t%u, %%t%u\n", t, mem_float_type, left, right);
                        } else {
                            /* use common native type for equality. */
                            const char *fb_ct = Wider_Int_Type(cg, left_int_type, right_int_type);
                            uint32_t ml = Emit_Convert(cg, left, left_int_type, fb_ct);
                            uint32_t mr = Emit_Convert(cg, right, right_int_type, fb_ct);
                            Emit(cg, "  %%t%u = icmp eq %s %%t%u, %%t%u\n", t, fb_ct, ml, mr);
                        }
                        if (negate) {
                            uint32_t neg = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = xor i1 %%t%u, 1\n", neg, t);
                            t = neg;
                        }
                    }
                }
                /* membership result stays as i1; widened at store boundary */
                Temp_Set_Type(cg, t, "i1");
                return t;
            }

        default:
            fprintf(stderr, "internal error: unhandled binary operator %d in codegen\n",
                    node->binary.op);
            abort();
    }

    if (not is_float and (Is_Float_Type(left_int_type) or Is_Float_Type(right_int_type))) {
        /* Type system said not float, but LLVM types are float (derived float).
         * Promote to float arithmetic. */
        is_float = true;
        float_type_str = Is_Float_Type(left_int_type) ? left_int_type : right_int_type;
        if (not Is_Float_Type(left_int_type)) {
            uint32_t cv = Emit_Temp(cg);
            Emit(cg, "  %%t%u = sitofp %s %%t%u to %s\n", cv, left_int_type, left, float_type_str);
            left = cv;
        }
        if (not Is_Float_Type(right_int_type)) {
            uint32_t cv = Emit_Temp(cg);
            Emit(cg, "  %%t%u = sitofp %s %%t%u to %s\n", cv, right_int_type, right, float_type_str);
            right = cv;
        }
    }
    if (not is_float) {
        /* use common native integer type for arithmetic. */
        const char *common_t = Wider_Int_Type(cg, left_int_type, right_int_type);
        left = Emit_Convert(cg, left, left_int_type, common_t);
        right = Emit_Convert(cg, right, right_int_type, common_t);

        /* Division/remainder: emit division-by-zero check and MIN_INT/-1 check
         * before the actual sdiv/udiv/srem/urem (RM 4.5.5). */
        Token_Kind binop = node->binary.op;
        if (binop == TK_SLASH or binop == TK_MOD or binop == TK_REM) {
            Emit_Division_Check(cg, right, common_t, result_type);
            if (binop == TK_SLASH and not lhs_unsigned) {
                Emit_Signed_Division_Overflow_Check(cg, left, right, common_t, result_type);
            }
            Emit(cg, "  %%t%u = %s %s %%t%u, %%t%u\n", t, op, common_t, left, right);
            Temp_Set_Type(cg, t, common_t);
            /* Ada MOD correction: MOD result has sign of divisor (RM 4.5.5)
             * srem result has sign of dividend. When signs differ, add divisor. */
            if (binop == TK_MOD and not lhs_unsigned) {
                uint32_t r_ne_zero = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp ne %s %%t%u, 0\n", r_ne_zero, common_t, t);
                uint32_t r_xor_b = Emit_Temp(cg);
                Emit(cg, "  %%t%u = xor %s %%t%u, %%t%u\n", r_xor_b, common_t, t, right);
                uint32_t signs_differ = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp slt %s %%t%u, 0\n", signs_differ, common_t, r_xor_b);
                uint32_t need_fix = Emit_Temp(cg);
                Emit(cg, "  %%t%u = and i1 %%t%u, %%t%u\n", need_fix, r_ne_zero, signs_differ);
                uint32_t r_plus_b = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s %%t%u, %%t%u\n", r_plus_b, common_t, t, right);
                uint32_t mod_result = Emit_Temp(cg);
                Emit(cg, "  %%t%u = select i1 %%t%u, %s %%t%u, %s %%t%u\n",
                     mod_result, need_fix, common_t, r_plus_b, common_t, t);
                t = mod_result;
                Temp_Set_Type(cg, t, common_t);
            }
        }
        /* Add/sub/mul: use overflow-checked intrinsics for signed types (RM 4.5).
         * Modular types wrap naturally; Emit_Overflow_Checked_Op handles this. */
        else if (binop == TK_PLUS or binop == TK_MINUS or binop == TK_STAR) {
            t = Emit_Overflow_Checked_Op(cg, left, right, op, common_t, result_type);
        } else {
            Emit(cg, "  %%t%u = %s %s %%t%u, %%t%u\n", t, op, common_t, left, right);
            Temp_Set_Type(cg, t, common_t);
        }

        /* Modular wrapping: Ada modular arithmetic wraps modulo M (RM 4.5.3).
         * For power-of-2 moduli, LLVM's natural integer wrapping suffices.
         * For non-power-of-2 moduli (e.g. mod 100), emit: urem result, modulus.
         * Only applies to add, sub, mul — div/rem already produce in-range values. */
        if (result_type and result_type->kind == TYPE_MODULAR and result_type->modulus > 0) {
            uint128_t m = result_type->modulus;
            /* Check if modulus is a power of 2: if so, no masking needed */
            if ((m & (m - 1)) != 0) {
                if (binop == TK_PLUS or binop == TK_MINUS or binop == TK_STAR) {
                    uint32_t mod_val = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s 0, %s  ; modulus\n", mod_val, common_t,
                         U128_Decimal(m));
                    uint32_t wrapped = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = urem %s %%t%u, %%t%u\n", wrapped, common_t, t, mod_val);
                    t = wrapped;
                }
            }
        }
    } else {
        /* RM 4.5.5: float division by zero raises CONSTRAINT_ERROR */
        if (node->binary.op == TK_SLASH and
            not Check_Is_Suppressed(result_type, NULL, CHK_DIVISION)) {
            uint32_t fz = Emit_Temp(cg);
            Emit(cg, "  %%t%u = fcmp oeq %s %%t%u, 0.0\n", fz, float_type_str, right);
            uint32_t ok = Emit_Label(cg), bad = Emit_Label(cg);
            Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n", fz, bad, ok);
            cg->block_terminated = true;
            Emit_Label_Here(cg, bad);
            cg->block_terminated = false;
            Emit_Raise_Constraint_Error(cg, "float division by zero");
            Emit_Label_Here(cg, ok);
            cg->block_terminated = false;
        }
        Emit(cg, "  %%t%u = %s %s %%t%u, %%t%u\n", t, op, float_type_str, left, right);
    }
    return t;
}

static uint32_t Generate_Unary_Op(Code_Generator *cg, Syntax_Node *node) {
    uint32_t operand = Generate_Expression(cg, node->unary.operand);
    uint32_t t = Emit_Temp(cg);
    Type_Info *op_type_info = node->unary.operand->type;
    bool is_float = Type_Is_Float_Representation(op_type_info);

    /* Determine LLVM float type from operand type */
    const char *float_type = Float_Llvm_Type_Of(op_type_info);

    /* determine native integer type for unary operations.
     * Fixed-point types use integer representation at LLVM level. */
    const char *unary_int_type = is_float ? Integer_Arith_Type(cg) : Expression_Llvm_Type(cg, node->unary.operand);

    switch (node->unary.op) {
        case TK_MINUS:
            if (is_float) {
                Emit(cg, "  %%t%u = fsub %s 0.0, %%t%u\n", t, float_type, operand);
                Temp_Set_Type(cg, t, float_type);
            } else {
                /* Unary negation: 0 - operand.  Overflow check for signed types:
                 * -Integer'First overflows on two's complement (RM 4.5). */
                Type_Info *res_type = node->type ? node->type : op_type_info;
                uint32_t zero = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s 0, 0\n", zero, unary_int_type);
                t = Emit_Overflow_Checked_Op(cg, zero, operand, "sub", unary_int_type, res_type);
                /* Modular wrapping for unary minus (RM 4.5.3): -x = modulus - x.
                 * For power-of-2 moduli, the sub already wraps correctly.
                 * For non-power-of-2, emit urem to wrap into 0..M-1. */
                if (res_type and res_type->kind == TYPE_MODULAR and res_type->modulus > 0) {
                    uint128_t m = res_type->modulus;
                    if ((m & (m - 1)) != 0) {
                        uint32_t mod_val = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = add %s 0, %s  ; modulus\n", mod_val, unary_int_type,
                             U128_Decimal(m));
                        uint32_t wrapped = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = urem %s %%t%u, %%t%u\n", wrapped, unary_int_type, t, mod_val);
                        t = wrapped;
                    }
                }
            }
            break;
        case TK_PLUS:
            return operand;
        case TK_NOT:
            {
                Type_Info *res_type = node->type ? node->type : op_type_info;
                if (res_type and res_type->kind == TYPE_MODULAR) {
                    /* Modular NOT is bitwise complement modulo M (RM 4.5.6).
                     * For power-of-2 moduli: XOR with (M-1) gives correct masking.
                     * For non-power-of-2: same — XOR with (M-1) is the Ada definition. */
                    uint128_t mask = (res_type->modulus > 0) ? res_type->modulus - 1 : (uint128_t)~0ULL;
                    Emit(cg, "  %%t%u = xor %s %%t%u, %s  ; modular NOT\n",
                         t, unary_int_type, operand, U128_Decimal(mask));
                    Temp_Set_Type(cg, t, unary_int_type);
                } else if (Type_Is_Bool_Array(res_type)) {
                    t = Emit_Bool_Array_Not(cg, operand, res_type);
                } else {
                    /* Boolean NOT: convert to i1, flip — result stays i1 (GNAT LLVM) */
                    const char *op_type = Expression_Llvm_Type(cg, node->unary.operand);
                    operand = Emit_Convert(cg, operand, op_type, "i1");
                    Emit(cg, "  %%t%u = xor i1 %%t%u, 1\n", t, operand);
                    Temp_Set_Type(cg, t, "i1");
                    /* result stays as i1; widened at store boundary */
                }
            }
            break;
        case TK_ABS:
            {
                if (is_float) {
                    uint32_t neg = Emit_Temp(cg);
                    uint32_t cmp = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = fsub %s 0.0, %%t%u\n", neg, float_type, operand);
                    Emit(cg, "  %%t%u = fcmp olt %s %%t%u, 0.0\n", cmp, float_type, operand);
                    Emit(cg, "  %%t%u = select i1 %%t%u, %s %%t%u, %s %%t%u\n",
                         t, cmp, float_type, neg, float_type, operand);
                    Temp_Set_Type(cg, t, float_type);
                } else {
                    /* Integer ABS with overflow check: ABS(MIN_INT) overflows.
                     * Use Emit_Overflow_Checked_Op for negation, then select. */
                    Type_Info *res_type = node->type ? node->type : op_type_info;
                    uint32_t zero = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s 0, 0\n", zero, unary_int_type);
                    uint32_t neg = Emit_Overflow_Checked_Op(cg, zero, operand, "sub", unary_int_type, res_type);
                    uint32_t cmp = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = icmp slt %s %%t%u, 0\n", cmp, unary_int_type, operand);
                    Emit(cg, "  %%t%u = select i1 %%t%u, %s %%t%u, %s %%t%u\n",
                         t, cmp, unary_int_type, neg, unary_int_type, operand);
                    Temp_Set_Type(cg, t, unary_int_type);
                }
            }
            break;
        case TK_ALL:
            {
                /* .ALL dereference: operand is pointer, load the value */
                Emit_Access_Check(cg, operand, node->unary.operand->type);
                Type_Info *designated = node->type;  /* Set by resolution */
                if (Type_Is_Composite(designated)) {
                    /* For composite types, pointer is the value */
                    return operand;
                }
                /* For scalar types, load the value from the pointer */
                const char *type_str = Type_To_Llvm(designated);
                Emit(cg, "  %%t%u = load %s, ptr %%t%u  ; .ALL dereference\n",
                     t, type_str, operand);
                Temp_Set_Type(cg, t, type_str);
                /* no widening at load — value stays at native type width.
                 * Conversions happen at use sites via Emit_Convert. */
            }
            break;
        default:
            fprintf(stderr, "internal error: unhandled unary operator %d in codegen\n",
                    node->unary.op);
            abort();
    }

    return t;
}

static uint32_t Generate_Apply(Code_Generator *cg, Syntax_Node *node) {
    Symbol *sym = node->apply.prefix->symbol;

    /* Emit call/apply comment if symbol is known */
    if (sym) {
        Emit(cg, "  ; apply %.*s (", (int)sym->name.length, sym->name.data);
        if (sym->kind == SYMBOL_FUNCTION)
            Emit(cg, "function");
        else if (sym->kind == SYMBOL_PROCEDURE)
            Emit(cg, "procedure");
        else if (sym->kind == SYMBOL_TYPE or sym->kind == SYMBOL_SUBTYPE)
            Emit(cg, "type conversion");
        else
            Emit(cg, "symbol");
        Emit(cg, ")\n");
    }

    /* Follow rename chain to get actual target symbol for code generation.
     * Renames don't generate their own function body - they call the target. */
    while (sym and sym->renamed_object and
           (sym->kind == SYMBOL_FUNCTION or sym->kind == SYMBOL_PROCEDURE)) {
        Symbol *target = (Symbol *)sym->renamed_object;
        if (target->kind == SYMBOL_FUNCTION or target->kind == SYMBOL_PROCEDURE) {
            sym = target;
        } else {
            break;
        }
    }

    /* Predefined operator called as function: P."="(X,Y) or "NOT"(X) etc.
     * These have is_predefined set and no body, or the prefix is an operator
     * symbol identifier with no symbol (resolved in semantic analysis). */
    bool is_operator_symbol = (sym and sym->is_predefined) or
        (not sym and node->apply.prefix->kind == NK_IDENTIFIER and
         node->apply.prefix->string_val.text.length <= 3);
    if (is_operator_symbol and node->apply.arguments.count >= 1) {
        String_Slice op_name = sym ? sym->name : node->apply.prefix->string_val.text;
        uint32_t argc = (uint32_t)node->apply.arguments.count;
        /* Get first argument */
        Syntax_Node *arg0 = node->apply.arguments.items[0];
        if (arg0->kind == NK_ASSOCIATION) arg0 = arg0->association.expression;
        uint32_t v0 = Generate_Expression(cg, arg0);
        const char *t0 = Expression_Llvm_Type(cg, arg0);
        Type_Info *ty0 = arg0->type;

        if (argc == 2) {
            Syntax_Node *arg1 = node->apply.arguments.items[1];
            if (arg1->kind == NK_ASSOCIATION) arg1 = arg1->association.expression;
            uint32_t v1 = Generate_Expression(cg, arg1);
            const char *t1 = Expression_Llvm_Type(cg, arg1);

            /* Composite equality/inequality: dispatch to record/array equality
             * before scalar widening (RM 4.5.2) */
            if (ty0 and (Type_Is_Record(ty0) or Type_Is_Array_Like(ty0)) and
                (Slice_Equal_Ignore_Case(op_name, S("=")) or
                 Slice_Equal_Ignore_Case(op_name, S("/=")))) {
                uint32_t eq_result;
                if (Type_Is_Record(ty0)) {
                    eq_result = Generate_Record_Equality(cg, v0, v1, ty0);
                } else {
                    eq_result = Generate_Array_Equality(cg, v0, v1, ty0);
                }
                if (Slice_Equal_Ignore_Case(op_name, S("/="))) {
                    uint32_t ne_r = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = xor i1 %%t%u, 1\n", ne_r, eq_result);
                    eq_result = ne_r;
                }
                /* Named operator returns BOOLEAN (i8), not bare i1 */
                const char *bool_t = (sym and sym->return_type) ? Type_To_Llvm(sym->return_type) : "i8";
                if (bool_t[0] == 'i' and bool_t[1] != '1') {
                    uint32_t ext = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = zext i1 %%t%u to %s\n", ext, eq_result, bool_t);
                    eq_result = ext;
                    Temp_Set_Type(cg, eq_result, bool_t);
                }
                return eq_result;
            }

            /* Widen to common type (scalar operands only) */
            const char *ct = Wider_Int_Type(cg, t0, t1);
            bool uns = Type_Is_Unsigned(ty0);
            v0 = Emit_Convert_Ext(cg, v0, t0, ct, uns);
            v1 = Emit_Convert_Ext(cg, v1, t1, ct, uns);

            /* Comparison operators */
            int cmp_tk = -1;
            if (Slice_Equal_Ignore_Case(op_name, S("=")))  cmp_tk = TK_EQ;
            else if (Slice_Equal_Ignore_Case(op_name, S("/="))) cmp_tk = TK_NE;
            else if (Slice_Equal_Ignore_Case(op_name, S("<")))  cmp_tk = TK_LT;
            else if (Slice_Equal_Ignore_Case(op_name, S("<="))) cmp_tk = TK_LE;
            else if (Slice_Equal_Ignore_Case(op_name, S(">")))  cmp_tk = TK_GT;
            else if (Slice_Equal_Ignore_Case(op_name, S(">="))) cmp_tk = TK_GE;
            if (cmp_tk >= 0) {
                uint32_t r = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp %s %s %%t%u, %%t%u  ; predef %.*s\n",
                     r, Int_Cmp_Predicate(cmp_tk, uns), ct, v0, v1,
                     (int)op_name.length, op_name.data);
                /* Widen i1 > i8 for Ada BOOLEAN */
                uint32_t w = Emit_Temp(cg);
                Emit(cg, "  %%t%u = zext i1 %%t%u to i8\n", w, r);
                Temp_Set_Type(cg, w, "i8");
                return w;
            }
            /* Arithmetic operators */
            const char *arith_op = NULL;
            if (Slice_Equal_Ignore_Case(op_name, S("+")))   arith_op = "add";
            else if (Slice_Equal_Ignore_Case(op_name, S("-")))   arith_op = "sub";
            else if (Slice_Equal_Ignore_Case(op_name, S("*")))   arith_op = "mul";
            else if (Slice_Equal_Ignore_Case(op_name, S("/")))   arith_op = uns ? "udiv" : "sdiv";
            else if (Slice_Equal_Ignore_Case(op_name, S("mod"))) arith_op = uns ? "urem" : "srem";
            else if (Slice_Equal_Ignore_Case(op_name, S("rem"))) arith_op = uns ? "urem" : "srem";
            if (arith_op) {
                uint32_t r = Emit_Temp(cg);
                Emit(cg, "  %%t%u = %s %s %%t%u, %%t%u  ; predef %.*s\n",
                     r, arith_op, ct, v0, v1,
                     (int)op_name.length, op_name.data);
                /* Ada MOD correction for named operator */
                if (Slice_Equal_Ignore_Case(op_name, S("mod")) and not uns) {
                    uint32_t rn = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = icmp ne %s %%t%u, 0\n", rn, ct, r);
                    uint32_t rxb = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = xor %s %%t%u, %%t%u\n", rxb, ct, r, v1);
                    uint32_t sd = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = icmp slt %s %%t%u, 0\n", sd, ct, rxb);
                    uint32_t nf = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = and i1 %%t%u, %%t%u\n", nf, rn, sd);
                    uint32_t rpb = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s %%t%u, %%t%u\n", rpb, ct, r, v1);
                    uint32_t mr = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = select i1 %%t%u, %s %%t%u, %s %%t%u\n",
                         mr, nf, ct, rpb, ct, r);
                    r = mr;
                }
                return r;
            }
            /* Exponentiation: "**"(base, exp) */
            if (Slice_Equal_Ignore_Case(op_name, S("**"))) {
                const char *iat = Integer_Arith_Type(cg);
                v0 = Emit_Convert(cg, v0, t0, iat);
                v1 = Emit_Convert(cg, v1, t1, iat);
                uint32_t r = Emit_Temp(cg);
                Emit(cg, "  %%t%u = call %s @__ada_integer_pow(%s %%t%u, %s %%t%u)\n",
                     r, iat, iat, v0, iat, v1);
                Temp_Set_Type(cg, r, iat);
                return r;
            }
            /* Boolean operators */
            if (Slice_Equal_Ignore_Case(op_name, S("and")) or
                Slice_Equal_Ignore_Case(op_name, S("or")) or
                Slice_Equal_Ignore_Case(op_name, S("xor"))) {
                const char *bool_op = Slice_Equal_Ignore_Case(op_name, S("and")) ? "and" :
                                      Slice_Equal_Ignore_Case(op_name, S("or")) ? "or" : "xor";
                v0 = Emit_Convert(cg, v0, t0, "i1");
                v1 = Emit_Convert(cg, v1, t1, "i1");
                uint32_t r = Emit_Temp(cg);
                Emit(cg, "  %%t%u = %s i1 %%t%u, %%t%u\n", r, bool_op, v0, v1);
                uint32_t w = Emit_Temp(cg);
                Emit(cg, "  %%t%u = zext i1 %%t%u to i8\n", w, r);
                Temp_Set_Type(cg, w, "i8");
                return w;
            }
        } else if (argc == 1) {
            /* Unary operators: abs, not, unary - */
            if (Slice_Equal_Ignore_Case(op_name, S("abs"))) {
                /* ABS with overflow check: ABS(MIN_INT) overflows */
                uint32_t zero = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s 0, 0\n", zero, t0);
                uint32_t neg = Emit_Overflow_Checked_Op(cg, zero, v0, "sub", t0, ty0);
                uint32_t cmp = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp slt %s %%t%u, 0\n", cmp, t0, v0);
                uint32_t r = Emit_Temp(cg);
                Emit(cg, "  %%t%u = select i1 %%t%u, %s %%t%u, %s %%t%u\n",
                     r, cmp, t0, neg, t0, v0);
                return r;
            }
            if (Slice_Equal_Ignore_Case(op_name, S("not"))) {
                v0 = Emit_Convert(cg, v0, t0, "i1");
                uint32_t r = Emit_Temp(cg);
                Emit(cg, "  %%t%u = xor i1 %%t%u, true\n", r, v0);
                uint32_t w = Emit_Temp(cg);
                Emit(cg, "  %%t%u = zext i1 %%t%u to i8\n", w, r);
                Temp_Set_Type(cg, w, "i8");
                return w;
            }
            if (Slice_Equal_Ignore_Case(op_name, S("-"))) {
                uint32_t r = Emit_Temp(cg);
                Emit(cg, "  %%t%u = sub %s 0, %%t%u\n", r, t0, v0);
                return r;
            }
        }
        /* Fall through to regular call for unhandled operators */
    }

    /* Generic formal subprogram substitution: if calling a formal subprogram
     * inside a generic instantiation, substitute with the actual subprogram
     * or generate inline code for built-in operators.
     * For subprograms exported from generic packages, the actuals are on the
     * parent package instance, not on the subprogram itself. */
    Symbol *actuals_holder = cg->current_instance;
    if (actuals_holder and not actuals_holder->generic_actuals and actuals_holder->parent and
        actuals_holder->parent->kind == SYMBOL_PACKAGE and actuals_holder->parent->generic_actuals) {
        actuals_holder = actuals_holder->parent;  /* Use package's generic_actuals */
    }
    if (sym and actuals_holder and actuals_holder->generic_actuals) {
        for (uint32_t i = 0; i < actuals_holder->generic_actual_count; i++) {
            if (Slice_Equal_Ignore_Case(sym->name,
                    actuals_holder->generic_actuals[i].formal_name)) {
                if (actuals_holder->generic_actuals[i].actual_subprogram) {
                    sym = actuals_holder->generic_actuals[i].actual_subprogram;
                } else if (actuals_holder->generic_actuals[i].builtin_operator) {
                    /* Built-in operator - generate inline */
                    Token_Kind op = cg->current_instance->generic_actuals[i].builtin_operator;
                    if (op == TK_AMPERSAND and node->apply.arguments.count == 2) {
                        /* String/array concatenation */
                        Syntax_Node *left_arg = node->apply.arguments.items[0];
                        Syntax_Node *right_arg = node->apply.arguments.items[1];
                        if (left_arg->kind == NK_ASSOCIATION)
                            left_arg = left_arg->association.expression;
                        if (right_arg->kind == NK_ASSOCIATION)
                            right_arg = right_arg->association.expression;

                        /* Get parameter types from formal subprogram symbol */
                        Type_Info *left_type = (sym and sym->parameter_count > 0) ?
                            sym->parameters[0].param_type : left_arg->type;
                        Type_Info *right_type = (sym and sym->parameter_count > 1) ?
                            sym->parameters[1].param_type : right_arg->type;

                        /* Substitute generic formal types with actual types */
                        if (actuals_holder and actuals_holder->generic_actuals) {
                            for (uint32_t k = 0; k < actuals_holder->generic_actual_count; k++) {
                                if (left_type and left_type->name.data and
                                    Slice_Equal_Ignore_Case(left_type->name,
                                        actuals_holder->generic_actuals[k].formal_name) and
                                    actuals_holder->generic_actuals[k].actual_type) {
                                    left_type = actuals_holder->generic_actuals[k].actual_type;
                                }
                                if (right_type and right_type->name.data and
                                    Slice_Equal_Ignore_Case(right_type->name,
                                        actuals_holder->generic_actuals[k].formal_name) and
                                    actuals_holder->generic_actuals[k].actual_type) {
                                    right_type = actuals_holder->generic_actuals[k].actual_type;
                                }
                            }
                        }

                        /* Check if first arg is CHARACTER (single byte) */
                        bool left_is_char = Type_Is_Character(left_type);
                        bool right_is_string = Type_Is_Unconstrained_Array(right_type) or
                                               (not Type_Is_Constrained_Array(right_type) and Type_Is_String(right_type));

                        uint32_t left_val = Generate_Expression(cg, left_arg);
                        uint32_t right_val = Generate_Expression(cg, right_arg);

                        const char *concat_bt = Array_Bound_Llvm_Type(right_type);
                        if (left_is_char and right_is_string) {
                            /* CHARACTER & STRING concatenation */
                            /* Wrap character in single-element fat pointer */
                            uint32_t char_alloc = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = alloca i8\n", char_alloc);
                            const char *char_src_type = Expression_Llvm_Type(cg, left_arg);
                            uint32_t char_trunc = Emit_Convert(cg, left_val, char_src_type, "i8");
                            Emit(cg, "  store i8 %%t%u, ptr %%t%u\n", char_trunc, char_alloc);
                            uint32_t one = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add %s 0, 1\n", one, concat_bt);

                            /* Extract right string bounds and data */
                            uint32_t right_data = Emit_Fat_Pointer_Data(cg, right_val, concat_bt);
                            uint32_t right_low = Emit_Fat_Pointer_Low(cg, right_val, concat_bt);
                            uint32_t right_high = Emit_Fat_Pointer_High(cg, right_val, concat_bt);

                            uint32_t right_len1 = Emit_Length_From_Bounds(cg, right_low, right_high, concat_bt);

                            /* Total length = 1 + right_len */
                            uint32_t total_len = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add %s 1, %%t%u\n", total_len, concat_bt, right_len1);

                            /* Extend to i64 for C-level calls */
                            uint32_t total_len_64 = Emit_Extend_To_I64(cg, total_len, concat_bt);
                            uint32_t right_len1_64 = Emit_Extend_To_I64(cg, right_len1, concat_bt);

                            /* Allocate result buffer */
                            uint32_t result_data = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = call ptr @__ada_sec_stack_alloc(i64 %%t%u)\n",
                                 result_data, total_len_64);

                            /* Store character at first position */
                            Emit(cg, "  store i8 %%t%u, ptr %%t%u\n", char_trunc, result_data);

                            /* Copy right string after character */
                            uint32_t dest = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 1\n", dest, result_data);
                            Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)\n",
                                 dest, right_data, right_len1_64);

                            /* Return fat pointer */
                            return Emit_Fat_Pointer_Dynamic(cg, result_data, one, total_len, concat_bt);
                        } else {
                            /* STRING & STRING concatenation */
                            uint32_t left_fat = left_val;
                            uint32_t right_fat = right_val;

                            uint32_t left_data = Emit_Fat_Pointer_Data(cg, left_fat, concat_bt);
                            uint32_t left_low = Emit_Fat_Pointer_Low(cg, left_fat, concat_bt);
                            uint32_t left_high = Emit_Fat_Pointer_High(cg, left_fat, concat_bt);

                            uint32_t right_data = Emit_Fat_Pointer_Data(cg, right_fat, concat_bt);
                            uint32_t right_low = Emit_Fat_Pointer_Low(cg, right_fat, concat_bt);
                            uint32_t right_high = Emit_Fat_Pointer_High(cg, right_fat, concat_bt);

                            uint32_t left_len1 = Emit_Length_From_Bounds(cg, left_low, left_high, concat_bt);
                            uint32_t right_len1 = Emit_Length_From_Bounds(cg, right_low, right_high, concat_bt);

                            uint32_t total_len = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add %s %%t%u, %%t%u\n", total_len, concat_bt, left_len1, right_len1);

                            /* Extend to i64 for C-level calls */
                            uint32_t total_len_64 = Emit_Extend_To_I64(cg, total_len, concat_bt);
                            uint32_t left_len1_64 = Emit_Extend_To_I64(cg, left_len1, concat_bt);
                            uint32_t right_len1_64 = Emit_Extend_To_I64(cg, right_len1, concat_bt);

                            uint32_t result_data = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = call ptr @__ada_sec_stack_alloc(i64 %%t%u)\n",
                                 result_data, total_len_64);

                            Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)\n",
                                 result_data, left_data, left_len1_64);

                            uint32_t right_dest = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %%t%u\n",
                                 right_dest, result_data, left_len1_64);

                            Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)\n",
                                 right_dest, right_data, right_len1_64);

                            uint32_t one = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add %s 0, 1\n", one, concat_bt);
                            return Emit_Fat_Pointer_Dynamic(cg, result_data, one, total_len, concat_bt);
                        }
                    }
                    /* Inline arithmetic operators (+, -, *, /) */
                    if ((op == TK_PLUS or op == TK_MINUS or op == TK_STAR or op == TK_SLASH)
                        and node->apply.arguments.count == 2) {
                        Syntax_Node *left_arg = node->apply.arguments.items[0];
                        Syntax_Node *right_arg = node->apply.arguments.items[1];
                        if (left_arg->kind == NK_ASSOCIATION)
                            left_arg = left_arg->association.expression;
                        if (right_arg->kind == NK_ASSOCIATION)
                            right_arg = right_arg->association.expression;

                        /* Find the actual type for the first type formal */
                        Type_Info *elem_type = NULL;
                        for (uint32_t k = 0; k < actuals_holder->generic_actual_count; k++) {
                            if (actuals_holder->generic_actuals[k].actual_type) {
                                elem_type = actuals_holder->generic_actuals[k].actual_type;
                                break;
                            }
                        }
                        const char *arith_type = elem_type ? Type_To_Llvm(elem_type)
                                                           : Integer_Arith_Type(cg);

                        uint32_t lv = Generate_Expression(cg, left_arg);
                        uint32_t rv = Generate_Expression(cg, right_arg);
                        const char *lt = Expression_Llvm_Type(cg, left_arg);
                        const char *rt = Expression_Llvm_Type(cg, right_arg);
                        lv = Emit_Convert(cg, lv, lt, arith_type);
                        rv = Emit_Convert(cg, rv, rt, arith_type);

                        uint32_t result = Emit_Temp(cg);
                        const char *ir_op = (op == TK_PLUS) ? "add" :
                                            (op == TK_MINUS) ? "sub" :
                                            (op == TK_STAR) ? "mul" : "sdiv";
                        Emit(cg, "  %%t%u = %s %s %%t%u, %%t%u\n",
                             result, ir_op, arith_type, lv, rv);
                        Temp_Set_Type(cg, result, arith_type);
                        return result;
                    }
                }
                break;
            }
        }
    }

    /* Slice on expression result: prefix(low..high).  NK_RANGE as argument
     * ALWAYS means slice in Ada — never a function parameter (RM 4.1.2).
     * Resolve array type, obtain ptr to array data, compute fat pointer.
     *
     * Generate_Expression returns different LLVM types for different sources:
     *   variable/param of ptr type > ptr  (not widened)
     *   function call returning ptr > i64 (ptrtoint)
     *   fat pointer (unconstrained) > { ptr, { bound, bound } }
     * We use Generate_Composite_Address (returns ptr) for lvalues and
     * Generate_Expression + inttoptr for function-call results. */
    if (node->apply.arguments.count > 0 and
        node->apply.arguments.items[0]->kind == NK_RANGE) {
        Type_Info *at = node->apply.prefix->type;

        /* Fallback type resolution for overloaded functions (RM 6.6) */
        if (not at and sym and sym->kind == SYMBOL_FUNCTION) at = sym->return_type;
        if (not at) at = node->type;

        /* Implicit dereference: access-to-array (RM 4.1(3)) */
        bool access_deref = false;
        if (Type_Is_Access(at) and Type_Is_Array_Like(at->access.designated_type)) {
            at = at->access.designated_type;
            access_deref = true;
        }

        if (at and Type_Is_Array_Like(at)) {
            Syntax_Node *rng = node->apply.arguments.items[0];
            uint32_t base, low_bound_val = 0;
            bool dyn_low = false;
            const char *dyn_low_bt = NULL;

            const char *repr = Type_To_Llvm(at);
            bool is_fat = Llvm_Type_Is_Fat_Pointer(repr);

            if (access_deref) {
                /* Access-to-array: evaluate prefix > access value (i64) > ptr */
                uint32_t access_val = Generate_Expression(cg, node->apply.prefix);
                uint32_t ptr = Emit_Temp(cg);
                Emit(cg, "  %%t%u = inttoptr i64 %%t%u to ptr\n",
                     ptr, access_val);
                const char *at_bt = Array_Bound_Llvm_Type(at);
                if (is_fat) {
                    /* Unconstrained designated: load fat pointer from heap */
                    uint32_t fat = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = load " FAT_PTR_TYPE ", ptr %%t%u\n",
                         fat, ptr);
                    base = Emit_Fat_Pointer_Data(cg, fat, at_bt);
                    low_bound_val = Emit_Fat_Pointer_Low(cg, fat, at_bt);
                    dyn_low = true;
                    dyn_low_bt = at_bt;
                } else {
                    base = ptr;
                }
            } else if (is_fat) {
                const char *at_bt = Array_Bound_Llvm_Type(at);
                /* Unconstrained/string: Generate_Expression > fat pointer */
                uint32_t pv = Generate_Expression(cg, node->apply.prefix);
                base = Emit_Fat_Pointer_Data(cg, pv, at_bt);
                low_bound_val = Emit_Fat_Pointer_Low(cg, pv, at_bt);
                dyn_low = true;
                dyn_low_bt = at_bt;
            } else {
                /* Constrained array: need ptr to array data.
                 * For lvalues (variable, param, field) use Generate_Composite_Address
                 * which always returns ptr.  For function results, Generate_Expression
                 * returns i64 (ptrtoint from ptr), so convert back. */
                bool is_lvalue = false;
                if (node->apply.prefix->kind == NK_IDENTIFIER) {
                    Symbol *ps = node->apply.prefix->symbol;
                    is_lvalue = ps and ps->kind != SYMBOL_FUNCTION;
                } else if (node->apply.prefix->kind == NK_SELECTED) {
                    is_lvalue = true;
                }

                if (is_lvalue) {
                    base = Generate_Composite_Address(cg, node->apply.prefix);
                } else {
                    uint32_t pv = Generate_Expression(cg, node->apply.prefix);
                    base = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = inttoptr i64 %%t%u to ptr\n",
                         base, pv);
                }
            }

            Type_Info *elem = at->array.element_type;
            uint32_t esz = elem ? elem->size : 1;
            if (esz == 0) esz = 1;

            uint32_t slo = Generate_Expression(cg, rng->range.low);
            uint32_t shi = Generate_Expression(cg, rng->range.high);

            const char *slice_iat = Integer_Arith_Type(cg);
            uint32_t off;
            if (dyn_low) {
                uint32_t low_bound_conv = Emit_Convert(cg, low_bound_val, dyn_low_bt, slice_iat);
                off = Emit_Temp(cg);
                Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", off, slice_iat, slo, low_bound_conv);
            } else {
                int128_t al = Array_Low_Bound(at);
                if (al != 0) {
                    off = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = sub %s %%t%u, %s\n", off, slice_iat, slo, I128_Decimal(al));
                } else off = slo;
            }
            uint32_t dp = Emit_Temp(cg);
            if (esz == 1) {
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s %%t%u\n", dp, base, slice_iat, off);
            } else {
                uint32_t bo = Emit_Temp(cg);
                const char *iat_gep = Integer_Arith_Type(cg);
                Emit(cg, "  %%t%u = mul %s %%t%u, %u\n", bo, iat_gep, off, esz);
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s %%t%u\n", dp, base, iat_gep, bo);
            }
            {
                const char *slice_bt = Array_Bound_Llvm_Type(at);
                uint32_t slo_bt = Emit_Convert(cg, slo, Integer_Arith_Type(cg), slice_bt);
                uint32_t shi_bt = Emit_Convert(cg, shi, Integer_Arith_Type(cg), slice_bt);
                return Emit_Fat_Pointer_Dynamic(cg, dp, slo_bt, shi_bt, slice_bt);
            }
        }
    }

    /* RM 12.3(17): redirect generic recursive calls to current instance */
    if (sym and sym->kind == SYMBOL_GENERIC and cg->current_instance)
        sym = cg->current_instance;

    if (sym and (sym->kind == SYMBOL_FUNCTION or sym->kind == SYMBOL_PROCEDURE)) {
        /* Function call - generate arguments
         * For OUT/IN OUT parameters, we need to pass the ADDRESS, not the value.
         * RM 6.2: Scalar and access types are passed by copy (copy-in/copy-out).
         * This prevents aliasing — P(I, I, I) uses independent copies. */
        uint32_t *args = Arena_Allocate(node->apply.arguments.count * sizeof(uint32_t));
        bool *is_byref = Arena_Allocate(node->apply.arguments.count * sizeof(bool));
        /* Track copy-back info for scalar/access OUT/IN OUT params */
        uint32_t *copyback_addr = Arena_Allocate(node->apply.arguments.count * sizeof(uint32_t));
        const char **copyback_llvm = Arena_Allocate(node->apply.arguments.count * sizeof(const char*));
        memset(copyback_addr, 0, node->apply.arguments.count * sizeof(uint32_t));
        memset(copyback_llvm, 0, node->apply.arguments.count * sizeof(const char*));

        for (uint32_t i = 0; i < node->apply.arguments.count; i++) {
            Syntax_Node *arg_node = node->apply.arguments.items[i];
            Syntax_Node *arg = arg_node;  /* Actual expression to evaluate */
            uint32_t param_idx = i;  /* Index into sym->parameters[] */

            /* Handle named association: PARAM_NAME => expression */
            if (arg_node->kind == NK_ASSOCIATION) {
                arg = arg_node->association.expression;
                /* Look up formal parameter by name to get correct index */
                if (arg_node->association.choices.count > 0 and sym->parameters) {
                    Syntax_Node *name_node = arg_node->association.choices.items[0];
                    if (name_node and name_node->kind == NK_IDENTIFIER) {
                        String_Slice param_name = name_node->string_val.text;
                        for (uint32_t p = 0; p < sym->parameter_count; p++) {
                            if (Slice_Equal_Ignore_Case(sym->parameters[p].name, param_name)) {
                                param_idx = p;
                                break;
                            }
                        }
                    }
                }
            }

            /* For ALI-loaded symbols, parameters may be NULL - default to pass by value */
            bool byref = sym->parameters and param_idx < sym->parameter_count and
                         Param_Is_By_Reference(sym->parameters[param_idx].mode);
            is_byref[i] = byref;

            if (byref) {
                /* OUT/IN OUT: pass address of variable */
                Parameter_Mode pmode = sym->parameters[param_idx].mode;
                Type_Info *formal_type = sym->parameters[param_idx].param_type;

                /* Get the actual's address */
                uint32_t actual_addr;
                if (arg->kind == NK_IDENTIFIER and arg->symbol) {
                    actual_addr = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = getelementptr i8, ptr %%", actual_addr);
                    Emit_Symbol_Name(cg, arg->symbol);
                    Emit(cg, ", i64 0  ; address for OUT/IN OUT\n");
                } else {
                    actual_addr = Generate_Composite_Address(cg, arg);
                }

                /* RM 6.2: scalar and access types use copy-in/copy-out */
                bool copy_semantics = formal_type and
                    (Type_Is_Scalar(formal_type) or Type_Is_Access(formal_type));

                if (copy_semantics) {
                    const char *ld_ty = Type_To_Llvm(formal_type);
                    /* Alloca temp for isolated copy */
                    uint32_t temp = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = alloca %s  ; copy-in/copy-out temp\n", temp, ld_ty);
                    if (pmode == PARAM_IN_OUT) {
                        /* Copy-in: load from actual, check constraint, store to temp */
                        uint32_t val = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", val, ld_ty, actual_addr);
                        Emit_Constraint_Check(cg, val, formal_type, arg->type);
                        Emit(cg, "  store %s %%t%u, ptr %%t%u  ; copy-in\n", ld_ty, val, temp);
                    }
                    args[i] = temp;
                    copyback_addr[i] = actual_addr;
                    copyback_llvm[i] = ld_ty;
                } else {
                    /* Composite: pass actual address directly (by reference) */
                    args[i] = actual_addr;
                    /* IN OUT constraint check for composites */
                    if (pmode == PARAM_IN_OUT and formal_type and
                        Type_Is_Scalar(formal_type)) {
                        const char *ld_ty = Type_To_Llvm(formal_type);
                        uint32_t cur_val = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", cur_val, ld_ty, args[i]);
                        Emit_Constraint_Check(cg, cur_val, formal_type, arg->type);
                    }
                }
            } else {
                args[i] = Generate_Expression(cg, arg);
                /* IN parameter: check constraint before call (RM 4.6) */
                if (sym->parameters and param_idx < sym->parameter_count and
                    sym->parameters[param_idx].param_type) {
                    Type_Info *formal_type = sym->parameters[param_idx].param_type;
                    Type_Info *actual_type = arg->type;
                    const char *arg_llvm = Expression_Llvm_Type(cg, arg);
                    args[i] = Emit_Constraint_Check_With_Type(cg, args[i], formal_type, actual_type, arg_llvm);

                    /* Discriminant constraint check for constrained record
                     * subtypes (RM 3.7.2(3)).  When a formal has a constrained
                     * discriminated record subtype like S_TRUE IS VAR_REC(TRUE),
                     * verify that the actual's discriminant matches. */
                    if (Type_Is_Record(formal_type) and
                        formal_type->record.has_disc_constraints and
                        formal_type->record.discriminant_count > 0 and
                        formal_type->record.disc_constraint_values) {
                        const char *iat = Integer_Arith_Type(cg);
                        for (uint32_t di = 0; di < formal_type->record.discriminant_count; di++) {
                            Component_Info *dc = &formal_type->record.components[di];
                            if (not dc->component_type) continue;
                            const char *disc_llvm = Type_To_Llvm(dc->component_type);
                            uint32_t disc_ptr = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %u"
                                     "  ; disc constraint addr\n",
                                 disc_ptr, args[i], dc->byte_offset);
                            uint32_t disc_val = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = load %s, ptr %%t%u"
                                     "  ; load actual discriminant\n",
                                 disc_val, disc_llvm, disc_ptr);
                            if (strcmp(disc_llvm, iat) != 0)
                                disc_val = Emit_Convert(cg, disc_val, disc_llvm, iat);
                            uint32_t expected = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add %s 0, %lld"
                                     "  ; expected disc value\n",
                                 expected, iat,
                                 (long long)formal_type->record.disc_constraint_values[di]);
                            Emit_Discriminant_Check(cg, disc_val, expected,
                                                    iat, formal_type);
                        }
                    }

                    /* Constrained array > unconstrained formal: build fat pointer (RM 6.4.1)
                     * When passing a constrained array to an unconstrained formal, we must
                     * create a fat pointer with the constrained type's bounds. */
                    bool formal_needs_fat = Type_Is_Unconstrained_Array(formal_type) or
                                            Type_Is_String(formal_type) or
                                            (Type_Is_Constrained_Array(formal_type) and
                                             Type_Has_Dynamic_Bounds(formal_type));
                    bool actual_is_constrained =
                        Type_Is_Constrained_Array(actual_type) and
                        not Type_Has_Dynamic_Bounds(actual_type) and
                        actual_type->array.index_count > 0;
                    if (formal_needs_fat and actual_is_constrained) {
                        /* Constrained array to unconstrained formal: build fat pointer.
                         * Generate_Expression returns ptr for constrained arrays; wrap
                         * with the type's static bounds for the unconstrained formal.
                         * But if the expression already produces a fat pointer (e.g.
                         * string literals, slices), skip the wrapping. */
                        const char *arg_llvm = Expression_Llvm_Type(cg, arg);
                        if (not Llvm_Type_Is_Fat_Pointer(arg_llvm)) {
                            const char *abt = Array_Bound_Llvm_Type(actual_type);
                            uint32_t ndims_a = actual_type->array.index_count;
                            if (ndims_a > 1) {
                                /* Multi-dim: build fat pointer with all dimension bounds */
                                uint32_t mlo[8], mhi[8];
                                if (ndims_a > 8) ndims_a = 8;
                                for (uint32_t d = 0; d < ndims_a; d++) {
                                    int128_t lo_d = Type_Bound_Value(actual_type->array.indices[d].low_bound);
                                    int128_t hi_d = Type_Bound_Value(actual_type->array.indices[d].high_bound);
                                    mlo[d] = Emit_Temp(cg);
                                    Emit(cg, "  %%t%u = add %s 0, %s  ; dim%u lo\n", mlo[d], abt, I128_Decimal(lo_d), d);
                                    mhi[d] = Emit_Temp(cg);
                                    Emit(cg, "  %%t%u = add %s 0, %s  ; dim%u hi\n", mhi[d], abt, I128_Decimal(hi_d), d);
                                }
                                args[i] = Emit_Fat_Pointer_MultiDim(cg, args[i], mlo, mhi, ndims_a, abt);
                            } else {
                                int128_t lo = Type_Bound_Value(actual_type->array.indices[0].low_bound);
                                int128_t hi = Type_Bound_Value(actual_type->array.indices[0].high_bound);
                                args[i] = Emit_Fat_Pointer(cg, args[i], lo, hi, abt);
                            }
                        }
                    } else if (Expression_Produces_Fat_Pointer(arg, actual_type) and
                               formal_type->array.is_constrained and
                               formal_type->array.index_count > 0) {
                        /* Fat pointer actual (string literal, slice) to constrained
                         * formal: rebuild fat pointer with the formal type's bounds.
                         * E.g. "ABCDE" passed to STRING(11..15) — bounds must be
                         * 11..15, not the literal's default 1..5.  (RM 4.3.2) */
                        const char *abt = Array_Bound_Llvm_Type(formal_type);
                        uint32_t data_ptr = Emit_Fat_Pointer_Data(cg, args[i], abt);
                        uint32_t lo = Emit_Single_Bound(cg,
                            &formal_type->array.indices[0].low_bound, abt);
                        uint32_t hi = Emit_Single_Bound(cg,
                            &formal_type->array.indices[0].high_bound, abt);
                        args[i] = Emit_Fat_Pointer_Dynamic(cg, data_ptr, lo, hi, abt);
                    } else {
                        const char *param_type = Type_To_Llvm_Sig(formal_type);
                        const char *arg_type = Expression_Llvm_Type(cg, arg);
                        /* Real literal > fixed-point param: scale by 1/SMALL */
                        if (Type_Is_Fixed_Point(formal_type) and arg_type and
                            arg_type[0] != 'i' and arg_type[0] != 'p') {
                            double small = formal_type->fixed.small;
                            if (small <= 0) small = formal_type->fixed.delta > 0
                                                  ? formal_type->fixed.delta : 1.0;
                            args[i] = Convert_Real_To_Fixed(cg, args[i], small, param_type);
                        } else {
                            args[i] = Emit_Convert(cg, args[i], arg_type, param_type);
                        }
                    }
                }
            }
        }

        /* For derived type operations (RM 3.4), emit direct call to parent.
         * Derived types have identical representation to parent in Ada 83,
         * so no wrapper needed - just call the parent's implementation directly.
         * This is the GNAT-style optimization. */
        Symbol *call_target = sym->parent_operation ? sym->parent_operation : sym;

        /* RM 12.3(17): recursive call within a generic body > call current
         * instance.  Redirect SYMBOL_GENERIC to cg->current_instance so the
         * emitted name, return type, and parameter list are correct.
         * GNAT: Expand_N_Subprogram_Call maps generic to current instance. */
        if (call_target->kind == SYMBOL_GENERIC and cg->current_instance) {
            sym = cg->current_instance;
            call_target = sym;
        }

        /* Check if calling a nested function (transitively inside another subprogram) */
        bool callee_is_nested = Subprogram_Needs_Static_Chain(call_target);

        /* Precompute static chain pointer before building call (RM 8.3) */
        uint32_t frame_pre = callee_is_nested ?
            Precompute_Nested_Frame_Arg(cg, call_target) : 0;

        /* Check if callee is a BIP function (returns limited type) */
        bool callee_is_bip = BIP_Is_BIP_Function(call_target);
        uint32_t bip_dest = 0;  /* Destination for BIP result */

        /* For BIP functions, allocate space for the result */
        if (callee_is_bip and sym->return_type) {
            uint32_t type_size = sym->return_type->size;
            if (type_size == 0) type_size = 8;  /* Default for opaque types */
            bip_dest = Emit_Temp(cg);
            Emit(cg, "  %%t%u = alloca [%u x i8]  ; BIP result space\n",
                 bip_dest, type_size);
        }

        uint32_t t = Emit_Temp(cg);

        /* BIP functions return void - result is built into destination */
        if (callee_is_bip) {
            Emit(cg, "  call void @");
        } else if (sym->return_type) {
            Emit(cg, "  %%t%u = call %s @", t, Type_To_Llvm_Sig(sym->return_type));
        } else {
            Emit(cg, "  call void @");
        }

        Emit_Symbol_Name(cg, call_target);
        Emit(cg, "(");

        bool need_comma = false;

        /* Pass frame pointer to nested functions (RM 8.3 static chain) */
        if (callee_is_nested) {
            if (Emit_Nested_Frame_Arg(cg, call_target, frame_pre)) {
                need_comma = true;
            }
        }

        /* BIP extra arguments: allocation form and destination pointer */
        if (callee_is_bip) {
            if (need_comma) Emit(cg, ", ");
            /* Determine allocation form from context:
             * - has_target = true (we allocate stack space above)
             * - is_allocator = false (not a new expression)
             * - in_return_stmt = false (not in return context) */
            BIP_Alloc_Form alloc_form = BIP_Determine_Alloc_Form(
                /*is_allocator=*/false, /*in_return_stmt=*/false, /*has_target=*/true);
            Emit(cg, "i32 %d, ptr %%t%u", alloc_form, bip_dest);
            need_comma = true;
            /* Pass task formals if callee's return type has task components */
            uint32_t bip_count = BIP_Extra_Formal_Count(call_target);
            if (bip_count > 2) {
                /* Pass master and chain (0 for now - full tasking support later) */
                Emit(cg, ", i32 0, ptr null");
            }
        }

        /* Regular arguments */
        for (uint32_t i = 0; i < node->apply.arguments.count; i++) {
            if (need_comma) Emit(cg, ", ");
            need_comma = true;
            if (is_byref[i]) {
                /* OUT/IN OUT: pass as pointer */
                Emit(cg, "ptr %%t%u", args[i]);
            } else {
                const char *param_type = (sym->parameters and i < sym->parameter_count and
                                          sym->parameters[i].param_type)
                    ? Type_To_Llvm_Sig(sym->parameters[i].param_type) : Integer_Arith_Type(cg);
                Emit(cg, "%s %%t%u", param_type, args[i]);
            }
        }

        Emit(cg, ")\n");

        /* For BIP functions, the result is now at bip_dest - keep as ptr */
        if (callee_is_bip and sym->return_type) {
            /* Result is directly at bip_dest, just use it as ptr */
            Temp_Set_Type(cg, bip_dest, "ptr");
            t = bip_dest;
        }

        /* Copy-out: for scalar/access OUT/IN OUT, copy from temp back to actual.
         * This only runs on normal return — exceptions skip via longjmp (RM 6.2). */
        for (uint32_t i = 0; i < node->apply.arguments.count; i++) {
            if (copyback_addr[i]) {
                /* Scalar/access copy-back */
                uint32_t ret_val = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load %s, ptr %%t%u  ; copy-out\n",
                     ret_val, copyback_llvm[i], args[i]);
                Emit(cg, "  store %s %%t%u, ptr %%t%u  ; copy-back to actual\n",
                     copyback_llvm[i], ret_val, copyback_addr[i]);
            } else if (is_byref[i]) {
                /* Composite by-ref: check constraint on returned value */
                Syntax_Node *arg_node = node->apply.arguments.items[i];
                Syntax_Node *arg = (arg_node->kind == NK_ASSOCIATION) ?
                    arg_node->association.expression : arg_node;
                Type_Info *actual_type = arg->type;
                if (not actual_type or not Type_Is_Scalar(actual_type)) continue;
                const char *ld_ty = Type_To_Llvm(actual_type);
                uint32_t ret_val = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load %s, ptr %%t%u  ; OUT/INOUT result\n", ret_val, ld_ty, args[i]);
                Emit_Constraint_Check(cg, ret_val, actual_type, NULL);
            }
        }

        /* return value stays at native type width.
         * No widening to INTEGER — callers use Emit_Convert at use sites.
         * Track the actual LLVM type of the call result so that Emit_Convert
         * at use sites (e.g. return statements) knows the true generated type. */
        if (sym->return_type) {
            Temp_Set_Type(cg, t, Type_To_Llvm_Sig(sym->return_type));
            /* For fat pointer returns (dynamic array), copy the data from the
             * callee's stack to a local alloca so it survives.  The callee's
             * alloca is freed on return, making the data pointer dangling. */
            Type_Info *rt = sym->return_type;
            if (not callee_is_bip and Type_Is_Array_Like(rt) and
                Type_Has_Dynamic_Bounds(rt)) {
                const char *rt_bt = Array_Bound_Llvm_Type(rt);
                /* Extract data and bounds pointers */
                uint32_t old_data = Emit_Fat_Pointer_Data(cg, t, rt_bt);
                /* Compute data size from bounds */
                uint32_t ndims = rt->array.index_count;
                uint32_t elem_sz = rt->array.element_type
                    ? rt->array.element_type->size : 1;
                if (elem_sz == 0) elem_sz = 1;
                uint32_t total_sz = 0;
                if (ndims == 1) {
                    uint32_t len = Emit_Fat_Pointer_Length(cg, t, rt_bt);
                    total_sz = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = mul i32 %%t%u, %u\n", total_sz, len, elem_sz);
                } else {
                    /* Multi-dim: multiply lengths of all dimensions */
                    uint32_t prod = 0;
                    for (uint32_t d = 0; d < ndims and d < 8; d++) {
                        uint32_t lo_d = Emit_Fat_Pointer_Low_Dim(cg, t, rt_bt, d);
                        uint32_t hi_d = Emit_Fat_Pointer_High_Dim(cg, t, rt_bt, d);
                        uint32_t diff = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = sub i32 %%t%u, %%t%u\n", diff, hi_d, lo_d);
                        uint32_t len_d = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = add i32 %%t%u, 1\n", len_d, diff);
                        if (d == 0) prod = len_d;
                        else {
                            uint32_t np = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = mul i32 %%t%u, %%t%u\n", np, prod, len_d);
                            prod = np;
                        }
                    }
                    total_sz = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = mul i32 %%t%u, %u\n", total_sz, prod, elem_sz);
                }
                /* Clamp size to >= 0 */
                uint32_t neg_chk = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp slt i32 %%t%u, 0\n", neg_chk, total_sz);
                uint32_t clamped = Emit_Temp(cg);
                Emit(cg, "  %%t%u = select i1 %%t%u, i32 0, i32 %%t%u\n",
                     clamped, neg_chk, total_sz);
                /* Allocate local buffer and copy data */
                uint32_t local_buf = Emit_Temp(cg);
                Emit(cg, "  %%t%u = alloca i8, i32 %%t%u  ; copy func return data\n",
                     local_buf, clamped);
                uint32_t sz64 = Emit_Temp(cg);
                Emit(cg, "  %%t%u = sext i32 %%t%u to i64\n", sz64, clamped);
                Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)  ; copy return data to caller\n",
                     local_buf, old_data, sz64);
                /* Also copy bounds to a local alloca */
                uint32_t old_bounds = Emit_Temp(cg);
                Emit(cg, "  %%t%u = extractvalue " FAT_PTR_TYPE " %%t%u, 1\n",
                     old_bounds, t);
                uint32_t bounds_sz = ndims * 2 * 4;  /* 2 bounds per dim, i32 each */
                uint32_t local_bounds = Emit_Temp(cg);
                Emit(cg, "  %%t%u = alloca [%u x i8]  ; local bounds copy\n",
                     local_bounds, bounds_sz);
                Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %u, i1 false)  ; copy return bounds\n",
                     local_bounds, old_bounds, bounds_sz);
                /* Rebuild fat pointer with local copies */
                uint32_t new_fat1 = Emit_Temp(cg);
                Emit(cg, "  %%t%u = insertvalue " FAT_PTR_TYPE " undef, ptr %%t%u, 0\n",
                     new_fat1, local_buf);
                uint32_t new_fat2 = Emit_Temp(cg);
                Emit(cg, "  %%t%u = insertvalue " FAT_PTR_TYPE " %%t%u, ptr %%t%u, 1\n",
                     new_fat2, new_fat1, local_bounds);
                Temp_Set_Type(cg, new_fat2, FAT_PTR_TYPE);
                t = new_fat2;
            }
            return t;
        }
        return 0;
    }

    /* Entry call (task rendezvous) */
    if (sym and sym->kind == SYMBOL_ENTRY) {
        /* Entry call: pack parameters, call entry, wait for accept completion */
        Emit(cg, "  ; Entry call: %.*s\n",
             (int)sym->name.length, sym->name.data);

        /* Check if this is an entry family - first argument is family index, not a parameter */
        bool is_entry_family = sym->declaration and sym->declaration->kind == NK_ENTRY_DECL and
                               sym->declaration->entry_decl.index_constraints.count > 0;
        uint32_t family_idx_temp = 0;
        uint32_t first_param_idx = 0;  /* Index of first actual parameter in arguments */

        if (is_entry_family and node->apply.arguments.count > 0) {
            /* First argument is the family index — widen to i32 for index arithmetic */
            family_idx_temp = Generate_Expression(cg, node->apply.arguments.items[0]);
            const char *fam_t = Expression_Llvm_Type(cg, node->apply.arguments.items[0]);
            family_idx_temp = Emit_Convert(cg, family_idx_temp, fam_t, Integer_Arith_Type(cg));
            first_param_idx = 1;  /* Skip family index when processing parameters */
        }

        /* Allocate parameter block (excluding family index for entry families) */
        uint32_t param_count = node->apply.arguments.count - first_param_idx;
        uint32_t param_block = Emit_Temp(cg);
        if (param_count > 0) {
            Emit(cg, "  %%t%u = alloca [%u x i64]  ; entry call parameters\n",
                 param_block, param_count);
        } else {
            Emit(cg, "  %%t%u = inttoptr i64 0 to ptr  ; no parameters\n", param_block);
        }

        /* Store arguments into parameter block (skip family index for entry families) */
        for (uint32_t i = first_param_idx; i < node->apply.arguments.count; i++) {
            uint32_t arg_val = Generate_Expression(cg, node->apply.arguments.items[i]);
            /* Widen argument to i64 for the parameter block ABI */
            const char *arg_t = Expression_Llvm_Type(cg, node->apply.arguments.items[i]);
            arg_val = Emit_Convert(cg, arg_val, arg_t, "i64");
            uint32_t arg_ptr = Emit_Temp(cg);
            Emit(cg, "  %%t%u = getelementptr [%u x i64], ptr %%t%u, i64 0, i64 %u\n",
                 arg_ptr, param_count, param_block, i - first_param_idx);
            Emit(cg, "  store i64 %%t%u, ptr %%t%u\n", arg_val, arg_ptr);
        }

        /* Get task object (from prefix if it's a selected component like Task_Obj.Entry).
         * For access-to-task (P.E1), load the pointer to get the designated task.
         * For .ALL dereference (P.ALL.E1), unwrap NK_UNARY_OP(TK_ALL) to get access var. */
        uint32_t task_ptr = 0;
        Syntax_Node *prefix = node->apply.prefix;
        if (prefix->kind == NK_SELECTED) {
            Symbol *task_sym = prefix->selected.prefix->symbol;
            /* Handle explicit .ALL: prefix->selected.prefix is NK_UNARY_OP(TK_ALL) */
            if (not task_sym and prefix->selected.prefix->kind == NK_UNARY_OP and
                prefix->selected.prefix->unary.op == TK_ALL and
                prefix->selected.prefix->unary.operand) {
                task_sym = prefix->selected.prefix->unary.operand->symbol;
            }
            if (not task_sym) goto entry_no_task;
            task_ptr = Emit_Temp(cg);
            if (task_sym->type and Type_Is_Access(task_sym->type)) {
                /* Access-to-task: load the pointer value (implicit dereference) */
                Emit(cg, "  %%t%u = load ptr, ptr ", task_ptr);
                Emit_Symbol_Storage(cg, task_sym);
                Emit(cg, "  ; access-to-task deref\n");
            } else {
                Emit(cg, "  %%t%u = getelementptr i8, ptr ", task_ptr);
                Emit_Symbol_Storage(cg, task_sym);
                Emit(cg, ", i64 0  ; task object\n");
            }
        } else {
            entry_no_task:
            task_ptr = Emit_Temp(cg);
            Emit(cg, "  %%t%u = inttoptr i64 0 to ptr  ; current task\n", task_ptr);
        }

        /* Get entry index - combine base index with family index for entry families.
         * Formula: entry_idx = base * 1000 + family_arg (matching accept side) */
        const char *eidx_t = Integer_Arith_Type(cg);
        uint32_t entry_idx = Emit_Temp(cg);
        if (is_entry_family and family_idx_temp) {
            Emit(cg, "  %%t%u = add %s %u, %%t%u  ; entry index (base + family)\n",
                 entry_idx, eidx_t, sym->entry_index * 1000, family_idx_temp);
        } else {
            Emit(cg, "  %%t%u = add %s 0, %u  ; entry index (simple entry)\n",
                 entry_idx, eidx_t, sym->entry_index * 1000);
        }

        /* Call runtime entry call function - extend entry index to i64 for RTS ABI */
        uint32_t entry_idx_64 = Emit_Extend_To_I64(cg, entry_idx, eidx_t);
        Emit(cg, "  call void @__ada_entry_call(ptr %%t%u, i64 %%t%u, ptr %%t%u)\n",
             task_ptr, entry_idx_64, param_block);

        return 0;
    }

    /* Type conversion must be checked BEFORE array indexing.
     * PARENT(X) where PARENT is an array type is a type conversion (RM 4.6),
     * not an indexed component.  When the prefix symbol is a type or subtype,
     * this is always a type conversion, never array indexing. */
    if (sym and (sym->kind == SYMBOL_TYPE or sym->kind == SYMBOL_SUBTYPE) and
        node->apply.arguments.count == 1) {
        /* Handled below in the type-conversion section */
        goto type_conversion;
    }

    /* Array indexing (with implicit access dereference per RM 4.1(3)) */
    Type_Info *prefix_type = node->apply.prefix->type;
    Type_Info *array_type = prefix_type;  /* Type to use for indexing */
    bool implicit_deref = false;

    /* Handle implicit dereference: A(I) where A is access-to-array */
    if (Type_Is_Access(prefix_type) and prefix_type->access.designated_type) {
        array_type = prefix_type->access.designated_type;
        implicit_deref = true;
    }

    if (Type_Is_Array_Like(array_type)) {
        Symbol *array_sym = node->apply.prefix->symbol;
        uint32_t base;
        uint32_t low_bound_val = 0, dyn_fat = 0;
        uint32_t high_bound_val = 0;  /* For index checks */
        bool has_dynamic_low = false;
        const char *dyn_bt = NULL;  /* bound type when has_dynamic_low */

        if (implicit_deref) {
            /* Load the access value (pointer to array) then use as base */
            if (array_sym) {
                base = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load ptr, ptr ", base);
                Emit_Symbol_Storage(cg, array_sym);
                Emit(cg, "  ; implicit dereference of access\n");
            } else {
                base = Generate_Expression(cg, node->apply.prefix);
            }
            Emit_Access_Check(cg, base, prefix_type);
        }
        /* Check if unconstrained array OR constrained array with dynamic bounds
         * needing fat pointer handling. Both are stored as fat pointers. */
        else if ((Type_Is_Unconstrained_Array(array_type) or Type_Has_Dynamic_Bounds(array_type)) and
            array_sym and (array_sym->kind == SYMBOL_PARAMETER or array_sym->kind == SYMBOL_VARIABLE or
                          array_sym->kind == SYMBOL_CONSTANT or array_sym->kind == SYMBOL_DISCRIMINANT)) {
            /* Load fat pointer and extract data pointer and low bound */
            Emit(cg, "  ; DEBUG ARRAY INDEX: using fat pointer path (unconstrained=%d, dynamic=%d)\n",
                 Type_Is_Unconstrained_Array(array_type), Type_Has_Dynamic_Bounds(array_type));
            const char *idx_bt = Array_Bound_Llvm_Type(array_type);
            uint32_t fat = Emit_Load_Fat_Pointer(cg, array_sym, idx_bt);
            dyn_fat = fat;
            base = Emit_Fat_Pointer_Data(cg, fat, idx_bt);
            low_bound_val = Emit_Fat_Pointer_Low(cg, fat, idx_bt);
            high_bound_val = Emit_Fat_Pointer_High(cg, fat, idx_bt);
            has_dynamic_low = true;
            dyn_bt = idx_bt;
        } else if (array_sym) {
            /* Constrained array - get direct pointer to data */
            Emit(cg, "  ; DEBUG ARRAY INDEX: using constrained path (sym_kind=%d)\n", array_sym->kind);
            base = Emit_Temp(cg);
            Emit(cg, "  %%t%u = getelementptr i8, ptr ", base);
            Emit_Symbol_Storage(cg, array_sym);
            Emit(cg, ", i64 0\n");
        } else {
            /* Complex prefix (e.g., array field of indexed record) */
            uint32_t prefix_val = Generate_Expression(cg, node->apply.prefix);

            /* If the array is unconstrained or has dynamic bounds, the expression
             * returns a fat pointer struct { ptr, { bound, bound } }. We need to extract
             * the data pointer and low bound from it. */
            if (Type_Is_Unconstrained_Array(array_type) or Type_Has_Dynamic_Bounds(array_type)) {
                /* Extract data pointer from fat pointer value */
                const char *pfx_bt = Array_Bound_Llvm_Type(array_type);
                dyn_fat = prefix_val;
                base = Emit_Fat_Pointer_Data(cg, prefix_val, pfx_bt);
                low_bound_val = Emit_Fat_Pointer_Low(cg, prefix_val, pfx_bt);
                high_bound_val = Emit_Fat_Pointer_High(cg, prefix_val, pfx_bt);
                has_dynamic_low = true;
                dyn_bt = pfx_bt;
            } else {
                /* Constrained array - the expression result is the base pointer */
                base = prefix_val;
            }
        }

        /* Check for slice: ARR(low..high) */
        Syntax_Node *arg0 = node->apply.arguments.items[0];
        if (arg0->kind == NK_RANGE) {
            /* Array slice - return fat pointer {ptr, {low, high}}
             * Slice bounds are absolute indices into the source array.
             * The fat pointer stores: {data_ptr_at_slice_start, {slice_low, slice_high}} */
            Type_Info *elem_type = array_type->array.element_type;
            uint32_t elem_size = elem_type ? elem_type->size : 1;
            if (elem_size == 0) elem_size = 1;

            /* Generate slice bounds (these are the logical bounds of the slice) */
            uint32_t slice_low = Generate_Expression(cg, arg0->range.low);
            uint32_t slice_high = Generate_Expression(cg, arg0->range.high);

            /* Compute zero-based offset for slice start
             * offset = (slice_low - array_low_bound) * elem_size */
            const char *sl_iat = Integer_Arith_Type(cg);
            uint32_t offset;
            int128_t array_low = Array_Low_Bound(array_type);
            if (has_dynamic_low) {
                uint32_t low_bound_conv = Emit_Convert(cg, low_bound_val, dyn_bt, sl_iat);
                offset = Emit_Temp(cg);
                Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", offset, sl_iat, slice_low, low_bound_conv);
            } else if (array_low != 0) {
                offset = Emit_Temp(cg);
                Emit(cg, "  %%t%u = sub %s %%t%u, %s\n", offset, sl_iat, slice_low, I128_Decimal(array_low));
            } else {
                offset = slice_low;
            }

            /* Compute data pointer at slice start */
            uint32_t data_ptr = Emit_Temp(cg);
            if (elem_size == 1) {
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s %%t%u\n",
                     data_ptr, base, sl_iat, offset);
            } else {
                uint32_t byte_off = Emit_Temp(cg);
                Emit(cg, "  %%t%u = mul %s %%t%u, %u\n", byte_off, sl_iat, offset, elem_size);
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s %%t%u\n",
                     data_ptr, base, sl_iat, byte_off);
            }

            /* Build fat pointer with slice bounds using helper */
            {
                const char *sl_bt = Array_Bound_Llvm_Type(array_type);
                uint32_t sl_low_bt = Emit_Convert(cg, slice_low, Integer_Arith_Type(cg), sl_bt);
                uint32_t sl_high_bt = Emit_Convert(cg, slice_high, Integer_Arith_Type(cg), sl_bt);
                return Emit_Fat_Pointer_Dynamic(cg, data_ptr, sl_low_bt, sl_high_bt, sl_bt);
            }
        }

        /* Multi-dimensional array indexing: linearize indices into flat offset.
         * For ARRAY(1..M, 1..N) OF T, D(I,J) > flat = (I-low0)*N + (J-low1)
         * For single-dimension, this reduces to (I - low0). */
        const char *idx_iat = Integer_Arith_Type(cg);
        uint32_t flat_idx = 0;  /* linearized zero-based index */
        uint32_t ndims = array_type->array.index_count;
        uint32_t nargs = node->apply.arguments.count;

        if (ndims > 1 and nargs >= ndims) {
            /* Multi-dimensional: compute flat index = sum of (idx[d] - lo[d]) * stride[d]
             * where stride[d] = product of lengths of dims d+1..ndims-1 */
            for (uint32_t d = 0; d < ndims; d++) {
                Syntax_Node *arg_d = node->apply.arguments.items[d];
                uint32_t dim_idx = Generate_Expression(cg, arg_d);
                const char *dim_src = Expression_Llvm_Type(cg, arg_d);
                if (dim_src and dim_src[0] == 'i' and strcmp(dim_src, idx_iat) != 0)
                    dim_idx = Emit_Convert(cg, dim_idx, dim_src, idx_iat);
                /* Subtract low bound for dimension d */
                if (has_dynamic_low and dyn_fat) {
                    uint32_t lo_d = Emit_Fat_Pointer_Low_Dim(cg, dyn_fat, dyn_bt, d);
                    lo_d = Emit_Convert(cg, lo_d, dyn_bt, idx_iat);
                    uint32_t adj = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u  ; dim %u dyn low adj\n",
                         adj, idx_iat, dim_idx, lo_d, d);
                    dim_idx = adj;
                } else {
                    int128_t lo_d = Type_Bound_Value(array_type->array.indices[d].low_bound);
                    if (lo_d != 0) {
                        uint32_t adj = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = sub %s %%t%u, %s  ; dim %u low adj\n",
                             adj, idx_iat, dim_idx, I128_Decimal(lo_d), d);
                        dim_idx = adj;
                    }
                }
                /* Compute stride: product of inner dimension lengths */
                if (has_dynamic_low and dyn_fat) {
                    uint32_t stride_val = 0;
                    for (uint32_t d2 = d + 1; d2 < ndims; d2++) {
                        uint32_t len_d2 = Emit_Fat_Pointer_Length_Dim(cg, dyn_fat, dyn_bt, d2);
                        len_d2 = Emit_Convert(cg, len_d2, dyn_bt, idx_iat);
                        if (stride_val == 0) {
                            stride_val = len_d2;
                        } else {
                            uint32_t product = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = mul %s %%t%u, %%t%u\n",
                                 product, idx_iat, stride_val, len_d2);
                            stride_val = product;
                        }
                    }
                    if (stride_val != 0) {
                        uint32_t scaled = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = mul %s %%t%u, %%t%u  ; dim %u dyn stride\n",
                             scaled, idx_iat, dim_idx, stride_val, d);
                        dim_idx = scaled;
                    }
                } else {
                    uint32_t stride = 1;
                    for (uint32_t d2 = d + 1; d2 < ndims; d2++) {
                        int128_t lo2 = Type_Bound_Value(array_type->array.indices[d2].low_bound);
                        int128_t hi2 = Type_Bound_Value(array_type->array.indices[d2].high_bound);
                        int128_t cnt2 = hi2 - lo2 + 1;
                        if (cnt2 > 0) stride *= (uint32_t)cnt2;
                    }
                    if (stride > 1) {
                        uint32_t scaled = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = mul %s %%t%u, %u  ; dim %u stride\n",
                             scaled, idx_iat, dim_idx, stride, d);
                        dim_idx = scaled;
                    }
                }
                if (d == 0) {
                    flat_idx = dim_idx;
                } else {
                    uint32_t sum = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s %%t%u, %%t%u  ; accum flat idx\n",
                         sum, idx_iat, flat_idx, dim_idx);
                    flat_idx = sum;
                }
            }
        } else {
            /* Single-dimension indexing (original path) */
            uint32_t idx = Generate_Expression(cg, arg0);
            /* Widen to native integer type for GEP compatibility */
            {
                const char *idx_src_type = Expression_Llvm_Type(cg, arg0);
                if (idx_src_type and idx_src_type[0] == 'i' and strcmp(idx_src_type, idx_iat) != 0)
                    idx = Emit_Convert(cg, idx, idx_src_type, idx_iat);
            }
            if (has_dynamic_low and high_bound_val) {
                uint32_t low_chk = Emit_Convert(cg, low_bound_val, dyn_bt, idx_iat);
                uint32_t high_chk = Emit_Convert(cg, high_bound_val, dyn_bt, idx_iat);
                idx = Emit_Index_Check(cg, idx, low_chk, high_chk, idx_iat, array_type);
            } else if (array_type->array.index_count > 0) {
                int128_t lo = Type_Bound_Value(array_type->array.indices[0].low_bound);
                int128_t hi = Type_Bound_Value(array_type->array.indices[0].high_bound);
                if (lo != hi || lo != 0) {
                    uint32_t lo_t = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s 0, %s  ; low bound\n", lo_t, idx_iat, I128_Decimal(lo));
                    uint32_t hi_t = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s 0, %s  ; high bound\n", hi_t, idx_iat, I128_Decimal(hi));
                    idx = Emit_Index_Check(cg, idx, lo_t, hi_t, idx_iat, array_type);
                }
            }
            /* Adjust for array low bound */
            if (has_dynamic_low) {
                uint32_t low_bound_conv = Emit_Convert(cg, low_bound_val, dyn_bt, idx_iat);
                uint32_t adj = Emit_Temp(cg);
                Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u  ; adjust for dynamic low bound\n",
                     adj, idx_iat, idx, low_bound_conv);
                idx = adj;
            } else {
                int128_t low_bound = Array_Low_Bound(array_type);
                if (low_bound != 0) {
                    uint32_t adj = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = sub %s %%t%u, %s\n", adj, idx_iat, idx, I128_Decimal(low_bound));
                    idx = adj;
                }
            }
            flat_idx = idx;
        }

        /* Get pointer to element and load */
        Type_Info *elem_type_info = array_type->array.element_type;
        bool elem_is_composite = Type_Is_Record(elem_type_info) or
            Type_Is_Constrained_Array(elem_type_info);
        uint32_t elem_size = elem_type_info ? elem_type_info->size : 8;
        const char *elem_type = Type_To_Llvm(elem_type_info);
        uint32_t ptr = Emit_Temp(cg);
        uint32_t t;

        if (elem_is_composite and elem_size > 0) {
            /* Composite element - use byte array for getelementptr */
            Emit(cg, "  %%t%u = getelementptr [%u x i8], ptr %%t%u, %s %%t%u"
                 "  ; array[idx] (composite elem, size=%u)\n",
                 ptr, elem_size, base, idx_iat, flat_idx, elem_size);
            /* Return pointer to composite element (don't load) */
            return ptr;
        } else {
            t = Emit_Temp(cg);
            const char *iat_idx = Integer_Arith_Type(cg);
            Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, %s %%t%u"
                 "  ; &array[idx] (elem_type=%s)\n",
                 ptr, elem_type, base, iat_idx, flat_idx, elem_type);
            Emit(cg, "  %%t%u = load %s, ptr %%t%u  ; array[idx]\n", t, elem_type, ptr);
            /* no widening at load — value stays at native type width.
             * Conversions happen at use sites via Emit_Convert. */
            return t;
        }
    }

    /* Type conversion: Type_Name(Expression) */
type_conversion:
    if (sym and (sym->kind == SYMBOL_TYPE or sym->kind == SYMBOL_SUBTYPE)) {
        /* Type conversion: TYPE_NAME(expression) per RM 4.6.
         * Handles scalar, array, and record conversions. */
        if (node->apply.arguments.count == 1) {
            Syntax_Node *arg = node->apply.arguments.items[0];

            /* Get source and destination types */
            Type_Info *src_type = arg->type;
            Type_Info *dst_type = sym->type;

            /* Array type conversions (RM 4.6(24)):
             * Constrained>Unconstrained: wrap data+bounds into fat pointer.
             * Unconstrained>Constrained: extract data (bounds checked at runtime).
             * Same representation: pass through. */
            if (dst_type and src_type and
                Type_Is_Array_Like(dst_type) and Type_Is_Array_Like(src_type)) {
                uint32_t result = Generate_Expression(cg, arg);
                bool dst_unc = Type_Is_Unconstrained_Array(dst_type);

                /* Check if the source expression actually produces a fat pointer value.
                 * This covers: unconstrained parameters/variables, function calls returning
                 * unconstrained arrays, slices, concatenations, string literals, etc. */
                bool src_is_fat = Expression_Produces_Fat_Pointer(arg, src_type);

                if (dst_unc and not src_is_fat) {
                    /* Constrained/flat storage > Unconstrained: build fat pointer {data, {low, high}}.
                     * Source is stored as a flat alloca; bounds come from type info. */
                    const char *bt = Array_Bound_Llvm_Type(dst_type);
                    int128_t lo = Array_Low_Bound(src_type);
                    int128_t hi = (src_type->kind == TYPE_ARRAY and src_type->array.index_count > 0)
                        ? Type_Bound_Value(src_type->array.indices[0].high_bound) : lo;
                    uint32_t lo_t = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s 0, %s  ; array conv low bound\n", lo_t, bt, I128_Decimal(lo));
                    uint32_t hi_t = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s 0, %s  ; array conv high bound\n", hi_t, bt, I128_Decimal(hi));
                    return Emit_Fat_Pointer_Dynamic(cg, result, lo_t, hi_t, bt);
                } else if (not dst_unc and src_is_fat) {
                    /* Unconstrained fat ptr > Constrained: extract data pointer */
                    const char *bt = Array_Bound_Llvm_Type(src_type);
                    return Emit_Fat_Pointer_Data(cg, result, bt);
                }
                /* Same representation: pass through */
                return result;
            }

            uint32_t result = Generate_Expression(cg, arg);

            if (src_type and dst_type and src_type != dst_type) {
                /* Special handling for fixed-point conversions (RM 4.6)
                 * Fixed-point uses scaled integer representation: value = integer * SMALL */
                if (Type_Is_Fixed_Point(src_type) and Type_Is_Float_Representation(dst_type)) {
                    /* Fixed > Float: convert integer to float, multiply by SMALL */
                    const char *dst_llvm = Type_To_Llvm(dst_type);
                    double small = src_type->fixed.small;
                    if (small <= 0) small = src_type->fixed.delta > 0 ? src_type->fixed.delta : 1.0;
                    uint32_t t1 = Emit_Temp(cg);
                    const char *fix_int_ty = Temp_Get_Type(cg, result);
                    if (not fix_int_ty or fix_int_ty[0] == '\0') fix_int_ty = Type_To_Llvm(src_type);
                    if (not fix_int_ty or fix_int_ty[0] == '\0') fix_int_ty = Integer_Arith_Type(cg);
                    Emit(cg, "  %%t%u = sitofp %s %%t%u to %s  ; fixed>float\n", t1, fix_int_ty, result, dst_llvm);
                    uint32_t t2 = Emit_Temp(cg);
                    uint64_t small_bits;
                    memcpy(&small_bits, &small, sizeof(small_bits));
                    Emit(cg, "  %%t%u = fmul %s %%t%u, 0x%016llX  ; scale by SMALL\n",
                         t2, dst_llvm, t1, (unsigned long long)small_bits);
                    return t2;
                } else if (Type_Is_Float_Representation(src_type) and Type_Is_Fixed_Point(dst_type)) {
                    /* Float > Fixed: divide by SMALL, convert to integer */
                    const char *src_llvm = Expression_Llvm_Type(cg, arg);
                    double small = dst_type->fixed.small;
                    if (small <= 0) small = dst_type->fixed.delta > 0 ? dst_type->fixed.delta : 1.0;
                    uint32_t t1 = Emit_Temp(cg);
                    uint64_t small_bits;
                    memcpy(&small_bits, &small, sizeof(small_bits));
                    Emit(cg, "  %%t%u = fdiv %s %%t%u, 0x%016llX  ; divide by SMALL\n",
                         t1, src_llvm, result, (unsigned long long)small_bits);
                    uint32_t t2 = Emit_Temp(cg);
                    const char *dst_llvm = Type_To_Llvm(dst_type);
                    Emit(cg, "  %%t%u = fptosi %s %%t%u to %s  ; float>fixed\n", t2, src_llvm, t1, dst_llvm);
                    Temp_Set_Type(cg, t2, dst_llvm);
                    return t2;
                }

                /* Types differ - need to convert.
                 * Use signedness-aware conversion: zext for unsigned src/dst. */
                const char *src_llvm = Expression_Llvm_Type(cg, arg);
                const char *dst_llvm = Type_To_Llvm(dst_type);
                bool conv_unsigned = Type_Is_Unsigned(src_type) or Type_Is_Unsigned(dst_type);

                if (strcmp(src_llvm, dst_llvm) != 0) {
                    result = Emit_Convert_Ext(cg, result, src_llvm, dst_llvm, conv_unsigned);
                }
                /* RM 4.6: Check converted value against target subtype constraint */
                if (Type_Is_Scalar(dst_type)) {
                    Emit_Constraint_Check_With_Type(cg, result, dst_type, src_type, dst_llvm);
                }
            }
            return result;
        }
    }

    fprintf(stderr, "warning: Generate_Apply: unhandled call expression at %s:%u\n",
            node->location.filename ? node->location.filename : "<unknown>",
            node->location.line);
    return 0;
}

static uint32_t Generate_Selected(Code_Generator *cg, Syntax_Node *node) {
    /* Generate code for A.B (selected component) */
    Type_Info *prefix_type = node->selected.prefix->type;
    Type_Info *record_type = prefix_type;
    bool implicit_deref = false;

    /* Handle explicit .ALL dereference (RM 4.1) */
    if (Type_Is_Access(prefix_type) and
        Slice_Equal_Ignore_Case(node->selected.selector, S("ALL"))) {
        Type_Info *designated = prefix_type->access.designated_type;

        /* Generate_Lvalue returns the loaded pointer (address of designated) */
        uint32_t ptr = Generate_Lvalue(cg, node);
        Emit_Access_Check(cg, ptr, prefix_type);

        /* For composite types (records, arrays), return pointer */
        if (Type_Is_Composite(designated)) {
            return ptr;
        }

        /* For scalar types, load the value */
        const char *type_str = Type_To_Llvm(designated);
        uint32_t t = Emit_Temp(cg);
        Emit(cg, "  %%t%u = load %s, ptr %%t%u  ; load via .ALL\n", t, type_str, ptr);
        /* no widening at load — value stays at native type width.
         * Conversions happen at use sites via Emit_Convert. */
        return t;
    }

    /* Handle implicit dereference: R.C where R is access-to-record (RM 4.1(3)) */
    if (Type_Is_Access(prefix_type) and Type_Is_Record(prefix_type->access.designated_type)) {
        record_type = prefix_type->access.designated_type;
        implicit_deref = true;
    }

    if (not Type_Is_Record(record_type)) {
        /* Package-qualified name - use the resolved symbol via Generate_Identifier
         * This handles named numbers, constants, variables, and literals properly */
        Symbol *sym = node->symbol;
        if (sym) {
            /* Create a temporary identifier node to reuse Generate_Identifier logic */
            Syntax_Node tmp_id = {.kind = NK_IDENTIFIER, .symbol = sym, .location = node->location};
            tmp_id.type = sym->type;
            return Generate_Identifier(cg, &tmp_id);
        }
        fprintf(stderr, "warning: Generate_Selected: '%.*s' not found in package at %s:%u\n",
                (int)node->selected.selector.length, node->selected.selector.data,
                node->location.filename ? node->location.filename : "<unknown>",
                node->location.line);
        return 0;
    }

    /* Record field access - find component by name */
    uint32_t byte_offset = 0;
    Type_Info *field_type = NULL;
    int32_t field_variant_index = -1;
    for (uint32_t i = 0; i < record_type->record.component_count; i++) {
        if (Slice_Equal_Ignore_Case(
                record_type->record.components[i].name, node->selected.selector)) {
            byte_offset = record_type->record.components[i].byte_offset;
            field_type = record_type->record.components[i].component_type;
            field_variant_index = record_type->record.components[i].variant_index;
            break;
        }
    }

    const char *field_llvm_type = Type_To_Llvm(field_type);

    /* Runtime discriminant check for variant component access (RM 3.7.3)
     * If accessing a component that belongs to a variant, verify the
     * discriminant value matches the variant's expected value. */
    if (field_variant_index >= 0 and record_type->record.has_discriminants and
        record_type->record.variant_count > 0 and
        (uint32_t)field_variant_index < record_type->record.variant_count) {
        Variant_Info *vinfo = &record_type->record.variants[field_variant_index];
        /* Load discriminant value from the first discriminant component */
        Component_Info *disc_comp = &record_type->record.components[0];
        uint32_t disc_offset = disc_comp->byte_offset;
        const char *disc_llvm = Type_To_Llvm(disc_comp->component_type);

        /* Get base address of record for discriminant check.
         * For implicit dereference, load the pointer to get the record address.
         * For direct records, get the storage address via Generate_Lvalue. */
        uint32_t rec_base;
        if (implicit_deref) {
            rec_base = Generate_Expression(cg, node->selected.prefix);
            Emit_Access_Check(cg, rec_base, prefix_type);
        } else {
            rec_base = Generate_Lvalue(cg, node->selected.prefix);
        }
        uint32_t disc_ptr = Emit_Temp(cg);
        Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %u  ; discriminant addr\n",
             disc_ptr, rec_base, disc_offset);
        uint32_t disc_val = Emit_Temp(cg);
        Emit(cg, "  %%t%u = load %s, ptr %%t%u  ; load discriminant\n",
             disc_val, disc_llvm, disc_ptr);
        const char *iat_disc = Integer_Arith_Type(cg);
        if (strcmp(disc_llvm, iat_disc) != 0) {
            disc_val = Emit_Convert(cg, disc_val, disc_llvm, iat_disc);
        }

        if (not vinfo->is_others) {
            uint32_t expected = Emit_Temp(cg);
            Emit(cg, "  %%t%u = add %s 0, %lld  ; expected discriminant\n",
                 expected, iat_disc, (long long)vinfo->disc_value);
            Emit_Discriminant_Check(cg, disc_val, expected, iat_disc, record_type);
        }
        /* For WHEN OTHERS variant, any discriminant value is valid - no check needed */
    }

    /* Use Generate_Lvalue to compute field address — handles all three paths:
     * implicit dereference, nested selection, and direct symbol access.
     * This eliminates duplicated address computation (GNAT LLVM GL_Relationship). */
    uint32_t ptr = Generate_Lvalue(cg, node);

    /* Discriminant-dependent array/string component: data is stored inline
     * in the record, so we must construct a fat pointer from the field
     * address and bounds derived from the discriminant (RM 3.7.1). */
    if (field_type and Type_Is_Array_Like(field_type) and Type_Needs_Fat_Pointer_Load(field_type)) {
        bool is_disc_dep = false;
        for (uint32_t xi = 0; xi < field_type->array.index_count; xi++) {
            if (field_type->array.indices[xi].high_bound.kind == BOUND_EXPR or
                field_type->array.indices[xi].low_bound.kind == BOUND_EXPR) {
                is_disc_dep = true;
                break;
            }
        }
        if (is_disc_dep and field_type->rt_global_id > 0) {
            /* RT-elaborated array in record: build fat ptr from type globals.
             * Multi-dim layout: [lo0, hi0, lo1, hi1, ...] */
            const char *bnd_type = Array_Bound_Llvm_Type(field_type);
            uint32_t rtid = field_type->rt_global_id;
            uint32_t ndims = field_type->array.index_count;
            uint32_t blo[8], bhi[8];
            for (uint32_t d = 0; d < ndims and d < 8; d++) {
                uint32_t lr = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load i64, ptr @__rt_type_%u_lo%u\n", lr, rtid, d);
                blo[d] = (strcmp(bnd_type, "i64") != 0)
                    ? Emit_Convert(cg, lr, "i64", bnd_type) : lr;
                uint32_t hr = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load i64, ptr @__rt_type_%u_hi%u\n", hr, rtid, d);
                bhi[d] = (strcmp(bnd_type, "i64") != 0)
                    ? Emit_Convert(cg, hr, "i64", bnd_type) : hr;
            }
            return Emit_Fat_Pointer_MultiDim(cg, ptr, blo, bhi, ndims, bnd_type);
        }
        if (is_disc_dep) {
            /* Build fat pointer: { ptr data, ptr bounds } */
            const char *bnd_type = Array_Bound_Llvm_Type(field_type);
            uint32_t bounds_alloca = Emit_Temp(cg);
            Emit(cg, "  %%t%u = alloca { %s, %s }\n", bounds_alloca, bnd_type, bnd_type);

            /* Get record base by backing up from field pointer by byte_offset */
            uint32_t rec_base = ptr;
            if (byte_offset > 0) {
                rec_base = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 -%u  ; record base\n",
                     rec_base, ptr, byte_offset);
            }

            for (uint32_t xi = 0; xi < field_type->array.index_count; xi++) {
                Type_Bound *lo_bnd = &field_type->array.indices[xi].low_bound;
                Type_Bound *hi_bnd = &field_type->array.indices[xi].high_bound;

                /* Emit low bound */
                uint32_t lo_val;
                if (lo_bnd->kind == BOUND_INTEGER) {
                    lo_val = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s 0, %lld\n",
                         lo_val, bnd_type, (long long)lo_bnd->int_value);
                } else if (lo_bnd->kind == BOUND_EXPR and lo_bnd->expr and
                           lo_bnd->expr->symbol) {
                    /* Load discriminant value for low bound */
                    Symbol *disc = lo_bnd->expr->symbol;
                    uint32_t d_off = 0;
                    for (uint32_t di = 0; di < record_type->record.component_count; di++) {
                        if (Slice_Equal_Ignore_Case(
                                record_type->record.components[di].name, disc->name)) {
                            d_off = record_type->record.components[di].byte_offset;
                            break;
                        }
                    }
                    uint32_t dp = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %u\n",
                         dp, rec_base, d_off);
                    lo_val = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", lo_val, bnd_type, dp);
                } else {
                    lo_val = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s 0, 1\n", lo_val, bnd_type);
                }

                /* Emit high bound */
                uint32_t hi_val;
                if (hi_bnd->kind == BOUND_INTEGER) {
                    hi_val = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s 0, %lld\n",
                         hi_val, bnd_type, (long long)hi_bnd->int_value);
                } else if (hi_bnd->kind == BOUND_EXPR and hi_bnd->expr and
                           hi_bnd->expr->symbol) {
                    Symbol *disc = hi_bnd->expr->symbol;
                    uint32_t d_off = 0;
                    for (uint32_t di = 0; di < record_type->record.component_count; di++) {
                        if (Slice_Equal_Ignore_Case(
                                record_type->record.components[di].name, disc->name)) {
                            d_off = record_type->record.components[di].byte_offset;
                            break;
                        }
                    }
                    uint32_t dp = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %u\n",
                         dp, rec_base, d_off);
                    hi_val = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", hi_val, bnd_type, dp);
                } else {
                    hi_val = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s 0, 0\n", hi_val, bnd_type);
                }

                /* Store low bound */
                uint32_t lo_ptr = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr { %s, %s }, ptr %%t%u, i32 0, i32 0\n",
                     lo_ptr, bnd_type, bnd_type, bounds_alloca);
                Emit(cg, "  store %s %%t%u, ptr %%t%u\n", bnd_type, lo_val, lo_ptr);

                /* Store high bound */
                uint32_t hi_ptr = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr { %s, %s }, ptr %%t%u, i32 0, i32 1\n",
                     hi_ptr, bnd_type, bnd_type, bounds_alloca);
                Emit(cg, "  store %s %%t%u, ptr %%t%u\n", bnd_type, hi_val, hi_ptr);
            }

            /* Construct fat pointer { data_ptr, bounds_ptr } */
            uint32_t fat1 = Emit_Temp(cg);
            Emit(cg, "  %%t%u = insertvalue { ptr, ptr } undef, ptr %%t%u, 0\n",
                 fat1, ptr);
            uint32_t fat2 = Emit_Temp(cg);
            Emit(cg, "  %%t%u = insertvalue { ptr, ptr } %%t%u, ptr %%t%u, 1\n",
                 fat2, fat1, bounds_alloca);
            return fat2;
        }
        /* Non-disc-dependent: load fat pointer from memory */
        return Emit_Load_Fat_Pointer_From_Temp(cg, ptr, Array_Bound_Llvm_Type(field_type));
    }
    /* Other composite types (records, constrained arrays) return ptr */
    if (Type_Is_Record(field_type) or (field_type and field_type->kind == TYPE_ARRAY))
        return ptr;
    /* For access-type components, load ptr without converting to i64 */
    if (Type_Is_Access(field_type)) {
        uint32_t t = Emit_Temp(cg);
        Emit(cg, "  %%t%u = load ptr, ptr %%t%u  ; .%.*s (access)\n", t, ptr,
             node->selected.selector.length > 20 ? 20 : (int)node->selected.selector.length, node->selected.selector.data);
        return t;
    }
    uint32_t t = Emit_Temp(cg);
    Emit(cg, "  %%t%u = load %s, ptr %%t%u  ; .%.*s\n", t, field_llvm_type, ptr,
         node->selected.selector.length > 20 ? 20 : (int)node->selected.selector.length, node->selected.selector.data);
    /* no widening at load — value stays at native type width.
     * Conversions happen at use sites via Emit_Convert. */
    return t;
}

/* Check if a type bound can be evaluated at compile time.
 * Returns true if the bound is compile-time known, false otherwise.
 * Per GNAT's sem_eval.ads, compile-time known is broader than static -
 * it includes values that can be determined at compile time even if
 * they technically involve non-static expressions. */
static bool Type_Bound_Is_Compile_Time_Known(Type_Bound b) {
    if (b.kind == BOUND_INTEGER or b.kind == BOUND_FLOAT) return true;
    if (b.kind == BOUND_EXPR and b.expr) {
        double val = Eval_Const_Numeric(b.expr);
        return val == val;  /* Returns true if not NaN */
    }
    return false;
}

static double Type_Bound_Float_Value(Type_Bound b) {
    if (b.kind == BOUND_FLOAT) return b.float_value;
    if (b.kind == BOUND_INTEGER) return (double)b.int_value;
    if (b.kind == BOUND_EXPR and b.expr) {
        /* Try to evaluate expression bound at compile time */
        double val = Eval_Const_Numeric(b.expr);
        if (val == val) return val;  /* Not NaN */
    }
    return 0.0;
}

/* Check if a type bound is explicitly set (not default/unset) */
static bool Type_Bound_Is_Set(Type_Bound b) {
    return b.kind == BOUND_INTEGER or b.kind == BOUND_FLOAT or
           (b.kind == BOUND_EXPR and b.expr != NULL);
}

/* Emit implementation-defined float limit: is_low=true > -FLT/DBL_MAX, else +FLT/DBL_MAX.
 * Per Ada RM 3.5.7, unconstrained types use at least ±SAFE_LARGE.
 * LLVM requires 64-bit double hex format for float constants. */
static void Emit_Float_Type_Limit(Code_Generator *cg, uint32_t t, Type_Info *type,
                                   bool is_low, String_Slice attr) {
    const char *fty = Float_Llvm_Type_Of(type);
    bool is_single = (strcmp(fty, "float") == 0);
    if (is_single) {
        /* Single-precision: emit via bitcast i32 > float */
        /* -FLT_MAX = 0xFF7FFFFF, +FLT_MAX = 0x7F7FFFFF */
        uint32_t hex = is_low ? 0xFF7FFFFFu : 0x7F7FFFFFu;
        Emit(cg, "  %%t%u = bitcast i32 %u to float  ; %.*s'%s (unconstrained)\n",
             t, hex, (int)attr.length, attr.data, is_low ? "FIRST" : "LAST");
    } else {
        /* Double-precision: emit via fadd double 0.0, 0x<hex> */
        static const char *dbl_hex[] = {
            "0xFFEFFFFFFFFFFFFF",  /* -DBL_MAX */
            "0x7FEFFFFFFFFFFFFF"   /* +DBL_MAX */
        };
        Emit(cg, "  %%t%u = fadd double 0.0, %s  ; %.*s'%s (unconstrained)\n",
             t, dbl_hex[not is_low],
             (int)attr.length, attr.data, is_low ? "FIRST" : "LAST");
    }
}

/* Get dimension index from attribute argument (1-based, default 1) */
static uint32_t Get_Dimension_Index(Syntax_Node *arg) {
    if (not arg) return 0;  /* Default to first dimension */
    if (arg->kind == NK_INTEGER) return (uint32_t)(arg->integer_lit.value - 1);
    return 0;
}

/* Emit T'FIRST or T'LAST — unified handler for both bound attributes.
 * is_low=true > FIRST (low_bound), is_low=false > LAST (high_bound).
 * For arrays: runtime bounds via fat pointer, or static from index_type.
 * For floats: runtime BOUND_EXPR, static float, or implementation limit.
 * For scalars: static integer or runtime BOUND_EXPR. */
static uint32_t Emit_Bound_Attribute(Code_Generator *cg, uint32_t t,
        Type_Info *prefix_type, Symbol *prefix_sym, Syntax_Node *prefix_expr,
        bool needs_runtime_bounds, uint32_t dim, bool is_low, String_Slice attr) {
    const char *tag = is_low ? "FIRST" : "LAST";

    if (Type_Is_Array_Like(prefix_type)) {
        if (needs_runtime_bounds) {
            const char *attr_bt = Array_Bound_Llvm_Type(prefix_type);
            uint32_t fat = (prefix_sym and prefix_sym->kind != SYMBOL_FUNCTION
                           and prefix_sym->kind != SYMBOL_PROCEDURE)
                ? Emit_Load_Fat_Pointer(cg, prefix_sym, attr_bt)
                : Generate_Expression(cg, prefix_expr);
            {
                /* return bound at native type width, no widening.
                 * Use dim-aware accessor to support multi-dimensional arrays. */
                uint32_t bound = is_low ? Emit_Fat_Pointer_Low_Dim(cg, fat, attr_bt, dim)
                                        : Emit_Fat_Pointer_High_Dim(cg, fat, attr_bt, dim);
                return bound;
            }
        } else if (dim < prefix_type->array.index_count) {
            Type_Bound b = is_low ? prefix_type->array.indices[dim].low_bound
                                  : prefix_type->array.indices[dim].high_bound;
            if (b.kind == BOUND_EXPR and b.expr) {
                /* Dynamic bound expression (e.g., TYPE AA IS ARRAY(SNI,..) where SNI has dynamic range) */
                uint32_t v = Generate_Expression(cg, b.expr);
                const char *iat = Integer_Arith_Type(cg);
                const char *vty = Expression_Llvm_Type(cg, b.expr);
                if (strcmp(vty, iat) != 0 and vty[0] == 'i')
                    v = Emit_Convert(cg, v, vty, iat);
                Emit(cg, "  %%t%u = add %s %%t%u, 0  ; %.*s'%s(%u) dynamic\n",
                     t, iat, v, (int)attr.length, attr.data, tag, dim+1);
                Temp_Set_Type(cg, t, iat);
            } else if (b.kind == BOUND_INTEGER or Type_Bound_Is_Set(b)) {
                Emit(cg, "  %%t%u = add %s 0, %s  ; %.*s'%s(%u)\n", t, Integer_Arith_Type(cg),
                     I128_Decimal(Type_Bound_Value(b)), (int)attr.length, attr.data, tag, dim+1);
                Temp_Set_Type(cg, t, Integer_Arith_Type(cg));
            } else if (prefix_type->array.indices[dim].index_type) {
                /* Bounds not set on array — derive from index type's bounds */
                Type_Info *idx_ty = prefix_type->array.indices[dim].index_type;
                Type_Bound ib = is_low ? idx_ty->low_bound : idx_ty->high_bound;
                if (ib.kind == BOUND_EXPR and ib.expr) {
                    uint32_t v = Generate_Expression(cg, ib.expr);
                    const char *iat = Integer_Arith_Type(cg);
                    const char *vty = Expression_Llvm_Type(cg, ib.expr);
                    if (strcmp(vty, iat) != 0 and vty[0] == 'i')
                        v = Emit_Convert(cg, v, vty, iat);
                    Emit(cg, "  %%t%u = add %s %%t%u, 0  ; %.*s'%s(%u) from idx_type\n",
                         t, iat, v, (int)attr.length, attr.data, tag, dim+1);
                    Temp_Set_Type(cg, t, iat);
                } else {
                    Emit(cg, "  %%t%u = add %s 0, %s  ; %.*s'%s(%u) from idx_type\n",
                         t, Integer_Arith_Type(cg),
                         I128_Decimal(Type_Bound_Value(ib)),
                         (int)attr.length, attr.data, tag, dim+1);
                    Temp_Set_Type(cg, t, Integer_Arith_Type(cg));
                }
            } else {
                /* Fallback: emit 0 */
                Emit(cg, "  %%t%u = add %s 0, 0  ; %.*s'%s(%u) unknown\n", t, Integer_Arith_Type(cg),
                     (int)attr.length, attr.data, tag, dim+1);
                Temp_Set_Type(cg, t, Integer_Arith_Type(cg));
            }
        }
    } else if (prefix_type and not Type_Is_Fixed_Point(prefix_type) and
               (Type_Is_Float(prefix_type) or
                Type_Is_Universal_Real(prefix_type) or
                (is_low  ? prefix_type->low_bound.kind  == BOUND_FLOAT
                         : prefix_type->high_bound.kind == BOUND_FLOAT))) {
        /* Float type — determine LLVM type, then emit bound */
        const char *fty = Float_Llvm_Type_Of(prefix_type);
        Type_Bound b = is_low ? prefix_type->low_bound : prefix_type->high_bound;
        if (b.kind == BOUND_EXPR and b.expr) {
            uint32_t v = Generate_Expression(cg, b.expr);
            /* Convert bound expression to target float type if needed */
            const char *expr_fty = Expression_Llvm_Type(cg, b.expr);
            if (strcmp(expr_fty, fty) != 0) {
                v = Emit_Convert(cg, v, expr_fty, fty);
            }
            Emit(cg, "  %%t%u = fadd %s %%t%u, 0.0  ; %.*s'%s (runtime)\n",
                 t, fty, v, (int)attr.length, attr.data, tag);
        } else if (Type_Bound_Is_Set(b)) {
            Emit(cg, "  %%t%u = fadd %s 0.0, %e  ; %.*s'%s\n",
                 t, fty, Type_Bound_Float_Value(b), (int)attr.length, attr.data, tag);
        } else {
            Emit_Float_Type_Limit(cg, t, prefix_type, is_low, attr);
        }
    } else if (prefix_type) {
        Type_Bound b = is_low ? prefix_type->low_bound : prefix_type->high_bound;
        /* Use prefix type's LLVM width so codegen matches Expression_Llvm_Type.
         * Inside generic instantiations, resolve through the base type chain
         * to get the actual type's native width (e.g., BOOLEAN > i8). */
        const char *bound_llvm = Type_To_Llvm(prefix_type);
        if (cg->current_instance and prefix_type->base_type) {
            Type_Info *resolved_base = Resolve_Generic_Actual_Type(cg, prefix_type->base_type);
            if (resolved_base != prefix_type->base_type) {
                const char *actual_llvm = Type_To_Llvm(resolved_base);
                if (actual_llvm and actual_llvm[0] == 'i') bound_llvm = actual_llvm;
            }
        }
        if (not bound_llvm or bound_llvm[0] != 'i') bound_llvm = Integer_Arith_Type(cg);
        if (Type_Is_Fixed_Point(prefix_type)) {
            /* Fixed-point FIRST/LAST must return scaled integer representation.
             * Internal repr = abstract_value / SMALL. */
            double small = prefix_type->fixed.small;
            if (small <= 0) small = prefix_type->fixed.delta > 0 ? prefix_type->fixed.delta : 1.0;
            if (b.kind == BOUND_EXPR and b.expr) {
                /* Runtime-computed bound (e.g. IDENT_INT(1) * (-1.0)) */
                uint32_t fv = Generate_Expression(cg, b.expr);
                const char *fv_ty = Temp_Get_Type(cg, fv);
                bool fv_float = (fv_ty and Is_Float_Type(fv_ty))
                    or Type_Is_Float_Representation(b.expr->type)
                    or (b.expr->type and b.expr->type->kind == TYPE_UNIVERSAL_REAL);
                if (fv_float) {
                    uint64_t sb; memcpy(&sb, &small, sizeof(sb));
                    uint32_t st = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = fadd double 0.0, 0x%016llX\n", st, (unsigned long long)sb);
                    uint32_t dv = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = fdiv double %%t%u, %%t%u\n", dv, fv, st);
                    Emit(cg, "  %%t%u = fptosi double %%t%u to %s\n", t, dv, bound_llvm);
                } else {
                    const char *fv_src = fv_ty ? fv_ty : Type_To_Llvm(b.expr->type);
                    if (not fv_src or fv_src[0] != 'i') fv_src = bound_llvm;
                    if (strcmp(fv_src, bound_llvm) == 0) {
                        Emit(cg, "  %%t%u = add %s 0, %%t%u\n", t, bound_llvm, fv);
                    } else {
                        Emit(cg, "  %%t%u = sext %s %%t%u to %s\n", t, fv_src, fv, bound_llvm);
                    }
                }
                Temp_Set_Type(cg, t, bound_llvm);
            } else {
                double fval = Type_Bound_Float_Value(b);
                int64_t scaled = (int64_t)(fval / small);
                Emit(cg, "  %%t%u = add %s 0, %lld  ; %.*s'%s (fixed scaled %g/small)\n", t,
                     bound_llvm, (long long)scaled, (int)attr.length, attr.data, tag, fval);
                Temp_Set_Type(cg, t, bound_llvm);
            }
        } else if (Type_Bound_Is_Compile_Time_Known(b)) {
            Emit(cg, "  %%t%u = add %s 0, %s  ; %.*s'%s\n", t,
                 bound_llvm, I128_Decimal(Type_Bound_Value(b)), (int)attr.length, attr.data, tag);
            Temp_Set_Type(cg, t, bound_llvm);
        } else {
            return Generate_Bound_Value(cg, b, bound_llvm);
        }
    } else {
        fprintf(stderr, "warning: attribute '%.*s'%s has no type, defaulting to 0\n",
                (int)attr.length, attr.data, tag);
        Emit(cg, "  %%t%u = add %s 0, 0  ; %.*s'%s (no type)\n", t,
             Integer_Arith_Type(cg), (int)attr.length, attr.data, tag);
    }
    return t;
}

static uint32_t Generate_Attribute(Code_Generator *cg, Syntax_Node *node) {
    Type_Info *prefix_type = node->attribute.prefix->type;
    String_Slice attr = node->attribute.name;
    uint32_t t = Emit_Temp(cg);
    Syntax_Node *first_arg = node->attribute.arguments.count > 0
                           ? node->attribute.arguments.items[0] : NULL;
    uint32_t dim = Get_Dimension_Index(first_arg);

    /* Resolve generic formal type > actual (RM 12.3), but preserve constrained subtypes */
    if (prefix_type and cg->current_instance and not prefix_type->base_type)
        prefix_type = Resolve_Generic_Actual_Type(cg, prefix_type);

    /* If the attribute prefix is T'BASE, resolve BASE after generic substitution.
     * T'BASE with T=C (constrained subtype) should use C's unconstrained base type.
     * Without this, T'BASE'FIRST/LAST incorrectly uses the subtype's bounds (RM 3.3.3). */
    if (node->attribute.prefix->kind == NK_ATTRIBUTE and
        Slice_Equal_Ignore_Case(node->attribute.prefix->attribute.name, S("BASE")) and
        prefix_type and prefix_type->base_type)
        prefix_type = Type_Root(prefix_type);

    /* For subtypes of generic formals (SUBTYPE S IS T where T is a formal),
     * resolve through the base chain to find the actual type for classification.
     * prefix_type keeps subtype bounds (for FIRST/LAST); classify_type has the
     * actual type kind (for IMAGE, VALUE, etc.) (RM 12.3). */
    Type_Info *classify_type = prefix_type;
    if (cg->current_instance and prefix_type) {
        Type_Info *walk = prefix_type;
        for (int depth = 0; walk and depth < 20; depth++) {
            Type_Info *resolved = Resolve_Generic_Actual_Type(cg, walk);
            if (resolved != walk) { classify_type = resolved; break; }
            walk = walk->base_type ? walk->base_type : walk->parent_type;
        }
    }

    /* Implicit dereference for access-to-array (RM 4.1(3)) */
    if (Type_Is_Access(prefix_type) and prefix_type->access.designated_type)
        prefix_type = prefix_type->access.designated_type;

    /* Determine if prefix needs runtime bounds (fat pointer) */
    bool needs_runtime_bounds = false;
    Symbol *prefix_sym = node->attribute.prefix->symbol;
    if (not prefix_type and prefix_sym and prefix_sym->type)
        prefix_type = prefix_sym->type;
    if (prefix_type and
        (Type_Is_Unconstrained_Array(prefix_type) or Type_Has_Dynamic_Bounds(prefix_type)))
        if (not prefix_sym or prefix_sym->kind == SYMBOL_PARAMETER or
            prefix_sym->kind == SYMBOL_VARIABLE or prefix_sym->kind == SYMBOL_CONSTANT or
            prefix_sym->kind == SYMBOL_DISCRIMINANT or
            prefix_sym->kind == SYMBOL_FUNCTION or prefix_sym->kind == SYMBOL_PROCEDURE)
            needs_runtime_bounds = true;

    /* ─── Array/Scalar Bound Attributes: unified FIRST/LAST ─── */

    if (Slice_Equal_Ignore_Case(attr, S("FIRST")))
        return Emit_Bound_Attribute(cg, t, prefix_type, prefix_sym,
                   node->attribute.prefix, needs_runtime_bounds, dim, true, attr);

    if (Slice_Equal_Ignore_Case(attr, S("LAST")))
        return Emit_Bound_Attribute(cg, t, prefix_type, prefix_sym,
                   node->attribute.prefix, needs_runtime_bounds, dim, false, attr);

    if (Slice_Equal_Ignore_Case(attr, S("LENGTH"))) {
        if (Type_Is_Array_Like(prefix_type)) {
            if (needs_runtime_bounds) {
                const char *len_bt = Array_Bound_Llvm_Type(prefix_type);
                uint32_t fat;
                if (prefix_sym) {
                    fat = Emit_Load_Fat_Pointer(cg, prefix_sym, len_bt);
                } else {
                    /* Complex prefix expression - generate it to get fat pointer value */
                    fat = Generate_Expression(cg, node->attribute.prefix);
                }
                {
                    /* return length at native type width, no widening.
                     * Use dim-aware accessor for multi-dimensional arrays. */
                    uint32_t len = Emit_Fat_Pointer_Length_Dim(cg, fat, len_bt, dim);
                    return len;
                }
            } else if (dim < prefix_type->array.index_count) {
                Type_Bound lb = prefix_type->array.indices[dim].low_bound;
                Type_Bound hb = prefix_type->array.indices[dim].high_bound;
                /* If bounds not set, try deriving from index_type */
                if (lb.kind != BOUND_INTEGER and lb.kind != BOUND_EXPR and
                    prefix_type->array.indices[dim].index_type) {
                    Type_Info *idx_ty = prefix_type->array.indices[dim].index_type;
                    lb = idx_ty->low_bound;
                    hb = idx_ty->high_bound;
                }
                if (lb.kind == BOUND_EXPR or hb.kind == BOUND_EXPR) {
                    /* Dynamic length: generate high - low + 1 at runtime */
                    const char *iat = Integer_Arith_Type(cg);
                    uint32_t lo_t = Emit_Type_Bound(cg, &lb, iat);
                    uint32_t hi_t = Emit_Type_Bound(cg, &hb, iat);
                    uint32_t len = Emit_Length_Clamped(cg, lo_t, hi_t, iat);
                    /* Copy to result temp t */
                    Emit(cg, "  %%t%u = add %s %%t%u, 0  ; 'LENGTH(%u)\n", t, iat, len, dim+1);
                    Temp_Set_Type(cg, t, iat);
                } else {
                    int128_t low = Type_Bound_Value(lb);
                    int128_t high = Type_Bound_Value(hb);
                    int128_t length = (high >= low) ? (high - low + 1) : 0;
                    Emit(cg, "  %%t%u = add %s 0, %s  ; 'LENGTH(%u)\n", t, Integer_Arith_Type(cg),
                         I128_Decimal(length), dim + 1);
                    Temp_Set_Type(cg, t, Integer_Arith_Type(cg));
                }
            }
        }
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("RANGE"))) {
        /* Range attribute - for general expression contexts, return low bound.
         * For loops handle RANGE specially in Generate_For_Loop. */
        if (Type_Is_Array_Like(prefix_type)) {
            if (needs_runtime_bounds) {
                const char *rng_bt = Array_Bound_Llvm_Type(prefix_type);
                uint32_t fat;
                if (prefix_sym) {
                    fat = Emit_Load_Fat_Pointer(cg, prefix_sym, rng_bt);
                } else {
                    /* Complex prefix expression - generate it to get fat pointer value */
                    fat = Generate_Expression(cg, node->attribute.prefix);
                }
                /* return RANGE low at native type width, no widening.
                 * Use dim-aware accessor for multi-dimensional arrays. */
                return Emit_Fat_Pointer_Low_Dim(cg, fat, rng_bt, dim);
            } else if (dim < prefix_type->array.index_count) {
                Type_Bound lb = prefix_type->array.indices[dim].low_bound;
                /* If bounds not set, try deriving from index_type */
                if (lb.kind != BOUND_INTEGER and lb.kind != BOUND_EXPR and
                    prefix_type->array.indices[dim].index_type) {
                    lb = prefix_type->array.indices[dim].index_type->low_bound;
                }
                if (lb.kind == BOUND_EXPR and lb.expr) {
                    uint32_t v = Generate_Expression(cg, lb.expr);
                    const char *iat = Integer_Arith_Type(cg);
                    const char *vty = Expression_Llvm_Type(cg, lb.expr);
                    if (strcmp(vty, iat) != 0 and vty[0] == 'i')
                        v = Emit_Convert(cg, v, vty, iat);
                    Emit(cg, "  %%t%u = add %s %%t%u, 0  ; 'RANGE(%u) low dynamic\n",
                         t, iat, v, dim + 1);
                    Temp_Set_Type(cg, t, iat);
                } else {
                    Emit(cg, "  %%t%u = add %s 0, %s  ; 'RANGE(%u) low\n", t, Integer_Arith_Type(cg),
                         I128_Decimal(Type_Bound_Value(lb)), dim + 1);
                }
            }
        }
        return t;
    }

    /* ─────────────────────────────────────────────────────────────────────
     * Size and Representation Attributes
     * ───────────────────────────────────────────────────────────────────── */

    if (Slice_Equal_Ignore_Case(attr, S("SIZE"))) {
        /* 'SIZE returns size in bits.
         * Use specified_bit_size if a SIZE clause was given (exact value),
         * otherwise compute from byte size. */
        if (not prefix_type)
            fprintf(stderr, "warning: 'SIZE attribute applied to expression with no type\n");
        int64_t bit_size = 0;
        if (prefix_type) {
            if (prefix_type->specified_bit_size > 0)
                bit_size = prefix_type->specified_bit_size;
            else
                bit_size = (int64_t)prefix_type->size * 8;
        }
        Emit(cg, "  %%t%u = add %s 0, %lld  ; 'SIZE in bits\n", t, Integer_Arith_Type(cg),
             (long long)bit_size);
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("ALIGNMENT"))) {
        if (not prefix_type)
            fprintf(stderr, "warning: 'ALIGNMENT attribute applied to expression with no type\n");
        Emit(cg, "  %%t%u = add %s 0, %lld  ; 'ALIGNMENT\n", t, Integer_Arith_Type(cg),
             (long long)(prefix_type ? prefix_type->alignment : 8));
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("COMPONENT_SIZE"))) {
        if (Type_Is_Array_Like(prefix_type) and prefix_type->array.element_type) {
            Emit(cg, "  %%t%u = add %s 0, %lld  ; 'COMPONENT_SIZE\n", t, Integer_Arith_Type(cg),
                 (long long)(prefix_type->array.element_type->size * 8));
        } else {
            fprintf(stderr, "warning: 'COMPONENT_SIZE applied to non-array type, returning 0\n");
            Emit(cg, "  %%t%u = add %s 0, 0\n", t, Integer_Arith_Type(cg));
        }
        return t;
    }

    /* ─────────────────────────────────────────────────────────────────────
     * Address Attribute
     * ───────────────────────────────────────────────────────────────────── */

    if (Slice_Equal_Ignore_Case(attr, S("ADDRESS"))) {
        /* Generate address of prefix object */
        Symbol *sym = node->attribute.prefix->symbol;
        if (sym) {
            if (sym->kind == SYMBOL_LABEL) {
                /* Label address - use blockaddress for code location */
                if (sym->llvm_label_id == 0) {
                    sym->llvm_label_id = cg->label_id++;
                }
                Emit(cg, "  %%t%u = ptrtoint ptr blockaddress(@", t);
                Emit_Symbol_Name(cg, cg->current_function);
                Emit(cg, ", %%L%u) to i64  ; '%.*s'ADDRESS\n",
                     sym->llvm_label_id,
                     (int)sym->name.length, sym->name.data);
            } else if (sym->kind == SYMBOL_FUNCTION or sym->kind == SYMBOL_PROCEDURE) {
                /* Subprogram address - use function pointer directly */
                Emit(cg, "  %%t%u = ptrtoint ptr @", t);
                Emit_Symbol_Name(cg, sym);
                Emit(cg, " to i64  ; '%.*s'ADDRESS (subprogram)\n",
                     (int)sym->name.length, sym->name.data);
            } else if (sym->kind == SYMBOL_PACKAGE or sym->kind == SYMBOL_GENERIC) {
                /* Package/generic address - use a global marker */
                Emit(cg, "  %%t%u = ptrtoint ptr @__addr.", t);
                Emit_Symbol_Name(cg, sym);
                Emit(cg, " to i64  ; '%.*s'ADDRESS (package/generic)\n",
                     (int)sym->name.length, sym->name.data);
                /* Mark that we need to emit this global marker */
                if (not sym->needs_address_marker and cg->address_marker_count < 256) {
                    sym->needs_address_marker = true;
                    cg->address_markers[cg->address_marker_count++] = sym;
                }
            } else if (sym->kind == SYMBOL_TYPE and Type_Is_Task(sym->type)) {
                /* Task type address - use a global marker */
                Emit(cg, "  %%t%u = ptrtoint ptr @__addr.", t);
                Emit_Symbol_Name(cg, sym);
                Emit(cg, " to i64  ; '%.*s'ADDRESS (task type)\n",
                     (int)sym->name.length, sym->name.data);
                if (not sym->needs_address_marker and cg->address_marker_count < 256) {
                    sym->needs_address_marker = true;
                    cg->address_markers[cg->address_marker_count++] = sym;
                }
            } else {
                /* Variable/task address — emit via uplevel predicate */
                Emit(cg, "  %%t%u = ptrtoint ptr ", t);
                Emit_Symbol_Storage(cg, sym);
                Emit(cg, " to i64  ; 'ADDRESS\n");
            }
        } else {
            fprintf(stderr, "warning: 'ADDRESS attribute applied to expression with no symbol\n");
            Emit(cg, "  %%t%u = add i64 0, 0  ; 'ADDRESS (no symbol)\n", t);
        }
        return t;
    }

    /* ─────────────────────────────────────────────────────────────────────
     * Enumeration Attributes
     * ───────────────────────────────────────────────────────────────────── */

    if (Slice_Equal_Ignore_Case(attr, S("POS"))) {
        /* T'POS(x) - position of enumeration value (RM 3.5.5).
         * POS returns universal_integer — convert to Integer_Arith_Type
         * so the result matches Expression_Llvm_Type's prediction. */
        if (first_arg) {
            uint32_t val = Generate_Expression(cg, first_arg);
            const char *arg_t = Expression_Llvm_Type(cg, first_arg);
            const char *iat = Integer_Arith_Type(cg);
            return Emit_Convert(cg, val, arg_t, iat);
        }
        fprintf(stderr, "warning: 'POS attribute requires an argument\n");
        return 0;
    }

    if (Slice_Equal_Ignore_Case(attr, S("VAL"))) {
        /* T'VAL(n) - value at position n (RM 3.5.5(5))
         * Raises CONSTRAINT_ERROR if n is outside T'BASE range */
        if (first_arg) {
            uint32_t val = Generate_Expression(cg, first_arg);
            /* Get BASE TYPE bounds for range check (RM 3.5.5(5)) */
            Type_Info *val_base = Type_Root(prefix_type);
            if (cg->current_instance)
                val_base = Type_Root(Resolve_Generic_Actual_Type(cg, val_base));
            int64_t lo = 0, hi = 0;
            bool have_bounds = false;
            if (Type_Is_Enumeration(val_base) and
                val_base->enumeration.literal_count > 0) {
                lo = 0;
                hi = (int64_t)(val_base->enumeration.literal_count - 1);
                have_bounds = true;
            } else if (val_base->low_bound.kind == BOUND_INTEGER and
                       val_base->high_bound.kind == BOUND_INTEGER) {
                lo = val_base->low_bound.int_value;
                hi = val_base->high_bound.int_value;
                have_bounds = true;
            }
            if (have_bounds) {
                /* Range check at i32 width (argument is integer) */
                const char *iat = Integer_Arith_Type(cg);
                const char *arg_t = Expression_Llvm_Type(cg, first_arg);
                uint32_t check_val = Emit_Convert(cg, val, arg_t, iat);
                Emit_Range_Check_With_Raise(cg, check_val, lo, hi, iat, "'VAL");
            }
            /* T'VAL returns at type T's width — convert from argument type.
             * Resolve generic formal types to their actuals. */
            const char *val_t = Expression_Llvm_Type(cg, first_arg);
            Type_Info *val_result_type = prefix_type;
            if (cg->current_instance)
                val_result_type = Resolve_Generic_Actual_Type(cg, val_result_type);
            const char *result_t = Type_To_Llvm(val_result_type);
            if (result_t and result_t[0] == 'i')
                val = Emit_Convert(cg, val, val_t, result_t);
            return val;
        }
        fprintf(stderr, "warning: 'VAL attribute requires an argument\n");
        return 0;
    }

    /* T'SUCC(x) / T'PRED(x) — RM 3.5.5: operates on base type.
     * SUCC adds 1 and checks against high bound; PRED subtracts 1 and checks low. */
    if (Slice_Equal_Ignore_Case(attr, S("SUCC")) or
        Slice_Equal_Ignore_Case(attr, S("PRED"))) {
        bool is_succ = (attr.data[0] == 'S' or attr.data[0] == 's');
        if (first_arg) {
            uint32_t val = Generate_Expression(cg, first_arg);
            /* Operate in i64 to avoid overflow when SUCC(LAST) or PRED(FIRST)
             * would wrap in the native type width (e.g. i32 INTEGER). */
            const char *wide_iat = "i64";
            const char *arg_t = Expression_Llvm_Type(cg, first_arg);
            uint32_t wide_val = Emit_Convert(cg, val, arg_t, wide_iat);
            Emit(cg, "  %%t%u = %s %s %%t%u, 1  ; '%s\n",
                 t, is_succ ? "add" : "sub", wide_iat, wide_val, is_succ ? "SUCC" : "PRED");
            Temp_Set_Type(cg, t, wide_iat);
            /* Resolve root base type for 'PRED/'SUCC bound check (RM 3.5.5(6)):
             * Result must be in T'BASE range, which for derived types
             * includes ALL values of the parent type's base range. */
            Type_Info *base = Type_Root(prefix_type);
            if (cg->current_instance)
                base = Type_Root(Resolve_Generic_Actual_Type(cg, base));
            /* Bound check: SUCC vs high, PRED vs low */
            Type_Bound limit = is_succ ? base->high_bound : base->low_bound;
            if (base and limit.kind == BOUND_INTEGER) {
                uint32_t cmp = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp %s %s %%t%u, %s\n", cmp,
                     is_succ ? "sgt" : "slt", wide_iat, t, I128_Decimal(limit.int_value));
                Emit_Check_With_Raise(cg, cmp, true, is_succ ? "'SUCC" : "'PRED");
            }
            /* Convert result back to prefix type width.
             * Resolve generic formal types to their actuals. */
            Type_Info *result_type = prefix_type;
            if (cg->current_instance)
                result_type = Resolve_Generic_Actual_Type(cg, result_type);
            const char *result_t = Type_To_Llvm(result_type);
            if (result_t and result_t[0] == 'i')
                t = Emit_Convert(cg, t, wide_iat, result_t);
            return t;
        }
    }

    /* ─────────────────────────────────────────────────────────────────────
     * Scalar Type Attributes
     * ───────────────────────────────────────────────────────────────────── */

    if (Slice_Equal_Ignore_Case(attr, S("MIN"))) {
        /* T'MIN(a, b) - minimum of two values */
        if (node->attribute.arguments.count >= 2) {
            uint32_t a = Generate_Expression(cg, node->attribute.arguments.items[0]);
            uint32_t b = Generate_Expression(cg, node->attribute.arguments.items[1]);
            /* Select minimum using icmp and select */
            uint32_t cmp = Emit_Temp(cg);
            Emit(cg, "  %%t%u = icmp slt %s %%t%u, %%t%u\n", cmp, Integer_Arith_Type(cg), a, b);
            Emit(cg, "  %%t%u = select i1 %%t%u, %s %%t%u, %s %%t%u  ; 'MIN\n", t, cmp, Integer_Arith_Type(cg), a, Integer_Arith_Type(cg), b);
            return t;
        }
        fprintf(stderr, "warning: 'MIN attribute requires two arguments\n");
        return 0;
    }

    if (Slice_Equal_Ignore_Case(attr, S("MAX"))) {
        /* T'MAX(a, b) - maximum of two values */
        if (node->attribute.arguments.count >= 2) {
            uint32_t a = Generate_Expression(cg, node->attribute.arguments.items[0]);
            uint32_t b = Generate_Expression(cg, node->attribute.arguments.items[1]);
            /* Select maximum using icmp and select */
            uint32_t cmp = Emit_Temp(cg);
            Emit(cg, "  %%t%u = icmp sgt %s %%t%u, %%t%u\n", cmp, Integer_Arith_Type(cg), a, b);
            Emit(cg, "  %%t%u = select i1 %%t%u, %s %%t%u, %s %%t%u  ; 'MAX\n", t, cmp, Integer_Arith_Type(cg), a, Integer_Arith_Type(cg), b);
            return t;
        }
        fprintf(stderr, "warning: 'MAX attribute requires two arguments\n");
        return 0;
    }

    if (Slice_Equal_Ignore_Case(attr, S("ABS"))) {
        /* T'ABS(x) with overflow check: ABS(MIN_INT) overflows */
        if (first_arg) {
            uint32_t val = Generate_Expression(cg, first_arg);
            const char *abs_type = Integer_Arith_Type(cg);
            Type_Info *res_type = first_arg->type;
            uint32_t zero = Emit_Temp(cg);
            Emit(cg, "  %%t%u = add %s 0, 0\n", zero, abs_type);
            uint32_t neg = Emit_Overflow_Checked_Op(cg, zero, val, "sub", abs_type, res_type);
            uint32_t cmp = Emit_Temp(cg);
            Emit(cg, "  %%t%u = icmp slt %s %%t%u, 0\n", cmp, abs_type, val);
            Emit(cg, "  %%t%u = select i1 %%t%u, %s %%t%u, %s %%t%u  ; 'ABS\n",
                 t, cmp, abs_type, neg, abs_type, val);
            return t;
        }
    }

    if (Slice_Equal_Ignore_Case(attr, S("MOD"))) {
        /* T'MOD — returns the modulus of a modular type (RM 3.5.4(17)) */
        if (prefix_type and prefix_type->kind == TYPE_MODULAR and prefix_type->modulus > 0) {
            const char *mod_type = Type_To_Llvm(prefix_type);
            Emit(cg, "  %%t%u = add %s 0, %s  ; 'MOD\n", t, mod_type,
                 U128_Decimal(prefix_type->modulus));
            return t;
        }
    }

    /* ─────────────────────────────────────────────────────────────────────
     * String/Image Attributes
     * These call runtime functions for string conversion.
     * ───────────────────────────────────────────────────────────────────── */

    if (Slice_Equal_Ignore_Case(attr, S("IMAGE"))) {
        /* T'IMAGE(x) - string representation (RM 3.5.5) */
        if (first_arg) {
            uint32_t arg_val = Generate_Expression(cg, first_arg);

            if (Type_Is_Integer_Like(classify_type) or
                Type_Is_Universal_Integer(classify_type)) {
                /* Integer'IMAGE — widen to INTEGER arith type for RTS ABI */
                uint32_t arg_w = Emit_Widen_For_Intrinsic(cg, arg_val, Expression_Llvm_Type(cg, first_arg));
                Emit(cg, "  %%t%u = call " FAT_PTR_TYPE " @__ada_integer_image(%s %%t%u)\n",
                     t, Integer_Arith_Type(cg), arg_w);
            } else if (Type_Is_Character(classify_type)) {
                /* Character'IMAGE — convert to i8 for RTS ABI */
                const char *arg_src_type = Expression_Llvm_Type(cg, first_arg);
                uint32_t char_val = Emit_Convert(cg, arg_val, arg_src_type, "i8");
                Emit(cg, "  %%t%u = call " FAT_PTR_TYPE " @__ada_character_image(i8 %%t%u)\n",
                     t, char_val);
            } else if (Type_Is_Boolean(classify_type)) {
                /* Boolean'IMAGE — switch on 0>"FALSE", 1>"TRUE" (RM 3.5.5) */
                const char *img_bt = String_Bound_Type(cg);
                uint32_t result_ptr = Emit_Temp(cg);
                uint32_t result_len = Emit_Temp(cg);
                Emit(cg, "  %%t%u = alloca ptr\n", result_ptr);
                Emit(cg, "  %%t%u = alloca %s\n", result_len, img_bt);
                uint32_t false_label = cg->label_id++;
                uint32_t true_label = cg->label_id++;
                uint32_t end_label = cg->label_id++;
                const char *arg_t = Expression_Llvm_Type(cg, first_arg);
                uint32_t cmp_val = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp ne %s %%t%u, 0\n", cmp_val, arg_t, arg_val);
                Emit(cg, "  br i1 %%t%u, label %%Lbimg_t%u, label %%Lbimg_f%u\n",
                     cmp_val, true_label, false_label);
                /* FALSE case */
                uint32_t false_str_id = cg->string_id++;
                Emit_String_Const(cg, "@.img_str%u = private unnamed_addr constant [6 x i8] c\"FALSE\\00\"\n", false_str_id);
                Emit(cg, "Lbimg_f%u:\n", false_label);
                Emit(cg, "  store ptr @.img_str%u, ptr %%t%u\n", false_str_id, result_ptr);
                Emit(cg, "  store %s 5, ptr %%t%u\n", img_bt, result_len);
                Emit(cg, "  br label %%Lbimg_end%u\n", end_label);
                /* TRUE case */
                uint32_t true_str_id = cg->string_id++;
                Emit_String_Const(cg, "@.img_str%u = private unnamed_addr constant [5 x i8] c\"TRUE\\00\"\n", true_str_id);
                Emit(cg, "Lbimg_t%u:\n", true_label);
                Emit(cg, "  store ptr @.img_str%u, ptr %%t%u\n", true_str_id, result_ptr);
                Emit(cg, "  store %s 4, ptr %%t%u\n", img_bt, result_len);
                Emit(cg, "  br label %%Lbimg_end%u\n", end_label);
                /* End */
                Emit(cg, "Lbimg_end%u:\n", end_label);
                uint32_t ptr_load = Emit_Temp(cg);
                uint32_t len_load = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load ptr, ptr %%t%u\n", ptr_load, result_ptr);
                Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", len_load, img_bt, result_len);
                uint32_t low_one = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s 0, 1\n", low_one, img_bt);
                t = Emit_Fat_Pointer_Dynamic(cg, ptr_load, low_one, len_load, img_bt);
            } else if (Type_Is_Float_Representation(classify_type)) {
                /* Float'IMAGE */
                Emit(cg, "  %%t%u = call " FAT_PTR_TYPE " @__ada_float_image(double %%t%u)\n",
                     t, arg_val);
            } else if (Type_Is_Enumeration(classify_type)) {
                /* Enumeration'IMAGE - return literal name as string */
                /* Find root enumeration type with literals */
                Type_Info *enum_type = classify_type;
                while (enum_type and not enum_type->enumeration.literals) {
                    if (enum_type->parent_type) enum_type = enum_type->parent_type;
                    else if (enum_type->base_type) enum_type = enum_type->base_type;
                    else break;
                }
                if (enum_type and enum_type->enumeration.literals and
                    enum_type->enumeration.literal_count > 0) {
                    /* Generate inline switch for literal lookup.
                     * Length stored in STRING bound type (derived from type system). */
                    const char *img_bt = String_Bound_Type(cg);
                    uint32_t result_ptr = Emit_Temp(cg);
                    uint32_t result_len = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = alloca ptr\n", result_ptr);
                    Emit(cg, "  %%t%u = alloca %s\n", result_len, img_bt);
                    uint32_t switch_label = cg->label_id++;
                    uint32_t default_label = cg->label_id++;
                    uint32_t end_label = cg->label_id++;
                    /* Widen arg to i64 for switch — arg may be i8 for small enums */
                    const char *arg_t = Expression_Llvm_Type(cg, first_arg);
                    uint32_t sw_val = Emit_Convert(cg, arg_val, arg_t, "i64");
                    Emit(cg, "  switch i64 %%t%u, label %%Limg_def%u [\n", sw_val, default_label);
                    for (uint32_t i = 0; i < enum_type->enumeration.literal_count; i++) {
                        Emit(cg, "    i64 %u, label %%Limg%u_%u\n", i, switch_label, i);
                    }
                    Emit(cg, "  ]\n");
                    /* Generate case labels */
                    for (uint32_t i = 0; i < enum_type->enumeration.literal_count; i++) {
                        String_Slice lit = enum_type->enumeration.literals[i];
                        /* Generate string constant name */
                        uint32_t str_id = cg->string_id++;
                        Emit(cg, "Limg%u_%u:\n", switch_label, i);
                        /* Character literals: IMAGE returns 'x' with quotes preserved.
                         * Identifier literals: IMAGE returns uppercased name. (RM 3.5.5) */
                        bool is_char_lit = (lit.length >= 3 and lit.data[0] == '\'');
                        if (is_char_lit) {
                            /* Character literal — emit as-is (e.g. 'a') */
                            Emit_String_Const(cg, "@.img_str%u = private unnamed_addr constant [%u x i8] c\"",
                                       str_id, (unsigned)lit.length + 1);
                            for (uint32_t j = 0; j < lit.length; j++) {
                                Emit_String_Const(cg, "%c", lit.data[j]);
                            }
                            Emit_String_Const(cg, "\\00\"\n");
                        } else {
                            /* Identifier — uppercase (Ada identifiers are case-insensitive) */
                            Emit_String_Const(cg, "@.img_str%u = private unnamed_addr constant [%u x i8] c\"",
                                       str_id, (unsigned)lit.length + 1);
                            for (uint32_t j = 0; j < lit.length; j++) {
                                Emit_String_Const(cg, "%c", (char)toupper((unsigned char)lit.data[j]));
                            }
                            Emit_String_Const(cg, "\\00\"\n");
                        }
                        Emit(cg, "  store ptr @.img_str%u, ptr %%t%u\n", str_id, result_ptr);
                        Emit(cg, "  store %s %u, ptr %%t%u\n", img_bt, (unsigned)lit.length, result_len);
                        Emit(cg, "  br label %%Limg_end%u\n", end_label);
                    }
                    /* Default case - return empty string */
                    Emit(cg, "Limg_def%u:\n", default_label);
                    Emit(cg, "  store ptr null, ptr %%t%u\n", result_ptr);
                    Emit(cg, "  store %s 0, ptr %%t%u\n", img_bt, result_len);
                    Emit(cg, "  br label %%Limg_end%u\n", end_label);
                    Emit(cg, "Limg_end%u:\n", end_label);
                    uint32_t ptr_load = Emit_Temp(cg);
                    uint32_t len_load = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = load ptr, ptr %%t%u\n", ptr_load, result_ptr);
                    Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", len_load, img_bt, result_len);
                    /* Build fat pointer result: { ptr_load, { 1, len_load } } */
                    uint32_t low_one = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s 0, 1\n", low_one, img_bt);
                    t = Emit_Fat_Pointer_Dynamic(cg, ptr_load, low_one, len_load, img_bt);
                } else {
                    /* No literals found, fallback to integer image */
                    uint32_t arg_w2 = Emit_Widen_For_Intrinsic(cg, arg_val, Expression_Llvm_Type(cg, first_arg));
                    Emit(cg, "  %%t%u = call " FAT_PTR_TYPE " @__ada_integer_image(%s %%t%u)\n",
                         t, Integer_Arith_Type(cg), arg_w2);
                }
            } else {
                /* Default: treat as integer */
                uint32_t arg_w3 = Emit_Widen_For_Intrinsic(cg, arg_val, Expression_Llvm_Type(cg, first_arg));
                Emit(cg, "  %%t%u = call " FAT_PTR_TYPE " @__ada_integer_image(%s %%t%u)\n",
                     t, Integer_Arith_Type(cg), arg_w3);
            }
            return t;
        }
        t = Emit_Fat_Pointer_Null(cg, String_Bound_Type(cg));  /* 'IMAGE no arg */
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("VALUE"))) {
        /* T'VALUE(s) - parse string to type (RM 3.5.5) */
        if (first_arg) {
            uint32_t str_val = Generate_Expression(cg, first_arg);
            if (Type_Is_Integer_Like(classify_type) or
                Type_Is_Universal_Integer(classify_type)) {
                /* Integer'VALUE - parse string as integer */
                const char *val_iat = Integer_Arith_Type(cg);
                Emit(cg, "  %%t%u = call %s @__ada_integer_value(" FAT_PTR_TYPE " %%t%u)\n",
                     t, val_iat, str_val);
                Temp_Set_Type(cg, t, val_iat);
                /* Convert to prefix type width if different */
                const char *val_result_t = Type_To_Llvm(prefix_type);
                t = Emit_Convert(cg, t, val_iat, val_result_t);
            } else if (Type_Is_Float_Representation(classify_type)) {
                /* Float'VALUE - parse string as float */
                Emit(cg, "  %%t%u = call double @__ada_float_value(" FAT_PTR_TYPE " %%t%u)\n",
                     t, str_val);
            } else if (Type_Is_Character(classify_type)) {
                /* Character'VALUE — parse "'x'" format, strip leading/trailing spaces (RM 3.5.5) */
                const char *val_bt = String_Bound_Type(cg);
                const char *val_iat = Integer_Arith_Type(cg);
                uint32_t str_ptr_raw = Emit_Fat_Pointer_Data(cg, str_val, val_bt);
                uint32_t str_len_bt = Emit_Fat_Pointer_Length(cg, str_val, val_bt);
                uint32_t str_len_raw = Emit_Convert(cg, str_len_bt, val_bt, val_iat);
                /* Trim leading/trailing spaces */
                uint32_t lead_off = Emit_Temp(cg);
                Emit(cg, "  %%t%u = call %s @__ada_count_leading_spaces(ptr %%t%u, %s %%t%u)\n",
                     lead_off, val_iat, str_ptr_raw, val_iat, str_len_raw);
                uint32_t trail_off = Emit_Temp(cg);
                Emit(cg, "  %%t%u = call %s @__ada_count_trailing_spaces(ptr %%t%u, %s %%t%u)\n",
                     trail_off, val_iat, str_ptr_raw, val_iat, str_len_raw);
                uint32_t str_ptr = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s %%t%u\n",
                     str_ptr, str_ptr_raw, val_iat, lead_off);
                uint32_t trim_total = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s %%t%u, %%t%u\n", trim_total, val_iat, lead_off, trail_off);
                uint32_t str_len = Emit_Temp(cg);
                Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", str_len, val_iat, str_len_raw, trim_total);
                cg->needs_trim_helpers = true;
                /* Must be exactly 3 chars: 'x' */
                uint32_t len3 = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp eq %s %%t%u, 3\n", len3, val_iat, str_len);
                uint32_t ok_label = cg->label_id++;
                uint32_t fail_label = cg->label_id++;
                uint32_t end_label = cg->label_id++;
                Emit(cg, "  br i1 %%t%u, label %%Lcval_ok%u, label %%Lcval_fail%u\n", len3, ok_label, fail_label);
                Emit(cg, "Lcval_ok%u:\n", ok_label);
                /* Check first and last chars are single quotes */
                uint32_t c0_ptr = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s 0\n", c0_ptr, str_ptr, val_iat);
                uint32_t c0 = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load i8, ptr %%t%u\n", c0, c0_ptr);
                uint32_t c2_ptr = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s 2\n", c2_ptr, str_ptr, val_iat);
                uint32_t c2 = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load i8, ptr %%t%u\n", c2, c2_ptr);
                uint32_t q0 = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp eq i8 %%t%u, 39  ; check first quote\n", q0, c0);
                uint32_t q2 = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp eq i8 %%t%u, 39  ; check last quote\n", q2, c2);
                uint32_t both_q = Emit_Temp(cg);
                Emit(cg, "  %%t%u = and i1 %%t%u, %%t%u\n", both_q, q0, q2);
                uint32_t extract_label = cg->label_id++;
                Emit(cg, "  br i1 %%t%u, label %%Lcval_ext%u, label %%Lcval_fail%u\n", both_q, extract_label, fail_label);
                Emit(cg, "Lcval_ext%u:\n", extract_label);
                /* Extract the character at position 1 */
                uint32_t c1_ptr = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s 1\n", c1_ptr, str_ptr, val_iat);
                uint32_t c1 = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load i8, ptr %%t%u\n", c1, c1_ptr);
                t = c1;
                Emit(cg, "  br label %%Lcval_end%u\n", end_label);
                /* Fail - raise CONSTRAINT_ERROR */
                Emit(cg, "Lcval_fail%u:\n", fail_label);
                Emit_Raise_Constraint_Error(cg, "VALUE no match");
                Emit(cg, "Lcval_end%u:\n", end_label);
                Temp_Set_Type(cg, t, "i8");
            } else if (Type_Is_Boolean(classify_type)) {
                /* Boolean'VALUE — match "TRUE"/"FALSE" case-insensitively, strip spaces (RM 3.5.5) */
                const char *val_bt = String_Bound_Type(cg);
                const char *val_iat = Integer_Arith_Type(cg);
                uint32_t str_ptr_raw = Emit_Fat_Pointer_Data(cg, str_val, val_bt);
                uint32_t str_len_bt = Emit_Fat_Pointer_Length(cg, str_val, val_bt);
                uint32_t str_len_raw = Emit_Convert(cg, str_len_bt, val_bt, val_iat);
                /* Trim leading/trailing spaces */
                uint32_t lead_off = Emit_Temp(cg);
                Emit(cg, "  %%t%u = call %s @__ada_count_leading_spaces(ptr %%t%u, %s %%t%u)\n",
                     lead_off, val_iat, str_ptr_raw, val_iat, str_len_raw);
                uint32_t trail_off = Emit_Temp(cg);
                Emit(cg, "  %%t%u = call %s @__ada_count_trailing_spaces(ptr %%t%u, %s %%t%u)\n",
                     trail_off, val_iat, str_ptr_raw, val_iat, str_len_raw);
                uint32_t str_ptr = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s %%t%u\n",
                     str_ptr, str_ptr_raw, val_iat, lead_off);
                uint32_t trim_total = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s %%t%u, %%t%u\n", trim_total, val_iat, lead_off, trail_off);
                uint32_t str_len = Emit_Temp(cg);
                Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", str_len, val_iat, str_len_raw, trim_total);
                cg->needs_trim_helpers = true;
                /* Check for "TRUE" (length 4) and "FALSE" (length 5) */
                uint32_t true_str_id = cg->string_id++;
                Emit_String_Const(cg, "@.val_str%u = private unnamed_addr constant [5 x i8] c\"TRUE\\00\"\n", true_str_id);
                uint32_t false_str_id = cg->string_id++;
                Emit_String_Const(cg, "@.val_str%u = private unnamed_addr constant [6 x i8] c\"FALSE\\00\"\n", false_str_id);
                uint32_t result_alloc = Emit_Temp(cg);
                Emit(cg, "  %%t%u = alloca %s\n", result_alloc, val_iat);
                Emit(cg, "  store %s 0, ptr %%t%u\n", val_iat, result_alloc);
                uint32_t check_true = cg->label_id++;
                uint32_t check_false_len = cg->label_id++;
                uint32_t check_false = cg->label_id++;
                uint32_t match_true = cg->label_id++;
                uint32_t match_false = cg->label_id++;
                uint32_t no_match = cg->label_id++;
                uint32_t end_label = cg->label_id++;
                /* Check length == 4 (TRUE) */
                uint32_t len4 = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp eq %s %%t%u, 4\n", len4, val_iat, str_len);
                Emit(cg, "  br i1 %%t%u, label %%Lbval_ct%u, label %%Lbval_cfl%u\n", len4, check_true, check_false_len);
                Emit(cg, "Lbval_ct%u:\n", check_true);
                uint32_t cmp_true = Emit_Temp(cg);
                Emit(cg, "  %%t%u = call i32 @strncasecmp(ptr %%t%u, ptr @.val_str%u, i64 4)\n",
                     cmp_true, str_ptr, true_str_id);
                uint32_t is_true = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp eq i32 %%t%u, 0\n", is_true, cmp_true);
                Emit(cg, "  br i1 %%t%u, label %%Lbval_mt%u, label %%Lbval_cfl%u\n", is_true, match_true, check_false_len);
                Emit(cg, "Lbval_mt%u:\n", match_true);
                Emit(cg, "  store %s 1, ptr %%t%u\n", val_iat, result_alloc);
                Emit(cg, "  br label %%Lbval_end%u\n", end_label);
                /* Check length == 5 (FALSE) */
                Emit(cg, "Lbval_cfl%u:\n", check_false_len);
                uint32_t len5 = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp eq %s %%t%u, 5\n", len5, val_iat, str_len);
                Emit(cg, "  br i1 %%t%u, label %%Lbval_cf%u, label %%Lbval_nm%u\n", len5, check_false, no_match);
                Emit(cg, "Lbval_cf%u:\n", check_false);
                uint32_t cmp_false = Emit_Temp(cg);
                Emit(cg, "  %%t%u = call i32 @strncasecmp(ptr %%t%u, ptr @.val_str%u, i64 5)\n",
                     cmp_false, str_ptr, false_str_id);
                uint32_t is_false = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp eq i32 %%t%u, 0\n", is_false, cmp_false);
                Emit(cg, "  br i1 %%t%u, label %%Lbval_mf%u, label %%Lbval_nm%u\n", is_false, match_false, no_match);
                Emit(cg, "Lbval_mf%u:\n", match_false);
                Emit(cg, "  store %s 0, ptr %%t%u\n", val_iat, result_alloc);
                Emit(cg, "  br label %%Lbval_end%u\n", end_label);
                /* No match - raise CONSTRAINT_ERROR */
                Emit(cg, "Lbval_nm%u:\n", no_match);
                Emit_Raise_Constraint_Error(cg, "VALUE no match");
                Emit(cg, "Lbval_end%u:\n", end_label);
                Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", t, val_iat, result_alloc);
                const char *bool_result_t = Type_To_Llvm(classify_type);
                if (bool_result_t and bool_result_t[0] == 'i')
                    t = Emit_Convert(cg, t, val_iat, bool_result_t);
            } else if (Type_Is_Enumeration(classify_type)) {
                /* Enumeration'VALUE - find literal by name and return position */
                /* Find root enumeration type with literals */
                Type_Info *enum_type = classify_type;
                while (enum_type and not enum_type->enumeration.literals) {
                    if (enum_type->parent_type) enum_type = enum_type->parent_type;
                    else if (enum_type->base_type) enum_type = enum_type->base_type;
                    else break;
                }
                if (enum_type and enum_type->enumeration.literals and
                    enum_type->enumeration.literal_count > 0) {
                    /* Enum'VALUE: compare input against each literal (case-insensitive).
                     * Ada RM 3.5.5: leading/trailing blanks are stripped first. */
                    const char *val_bt = String_Bound_Type(cg);
                    uint32_t str_ptr_raw = Emit_Fat_Pointer_Data(cg, str_val, val_bt);
                    uint32_t str_len_bt = Emit_Fat_Pointer_Length(cg, str_val, val_bt);
                    const char *val_iat = Integer_Arith_Type(cg);
                    uint32_t str_len_raw = Emit_Convert(cg, str_len_bt, val_bt, val_iat);

                    /* Trim leading/trailing spaces via runtime helpers (Ada RM 3.5) */
                    uint32_t lead_off = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = call %s @__ada_count_leading_spaces(ptr %%t%u, %s %%t%u)\n",
                         lead_off, val_iat, str_ptr_raw, val_iat, str_len_raw);
                    /* Backward scan for trailing spaces */
                    uint32_t trail_off = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = call %s @__ada_count_trailing_spaces(ptr %%t%u, %s %%t%u)\n",
                         trail_off, val_iat, str_ptr_raw, val_iat, str_len_raw);
                    /* Trimmed pointer and length */
                    uint32_t str_ptr = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s %%t%u\n",
                         str_ptr, str_ptr_raw, val_iat, lead_off);
                    uint32_t trim_total = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s %%t%u, %%t%u\n", trim_total, val_iat, lead_off, trail_off);
                    uint32_t str_len = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", str_len, val_iat, str_len_raw, trim_total);
                    cg->needs_trim_helpers = true;

                    uint32_t result_alloc = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = alloca %s\n", result_alloc, val_iat);
                    Emit(cg, "  store %s 0, ptr %%t%u\n", val_iat, result_alloc);

                    uint32_t end_label = cg->label_id++;
                    for (uint32_t i = 0; i < enum_type->enumeration.literal_count; i++) {
                        String_Slice lit = enum_type->enumeration.literals[i];
                        uint32_t check_label = cg->label_id++;
                        uint32_t next_label = cg->label_id++;
                        /* Character literals are case-sensitive; identifiers are uppercased
                         * and compared case-insensitively (RM 3.5.5) */
                        bool is_char_lit = (lit.length >= 3 and lit.data[0] == '\'');

                        uint32_t str_id = cg->string_id++;
                        Emit_String_Const(cg, "@.val_str%u = private unnamed_addr constant [%u x i8] c\"",
                                   str_id, (unsigned)lit.length + 1);
                        for (uint32_t j = 0; j < lit.length; j++) {
                            Emit_String_Const(cg, "%c",
                                is_char_lit ? lit.data[j] : (char)toupper((unsigned char)lit.data[j]));
                        }
                        Emit_String_Const(cg, "\\00\"\n");

                        /* Check trimmed length matches literal */
                        uint32_t len_cmp = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = icmp eq %s %%t%u, %u\n", len_cmp, val_iat, str_len, (unsigned)lit.length);
                        Emit(cg, "  br i1 %%t%u, label %%Lval%u, label %%Lval_next%u\n", len_cmp, check_label, next_label);

                        Emit(cg, "Lval%u:\n", check_label);
                        uint32_t cmp_result = Emit_Temp(cg);
                        if (is_char_lit) {
                            /* Case-sensitive comparison for character literals (RM 3.5.5) */
                            Emit(cg, "  %%t%u = call i32 @memcmp(ptr %%t%u, ptr @.val_str%u, i64 %u)\n",
                                 cmp_result, str_ptr, str_id, (unsigned)lit.length);
                        } else {
                            /* Case-insensitive comparison for identifiers */
                            Emit(cg, "  %%t%u = call i32 @strncasecmp(ptr %%t%u, ptr @.val_str%u, i64 %u)\n",
                                 cmp_result, str_ptr, str_id, (unsigned)lit.length);
                        }
                        uint32_t cmp_eq = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = icmp eq i32 %%t%u, 0\n", cmp_eq, cmp_result);
                        uint32_t match_label = cg->label_id++;
                        Emit(cg, "  br i1 %%t%u, label %%Lval_match%u, label %%Lval_next%u\n", cmp_eq, match_label, next_label);

                        Emit(cg, "Lval_match%u:\n", match_label);
                        Emit(cg, "  store %s %u, ptr %%t%u\n", val_iat, i, result_alloc);
                        Emit(cg, "  br label %%Lval_end%u\n", end_label);

                        Emit(cg, "Lval_next%u:\n", next_label);
                    }
                    /* No match - raise CONSTRAINT_ERROR (RM 3.5.5) */
                    Emit_Raise_Constraint_Error(cg, "VALUE no match");
                    Emit(cg, "Lval_end%u:\n", end_label);
                    Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", t, val_iat, result_alloc);
                    /* Convert from i32 result to prefix type width so codegen
                     * matches Expression_Llvm_Type prediction */
                    const char *result_t = Type_To_Llvm(prefix_type);
                    if (result_t and result_t[0] == 'i')
                        t = Emit_Convert(cg, t, val_iat, result_t);
                } else {
                    /* No literals found, fallback to integer value */
                    const char *fb_iat = Integer_Arith_Type(cg);
                    Emit(cg, "  %%t%u = call %s @__ada_integer_value(" FAT_PTR_TYPE " %%t%u)\n",
                         t, fb_iat, str_val);
                    Temp_Set_Type(cg, t, fb_iat);
                    const char *fb_result_t = Type_To_Llvm(prefix_type);
                    return Emit_Convert(cg, t, fb_iat, fb_result_t);
                }
            } else {
                /* Default: treat as integer */
                const char *def_iat = Integer_Arith_Type(cg);
                Emit(cg, "  %%t%u = call %s @__ada_integer_value(" FAT_PTR_TYPE " %%t%u)\n",
                     t, def_iat, str_val);
                Temp_Set_Type(cg, t, def_iat);
                const char *def_result_t = Type_To_Llvm(prefix_type);
                return Emit_Convert(cg, t, def_iat, def_result_t);
            }
            return t;
        }
        return 0;
    }

    if (Slice_Equal_Ignore_Case(attr, S("WIDTH"))) {
        /* T'WIDTH - maximum image width for type (RM 3.5.5)
         * Per GNAT exp_imgv.adb Expand_Width_Attribute:
         * - For null range (FIRST > LAST), WIDTH is 0
         * - For enumeration: max length of literal names in range
         * - For integer: max width of first/last images
         * - For boolean: max("FALSE", "TRUE") = 5
         * - For character: 3 ('X')
         *
         * When bounds are not compile-time known, generate runtime code. */
        if (prefix_type) {
            bool lo_known = Type_Bound_Is_Compile_Time_Known(prefix_type->low_bound);
            bool hi_known = Type_Bound_Is_Compile_Time_Known(prefix_type->high_bound);

            /* Find root enumeration type (traversing base_type and parent_type chains) */
            Type_Info *root_enum = NULL;
            for (Type_Info *ti = prefix_type; ti; ti = ti->base_type ? ti->base_type : ti->parent_type) {
                if (Type_Is_Enumeration(ti) and ti->enumeration.literals) {
                    root_enum = ti;
                    break;
                }
                if (not ti->base_type and not ti->parent_type) break;
            }

            if (lo_known and hi_known) {
                /* Both bounds are compile-time known - compute WIDTH statically */
                int128_t width = 0;
                int128_t lo = Type_Bound_Value(prefix_type->low_bound);
                int128_t hi = Type_Bound_Value(prefix_type->high_bound);

                if (hi < lo) {
                    /* Empty range - width is 0 */
                    width = 0;
                } else if (root_enum) {
                    /* Enumeration: max length of literal names in range */
                    for (int128_t i = lo; i <= hi and i < (int128_t)root_enum->enumeration.literal_count; i++) {
                        if (i >= 0) {
                            uint32_t len = root_enum->enumeration.literals[(int64_t)i].length;
                            if (len > (uint32_t)width) width = (int128_t)len;
                        }
                    }
                } else if (Type_Is_Boolean(prefix_type) or Type_Is_Boolean(prefix_type->base_type)) {
                    /* Boolean: "FALSE" is 5, "TRUE" is 4 */
                    width = (lo <= 0 and hi >= 0) ? 5 : (lo <= 1 and hi >= 1) ? 4 : 0;
                } else if (Type_Is_Character(prefix_type) or Type_Is_Character(prefix_type->base_type)) {
                    /* Character: 'X' is 3 chars */
                    width = 3;
                } else {
                    /* Integer types: max width of first/last images */
                    /* Width includes leading space for non-negative */
                    int128_t abs_lo = lo < 0 ? -lo : lo;
                    int128_t abs_hi = hi < 0 ? -hi : hi;
                    int128_t max_abs = abs_lo > abs_hi ? abs_lo : abs_hi;
                    int digits = 1;
                    while (max_abs >= 10) { digits++; max_abs /= 10; }
                    width = digits + 1;  /* +1 for leading space or minus sign */
                }
                Emit(cg, "  %%t%u = add %s 0, %s  ; 'WIDTH\n", t, Integer_Arith_Type(cg), I128_Decimal(width));
            } else {
                /* Bounds not compile-time known - generate runtime code.
                 * Per GNAT exp_imgv.adb: generate if FIRST > LAST then 0 else <width>
                 * For enumeration types with runtime bounds, we compute the full-range
                 * width at compile time (since literals are known) and use 0 for null range. */
                uint32_t lo_val = Generate_Bound_Value(cg, prefix_type->low_bound, Integer_Arith_Type(cg));
                uint32_t hi_val = Generate_Bound_Value(cg, prefix_type->high_bound, Integer_Arith_Type(cg));

                /* Compare: is_null = (lo > hi) */
                const char *width_type = Integer_Arith_Type(cg);
                uint32_t cmp = cg->temp_id++;
                Emit(cg, "  %%t%u = icmp sgt %s %%t%u, %%t%u  ; FIRST > LAST?\n", cmp, width_type, lo_val, hi_val);

                /* Compute the width for non-null range at compile time */
                int64_t full_width = 0;
                if (root_enum) {
                    /* For enumeration: compute max width over full base type range */
                    for (uint32_t i = 0; i < root_enum->enumeration.literal_count; i++) {
                        uint32_t len = root_enum->enumeration.literals[i].length;
                        if (len > (uint32_t)full_width) full_width = (int64_t)len;
                    }
                } else if (Type_Is_Boolean(prefix_type) or Type_Is_Boolean(prefix_type->base_type)) {
                    /* Boolean: WIDTH depends on which values are in range.
                     * FALSE=0 has width 5, TRUE=1 has width 4.
                     * If lo <= 0 (FALSE is in range): width = 5
                     * Otherwise (only TRUE in range): width = 4
                     * Generate: select (lo <= 0), 5, 4 */
                    uint32_t has_false = cg->temp_id++;
                    Emit(cg, "  %%t%u = icmp sle %s %%t%u, 0  ; has FALSE?\n", has_false, width_type, lo_val);
                    uint32_t bool_width = cg->temp_id++;
                    Emit(cg, "  %%t%u = select i1 %%t%u, %s 5, %s 4  ; FALSE=5, TRUE=4\n", bool_width, has_false, width_type, width_type);

                    /* Select: if is_null then 0 else bool_width */
                    Emit(cg, "  %%t%u = select i1 %%t%u, %s 0, %s %%t%u  ; 'WIDTH (runtime bool)\n",
                         t, cmp, width_type, width_type, bool_width);
                    return t;
                } else if (Type_Is_Character(prefix_type) or Type_Is_Character(prefix_type->base_type)) {
                    full_width = 3;  /* 'X' */
                } else {
                    /* Integer: compute WIDTH based on actual runtime bounds.
                     * WIDTH = max(digits(abs(lo)), digits(abs(hi))) + 1
                     * Generate runtime code to compute this. */

                    /* Compute abs(lo): if lo < 0 then -lo else lo */
                    uint32_t neg_lo = cg->temp_id++;
                    Emit(cg, "  %%t%u = sub %s 0, %%t%u\n", neg_lo, width_type, lo_val);
                    uint32_t is_neg_lo = cg->temp_id++;
                    Emit(cg, "  %%t%u = icmp slt %s %%t%u, 0\n", is_neg_lo, width_type, lo_val);
                    uint32_t abs_lo = cg->temp_id++;
                    Emit(cg, "  %%t%u = select i1 %%t%u, %s %%t%u, %s %%t%u\n", abs_lo, is_neg_lo, width_type, neg_lo, width_type, lo_val);

                    /* Compute abs(hi): if hi < 0 then -hi else hi */
                    uint32_t neg_hi = cg->temp_id++;
                    Emit(cg, "  %%t%u = sub %s 0, %%t%u\n", neg_hi, width_type, hi_val);
                    uint32_t is_neg_hi = cg->temp_id++;
                    Emit(cg, "  %%t%u = icmp slt %s %%t%u, 0\n", is_neg_hi, width_type, hi_val);
                    uint32_t abs_hi = cg->temp_id++;
                    Emit(cg, "  %%t%u = select i1 %%t%u, %s %%t%u, %s %%t%u\n", abs_hi, is_neg_hi, width_type, neg_hi, width_type, hi_val);

                    /* max_abs = max(abs_lo, abs_hi) */
                    uint32_t cmp_abs = cg->temp_id++;
                    Emit(cg, "  %%t%u = icmp ugt %s %%t%u, %%t%u\n", cmp_abs, width_type, abs_lo, abs_hi);
                    uint32_t max_abs = cg->temp_id++;
                    Emit(cg, "  %%t%u = select i1 %%t%u, %s %%t%u, %s %%t%u\n", max_abs, cmp_abs, width_type, abs_lo, width_type, abs_hi);

                    /* Count digits using comparison chain.
                     * Derive max digits from type width (works for i8..i128):
                     *   i8: 2, i16: 4, i32: 9, i64: 18, i128: 38 */
                    int width_bits = Type_Bits(width_type);
                    int max_digits = (width_bits <= 8) ? 2 : (width_bits <= 16) ? 4 :
                                     (width_bits <= 32) ? 9 : (width_bits <= 64) ? 18 : 38;
                    uint32_t digits_val = cg->temp_id++;
                    Emit(cg, "  %%t%u = add %s 0, 1  ; initial digits\n", digits_val, width_type);

                    int64_t thresholds[] = {10, 100, 1000, 10000, 100000, 1000000, 10000000,
                                           100000000, 1000000000, 10000000000LL, 100000000000LL,
                                           1000000000000LL, 10000000000000LL, 100000000000000LL,
                                           1000000000000000LL, 10000000000000000LL,
                                           100000000000000000LL, 1000000000000000000LL};
                    for (int d = 0; d < max_digits; d++) {
                        uint32_t cmp_d = cg->temp_id++;
                        Emit(cg, "  %%t%u = icmp uge %s %%t%u, %lld\n", cmp_d, width_type, max_abs, (long long)thresholds[d]);
                        uint32_t next_digits = cg->temp_id++;
                        Emit(cg, "  %%t%u = select i1 %%t%u, %s %d, %s %%t%u\n",
                             next_digits, cmp_d, width_type, d + 2, width_type, digits_val);
                        digits_val = next_digits;
                    }

                    /* width = digits + 1 (for leading space or minus sign) */
                    uint32_t width_val = cg->temp_id++;
                    Emit(cg, "  %%t%u = add %s %%t%u, 1  ; +1 for sign/space\n", width_val, width_type, digits_val);

                    full_width = 0;  /* Not used - we have runtime value */

                    /* Select: if is_null then 0 else width_val */
                    Emit(cg, "  %%t%u = select i1 %%t%u, %s 0, %s %%t%u  ; 'WIDTH (runtime)\n",
                         t, cmp, width_type, width_type, width_val);
                    return t;
                }

                /* Select: if is_null then 0 else full_width */
                Emit(cg, "  %%t%u = select i1 %%t%u, %s 0, %s %lld  ; 'WIDTH (runtime)\n",
                     t, cmp, width_type, width_type, (long long)full_width);
            }
            return t;
        }
    }

    /* ─────────────────────────────────────────────────────────────────────
     * Access Type Attributes
     * ───────────────────────────────────────────────────────────────────── */

    /* X'ACCESS / X'UNCHECKED_ACCESS — identical codegen (RM 3.10.2) */
    if (Slice_Equal_Ignore_Case(attr, S("ACCESS")) or
        Slice_Equal_Ignore_Case(attr, S("UNCHECKED_ACCESS"))) {
        Symbol *sym = node->attribute.prefix->symbol;
        if (sym) {
            Emit(cg, "  %%t%u = getelementptr i8, ptr ", t);
            Emit_Symbol_Ref(cg, sym);
            Emit(cg, ", i64 0  ; '%.*s\n", (int)attr.length, attr.data);
        } else {
            fprintf(stderr, "warning: 'ACCESS attribute applied to expression with no symbol\n");
            Emit(cg, "  %%t%u = add %s 0, 0\n", t, Integer_Arith_Type(cg));
        }
        return t;
    }

    /* ─────────────────────────────────────────────────────────────────────
     * Floating-Point Type Attributes (RM 3.5.8)
     * These attributes return compile-time values for floating-point types.
     * ───────────────────────────────────────────────────────────────────── */

    if (Slice_Equal_Ignore_Case(attr, S("DIGITS"))) {
        /* T'DIGITS - number of significant decimal digits (RM 3.5.7) */
        int64_t digits = Type_Is_Float(prefix_type)
            ? Float_Effective_Digits(prefix_type)
            : IEEE_DOUBLE_DIGITS;
        Emit(cg, "  %%t%u = add %s 0, %lld  ; 'DIGITS\n", t, Integer_Arith_Type(cg), (long long)digits);
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("MANTISSA"))) {
        /* T'MANTISSA - number of binary digits (RM 3.5.8, 3.5.10)
         * For floating-point: ceiling(D * log(10)/log(2)) + 1
         * For fixed-point: ceiling(log2(bound / small)) */
        int64_t mantissa = IEEE_DOUBLE_MANTISSA - 1;  /* Default for double */
        if (Type_Is_Float(classify_type)) {
            Float_Model_Parameters(classify_type, &mantissa, NULL);
        } else if (Type_Is_Fixed_Point(classify_type)) {
            Type_Info *ft = Type_Is_Fixed_Point(prefix_type) ? prefix_type : classify_type;
            double small = ft->fixed.small;
            double low_val = Type_Bound_Float_Value(ft->low_bound);
            double high_val = Type_Bound_Float_Value(ft->high_bound);
            if (small <= 0) small = ft->fixed.delta > 0 ? ft->fixed.delta : 1.0;
            double bound = fmax(fabs(low_val), fabs(high_val));
            if (bound > 0 and small > 0) {
                mantissa = (int64_t)ceil(log2(bound / small));
                if (mantissa < 1) mantissa = 1;
            }
        }
        Emit(cg, "  %%t%u = add %s 0, %lld  ; 'MANTISSA\n", t, Integer_Arith_Type(cg), (long long)mantissa);
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("EMAX"))) {
        /* T'EMAX - maximum binary exponent (RM 3.5.8)
         * For model numbers: EMAX = 4 * MANTISSA */
        int64_t emax = IEEE_DOUBLE_EMAX - 1;  /* Default for double */
        if (Type_Is_Float(prefix_type)) {
            Float_Model_Parameters(prefix_type, NULL, &emax);
        }
        Emit(cg, "  %%t%u = add %s 0, %lld  ; 'EMAX\n", t, Integer_Arith_Type(cg), (long long)emax);
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("SAFE_EMAX"))) {
        /* T'SAFE_EMAX - safe maximum exponent (RM 3.5.8)
         * For IEEE: MACHINE_EMAX - 1 */
        bool single = Type_Is_Float(prefix_type) and Float_Is_Single(prefix_type);
        int64_t safe_emax = single ? (IEEE_FLOAT_EMAX - 1) : (IEEE_DOUBLE_EMAX - 1);
        Emit(cg, "  %%t%u = add %s 0, %lld  ; 'SAFE_EMAX\n", t, Integer_Arith_Type(cg), (long long)safe_emax);
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("EPSILON"))) {
        /* T'EPSILON - model epsilon (RM 3.5.8(9))
         * EPSILON = 2^(1 - MANTISSA) */
        int64_t mantissa = IEEE_DOUBLE_MANTISSA - 1;
        if (Type_Is_Float(prefix_type))
            Float_Model_Parameters(prefix_type, &mantissa, NULL);
        double epsilon = pow(2.0, 1 - mantissa);
        /* generate at double (UNIVERSAL_REAL) — callers convert.
         * This matches Expression_Llvm_Type(UNIVERSAL_REAL) = "double". */
        Emit_Float_Constant(cg, t, "double", epsilon, "'EPSILON");
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("SMALL"))) {
        /* T'SMALL - fixed-point: power of 2 <= delta; float: 2^(-EMAX - 1) */
        double small_val;
        if (Type_Is_Fixed_Point(classify_type)) {
            /* Use classify_type which is resolved to actual type in generics */
            Type_Info *ft = classify_type;
            small_val = ft->fixed.small;
            if (small_val <= 0) small_val = ft->fixed.delta;
            if (small_val <= 0) small_val = 1.0;
        } else if (Type_Is_Float(prefix_type)) {
            int64_t mantissa, emax;
            Float_Model_Parameters(prefix_type, &mantissa, &emax);
            small_val = pow(2.0, -(emax + 1));
        } else {
            small_val = pow(2.0, -(IEEE_DOUBLE_EMIN));  /* 2^-1022 */
        }
        /* generate at double (UNIVERSAL_REAL) — callers convert. */
        Emit_Float_Constant(cg, t, "double", small_val, "'SMALL");
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("LARGE"))) {
        /* T'LARGE - fixed-point: (2^MANTISSA - 1) * SMALL (RM 3.5.10)
         * float: 2^EMAX * (1 - 2^(-MANTISSA)) (RM 3.5.8(10)) */
        double large_val;
        if (Type_Is_Fixed_Point(classify_type)) {
            /* Use classify_type which is resolved to actual type in generics */
            Type_Info *ft = classify_type;
            double small = ft->fixed.small;
            if (small <= 0) small = ft->fixed.delta > 0 ? ft->fixed.delta : 1.0;
            double bound = fmax(fabs(Type_Bound_Float_Value(ft->low_bound)),
                               fabs(Type_Bound_Float_Value(ft->high_bound)));
            int64_t mantissa = (bound > 0 and small > 0) ?
                              (int64_t)ceil(log2(bound / small)) : 1;
            if (mantissa < 1) mantissa = 1;
            large_val = ((double)((1LL << mantissa) - 1)) * small;
        } else if (Type_Is_Float(prefix_type)) {
            int64_t mantissa, emax;
            Float_Model_Parameters(prefix_type, &mantissa, &emax);
            large_val = pow(2.0, emax) * (1.0 - pow(2.0, -mantissa));
        } else {
            large_val = __DBL_MAX__;
        }
        /* generate at double (UNIVERSAL_REAL) — callers convert. */
        Emit_Float_Constant(cg, t, "double", large_val, "'LARGE");
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("SAFE_SMALL"))) {
        /* T'SAFE_SMALL - smallest positive safe value
         * Fixed-point (RM 3.5.10): SAFE_SMALL = BASE'SMALL
         * Float (RM 3.5.8): 2^(-(SAFE_EMAX+1)) */
        double safe_small;
        if (Type_Is_Fixed_Point(classify_type)) {
            /* Use classify_type which is resolved to actual type in generics */
            Type_Info *ft = classify_type;
            Type_Info *base = ft->base_type ? ft->base_type : ft;
            safe_small = base->fixed.small;
            if (safe_small <= 0) safe_small = base->fixed.delta > 0 ? base->fixed.delta : 1.0;
        } else if (Type_Is_Float(prefix_type) and Float_Is_Single(prefix_type)) {
            safe_small = IEEE_FLOAT_MIN_NORMAL;
        } else {
            safe_small = IEEE_DOUBLE_MIN_NORMAL;
        }
        /* generate at double (UNIVERSAL_REAL) — callers convert. */
        Emit_Float_Constant(cg, t, "double", safe_small, "'SAFE_SMALL");
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("SAFE_LARGE"))) {
        /* T'SAFE_LARGE - largest safe value
         * Fixed-point (RM 3.5.10): SAFE_LARGE = BASE'LARGE = (2^B_MANT - 1) * BASE'SMALL
         * Float (RM 3.5.8): 2^(SAFE_EMAX) * (1 - 2^(-MANTISSA)) */
        double safe_large;
        if (Type_Is_Fixed_Point(classify_type)) {
            /* Use classify_type which is resolved to actual type in generics */
            Type_Info *ft = classify_type;
            Type_Info *base = ft->base_type ? ft->base_type : ft;
            double small = base->fixed.small;
            if (small <= 0) small = base->fixed.delta > 0 ? base->fixed.delta : 1.0;
            double low_val = Type_Bound_Float_Value(base->low_bound);
            double high_val = Type_Bound_Float_Value(base->high_bound);
            double bound = fmax(fabs(low_val), fabs(high_val));
            int64_t mant = (bound > 0 and small > 0) ?
                          (int64_t)ceil(log2(bound / small)) : 1;
            if (mant < 1) mant = 1;
            safe_large = ((double)((1LL << mant) - 1)) * small;
        } else {
            int emax = IEEE_DOUBLE_EMAX;
            int mantissa = IEEE_DOUBLE_MANTISSA;
            if (Type_Is_Float(prefix_type) and Float_Is_Single(prefix_type)) {
                emax = IEEE_FLOAT_EMAX;
                mantissa = IEEE_FLOAT_MANTISSA;
            }
            safe_large = pow(2.0, emax - 1) * (1.0 - pow(2.0, -mantissa));
        }
        /* generate at double (UNIVERSAL_REAL) — callers convert. */
        Emit_Float_Constant(cg, t, "double", safe_large, "'SAFE_LARGE");
        return t;
    }

    /* ─────────────────────────────────────────────────────────────────────
     * Fixed-Point Type Attributes (RM 3.5.9)
     * ───────────────────────────────────────────────────────────────────── */

    if (Slice_Equal_Ignore_Case(attr, S("DELTA"))) {
        /* T'DELTA - delta for fixed-point type (universal real) */
        double delta = 1.0;
        if (Type_Is_Fixed_Point(classify_type)) {
            Type_Info *ft = Type_Is_Fixed_Point(prefix_type) ? prefix_type : classify_type;
            delta = ft->fixed.delta > 0 ? ft->fixed.delta : 1.0;
        }
        Emit(cg, "  %%t%u = fadd double 0.0, %e  ; 'DELTA\n", t, delta);
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("FORE"))) {
        /* T'FORE - minimum field width for integer part (RM 3.5.10(5))
         * Includes a one-character prefix (minus sign or space).
         * FORE = 2 when integer part is 0, otherwise 1 + 1 + floor(log10(int_part)) */
        int64_t fore = 2;  /* minimum: sign + at least one digit */
        if (Type_Is_Fixed_Point(classify_type)) {
            Type_Info *ft = Type_Is_Fixed_Point(prefix_type) ? prefix_type : classify_type;
            double bound = fmax(fabs(Type_Bound_Float_Value(ft->low_bound)),
                               fabs(Type_Bound_Float_Value(ft->high_bound)));
            if (bound >= 1.0) {
                fore = 2 + (int64_t)floor(log10(bound));
            }
        }
        Emit(cg, "  %%t%u = add %s 0, %lld  ; 'FORE\n", t, Integer_Arith_Type(cg), (long long)fore);
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("AFT"))) {
        /* T'AFT - decimal digits after point in default output (RM 3.5.10)
         * AFT = smallest N such that 10^(-N) <= T'DELTA */
        int64_t aft = 1;
        if (Type_Is_Fixed_Point(classify_type)) {
            Type_Info *ft = Type_Is_Fixed_Point(prefix_type) ? prefix_type : classify_type;
            double delta = ft->fixed.delta;
            if (delta > 0 and delta < 1.0) {
                aft = (int64_t)ceil(-log10(delta));
            }
        }
        Emit(cg, "  %%t%u = add %s 0, %lld  ; 'AFT\n", t, Integer_Arith_Type(cg), (long long)aft);
        return t;
    }

    /* ─────────────────────────────────────────────────────────────────────
     * Floating-Point Boolean Attributes (RM 3.5.8)
     * ───────────────────────────────────────────────────────────────────── */

    if (Slice_Equal_Ignore_Case(attr, S("MACHINE_ROUNDS"))) {
        /* T'MACHINE_ROUNDS - does the hardware round? (RM 3.5.8)
         * IEEE 754 hardware rounds, so return TRUE.
         * Boolean type in GNAT LLVM is i8. */
        Emit(cg, "  %%t%u = add i8 0, 1  ; 'MACHINE_ROUNDS (IEEE rounds)\n", t);
        Temp_Set_Type(cg, t, "i8");
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("MACHINE_OVERFLOWS"))) {
        /* T'MACHINE_OVERFLOWS - does the hardware raise on overflow? (RM 3.5.8)
         * IEEE 754 generates infinity on overflow (doesn't trap), return FALSE.
         * Boolean type in GNAT LLVM is i8. */
        Emit(cg, "  %%t%u = add i8 0, 0  ; 'MACHINE_OVERFLOWS (IEEE no trap)\n", t);
        Temp_Set_Type(cg, t, "i8");
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("MACHINE_RADIX"))) {
        /* T'MACHINE_RADIX - hardware floating-point radix (RM 3.5.8)
         * IEEE 754 uses radix 2 */
        Emit(cg, "  %%t%u = add %s 0, %d  ; 'MACHINE_RADIX (IEEE binary)\n", t, Integer_Arith_Type(cg), IEEE_MACHINE_RADIX);
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("MACHINE_MANTISSA"))) {
        /* T'MACHINE_MANTISSA - hardware mantissa bits (RM 3.5.8)
         * IEEE 754 double: 53 bits, float: 24 bits */
        int64_t machine_mantissa = IEEE_DOUBLE_MANTISSA;
        if (Type_Is_Float(prefix_type) and Float_Is_Single(prefix_type)) {
            machine_mantissa = IEEE_FLOAT_MANTISSA;
        }
        Emit(cg, "  %%t%u = add %s 0, %lld  ; 'MACHINE_MANTISSA\n", t, Integer_Arith_Type(cg), (long long)machine_mantissa);
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("MACHINE_EMAX"))) {
        /* T'MACHINE_EMAX - hardware max exponent (RM 3.5.8)
         * IEEE 754 double: 1024, float: 128 */
        int64_t machine_emax = IEEE_DOUBLE_EMAX;
        if (Type_Is_Float(prefix_type) and Float_Is_Single(prefix_type)) {
            machine_emax = IEEE_FLOAT_EMAX;
        }
        Emit(cg, "  %%t%u = add %s 0, %lld  ; 'MACHINE_EMAX\n", t, Integer_Arith_Type(cg), (long long)machine_emax);
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("MACHINE_EMIN"))) {
        /* T'MACHINE_EMIN - hardware min exponent (RM 3.5.8)
         * IEEE 754 double: -1021, float: -125 */
        int64_t machine_emin = IEEE_DOUBLE_EMIN;
        if (Type_Is_Float(prefix_type) and Float_Is_Single(prefix_type)) {
            machine_emin = IEEE_FLOAT_EMIN;
        }
        Emit(cg, "  %%t%u = add %s 0, %lld  ; 'MACHINE_EMIN\n", t, Integer_Arith_Type(cg), (long long)machine_emin);
        return t;
    }

    /* ─────────────────────────────────────────────────────────────────────
     * Object Attributes (RM 3.7.1, 9.9)
     * ───────────────────────────────────────────────────────────────────── */

    if (Slice_Equal_Ignore_Case(attr, S("CONSTRAINED"))) {
        /* X'CONSTRAINED - is the object constrained? (RM 3.7.1)
         * Returns TRUE if:
         *   - Object type has no discriminants (always constrained)
         *   - Object was declared with explicit discriminant constraint
         *   - Object type has no default discriminant values (immutable)
         * Returns FALSE if:
         *   - Object type has discriminants with defaults and no explicit constraint
         * Use i64 for consistency with Boolean storage/comparison. */
        Symbol *obj_sym = node->attribute.prefix ? node->attribute.prefix->symbol : NULL;
        Type_Info *obj_type = node->attribute.prefix ? node->attribute.prefix->type : NULL;
        bool is_constrained = true;  /* Default: constrained */
        if (obj_type and Type_Is_Record(obj_type) and obj_type->record.has_discriminants) {
            if (obj_type->record.is_constrained) {
                is_constrained = true;  /* Explicitly constrained subtype */
            } else if (obj_sym and obj_sym->is_disc_constrained) {
                is_constrained = true;  /* Object declared with constraint */
            } else if (obj_type->record.all_defaults) {
                is_constrained = false;  /* Mutable: defaults, no constraint */
            }
        }
        /* Boolean-valued attributes produce i8 (Boolean storage type) */
        Emit(cg, "  %%t%u = add i8 0, %d  ; 'CONSTRAINED\n", t, is_constrained ? 1 : 0);
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("CALLABLE"))) {
        /* T'CALLABLE (RM 9.9): load TCB handle, check completed flag */
        uint32_t handle = Generate_Expression(cg, node->attribute.prefix);
        Emit(cg, "  %%t%u = call i8 @__ada_task_callable(ptr %%t%u)\n", t, handle);
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("TERMINATED"))) {
        /* T'TERMINATED (RM 9.9): load TCB handle, check completed flag */
        uint32_t handle = Generate_Expression(cg, node->attribute.prefix);
        uint32_t tcb_ptr = Emit_Temp(cg);
        Emit(cg, "  %%t%u = icmp eq ptr %%t%u, null\n", tcb_ptr, handle);
        uint32_t ok_l = cg->label_id++, nil_l = cg->label_id++, done_l = cg->label_id++;
        Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n", tcb_ptr, nil_l, ok_l);
        cg->block_terminated = true;
        Emit_Label_Here(cg, nil_l);
        Emit(cg, "  br label %%L%u\n", done_l);
        Emit_Label_Here(cg, ok_l);
        uint32_t gep = Emit_Temp(cg);
        Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 24\n", gep, handle);
        uint32_t val = Emit_Temp(cg);
        Emit(cg, "  %%t%u = load i8, ptr %%t%u\n", val, gep);
        Emit(cg, "  br label %%L%u\n", done_l);
        cg->block_terminated = true;
        Emit_Label_Here(cg, done_l);
        Emit(cg, "  %%t%u = phi i8 [ 0, %%L%u ], [ %%t%u, %%L%u ]\n", t, nil_l, val, ok_l);
        return t;
    }

    if (Slice_Equal_Ignore_Case(attr, S("STORAGE_SIZE"))) {
        /* T'STORAGE_SIZE (RM 13.7.1) — return user-specified value if set,
         * otherwise return a reasonable implementation-defined default. */
        int64_t ss = 0;
        if (prefix_type and prefix_type->storage_size != 0)
            ss = prefix_type->storage_size;
        else if (prefix_type)
            ss = (int64_t)prefix_type->size * 8;
        Emit(cg, "  %%t%u = add %s 0, %lld  ; 'STORAGE_SIZE\n", t, Integer_Arith_Type(cg),
             (long long)ss);
        return t;
    }

    /* Unhandled attribute */
    fprintf(stderr, "warning: unhandled attribute '%.*s'\n",
            (int)attr.length, attr.data);
    Emit(cg, "  %%t%u = add %s 0, 0  ; unhandled '%.*s\n", t, Integer_Arith_Type(cg),
         (int)attr.length, attr.data);
    return t;
}

/* Helper: Find component index by name in record type */
static int32_t Find_Record_Component(Type_Info *record_type, String_Slice name) {
    if (not Type_Is_Record(record_type)) return -1;
    for (uint32_t i = 0; i < record_type->record.component_count; i++) {
        if (Slice_Equal_Ignore_Case(record_type->record.components[i].name, name)) {
            return (int32_t)i;
        }
    }
    return -1;
}

/* Check if a choice is "others" */
static bool Is_Others_Choice(Syntax_Node *choice) {
    return choice and (choice->kind == NK_OTHERS or
           (choice->kind == NK_IDENTIFIER and
            Slice_Equal_Ignore_Case(choice->string_val.text, S("others"))));
}

static uint32_t Generate_Aggregate(Code_Generator *cg, Syntax_Node *node) {
    /* Generate code for record/array aggregates
     * Supports: positional, named associations, others clause, ranges */
    Type_Info *agg_type = node->type;

    if (not agg_type) {
        Report_Error(node->location, "untyped aggregate in codegen");
        return 0;
    }

    if (Type_Is_Array_Like(agg_type) and agg_type->array.index_count > 0) {
        /* Array aggregate - allocate on stack and initialize */
        const char *elem_type = Type_To_Llvm(agg_type->array.element_type);
        uint32_t elem_size = agg_type->array.element_type ?
                             agg_type->array.element_type->size : 8;
        if (elem_size == 0) elem_size = 8;

        /* RM 4.3.3(6): For positional aggregates of unconstrained array types,
         * the lower bound of each dimension is the index subtype's 'FIRST.
         * Derive bounds for ALL dimensions from index_type when BOUND_NONE. */
        uint32_t agg_ndims = agg_type->array.index_count;
        if (agg_ndims > 8) agg_ndims = 8;
        Type_Bound dim_lo[8], dim_hi[8];
        for (uint32_t d = 0; d < agg_ndims; d++) {
            dim_lo[d] = agg_type->array.indices[d].low_bound;
            dim_hi[d] = agg_type->array.indices[d].high_bound;
            if (dim_lo[d].kind == BOUND_NONE and agg_type->array.indices[d].index_type)
                dim_lo[d] = agg_type->array.indices[d].index_type->low_bound;
            if (dim_hi[d].kind == BOUND_NONE and agg_type->array.indices[d].index_type)
                dim_hi[d] = agg_type->array.indices[d].index_type->high_bound;
        }
        /* For positional aggregates, override upper bound from element count:
         * high = low + N - 1.  For multidimensional aggregates, also adjust
         * inner dimension bounds from the first inner aggregate (RM 4.3.2). */
        uint32_t n_positional = 0;
        bool has_named = false;
        {
            for (uint32_t i = 0; i < node->aggregate.items.count; i++) {
                Syntax_Node *item = node->aggregate.items.items[i];
                if (item->kind == NK_ASSOCIATION) has_named = true;
                else n_positional++;
            }
            if (n_positional > 0 and not has_named and
                dim_lo[0].kind == BOUND_INTEGER) {
                dim_hi[0] = (Type_Bound){
                    .kind = BOUND_INTEGER,
                    .int_value = dim_lo[0].int_value + (int128_t)n_positional - 1
                };
            }
            /* Walk into nested inner aggregates to fix inner dimension bounds.
             * E.g. ((5,4,3),(2,1,0)) for ARRAY(STC1 RANGE <>, STC2 RANGE <>)
             * — the inner aggregate has 3 elements, so dim_hi[1] = STC2'FIRST + 3 - 1. */
            if (n_positional > 0 and not has_named and agg_ndims > 1) {
                Syntax_Node *inner = node->aggregate.items.items[0];
                for (uint32_t d = 1; d < agg_ndims and inner; d++) {
                    if (inner->kind != NK_AGGREGATE) break;
                    uint32_t inner_n = 0;
                    bool inner_named = false;
                    for (uint32_t j = 0; j < inner->aggregate.items.count; j++) {
                        if (inner->aggregate.items.items[j]->kind == NK_ASSOCIATION)
                            inner_named = true;
                        else inner_n++;
                    }
                    if (inner_n > 0 and not inner_named and
                        dim_lo[d].kind == BOUND_INTEGER) {
                        dim_hi[d] = (Type_Bound){
                            .kind = BOUND_INTEGER,
                            .int_value = dim_lo[d].int_value + (int128_t)inner_n - 1
                        };
                    }
                    /* Descend into the first element of this inner aggregate
                     * for the next dimension (3-D, 4-D, ...) */
                    inner = (inner->aggregate.items.count > 0) ?
                            inner->aggregate.items.items[0] : NULL;
                }
            }
            /* Named aggregates: compute outer bounds from explicit choice indices.
             * E.g. (1 => "WHEN", 2 => "WHAT") → dim_lo[0]=1, dim_hi[0]=2.
             * Also compute inner dimension from first inner element's size. */
            if (has_named and not agg_type->array.is_constrained) {
                int128_t named_lo = INT64_MAX, named_hi = INT64_MIN;
                bool found_named = false;
                Syntax_Node *first_inner_expr = NULL;
                for (uint32_t i = 0; i < node->aggregate.items.count; i++) {
                    Syntax_Node *item = node->aggregate.items.items[i];
                    if (item->kind != NK_ASSOCIATION) continue;
                    if (not first_inner_expr)
                        first_inner_expr = item->association.expression;
                    for (uint32_t c = 0; c < item->association.choices.count; c++) {
                        Syntax_Node *ch = item->association.choices.items[c];
                        if (Is_Others_Choice(ch)) continue;
                        if (ch->kind == NK_INTEGER) {
                            int128_t v = (int128_t)ch->integer_lit.value;
                            if (v < named_lo) named_lo = v;
                            if (v > named_hi) named_hi = v;
                            found_named = true;
                        } else if (ch->kind == NK_RANGE) {
                            if (ch->range.low and ch->range.low->kind == NK_INTEGER) {
                                int128_t v = (int128_t)ch->range.low->integer_lit.value;
                                if (v < named_lo) named_lo = v;
                                found_named = true;
                            }
                            if (ch->range.high and ch->range.high->kind == NK_INTEGER) {
                                int128_t v = (int128_t)ch->range.high->integer_lit.value;
                                if (v > named_hi) named_hi = v;
                                found_named = true;
                            }
                        }
                    }
                }
                if (found_named) {
                    dim_lo[0] = (Type_Bound){.kind = BOUND_INTEGER, .int_value = named_lo};
                    dim_hi[0] = (Type_Bound){.kind = BOUND_INTEGER, .int_value = named_hi};
                }
                /* Inner dimension: if inner elements are string literals,
                 * use string length for the second dimension extent. */
                if (agg_ndims > 1 and first_inner_expr and dim_lo[1].kind == BOUND_INTEGER) {
                    if (first_inner_expr->kind == NK_STRING and
                        first_inner_expr->string_val.text.length > 0) {
                        uint32_t slen = (uint32_t)first_inner_expr->string_val.text.length;
                        dim_hi[1] = (Type_Bound){
                            .kind = BOUND_INTEGER,
                            .int_value = dim_lo[1].int_value + (int128_t)slen - 1
                        };
                    } else if (first_inner_expr->kind == NK_AGGREGATE) {
                        /* Inner aggregate: count its elements */
                        uint32_t inner_cnt = 0;
                        for (uint32_t j = 0; j < first_inner_expr->aggregate.items.count; j++) {
                            if (first_inner_expr->aggregate.items.items[j]->kind != NK_ASSOCIATION)
                                inner_cnt++;
                        }
                        if (inner_cnt > 0) {
                            dim_hi[1] = (Type_Bound){
                                .kind = BOUND_INTEGER,
                                .int_value = dim_lo[1].int_value + (int128_t)inner_cnt - 1
                            };
                        }
                    }
                }
            }
        }
        Type_Bound low_bound = dim_lo[0], high_bound = dim_hi[0];

        /* For multi-dimensional arrays, the effective "element" of the outer
         * aggregate is a row (slice along the first dimension), not the scalar
         * element_type.  Compute the row size so memcpy uses the right length.
         * Use derived bounds (not raw BOUND_NONE) for correct sizing. */
        bool multidim = (agg_ndims > 1);
        uint32_t row_size = elem_size;
        bool inner_dynamic = false;
        if (multidim) {
            /* Check if any inner dimension has dynamic bounds */
            for (uint32_t d = 1; d < agg_ndims; d++) {
                if (dim_lo[d].kind == BOUND_EXPR or dim_hi[d].kind == BOUND_EXPR) {
                    inner_dynamic = true; break;
                }
            }
            if (not inner_dynamic) {
                /* All inner dims static: compute row_size at compile time */
                uint32_t row_elems = 1;
                for (uint32_t d = 1; d < agg_ndims; d++) {
                    int128_t lo = Type_Bound_Value(dim_lo[d]);
                    int128_t hi = Type_Bound_Value(dim_hi[d]);
                    int128_t cnt = hi - lo + 1;
                    if (cnt > 0) row_elems *= (uint32_t)cnt;
                }
                row_size = row_elems * elem_size;
                elem_size = row_size;  /* outer dimension "element" is a row */
            }
        }

        /* Any dimension with dynamic bounds requires runtime path (RM 3.6.1).
         * Type_Bound_Value returns 0 for BOUND_EXPR so compile-time size
         * calculation would be wrong; the dynamic path evaluates bounds at
         * runtime via Emit_Single_Bound. */
        bool dynamic_bounds = false;
        for (uint32_t d = 0; d < agg_ndims; d++) {
            if (dim_lo[d].kind == BOUND_EXPR or dim_hi[d].kind == BOUND_EXPR) {
                dynamic_bounds = true; break;
            }
        }

        if (dynamic_bounds) {
            /* Dynamic bounds: generate runtime allocation and loop-based init */
            const char *iat_bnd = Integer_Arith_Type(cg);
            uint32_t low_val = Emit_Single_Bound(cg, &low_bound, iat_bnd);
            uint32_t high_val = Emit_Single_Bound(cg, &high_bound, iat_bnd);

            /* For multidim with dynamic inner bounds, compute row_size and
             * total_flat_count at runtime so allocation is correct. */
            uint32_t rt_row_size = 0;  /* SSA temp for runtime row size */
            uint32_t rt_inner_lo[8] = {0}, rt_inner_hi[8] = {0};
            if (multidim and inner_dynamic) {
                /* Evaluate inner dimension bounds at runtime */
                uint32_t rt_row_elems = 0;
                for (uint32_t d = 1; d < agg_ndims; d++) {
                    rt_inner_lo[d] = Emit_Single_Bound(cg, &dim_lo[d], iat_bnd);
                    rt_inner_hi[d] = Emit_Single_Bound(cg, &dim_hi[d], iat_bnd);
                    uint32_t dim_len = Emit_Length_From_Bounds(cg, rt_inner_lo[d],
                                                               rt_inner_hi[d], iat_bnd);
                    if (d == 1)
                        rt_row_elems = dim_len;
                    else {
                        uint32_t prod = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = mul %s %%t%u, %%t%u\n",
                             prod, iat_bnd, rt_row_elems, dim_len);
                        rt_row_elems = prod;
                    }
                }
                uint32_t raw_row_size = Emit_Temp(cg);
                uint32_t scalar_sz = agg_type->array.element_type ?
                                     agg_type->array.element_type->size : 8;
                if (scalar_sz == 0) scalar_sz = 8;
                Emit(cg, "  %%t%u = mul %s %%t%u, %u  ; row byte size\n",
                     raw_row_size, iat_bnd, rt_row_elems, scalar_sz);
                /* Clamp to >= 0: null inner ranges produce negative sizes */
                uint32_t neg = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp slt %s %%t%u, 0\n",
                     neg, iat_bnd, raw_row_size);
                rt_row_size = Emit_Temp(cg);
                Emit(cg, "  %%t%u = select i1 %%t%u, %s 0, %s %%t%u\n",
                     rt_row_size, neg, iat_bnd, iat_bnd, raw_row_size);
            }

            /* Calculate count and byte size */
            uint32_t count_plus1 = Emit_Length_From_Bounds(cg, low_val, high_val, iat_bnd);
            uint32_t byte_size;
            if (rt_row_size) {
                /* Runtime elem_size: total = outer_count * row_byte_size */
                byte_size = Emit_Temp(cg);
                Emit(cg, "  %%t%u = mul %s %%t%u, %%t%u\n",
                     byte_size, iat_bnd, count_plus1, rt_row_size);
            } else {
                byte_size = Emit_Temp(cg);
                Emit(cg, "  %%t%u = mul %s %%t%u, %u\n",
                     byte_size, iat_bnd, count_plus1, elem_size);
            }

            /* Clamp byte_size to 0 for null ranges (RM 3.6.1) */
            uint32_t neg_chk = Emit_Temp(cg);
            Emit(cg, "  %%t%u = icmp slt %s %%t%u, 0\n", neg_chk, iat_bnd, byte_size);
            uint32_t clamped = Emit_Temp(cg);
            Emit(cg, "  %%t%u = select i1 %%t%u, %s 0, %s %%t%u\n",
                 clamped, neg_chk, iat_bnd, iat_bnd, byte_size);

            /* Dynamic stack allocation */
            uint32_t base = Emit_Temp(cg);
            Emit(cg, "  %%t%u = alloca i8, %s %%t%u  ; dynamic array aggregate\n", base, iat_bnd, clamped);

            /* Find "others" clause and generate value */
            uint32_t others_val = 0;
            bool has_others = false;
            for (uint32_t i = 0; i < node->aggregate.items.count; i++) {
                Syntax_Node *item = node->aggregate.items.items[i];
                if (item->kind == NK_ASSOCIATION and item->association.choices.count > 0) {
                    if (Is_Others_Choice(item->association.choices.items[0])) {
                        Syntax_Node *oe = item->association.expression;
                        others_val = Generate_Expression(cg, oe);
                        /* RM 4.3.2: fat pointer others (e.g. string) → extract data */
                        if (multidim and oe->kind == NK_AGGREGATE) {
                            /* Inner aggregate for multidim: returns fat ptr alloca
                             * (dynamic) or data alloca (static).  For dynamic inner
                             * bounds, load fat ptr then extract data pointer. */
                            if (oe->type and Type_Has_Dynamic_Bounds(oe->type)) {
                                uint32_t loaded = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = load " FAT_PTR_TYPE ", ptr %%t%u\n",
                                     loaded, others_val);
                                others_val = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = extractvalue " FAT_PTR_TYPE
                                     " %%t%u, 0\n", others_val, loaded);
                            }
                            /* else: static inner aggregate alloca IS the data */
                        } else if (Expression_Produces_Fat_Pointer(oe, oe->type))
                            others_val = Emit_Fat_Pointer_Data(cg, others_val,
                                             Array_Bound_Llvm_Type(agg_type));
                        else {
                            const char *src_type = Expression_Llvm_Type(cg, oe);
                            others_val = Emit_Convert(cg, others_val, src_type,
                                                      elem_type);
                        }
                        has_others = true;
                        break;
                    }
                }
            }

            /* Positional elements: store each element at its index offset.
             * Index = positional_idx * elem_size bytes from base. */
            {
                uint32_t positional_idx = 0;
                for (uint32_t i = 0; i < node->aggregate.items.count; i++) {
                    Syntax_Node *item = node->aggregate.items.items[i];
                    if (item->kind == NK_ASSOCIATION) continue;  /* skip named/others */
                    uint32_t val = Generate_Expression(cg, item);
                    Type_Info *elem_ti = agg_type->array.element_type;
                    bool elem_is_composite = multidim or (elem_ti and (Type_Is_Record(elem_ti) or
                        Type_Is_Constrained_Array(elem_ti)));
                    if (elem_is_composite) {
                        /* RM 4.3.2: fat pointer (e.g. string literal) → extract data ptr */
                        if (Expression_Produces_Fat_Pointer(item, item->type))
                            val = Emit_Fat_Pointer_Data(cg, val,
                                      Array_Bound_Llvm_Type(agg_type));
                        else if (multidim and item->kind == NK_AGGREGATE and
                                 item->type and Type_Has_Dynamic_Bounds(item->type)) {
                            /* Dynamic inner aggregate: fat ptr alloca → data ptr */
                            uint32_t loaded = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = load " FAT_PTR_TYPE ", ptr %%t%u\n",
                                 loaded, val);
                            val = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = extractvalue " FAT_PTR_TYPE
                                 " %%t%u, 0\n", val, loaded);
                        }
                        uint32_t ptr = Emit_Temp(cg);
                        if (rt_row_size) {
                            /* Runtime row offset: positional_idx * rt_row_size */
                            uint32_t idx_t = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add i32 0, %u\n", idx_t, positional_idx);
                            uint32_t off = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = mul i32 %%t%u, %%t%u\n", off, idx_t, rt_row_size);
                            Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i32 %%t%u\n",
                                 ptr, base, off);
                            uint32_t sz64 = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = sext i32 %%t%u to i64\n", sz64, rt_row_size);
                            Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)\n",
                                 ptr, val, sz64);
                        } else {
                            Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %u\n",
                                 ptr, base, positional_idx * elem_size);
                            Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %u, i1 false)\n",
                                 ptr, val, elem_size);
                        }
                    } else {
                        const char *src_type = Expression_Llvm_Type(cg, item);
                        val = Emit_Convert(cg, val, src_type, elem_type);
                        /* RM 4.3.2: check element against component subtype constraint */
                        if (elem_ti && Type_Is_Scalar(elem_ti))
                            val = Emit_Constraint_Check_With_Type(cg, val, elem_ti,
                                item->type, elem_type);
                        uint32_t ptr = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, i64 %u\n",
                             ptr, elem_type, base, positional_idx);
                        Emit(cg, "  store %s %%t%u, ptr %%t%u\n", elem_type, val, ptr);
                    }
                    positional_idx++;
                }
            }

            /* For dynamic aggregates with named range association (1..H1 => val),
             * generate a loop to initialize all elements */
            for (uint32_t i = 0; i < node->aggregate.items.count; i++) {
                Syntax_Node *item = node->aggregate.items.items[i];
                if (item->kind == NK_ASSOCIATION and item->association.choices.count > 0) {
                    Syntax_Node *choice = item->association.choices.items[0];
                    if (Is_Others_Choice(choice)) continue;

                    if (choice->kind == NK_RANGE) {
                        /* Generate loop bounds */
                        uint32_t rng_low_val, rng_high_val;
                        if (choice->range.low->kind == NK_INTEGER) {
                            rng_low_val = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add %s 0, %lld\n", rng_low_val, Integer_Arith_Type(cg),
                                 (long long)choice->range.low->integer_lit.value);
                        } else {
                            rng_low_val = Generate_Expression(cg, choice->range.low);
                        }
                        if (choice->range.high->kind == NK_INTEGER) {
                            rng_high_val = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add %s 0, %lld\n", rng_high_val, Integer_Arith_Type(cg),
                                 (long long)choice->range.high->integer_lit.value);
                        } else {
                            rng_high_val = Generate_Expression(cg, choice->range.high);
                        }

                        /* Coerce range bounds to loop index type.
                         * RM 4.3.2: expression is evaluated ONCE PER
                         * COMPONENT — Generate_Expression goes inside
                         * the loop body. */
                        const char *agg_idx_type = Integer_Arith_Type(cg);
                        rng_low_val = Emit_Coerce(cg, rng_low_val, agg_idx_type);
                        rng_high_val = Emit_Coerce(cg, rng_high_val, agg_idx_type);

                        /* RM 4.3.2(3): non-null range choice bounds must
                         * belong to the index subtype.  Check at runtime.
                         * Only check when index_type has meaningful bounds
                         * (named subtype like STA, not anonymous ranges). */
                        if (agg_type->array.indices &&
                            agg_type->array.indices[0].index_type &&
                            agg_type->array.indices[0].index_type->low_bound.kind == BOUND_INTEGER &&
                            agg_type->array.indices[0].index_type->high_bound.kind == BOUND_INTEGER) {
                            Type_Info *idx_t = agg_type->array.indices[0].index_type;
                            int64_t is_lo = (int64_t)Type_Bound_Value(idx_t->low_bound);
                            int64_t is_hi = (int64_t)Type_Bound_Value(idx_t->high_bound);
                            /* Skip check if bounds are full INTEGER range (no real subtype) */
                            if (is_lo != (int64_t)(-2147483648LL) ||
                                is_hi != (int64_t)2147483647LL) {
                                /* Only check for non-null ranges (lo <= hi) */
                                uint32_t null_cmp = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = icmp sgt %s %%t%u, %%t%u"
                                         "  ; null range?\n",
                                     null_cmp, agg_idx_type, rng_low_val, rng_high_val);
                                uint32_t skip_lbl = cg->label_id++;
                                uint32_t chk_lbl  = cg->label_id++;
                                Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n",
                                     null_cmp, skip_lbl, chk_lbl);
                                cg->block_terminated = true;
                                Emit_Label_Here(cg, chk_lbl);
                                Emit_Range_Check_With_Raise(cg, rng_low_val,
                                    is_lo, is_hi, agg_idx_type,
                                    "dynamic aggregate index subtype check");
                                Emit_Range_Check_With_Raise(cg, rng_high_val,
                                    is_lo, is_hi, agg_idx_type,
                                    "dynamic aggregate index subtype check");
                                Emit(cg, "  br label %%L%u\n", skip_lbl);
                                cg->block_terminated = true;
                                Emit_Label_Here(cg, skip_lbl);
                            }
                        }

                        Type_Info *elem_ti = agg_type->array.element_type;
                        bool elem_is_composite = multidim or Type_Is_Record(elem_ti) or
                            Type_Is_Constrained_Array(elem_ti);

                        uint32_t loop_var = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = alloca %s\n", loop_var, agg_idx_type);
                        Emit(cg, "  store %s %%t%u, ptr %%t%u\n", agg_idx_type, rng_low_val, loop_var);

                        uint32_t loop_start = cg->label_id++;
                        uint32_t loop_body = cg->label_id++;
                        uint32_t loop_end = cg->label_id++;

                        Emit(cg, "  br label %%L%u\n", loop_start);
                        cg->block_terminated = true;
                        Emit_Label_Here(cg, loop_start);

                        uint32_t cur_idx = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", cur_idx, agg_idx_type, loop_var);
                        uint32_t cmp = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = icmp sle %s %%t%u, %%t%u\n", cmp, agg_idx_type, cur_idx, rng_high_val);
                        Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n", cmp, loop_body, loop_end);
                        cg->block_terminated = true;

                        Emit_Label_Here(cg, loop_body);

                        /* Evaluate expression anew for this component */
                        uint32_t val = Generate_Expression(cg, item->association.expression);
                        if (elem_is_composite and
                            Expression_Produces_Fat_Pointer(item->association.expression,
                                item->association.expression->type))
                            val = Emit_Fat_Pointer_Data(cg, val,
                                      Array_Bound_Llvm_Type(agg_type));
                        else if (elem_is_composite and multidim and
                                 item->association.expression->kind == NK_AGGREGATE and
                                 item->association.expression->type and
                                 Type_Has_Dynamic_Bounds(item->association.expression->type)) {
                            uint32_t loaded = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = load " FAT_PTR_TYPE ", ptr %%t%u\n",
                                 loaded, val);
                            val = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = extractvalue " FAT_PTR_TYPE
                                 " %%t%u, 0\n", val, loaded);
                        }
                        if (not elem_is_composite) {
                            const char *src_type = Expression_Llvm_Type(cg, item->association.expression);
                            val = Emit_Convert(cg, val, src_type, elem_type);
                        }

                        /* Calculate array index: (cur_idx - low_val) */
                        uint32_t arr_idx = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", arr_idx, agg_idx_type, cur_idx, low_val);

                        if (elem_is_composite) {
                            uint32_t byte_off = Emit_Temp(cg);
                            if (rt_row_size)
                                Emit(cg, "  %%t%u = mul %s %%t%u, %%t%u\n",
                                     byte_off, agg_idx_type, arr_idx, rt_row_size);
                            else
                                Emit(cg, "  %%t%u = mul %s %%t%u, %u\n",
                                     byte_off, agg_idx_type, arr_idx, elem_size);
                            uint32_t ptr = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s %%t%u\n",
                                 ptr, base, agg_idx_type, byte_off);
                            if (rt_row_size) {
                                uint32_t sz64 = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = sext i32 %%t%u to i64\n", sz64, rt_row_size);
                                Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)\n",
                                     ptr, val, sz64);
                            } else
                                Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %u, i1 false)\n",
                                     ptr, val, elem_size);
                        } else {
                            uint32_t ptr = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, %s %%t%u\n",
                                 ptr, elem_type, base, agg_idx_type, arr_idx);
                            Emit(cg, "  store %s %%t%u, ptr %%t%u\n", elem_type, val, ptr);
                        }

                        /* Increment and loop */
                        uint32_t next_idx = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = add %s %%t%u, 1\n", next_idx, agg_idx_type, cur_idx);
                        Emit(cg, "  store %s %%t%u, ptr %%t%u\n", agg_idx_type, next_idx, loop_var);
                        Emit(cg, "  br label %%L%u\n", loop_start);
                        cg->block_terminated = true;

                        Emit_Label_Here(cg, loop_end);
                        cg->block_terminated = false;
                    } else {
                        /* Single-index named association: INDEX => expr.
                         * Evaluate the index, compute offset, store once. */
                        uint32_t idx_val = Generate_Expression(cg, choice);
                        const char *agg_idx_type = Integer_Arith_Type(cg);
                        idx_val = Emit_Coerce(cg, idx_val, agg_idx_type);

                        Type_Info *elem_ti = agg_type->array.element_type;
                        bool elem_is_composite = multidim or Type_Is_Record(elem_ti) or
                            Type_Is_Constrained_Array(elem_ti);

                        uint32_t val = Generate_Expression(cg, item->association.expression);
                        if (elem_is_composite and
                            Expression_Produces_Fat_Pointer(item->association.expression,
                                item->association.expression->type))
                            val = Emit_Fat_Pointer_Data(cg, val,
                                      Array_Bound_Llvm_Type(agg_type));
                        else if (elem_is_composite and multidim and
                                 item->association.expression->kind == NK_AGGREGATE and
                                 item->association.expression->type and
                                 Aggregate_Produces_Fat_Pointer(item->association.expression->type)) {
                            uint32_t loaded = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = load " FAT_PTR_TYPE ", ptr %%t%u\n",
                                 loaded, val);
                            val = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = extractvalue " FAT_PTR_TYPE
                                 " %%t%u, 0\n", val, loaded);
                        }
                        if (not elem_is_composite) {
                            const char *src_type = Expression_Llvm_Type(cg, item->association.expression);
                            val = Emit_Convert(cg, val, src_type, elem_type);
                        }

                        uint32_t arr_idx = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", arr_idx, agg_idx_type, idx_val, low_val);

                        if (elem_is_composite) {
                            uint32_t byte_off = Emit_Temp(cg);
                            if (rt_row_size)
                                Emit(cg, "  %%t%u = mul %s %%t%u, %%t%u\n",
                                     byte_off, agg_idx_type, arr_idx, rt_row_size);
                            else
                                Emit(cg, "  %%t%u = mul %s %%t%u, %u\n",
                                     byte_off, agg_idx_type, arr_idx, elem_size);
                            uint32_t ptr = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s %%t%u\n",
                                 ptr, base, agg_idx_type, byte_off);
                            if (rt_row_size) {
                                uint32_t sz64 = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = sext i32 %%t%u to i64\n", sz64, rt_row_size);
                                Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)\n",
                                     ptr, val, sz64);
                            } else
                                Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %u, i1 false)\n",
                                     ptr, val, elem_size);
                        } else {
                            uint32_t ptr = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, %s %%t%u\n",
                                 ptr, elem_type, base, agg_idx_type, arr_idx);
                            Emit(cg, "  store %s %%t%u, ptr %%t%u\n", elem_type, val, ptr);
                        }
                    }
                }
            }

            /* If "others" clause, fill remaining with loop (already handled by range above
             * for typical cases like (1..H1 => val), but add fallback if needed) */
            if (has_others) {
                /* Check if element is composite */
                Type_Info *elem_ti = agg_type->array.element_type;
                bool elem_is_composite = multidim or Type_Is_Record(elem_ti) or
                    Type_Is_Constrained_Array(elem_ti);

                /* Generate loop from low to high */
                const char *oth_idx_type = Integer_Arith_Type(cg);
                uint32_t loop_var = Emit_Temp(cg);
                Emit(cg, "  %%t%u = alloca %s\n", loop_var, oth_idx_type);
                Emit(cg, "  store %s %%t%u, ptr %%t%u\n", oth_idx_type, low_val, loop_var);

                uint32_t loop_start = cg->label_id++;
                uint32_t loop_body = cg->label_id++;
                uint32_t loop_end = cg->label_id++;

                Emit(cg, "  br label %%L%u\n", loop_start);
                cg->block_terminated = true;
                Emit_Label_Here(cg, loop_start);

                uint32_t cur_idx = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", cur_idx, oth_idx_type, loop_var);
                uint32_t cmp = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp sle %s %%t%u, %%t%u\n", cmp, oth_idx_type, cur_idx, high_val);
                Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n", cmp, loop_body, loop_end);
                cg->block_terminated = true;

                Emit_Label_Here(cg, loop_body);
                uint32_t arr_idx = Emit_Temp(cg);
                Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", arr_idx, oth_idx_type, cur_idx, low_val);

                if (elem_is_composite) {
                    /* Composite element: use byte-based indexing and memcpy */
                    uint32_t byte_off = Emit_Temp(cg);
                    if (rt_row_size)
                        Emit(cg, "  %%t%u = mul %s %%t%u, %%t%u\n",
                             byte_off, oth_idx_type, arr_idx, rt_row_size);
                    else
                        Emit(cg, "  %%t%u = mul %s %%t%u, %u\n",
                             byte_off, oth_idx_type, arr_idx, elem_size);
                    uint32_t ptr = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s %%t%u\n",
                         ptr, base, oth_idx_type, byte_off);
                    if (rt_row_size) {
                        uint32_t sz64 = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = sext i32 %%t%u to i64\n", sz64, rt_row_size);
                        Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)\n",
                             ptr, others_val, sz64);
                    } else
                        Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %u, i1 false)\n",
                             ptr, others_val, elem_size);
                } else {
                    /* Scalar element: use typed indexing and store */
                    uint32_t ptr = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, %s %%t%u\n",
                         ptr, elem_type, base, oth_idx_type, arr_idx);
                    Emit(cg, "  store %s %%t%u, ptr %%t%u\n", elem_type, others_val, ptr);
                }

                uint32_t next_idx = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s %%t%u, 1\n", next_idx, oth_idx_type, cur_idx);
                Emit(cg, "  store %s %%t%u, ptr %%t%u\n", oth_idx_type, next_idx, loop_var);
                Emit(cg, "  br label %%L%u\n", loop_start);
                cg->block_terminated = true;

                Emit_Label_Here(cg, loop_end);
                cg->block_terminated = false;
            }

            /* For dynamic bounds arrays, return a fat pointer { ptr, ptr }
             * where the bounds pointer contains ALL dimension bounds in flat
             * layout [lo0, hi0, lo1, hi1, ...] so multi-dim indexing works. */
            uint32_t fat_ptr = Emit_Temp(cg);
            {
                const char *agg_bt = Array_Bound_Llvm_Type(agg_type);
                Emit(cg, "  %%t%u = alloca " FAT_PTR_TYPE "  ; dynamic array fat ptr\n", fat_ptr);
                if (multidim and agg_ndims > 1) {
                    uint32_t md_lo[8], md_hi[8];
                    md_lo[0] = low_val;
                    md_hi[0] = high_val;
                    for (uint32_t d = 1; d < agg_ndims; d++) {
                        md_lo[d] = rt_inner_lo[d] ? rt_inner_lo[d]
                                 : Emit_Static_Int(cg, Type_Bound_Value(dim_lo[d]), iat_bnd);
                        md_hi[d] = rt_inner_hi[d] ? rt_inner_hi[d]
                                 : Emit_Static_Int(cg, Type_Bound_Value(dim_hi[d]), iat_bnd);
                    }
                    uint32_t bounds_alloca = Emit_Alloc_Bounds_MultiDim(cg, md_lo, md_hi, agg_ndims, agg_bt);
                    uint32_t ds = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = getelementptr " FAT_PTR_TYPE ", ptr %%t%u, i32 0, i32 0\n", ds, fat_ptr);
                    Emit(cg, "  store ptr %%t%u, ptr %%t%u\n", base, ds);
                    uint32_t bs = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = getelementptr " FAT_PTR_TYPE ", ptr %%t%u, i32 0, i32 1\n", bs, fat_ptr);
                    Emit(cg, "  store ptr %%t%u, ptr %%t%u\n", bounds_alloca, bs);
                } else {
                    Emit_Store_Fat_Pointer_Fields_To_Temp(cg, base, low_val, high_val, fat_ptr, agg_bt);
                }
            }
            return fat_ptr;
        }

        /* Static bounds: use compile-time allocation and unrolled initialization */
        uint32_t base = Emit_Temp(cg);
        int128_t low = Type_Bound_Value(low_bound);
        int128_t high = Type_Bound_Value(high_bound);
        int128_t count = high - low + 1;
        if (count < 1) count = 1;  /* Ensure at least 1 element for safety */

        /* RM 4.3.2(3): index subtype bounds for aggregate constraint checking.
         * Each choice bound of a non-null range must belong to the index
         * subtype.  This check applies when:
         *   (a) the type is unconstrained (choices define aggregate bounds),
         *   (b) it's a constrained subtype of an unconstrained base
         *       (T IS BASE(5..7) where BASE IS ARRAY(ST RANGE <>)),
         *   (c) directly constrained with named index type
         *       (ARRAY(STA RANGE 5..6, ...) where STA IS INTEGER RANGE 4..7);
         *       choice bounds must belong to the index type (STA = 4..7). */
        bool has_unconstrained_base = agg_type->base_type &&
            Type_Is_Array_Like(agg_type->base_type) &&
            !agg_type->base_type->array.is_constrained;
        bool need_idx_subtype_check = !agg_type->array.is_constrained ||
                                      has_unconstrained_base;
        int128_t idx_sub_lo = low, idx_sub_hi = high;
        if (has_unconstrained_base &&
            agg_type->base_type->array.index_count > 0 &&
            agg_type->base_type->array.indices &&
            agg_type->base_type->array.indices[0].index_type) {
            idx_sub_lo = Type_Bound_Value(
                agg_type->base_type->array.indices[0].index_type->low_bound);
            idx_sub_hi = Type_Bound_Value(
                agg_type->base_type->array.indices[0].index_type->high_bound);
        } else if (!agg_type->array.is_constrained &&
                   agg_type->array.index_count > 0 &&
                   agg_type->array.indices &&
                   agg_type->array.indices[0].index_type) {
            /* Directly unconstrained type: get index subtype from index_type */
            idx_sub_lo = Type_Bound_Value(
                agg_type->array.indices[0].index_type->low_bound);
            idx_sub_hi = Type_Bound_Value(
                agg_type->array.indices[0].index_type->high_bound);
        }

        /* RM 4.3.2(3): for named aggregates of unconstrained types, the
         * bounds are determined by the choices.  The lower bound is the
         * minimum of all range-low values; the upper bound is the maximum
         * of all range-high values.  For a null range (L..H where L>H),
         * the bounds stay L..H because we track lows and highs separately. */
        bool has_choice_lo = false, has_choice_hi = false;
        bool early_has_others = false;
        int128_t choice_lo = 0, choice_hi = 0;
        for (uint32_t ci = 0; ci < node->aggregate.items.count; ci++) {
            Syntax_Node *cit = node->aggregate.items.items[ci];
            if (cit->kind != NK_ASSOCIATION) continue;
            for (uint32_t cc = 0; cc < cit->association.choices.count; cc++) {
                Syntax_Node *ch = cit->association.choices.items[cc];
                if (Is_Others_Choice(ch)) { early_has_others = true; continue; }
                if (ch->kind == NK_RANGE) {
                    if (ch->range.low->kind == NK_INTEGER) {
                        int128_t v = (int128_t)ch->range.low->integer_lit.value;
                        if (not has_choice_lo or v < choice_lo) choice_lo = v;
                        has_choice_lo = true;
                    }
                    if (ch->range.high->kind == NK_INTEGER) {
                        int128_t v = (int128_t)ch->range.high->integer_lit.value;
                        if (not has_choice_hi or v > choice_hi) choice_hi = v;
                        has_choice_hi = true;
                    }
                } else if (ch->kind == NK_INTEGER) {
                    int128_t v = (int128_t)ch->integer_lit.value;
                    if (not has_choice_lo or v < choice_lo) choice_lo = v;
                    has_choice_lo = true;
                    if (not has_choice_hi or v > choice_hi) choice_hi = v;
                    has_choice_hi = true;
                }
            }
        }
        if (has_choice_lo and has_choice_hi and not early_has_others) {
            /* RM 4.3.2(5): Named aggregate bounds are determined by the
             * lowest and highest choices.  For aggregates without OTHERS,
             * the aggregate storage uses choice bounds (sliding occurs at
             * assignment for constrained targets).  With OTHERS, the
             * aggregate must cover the full type range. */
            low = choice_lo;
            high = choice_hi;
            count = high - low + 1;
            if (count < 1) count = 1;
        }
        /* RM 4.3.2(6): For constrained array subtypes, the aggregate bounds
         * must match the constraint bounds.  For positional aggregates, the
         * lower bound is INDEX_SUBTYPE'FIRST (from the base unconstrained
         * type), which may differ from the constraint.  For named aggregates
         * without OTHERS, the bounds come from the choices. */
        if (agg_type->array.is_constrained and
            agg_type->array.indices[0].low_bound.kind == BOUND_INTEGER and
            agg_type->array.indices[0].high_bound.kind == BOUND_INTEGER) {
            int128_t con_lo = Type_Bound_Value(agg_type->array.indices[0].low_bound);
            int128_t con_hi = Type_Bound_Value(agg_type->array.indices[0].high_bound);

            if (n_positional > 0 and not has_named and has_unconstrained_base) {
                /* Positional aggregate: true lower bound is index subtype FIRST,
                 * not the constrained bound.  RM 4.3.2(5). */
                int128_t true_lo = idx_sub_lo;
                int128_t true_hi = true_lo + (int128_t)n_positional - 1;
                if (true_lo != con_lo or true_hi != con_hi) {
                    Emit_Raise_Constraint_Error(cg, "positional aggregate bounds vs constraint");
                    uint32_t cont = cg->label_id++;
                    Emit_Label_Here(cg, cont);
                }
            }

            if (has_choice_lo and has_choice_hi and not early_has_others
                and has_unconstrained_base and agg_ndims == 1) {
                /* Named aggregate of constrained 1-D subtype of unconstrained
                 * base: choice bounds must match the constraint (array-of-array
                 * component).  For multidim arrays (agg_ndims > 1), sliding
                 * applies at assignment per RM 5.2.1. */
                if (low != con_lo or high != con_hi) {
                    Emit_Raise_Constraint_Error(cg, "named aggregate bounds vs constraint");
                    uint32_t cont = cg->label_id++;
                    Emit_Label_Here(cg, cont);
                }
            }
        }

        /* For unconstrained types, track LLVM SSA values for the aggregate's
         * actual bounds (from choice expressions) to populate the fat pointer.
         * These are set during range-choice processing below. */
        uint32_t agg_lo_ssa = 0, agg_hi_ssa = 0;
        uint32_t agg_d1_lo_ssa = 0, agg_d1_hi_ssa = 0;  /* dim 1 inner choice SSA */

        /* Check if element type is composite (record or constrained array).
         * For composite elements, Generate_Expression returns a ptr to an alloca,
         * so we must use memcpy to copy element data instead of store.
         * Multi-dimensional arrays are always composite at the outer level
         * because each "element" is a row (inner array). */
        Type_Info *elem_ti = agg_type->array.element_type;
        bool elem_is_composite = multidim or (elem_ti and (Type_Is_Record(elem_ti) or
            Type_Is_Constrained_Array(elem_ti)));

        if (elem_is_composite) {
            /* Allocate as byte array so the size matches the actual data layout */
            int128_t total_bytes = count * (int128_t)elem_size;
            Emit(cg, "  %%t%u = alloca [%s x i8]  ; array aggregate (composite elems)\n",
                 base, I128_Decimal(total_bytes));
        } else {
            Emit(cg, "  %%t%u = alloca [%s x %s]  ; array aggregate\n",
                 base, I128_Decimal(count), elem_type);
        }

        /* Track which elements are initialized (for others clause) */
        bool *initialized = Arena_Allocate((size_t)count * sizeof(bool));
        for (int128_t i = 0; i < count; i++) initialized[i] = false;

        /* Default value for "others" clause (if any) */
        uint32_t others_val = 0;
        bool has_others = false;
        Syntax_Node *others_item_expr = NULL;  /* RM 4.3.3(5): re-evaluate per component */

        /* First pass: find "others" clause and save expression node */
        for (uint32_t i = 0; i < node->aggregate.items.count; i++) {
            Syntax_Node *item = node->aggregate.items.items[i];
            if (item->kind == NK_ASSOCIATION and item->association.choices.count > 0) {
                if (Is_Others_Choice(item->association.choices.items[0])) {
                    others_item_expr = item->association.expression;
                    has_others = true;
                    break;
                }
            }
        }

        /* Second pass: initialize elements */
        uint32_t positional_idx = 0;
        for (uint32_t i = 0; i < node->aggregate.items.count; i++) {
            Syntax_Node *item = node->aggregate.items.items[i];

            if (item->kind == NK_ASSOCIATION) {
                /* Named association: handle each choice */
                for (uint32_t c = 0; c < item->association.choices.count; c++) {
                    Syntax_Node *choice = item->association.choices.items[c];

                    if (Is_Others_Choice(choice)) {
                        continue;  /* Handle in third pass */
                    }

                    if (choice->kind == NK_RANGE) {
                        /* Range choice: 1..5 => value
                         * RM 4.3.2: the expression is evaluated ONCE PER
                         * COMPONENT, so Generate_Expression must be called
                         * inside the per-element loop. */
                        int128_t rng_low, rng_high;
                        uint32_t rng_lo_ssa = 0, rng_hi_ssa = 0;
                        bool must_eval_low  = (choice->range.low->kind != NK_INTEGER);
                        bool must_eval_high = (choice->range.high->kind != NK_INTEGER);
                        if (not must_eval_low) {
                            rng_low = (int128_t)choice->range.low->integer_lit.value;
                        } else {
                            uint32_t ev = Generate_Expression(cg, choice->range.low);
                            rng_low = low;
                            const char *bt = Array_Bound_Llvm_Type(agg_type);
                            const char *st = Expression_Llvm_Type(cg, choice->range.low);
                            rng_lo_ssa = (strcmp(st, bt) != 0)
                                ? Emit_Convert(cg, ev, st, bt) : ev;
                            if (not agg_type->array.is_constrained and agg_lo_ssa == 0)
                                agg_lo_ssa = rng_lo_ssa;
                        }
                        if (not must_eval_high) {
                            rng_high = (int128_t)choice->range.high->integer_lit.value;
                        } else {
                            uint32_t ev = Generate_Expression(cg, choice->range.high);
                            rng_high = high;
                            const char *bt = Array_Bound_Llvm_Type(agg_type);
                            const char *st = Expression_Llvm_Type(cg, choice->range.high);
                            rng_hi_ssa = (strcmp(st, bt) != 0)
                                ? Emit_Convert(cg, ev, st, bt) : ev;
                            if (not agg_type->array.is_constrained and agg_hi_ssa == 0)
                                agg_hi_ssa = rng_hi_ssa;
                        }

                        /* RM 4.3.2(3): for a non-null range, the bounds must
                         * belong to the index subtype.  Raise CONSTRAINT_ERROR
                         * if not.  Null ranges (lo > hi) are exempt. */
                        if (need_idx_subtype_check) {
                            const char *bt = Array_Bound_Llvm_Type(agg_type);
                            if (not must_eval_low and not must_eval_high) {
                                /* Both bounds static: compile-time check */
                                if (rng_low <= rng_high and
                                    (rng_low < idx_sub_lo or rng_low > idx_sub_hi or
                                     rng_high < idx_sub_lo or rng_high > idx_sub_hi)) {
                                    Emit_Raise_Constraint_Error(cg, "aggregate index check");
                                    uint32_t cont = cg->label_id++;
                                    Emit_Label_Here(cg, cont);
                                }
                            } else {
                                /* At least one expression bound: runtime check */
                                uint32_t lo_s = rng_lo_ssa ? rng_lo_ssa
                                              : Emit_Static_Int(cg, rng_low, bt);
                                uint32_t hi_s = rng_hi_ssa ? rng_hi_ssa
                                              : Emit_Static_Int(cg, rng_high, bt);
                                /* Is range non-null? (lo <= hi) */
                                uint32_t null_cmp = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = icmp sgt %s %%t%u, %%t%u"
                                         "  ; null range?\n",
                                     null_cmp, bt, lo_s, hi_s);
                                uint32_t skip_lbl = cg->label_id++;
                                uint32_t chk_lbl  = cg->label_id++;
                                Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n",
                                     null_cmp, skip_lbl, chk_lbl);
                                cg->block_terminated = true;
                                Emit_Label_Here(cg, chk_lbl);
                                Emit_Range_Check_With_Raise(cg, lo_s,
                                    (int64_t)idx_sub_lo, (int64_t)idx_sub_hi,
                                    bt, "aggregate index subtype check");
                                Emit_Range_Check_With_Raise(cg, hi_s,
                                    (int64_t)idx_sub_lo, (int64_t)idx_sub_hi,
                                    bt, "aggregate index subtype check");
                                Emit(cg, "  br label %%L%u\n", skip_lbl);
                                cg->block_terminated = true;
                                Emit_Label_Here(cg, skip_lbl);
                            }
                        }

                        /* Detect multidim inner aggregates with expression
                         * bounds that must be evaluated exactly once. */
                        bool inline_multidim = false;
                        if (multidim and item->association.expression->kind == NK_AGGREGATE) {
                            Syntax_Node *ia = item->association.expression;
                            for (uint32_t qi = 0; qi < ia->aggregate.items.count; qi++) {
                                Syntax_Node *qit = ia->aggregate.items.items[qi];
                                if (qit->kind != NK_ASSOCIATION) continue;
                                for (uint32_t qc = 0; qc < qit->association.choices.count; qc++) {
                                    Syntax_Node *qch = qit->association.choices.items[qc];
                                    if (qch->kind == NK_RANGE) {
                                        if (qch->range.low->kind != NK_INTEGER)
                                            inline_multidim = true;
                                        if (qch->range.high->kind != NK_INTEGER)
                                            inline_multidim = true;
                                    }
                                }
                            }
                        }
                        if (inline_multidim) {
                            /* Multidimensional aggregate with expression bounds:
                             * inline the inner aggregate.  RM 4.3.2(6): for
                             * (F..G => (H..I => J)), the inner bounds H,I are
                             * evaluated once; the value J is evaluated once per
                             * component (outer × inner, zero if null). */
                            Syntax_Node *inner_agg = item->association.expression;
                            int128_t inner_low  = Type_Bound_Value(dim_lo[1]);
                            int128_t inner_high = Type_Bound_Value(dim_hi[1]);
                            int128_t inner_count = (inner_high >= inner_low)
                                                 ? (inner_high - inner_low + 1) : 0;

                            /* Evaluate inner choice bounds once for side effects,
                             * even when the outer range is null (RM 4.3.2(6)).
                             * Also check inner bounds against dim 1 index subtype
                             * and capture SSA values for fat pointer. */
                            int128_t inner_idx_sub_lo = inner_low, inner_idx_sub_hi = inner_high;
                            if (agg_type->base_type &&
                                Type_Is_Array_Like(agg_type->base_type) &&
                                !agg_type->base_type->array.is_constrained &&
                                agg_type->base_type->array.index_count > 1 &&
                                agg_type->base_type->array.indices &&
                                agg_type->base_type->array.indices[1].index_type) {
                                inner_idx_sub_lo = Type_Bound_Value(
                                    agg_type->base_type->array.indices[1].index_type->low_bound);
                                inner_idx_sub_hi = Type_Bound_Value(
                                    agg_type->base_type->array.indices[1].index_type->high_bound);
                            } else if (!agg_type->array.is_constrained &&
                                       agg_type->array.index_count > 1 &&
                                       agg_type->array.indices &&
                                       agg_type->array.indices[1].index_type) {
                                inner_idx_sub_lo = Type_Bound_Value(
                                    agg_type->array.indices[1].index_type->low_bound);
                                inner_idx_sub_hi = Type_Bound_Value(
                                    agg_type->array.indices[1].index_type->high_bound);
                            }
                            Syntax_Node *inner_val_expr = NULL;
                            uint32_t inner_lo_ssa = 0, inner_hi_ssa = 0;
                            for (uint32_t qi = 0; qi < inner_agg->aggregate.items.count; qi++) {
                                Syntax_Node *qi_item = inner_agg->aggregate.items.items[qi];
                                if (qi_item->kind != NK_ASSOCIATION) continue;
                                if (not inner_val_expr)
                                    inner_val_expr = qi_item->association.expression;
                                for (uint32_t qc = 0; qc < qi_item->association.choices.count; qc++) {
                                    Syntax_Node *qch = qi_item->association.choices.items[qc];
                                    if (qch->kind == NK_RANGE) {
                                        uint32_t ilo_s = 0, ihi_s = 0;
                                        bool ilo_expr = (qch->range.low->kind != NK_INTEGER);
                                        bool ihi_expr = (qch->range.high->kind != NK_INTEGER);
                                        if (ilo_expr) {
                                            uint32_t ev = Generate_Expression(cg, qch->range.low);
                                            const char *bt = Array_Bound_Llvm_Type(agg_type);
                                            const char *st = Expression_Llvm_Type(cg, qch->range.low);
                                            ilo_s = (strcmp(st, bt) != 0)
                                                ? Emit_Convert(cg, ev, st, bt) : ev;
                                            if (!inner_lo_ssa) inner_lo_ssa = ilo_s;
                                            if (!agg_d1_lo_ssa) agg_d1_lo_ssa = ilo_s;
                                        }
                                        if (ihi_expr) {
                                            uint32_t ev = Generate_Expression(cg, qch->range.high);
                                            const char *bt = Array_Bound_Llvm_Type(agg_type);
                                            const char *st = Expression_Llvm_Type(cg, qch->range.high);
                                            ihi_s = (strcmp(st, bt) != 0)
                                                ? Emit_Convert(cg, ev, st, bt) : ev;
                                            if (!inner_hi_ssa) inner_hi_ssa = ihi_s;
                                            if (!agg_d1_hi_ssa) agg_d1_hi_ssa = ihi_s;
                                        }
                                        /* RM 4.3.2(3): inner dim non-null range bounds
                                         * must belong to dim 1 index subtype. */
                                        {
                                            const char *bt = Array_Bound_Llvm_Type(agg_type);
                                            if (!ilo_expr && !ihi_expr) {
                                                int128_t rlo = (int128_t)qch->range.low->integer_lit.value;
                                                int128_t rhi = (int128_t)qch->range.high->integer_lit.value;
                                                if (rlo <= rhi &&
                                                    (rlo < inner_idx_sub_lo || rlo > inner_idx_sub_hi ||
                                                     rhi < inner_idx_sub_lo || rhi > inner_idx_sub_hi)) {
                                                    Emit_Raise_Constraint_Error(cg, "aggregate inner index check");
                                                    uint32_t cont = cg->label_id++;
                                                    Emit_Label_Here(cg, cont);
                                                }
                                            } else {
                                                uint32_t lo_v = ilo_s ? ilo_s
                                                    : Emit_Static_Int(cg, (int128_t)qch->range.low->integer_lit.value, bt);
                                                uint32_t hi_v = ihi_s ? ihi_s
                                                    : Emit_Static_Int(cg, (int128_t)qch->range.high->integer_lit.value, bt);
                                                uint32_t nc = Emit_Temp(cg);
                                                Emit(cg, "  %%t%u = icmp sgt %s %%t%u, %%t%u"
                                                         "  ; inner null?\n", nc, bt, lo_v, hi_v);
                                                uint32_t sk = cg->label_id++;
                                                uint32_t ck = cg->label_id++;
                                                Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n",
                                                     nc, sk, ck);
                                                cg->block_terminated = true;
                                                Emit_Label_Here(cg, ck);
                                                Emit_Range_Check_With_Raise(cg, lo_v,
                                                    (int64_t)inner_idx_sub_lo, (int64_t)inner_idx_sub_hi,
                                                    bt, "aggregate inner index subtype check");
                                                Emit_Range_Check_With_Raise(cg, hi_v,
                                                    (int64_t)inner_idx_sub_lo, (int64_t)inner_idx_sub_hi,
                                                    bt, "aggregate inner index subtype check");
                                                Emit(cg, "  br label %%L%u\n", sk);
                                                cg->block_terminated = true;
                                                Emit_Label_Here(cg, sk);
                                            }
                                        }
                                    }
                                }
                            }

                            /* Nested loop: for each (row, col) cell, evaluate J
                             * and store at the flat offset in row-major order.
                             * When outer choice bounds are dynamic, fall back to
                             * type-count iteration (positions 0..count-1) since
                             * we can't iterate a C loop over runtime values. */
                            if (inner_val_expr) {
                                int128_t eff_lo = rng_low, eff_hi = rng_high;
                                if (must_eval_low or must_eval_high) {
                                    eff_lo = low;
                                    eff_hi = high;  /* preserves null range (high<low → 0 iter) */
                                }
                                for (int128_t oi = eff_lo; oi <= eff_hi; oi++) {
                                    int128_t oai = oi - low;
                                    if (oai < 0 or oai >= count) continue;
                                    for (int128_t ci = inner_low; ci <= inner_high; ci++) {
                                        int128_t flat = oai * inner_count + (ci - inner_low);
                                        uint32_t val = Generate_Expression(cg, inner_val_expr);
                                        const char *st = Expression_Llvm_Type(cg, inner_val_expr);
                                        val = Emit_Convert(cg, val, st, elem_type);
                                        uint32_t ptr = Emit_Temp(cg);
                                        Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, "
                                                 "i64 %s  ; multidim [%s,%s]\n",
                                             ptr, elem_type, base, I128_Decimal(flat),
                                             I128_Decimal(oi), I128_Decimal(ci));
                                        Emit(cg, "  store %s %%t%u, ptr %%t%u\n",
                                             elem_type, val, ptr);
                                    }
                                    initialized[oai] = true;
                                }
                            }
                        } else {
                            /* For multidim with static inner bounds, check inner
                             * aggregate choices against dim 1 index subtype. */
                            if (multidim and item->association.expression->kind == NK_AGGREGATE) {
                                int128_t isl = Type_Bound_Value(dim_lo[1]);
                                int128_t ish = Type_Bound_Value(dim_hi[1]);
                                if (agg_type->base_type &&
                                    Type_Is_Array_Like(agg_type->base_type) &&
                                    !agg_type->base_type->array.is_constrained &&
                                    agg_type->base_type->array.index_count > 1 &&
                                    agg_type->base_type->array.indices &&
                                    agg_type->base_type->array.indices[1].index_type) {
                                    isl = Type_Bound_Value(agg_type->base_type->array.indices[1].index_type->low_bound);
                                    ish = Type_Bound_Value(agg_type->base_type->array.indices[1].index_type->high_bound);
                                } else if (!agg_type->array.is_constrained &&
                                           agg_type->array.index_count > 1 &&
                                           agg_type->array.indices &&
                                           agg_type->array.indices[1].index_type) {
                                    isl = Type_Bound_Value(agg_type->array.indices[1].index_type->low_bound);
                                    ish = Type_Bound_Value(agg_type->array.indices[1].index_type->high_bound);
                                }
                                Syntax_Node *ia = item->association.expression;
                                for (uint32_t qi = 0; qi < ia->aggregate.items.count; qi++) {
                                    Syntax_Node *qit = ia->aggregate.items.items[qi];
                                    if (qit->kind != NK_ASSOCIATION) continue;
                                    for (uint32_t qc = 0; qc < qit->association.choices.count; qc++) {
                                        Syntax_Node *qch = qit->association.choices.items[qc];
                                        if (Is_Others_Choice(qch)) continue;
                                        if (qch->kind == NK_RANGE &&
                                            qch->range.low->kind == NK_INTEGER &&
                                            qch->range.high->kind == NK_INTEGER) {
                                            int128_t rlo = (int128_t)qch->range.low->integer_lit.value;
                                            int128_t rhi = (int128_t)qch->range.high->integer_lit.value;
                                            if (rlo <= rhi &&
                                                (rlo < isl || rlo > ish || rhi < isl || rhi > ish)) {
                                                Emit_Raise_Constraint_Error(cg, "aggregate inner index check");
                                                uint32_t cont = cg->label_id++;
                                                Emit_Label_Here(cg, cont);
                                            }
                                        } else if (qch->kind == NK_INTEGER) {
                                            int128_t v = (int128_t)qch->integer_lit.value;
                                            if (v < isl || v > ish) {
                                                Emit_Raise_Constraint_Error(cg, "aggregate inner index check");
                                                uint32_t cont = cg->label_id++;
                                                Emit_Label_Here(cg, cont);
                                            }
                                        }
                                    }
                                }
                            }
                            /* Non-multidim (or non-aggregate inner expression):
                             * evaluate expression per component (RM 4.3.2(6)). */
                            for (int128_t idx = rng_low; idx <= rng_high; idx++) {
                                int128_t arr_idx = idx - low;
                                if (arr_idx >= 0 and arr_idx < count) {
                                    uint32_t val = Generate_Expression(cg, item->association.expression);
                                    if (elem_is_composite and
                                        Expression_Produces_Fat_Pointer(item->association.expression,
                                            item->association.expression->type))
                                        val = Emit_Fat_Pointer_Data(cg, val,
                                                  Array_Bound_Llvm_Type(agg_type));
                                    if (not elem_is_composite) {
                                        const char *src_type = Expression_Llvm_Type(cg, item->association.expression);
                                        if (elem_ti and elem_ti->kind == TYPE_FIXED and Is_Float_Type(src_type)) {
                                            double small = elem_ti->fixed.small;
                                            if (small <= 0) small = elem_ti->fixed.delta > 0 ? elem_ti->fixed.delta : 1.0;
                                            uint64_t sb; memcpy(&sb, &small, sizeof(sb));
                                            uint32_t st = Emit_Temp(cg);
                                            Emit(cg, "  %%t%u = fadd double 0.0, 0x%016llX  ; small\n", st, (unsigned long long)sb);
                                            uint32_t dv = Emit_Temp(cg);
                                            Emit(cg, "  %%t%u = fdiv %s %%t%u, %%t%u  ; agg range/small\n", dv, src_type, val, st);
                                            val = dv;
                                        }
                                        val = Emit_Convert(cg, val, src_type, elem_type);
                                    }
                                    uint32_t ptr = Emit_Temp(cg);
                                    if (elem_is_composite) {
                                        Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %s\n",
                                             ptr, base, I128_Decimal(arr_idx * (int128_t)elem_size));
                                        Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %u, i1 false)\n",
                                             ptr, val, elem_size);
                                    } else {
                                        Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, i64 %s\n",
                                             ptr, elem_type, base, I128_Decimal(arr_idx));
                                        Emit(cg, "  store %s %%t%u, ptr %%t%u\n", elem_type, val, ptr);
                                    }
                                    initialized[arr_idx] = true;
                                }
                            }
                        }
                    } else if (choice->kind == NK_IDENTIFIER and choice->symbol and
                               choice->symbol->kind == SYMBOL_TYPE and choice->symbol->type) {
                        /* Type name as choice: T => val means T'FIRST..T'LAST => val
                         * (RM 4.3.2(4)). Re-evaluate expression per component. */
                        Type_Info *ct = choice->symbol->type;
                        int128_t rng_low = Type_Bound_Value(ct->low_bound);
                        int128_t rng_high = Type_Bound_Value(ct->high_bound);

                        for (int128_t idx = rng_low; idx <= rng_high; idx++) {
                            int128_t arr_idx = idx - low;
                            if (arr_idx >= 0 and arr_idx < count) {
                                uint32_t val = Generate_Expression(cg, item->association.expression);
                                if (elem_is_composite and
                                    Expression_Produces_Fat_Pointer(item->association.expression,
                                        item->association.expression->type))
                                    val = Emit_Fat_Pointer_Data(cg, val,
                                              Array_Bound_Llvm_Type(agg_type));
                                if (not elem_is_composite) {
                                    const char *src_type = Expression_Llvm_Type(cg, item->association.expression);
                                    val = Emit_Convert(cg, val, src_type, elem_type);
                                }
                                uint32_t ptr = Emit_Temp(cg);
                                if (elem_is_composite) {
                                    Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %s\n",
                                         ptr, base, I128_Decimal(arr_idx * (int128_t)elem_size));
                                    Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %u, i1 false)\n",
                                         ptr, val, elem_size);
                                } else {
                                    Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, i64 %s\n",
                                         ptr, elem_type, base, I128_Decimal(arr_idx));
                                    Emit(cg, "  store %s %%t%u, ptr %%t%u\n", elem_type, val, ptr);
                                }
                                initialized[arr_idx] = true;
                            }
                        }
                    } else if (choice->kind == NK_INTEGER) {
                        /* Single index: 3 => value */
                        /* RM 4.3.2(3): single index always non-null; must be
                         * in the index subtype. */
                        if (need_idx_subtype_check) {
                            int128_t cv = (int128_t)choice->integer_lit.value;
                            if (cv < idx_sub_lo or cv > idx_sub_hi) {
                                Emit_Raise_Constraint_Error(cg, "aggregate index check");
                                uint32_t cont = cg->label_id++;
                                Emit_Label_Here(cg, cont);
                            }
                        }
                        int128_t idx = (int128_t)choice->integer_lit.value - low;
                        if (idx >= 0 and idx < count) {
                            uint32_t val = Generate_Expression(cg, item->association.expression);
                            if (elem_is_composite and
                                Expression_Produces_Fat_Pointer(item->association.expression,
                                    item->association.expression->type))
                                val = Emit_Fat_Pointer_Data(cg, val,
                                          Array_Bound_Llvm_Type(agg_type));
                            uint32_t ptr = Emit_Temp(cg);
                            if (elem_is_composite) {
                                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %s\n",
                                     ptr, base, I128_Decimal(idx * (int128_t)elem_size));
                                Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %u, i1 false)\n",
                                     ptr, val, elem_size);
                            } else {
                                const char *src_type = Expression_Llvm_Type(cg, item->association.expression);
                                /* Float>fixed-point aggregate element: divide by SMALL (RM 4.6) */
                                if (elem_ti and elem_ti->kind == TYPE_FIXED and Is_Float_Type(src_type)) {
                                    double small = elem_ti->fixed.small;
                                    if (small <= 0) small = elem_ti->fixed.delta > 0 ? elem_ti->fixed.delta : 1.0;
                                    uint64_t sb; memcpy(&sb, &small, sizeof(sb));
                                    uint32_t st = Emit_Temp(cg);
                                    Emit(cg, "  %%t%u = fadd double 0.0, 0x%016llX  ; small\n", st, (unsigned long long)sb);
                                    uint32_t dv = Emit_Temp(cg);
                                    Emit(cg, "  %%t%u = fdiv %s %%t%u, %%t%u  ; agg idx/small\n", dv, src_type, val, st);
                                    val = dv;
                                }
                                val = Emit_Convert(cg, val, src_type, elem_type);
                                Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, i64 %s\n",
                                     ptr, elem_type, base, I128_Decimal(idx));
                                Emit(cg, "  store %s %%t%u, ptr %%t%u\n", elem_type, val, ptr);
                            }
                            initialized[idx] = true;
                        }
                    }
                }
            } else {
                /* Positional association */
                if (positional_idx < (uint32_t)count) {
                    uint32_t val = Generate_Expression(cg, item);
                    if (elem_is_composite and
                        Expression_Produces_Fat_Pointer(item, item->type))
                        val = Emit_Fat_Pointer_Data(cg, val,
                                  Array_Bound_Llvm_Type(agg_type));
                    else if (elem_is_composite and multidim and
                             item->kind == NK_AGGREGATE and item->type and
                             Type_Has_Dynamic_Bounds(item->type)) {
                        uint32_t loaded = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = load " FAT_PTR_TYPE ", ptr %%t%u\n",
                             loaded, val);
                        val = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = extractvalue " FAT_PTR_TYPE
                             " %%t%u, 0\n", val, loaded);
                    }
                    uint32_t ptr = Emit_Temp(cg);
                    if (elem_is_composite) {
                        Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %s\n",
                             ptr, base, I128_Decimal((int128_t)positional_idx * (int128_t)elem_size));
                        Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %u, i1 false)\n",
                             ptr, val, elem_size);
                    } else {
                        const char *src_type = Expression_Llvm_Type(cg, item);
                        /* Float>fixed-point aggregate element: divide by SMALL (RM 4.6) */
                        if (elem_ti and elem_ti->kind == TYPE_FIXED and Is_Float_Type(src_type)) {
                            double small = elem_ti->fixed.small;
                            if (small <= 0) small = elem_ti->fixed.delta > 0 ? elem_ti->fixed.delta : 1.0;
                            uint64_t sb; memcpy(&sb, &small, sizeof(sb));
                            uint32_t st = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = fadd double 0.0, 0x%016llX  ; small\n", st, (unsigned long long)sb);
                            uint32_t dv = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = fdiv %s %%t%u, %%t%u  ; agg elem/small\n", dv, src_type, val, st);
                            val = dv;
                        }
                        val = Emit_Convert(cg, val, src_type, elem_type);
                        /* RM 4.3.2: check element against component subtype constraint */
                        if (elem_ti && Type_Is_Scalar(elem_ti))
                            val = Emit_Constraint_Check_With_Type(cg, val, elem_ti,
                                item->type, elem_type);
                        Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, i64 %u\n",
                             ptr, elem_type, base, positional_idx);
                        Emit(cg, "  store %s %%t%u, ptr %%t%u\n", elem_type, val, ptr);
                    }
                    initialized[positional_idx] = true;
                    positional_idx++;
                }
            }
        }

        /* Third pass: fill uninitialized with "others" value.
         * RM 4.3.3(5): the expression is evaluated once per component,
         * so allocators produce distinct objects for each element. */
        if (has_others and others_item_expr) {
            for (int128_t idx = 0; idx < count; idx++) {
                if (not initialized[idx]) {
                    /* Re-evaluate for each component (allocators, functions) */
                    others_val = Generate_Expression(cg, others_item_expr);
                    if (elem_is_composite and
                        Expression_Produces_Fat_Pointer(others_item_expr,
                            others_item_expr->type))
                        others_val = Emit_Fat_Pointer_Data(cg, others_val,
                                         Array_Bound_Llvm_Type(agg_type));
                    else if (elem_is_composite and multidim and
                             others_item_expr->kind == NK_AGGREGATE and
                             others_item_expr->type and
                             Type_Has_Dynamic_Bounds(others_item_expr->type)) {
                        /* Dynamic inner aggregate: fat ptr alloca → data ptr */
                        uint32_t loaded = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = load " FAT_PTR_TYPE ", ptr %%t%u\n",
                             loaded, others_val);
                        others_val = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = extractvalue " FAT_PTR_TYPE
                             " %%t%u, 0\n", others_val, loaded);
                    }
                    if (not elem_is_composite) {
                        const char *src_type = Expression_Llvm_Type(cg, others_item_expr);
                        if (elem_ti and elem_ti->kind == TYPE_FIXED and Is_Float_Type(src_type)) {
                            double small = elem_ti->fixed.small;
                            if (small <= 0) small = elem_ti->fixed.delta > 0 ? elem_ti->fixed.delta : 1.0;
                            uint64_t sb; memcpy(&sb, &small, sizeof(sb));
                            uint32_t st = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = fadd double 0.0, 0x%016llX  ; small\n", st, (unsigned long long)sb);
                            uint32_t dv = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = fdiv %s %%t%u, %%t%u  ; agg others/small\n", dv, src_type, others_val, st);
                            others_val = dv;
                        }
                        others_val = Emit_Convert(cg, others_val, src_type, elem_type);
                    }
                    uint32_t ptr = Emit_Temp(cg);
                    if (elem_is_composite) {
                        Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %s\n",
                             ptr, base, I128_Decimal(idx * (int128_t)elem_size));
                        Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %u, i1 false)\n",
                             ptr, others_val, elem_size);
                    } else {
                        Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, i64 %s\n",
                             ptr, elem_type, base, I128_Decimal(idx));
                        Emit(cg, "  store %s %%t%u, ptr %%t%u\n", elem_type, others_val, ptr);
                    }
                }
            }
        }

        /* If the array type is unconstrained, wrap in a fat pointer so that
         * the caller receives { ptr, ptr } (data + bounds).  Constrained
         * arrays just return the raw data pointer.
         * Multi-dimensional arrays store bounds for ALL dimensions. */
        if (not agg_type->array.is_constrained) {
            const char *agg_bt = Array_Bound_Llvm_Type(agg_type);
            if (multidim) {
                uint32_t mlo[8], mhi[8];
                for (uint32_t d = 0; d < agg_ndims; d++) {
                    /* Dimension 0 uses the (possibly overridden) choice-based
                     * low/high; other dimensions use type bounds. */
                    int128_t dlo = (d == 0) ? low  : Type_Bound_Value(dim_lo[d]);
                    int128_t dhi = (d == 0) ? high : Type_Bound_Value(dim_hi[d]);
                    if (d == 0 and agg_lo_ssa != 0) {
                        mlo[d] = agg_lo_ssa;
                    } else if (d == 1 and agg_d1_lo_ssa != 0) {
                        mlo[d] = agg_d1_lo_ssa;
                    } else {
                        mlo[d] = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = add %s 0, %s  ; dim%u lo\n",
                             mlo[d], agg_bt, I128_Decimal(dlo), d);
                    }
                    Temp_Set_Type(cg, mlo[d], agg_bt);
                    if (d == 0 and agg_hi_ssa != 0) {
                        mhi[d] = agg_hi_ssa;
                    } else if (d == 1 and agg_d1_hi_ssa != 0) {
                        mhi[d] = agg_d1_hi_ssa;
                    } else {
                        mhi[d] = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = add %s 0, %s  ; dim%u hi\n",
                             mhi[d], agg_bt, I128_Decimal(dhi), d);
                    }
                    Temp_Set_Type(cg, mhi[d], agg_bt);
                }
                uint32_t fat_val = Emit_Fat_Pointer_MultiDim(cg, base, mlo, mhi, agg_ndims, agg_bt);
                uint32_t fat_ptr = Emit_Temp(cg);
                Emit(cg, "  %%t%u = alloca " FAT_PTR_TYPE "  ; multidim array fat ptr\n", fat_ptr);
                Emit(cg, "  store " FAT_PTR_TYPE " %%t%u, ptr %%t%u\n", fat_val, fat_ptr);
                return fat_ptr;
            }
            /* Use SSA-evaluated choice bounds if available (expression
             * bounds like IDENT_INT(6)), otherwise use the compile-time
             * low/high already overridden from static choice values. */
            uint32_t low_temp;
            if (agg_lo_ssa != 0) {
                low_temp = agg_lo_ssa;
            } else {
                low_temp = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s 0, %s  ; static agg low\n",
                     low_temp, agg_bt, I128_Decimal(low));
            }
            Temp_Set_Type(cg, low_temp, agg_bt);
            uint32_t high_temp;
            if (agg_hi_ssa != 0) {
                high_temp = agg_hi_ssa;
            } else {
                high_temp = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s 0, %s  ; static agg high\n",
                     high_temp, agg_bt, I128_Decimal(high));
            }
            Temp_Set_Type(cg, high_temp, agg_bt);
            uint32_t fat_ptr = Emit_Temp(cg);
            Emit(cg, "  %%t%u = alloca " FAT_PTR_TYPE "  ; static array fat ptr\n", fat_ptr);
            Emit_Store_Fat_Pointer_Fields_To_Temp(cg, base, low_temp, high_temp, fat_ptr, agg_bt);
            return fat_ptr;
        }

        return base;
    }

    if (Type_Is_Record(agg_type)) {
        /* Record aggregate - allocate [N x i8] and fill fields by offset */
        uint32_t base = Emit_Temp(cg);
        uint32_t record_size = agg_type->size > 0 ? agg_type->size : 8;

        /* Adjust record_size for discriminant-dependent array/string components
         * whose sizes are not included in the type's static size (RM 3.7.1). */
        for (uint32_t ci = 0; ci < agg_type->record.component_count; ci++) {
            Component_Info *comp_ci = &agg_type->record.components[ci];
            Type_Info *cti = comp_ci->component_type;
            if (not cti or not Type_Is_Array_Like(cti)) continue;
            for (uint32_t xi = 0; xi < cti->array.index_count; xi++) {
                Type_Bound *lo = &cti->array.indices[xi].low_bound;
                Type_Bound *hi = &cti->array.indices[xi].high_bound;
                if (hi->kind == BOUND_EXPR and hi->expr and hi->expr->symbol) {
                    Symbol *disc = hi->expr->symbol;
                    Type_Info *disc_ty = disc->type;
                    if (disc_ty and disc_ty->high_bound.kind == BOUND_INTEGER) {
                        int64_t max_hi = disc_ty->high_bound.int_value;
                        int64_t lo_val = (lo->kind == BOUND_INTEGER) ? lo->int_value : 0;
                        int64_t max_extent = max_hi - lo_val + 1;
                        if (max_extent < 0) max_extent = 0;
                        uint32_t elem_sz = (cti->array.element_type and
                            cti->array.element_type->size > 0) ?
                            cti->array.element_type->size : 1;
                        uint32_t needed = comp_ci->byte_offset +
                            (uint32_t)(max_extent * elem_sz);
                        if (needed > record_size) record_size = needed;
                    }
                }
            }
        }

        Emit(cg, "  %%t%u = alloca [%u x i8]  ; record aggregate\n", base, record_size);

        /* Pre-allocate discriminant symbols that may be referenced by
         * dependent array bounds (RM 3.7.1).  Scan array component bounds
         * for BOUND_EXPR references to discriminant symbols and emit allocas
         * for them.  Values will be stored during the component passes below. */
        Symbol *disc_alloc[16];
        uint32_t disc_alloc_count = 0;
        for (uint32_t ci = 0; ci < agg_type->record.component_count; ci++) {
            Component_Info *comp_ci = &agg_type->record.components[ci];
            Type_Info *cti = comp_ci->component_type;
            if (not cti or not Type_Is_Array_Like(cti)) continue;
            for (uint32_t xi = 0; xi < cti->array.index_count; xi++) {
                Type_Bound *bounds[2] = { &cti->array.indices[xi].low_bound,
                                          &cti->array.indices[xi].high_bound };
                for (int bi = 0; bi < 2; bi++) {
                    if (bounds[bi]->kind == BOUND_EXPR and bounds[bi]->expr and
                        bounds[bi]->expr->symbol) {
                        Symbol *disc_sym = bounds[bi]->expr->symbol;
                        if (disc_sym->alloca_emitted) continue;
                        const char *disc_type = Type_To_Llvm(disc_sym->type);
                        if (not disc_type or disc_type[0] == '\0') disc_type = Integer_Arith_Type(cg);
                        Emit(cg, "  %%");
                        Emit_Symbol_Name(cg, disc_sym);
                        Emit(cg, " = alloca %s  ; disc for aggregate bounds\n", disc_type);
                        disc_sym->alloca_emitted = true;
                        if (disc_alloc_count < 16) disc_alloc[disc_alloc_count++] = disc_sym;
                    }
                }
            }
        }

        /* Track initialized components for others clause */
        uint32_t comp_count = agg_type->record.component_count;
        bool *initialized = Arena_Allocate(comp_count * sizeof(bool));
        for (uint32_t i = 0; i < comp_count; i++) initialized[i] = false;

        /* Default value for "others" clause */
        Syntax_Node *others_expr = NULL;
        bool has_others = false;

        /* First pass: find "others" clause (defer generation to third pass) */
        for (uint32_t i = 0; i < node->aggregate.items.count; i++) {
            Syntax_Node *item = node->aggregate.items.items[i];
            if (item->kind == NK_ASSOCIATION and item->association.choices.count > 0) {
                if (Is_Others_Choice(item->association.choices.items[0])) {
                    others_expr = item->association.expression;
                    has_others = true;
                    break;
                }
            }
        }

        /* Second pass: initialize fields */
        uint32_t positional_idx = 0;
        for (uint32_t i = 0; i < node->aggregate.items.count; i++) {
            Syntax_Node *item = node->aggregate.items.items[i];

            if (item->kind == NK_ASSOCIATION) {
                /* Named association: field_name => value */
                for (uint32_t c = 0; c < item->association.choices.count; c++) {
                    Syntax_Node *choice = item->association.choices.items[c];

                    if (Is_Others_Choice(choice)) {
                        continue;  /* Handle in third pass */
                    }

                    if (choice->kind == NK_IDENTIFIER) {
                        int32_t comp_idx = Find_Record_Component(agg_type, choice->string_val.text);
                        if (comp_idx >= 0) {
                            Component_Info *comp = &agg_type->record.components[comp_idx];
                            Type_Info *comp_ti = comp->component_type;
                            uint32_t val = Generate_Expression(cg, item->association.expression);

                            uint32_t ptr = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %u\n",
                                 ptr, base, comp->byte_offset);

                            {
                                const char *src_type = Expression_Llvm_Type(cg, item->association.expression);
                                const char *comp_type = Type_To_Llvm(comp_ti);
                                bool src_is_ptr = (src_type and strcmp(src_type, "ptr") == 0);
                                bool src_is_fat = (src_type and strstr(src_type, "{ ptr, ptr }") != NULL);
                                if (comp_ti and src_is_fat and
                                    (Type_Is_String(comp_ti) or Type_Is_Array_Like(comp_ti))) {
                                    Emit_Fat_To_Array_Memcpy(cg, val, ptr, comp_ti);
                                } else if (comp_ti and src_is_ptr and
                                    (Type_Is_Record(comp_ti) or Type_Is_Constrained_Array(comp_ti))) {
                                    /* Composite component: use memcpy */
                                    Syntax_Node *src_expr = item->association.expression;
                                    uint32_t comp_size = comp_ti->size;
                                    if (comp_size == 0 and Type_Is_Array_Like(comp_ti)
                                        and comp_ti->array.element_type) {
                                        uint32_t esz = comp_ti->array.element_type->size;
                                        if (esz == 0) esz = 1;
                                        if (src_expr and src_expr->kind == NK_AGGREGATE) {
                                            comp_size = src_expr->aggregate.items.count * esz;
                                        } else if (src_expr and src_expr->type
                                                   and src_expr->type->size > 0) {
                                            comp_size = src_expr->type->size;
                                        }
                                    }
                                    if (comp_size == 0) comp_size = 8;
                                    Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %u, i1 false)\n",
                                         ptr, val, comp_size);
                                } else {
                                    val = Emit_Convert(cg, val, src_type, comp_type);
                                    /* RM 4.3.1: check component value against subtype constraint */
                                    if (comp_ti and Type_Is_Scalar(comp_ti) and not comp->is_discriminant)
                                        val = Emit_Constraint_Check_With_Type(cg, val, comp_ti,
                                            item->association.expression->type, comp_type);
                                    Emit(cg, "  store %s %%t%u, ptr %%t%u\n", comp_type, val, ptr);
                                }
                                /* Also store discriminant value into pre-allocated symbol */
                                if (comp->is_discriminant) {
                                    for (uint32_t da = 0; da < disc_alloc_count; da++) {
                                        if (Slice_Equal_Ignore_Case(disc_alloc[da]->name, comp->name)) {
                                            Emit(cg, "  store %s %%t%u, ptr %%", comp_type, val);
                                            Emit_Symbol_Name(cg, disc_alloc[da]);
                                            Emit(cg, "\n");
                                            break;
                                        }
                                    }
                                }
                            }
                            initialized[comp_idx] = true;
                        }
                    }
                }
            } else {
                /* Positional: initialize component by position */
                if (positional_idx < comp_count) {
                    Component_Info *comp = &agg_type->record.components[positional_idx];
                    Type_Info *comp_ti = comp->component_type;
                    uint32_t val = Generate_Expression(cg, item);

                    uint32_t ptr = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %u\n",
                         ptr, base, comp->byte_offset);

                    {
                        const char *src_type = Expression_Llvm_Type(cg, item);
                        const char *comp_type = Type_To_Llvm(comp_ti);
                        bool src_is_ptr = (src_type and strcmp(src_type, "ptr") == 0);
                        bool src_is_fat = (src_type and strstr(src_type, "{ ptr, ptr }") != NULL);
                        if (comp_ti and src_is_fat and
                            (Type_Is_String(comp_ti) or Type_Is_Array_Like(comp_ti))) {
                            /* Fat pointer source > constrained string/array component */
                            Emit_Fat_To_Array_Memcpy(cg, val, ptr, comp_ti);
                        } else if (comp_ti and src_is_ptr and
                            (Type_Is_Record(comp_ti) or Type_Is_Constrained_Array(comp_ti))) {
                            /* Composite component: use memcpy.  For discriminant-
                             * dependent array components (size==0), derive the actual
                             * byte count from the source expression or discriminant. */
                            uint32_t comp_size = comp_ti->size;
                            if (comp_size == 0 and Type_Is_Array_Like(comp_ti)
                                and comp_ti->array.element_type) {
                                uint32_t esz = comp_ti->array.element_type->size;
                                if (esz == 0) esz = 1;
                                if (item->kind == NK_AGGREGATE) {
                                    comp_size = item->aggregate.items.count * esz;
                                } else if (item->type and item->type->size > 0) {
                                    comp_size = item->type->size;
                                }
                            }
                            if (comp_size == 0) comp_size = 8;
                            Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %u, i1 false)\n",
                                 ptr, val, comp_size);
                        } else {
                            val = Emit_Convert(cg, val, src_type, comp_type);
                            /* RM 4.3.1: check component value against subtype constraint */
                            if (comp_ti and Type_Is_Scalar(comp_ti) and not comp->is_discriminant)
                                val = Emit_Constraint_Check_With_Type(cg, val, comp_ti,
                                    item->type, comp_type);
                            Emit(cg, "  store %s %%t%u, ptr %%t%u\n", comp_type, val, ptr);
                        }
                        /* Also store discriminant value into pre-allocated symbol */
                        if (comp->is_discriminant) {
                            for (uint32_t da = 0; da < disc_alloc_count; da++) {
                                if (Slice_Equal_Ignore_Case(disc_alloc[da]->name, comp->name)) {
                                    Emit(cg, "  store %s %%t%u, ptr %%", comp_type, val);
                                    Emit_Symbol_Name(cg, disc_alloc[da]);
                                    Emit(cg, "\n");
                                    break;
                                }
                            }
                        }
                    }
                    initialized[positional_idx] = true;
                    positional_idx++;
                }
            }
        }

        /* Determine selected variant for OTHERS filtering (RM 3.7.3).
         * In a variant record aggregate, OTHERS only applies to components
         * in the fixed part and the selected variant — not all variants. */
        int32_t selected_variant = -1;
        if (has_others and agg_type->record.has_discriminants and
            agg_type->record.variant_count > 0) {
            /* Method 1: infer from explicitly named variant components.
             * If C => 3 was named and C is in the WHEN TRUE variant, the
             * selected variant must be WHEN TRUE. */
            for (uint32_t ci = 0; ci < comp_count; ci++) {
                if (initialized[ci] and
                    agg_type->record.components[ci].variant_index >= 0) {
                    selected_variant =
                        agg_type->record.components[ci].variant_index;
                    break;
                }
            }
            /* Method 2: determine from discriminant value if no variant
             * component was explicitly named. */
            if (selected_variant < 0) {
                int64_t disc_val = 0;
                bool disc_known = false;
                /* Try the OTHERS expression as a discriminant value */
                if (others_expr and others_expr->symbol and
                    others_expr->symbol->kind == SYMBOL_LITERAL) {
                    disc_val = (int64_t)others_expr->symbol->frame_offset;
                    disc_known = true;
                } else if (others_expr and others_expr->kind == NK_INTEGER) {
                    disc_val = others_expr->integer_lit.value;
                    disc_known = true;
                }
                if (disc_known) {
                    for (uint32_t vi = 0; vi < agg_type->record.variant_count; vi++) {
                        if (agg_type->record.variants[vi].disc_value == disc_val) {
                            selected_variant = (int32_t)vi;
                            break;
                        }
                        if (agg_type->record.variants[vi].is_others)
                            selected_variant = (int32_t)vi;
                    }
                }
            }
        }

        /* Third pass: fill uninitialized with "others" value (uncommon for records) */
        if (has_others and others_expr) {
            for (uint32_t idx = 0; idx < comp_count; idx++) {
                if (not initialized[idx]) {
                    Component_Info *comp = &agg_type->record.components[idx];

                    /* Skip components from non-selected variants (RM 4.3.1(5)).
                     * D from WHEN FALSE must not be initialized when the
                     * discriminant selects WHEN TRUE. */
                    if (comp->variant_index >= 0 and selected_variant >= 0 and
                        comp->variant_index != selected_variant)
                        continue;
                    Type_Info *comp_ti = comp->component_type;

                    /* Set type context on the expression so nested aggregates resolve */
                    Type_Info *saved_type = others_expr->type;
                    if (not others_expr->type) others_expr->type = comp_ti;

                    uint32_t val = Generate_Expression(cg, others_expr);
                    uint32_t ptr = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %u\n",
                         ptr, base, comp->byte_offset);

                    if (comp_ti and (Type_Is_Record(comp_ti) or Type_Is_Array_Like(comp_ti))) {
                        /* Composite component: memcpy */
                        uint32_t comp_size = comp_ti->size > 0 ? comp_ti->size : 8;
                        Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %u, i1 false)\n",
                             ptr, val, comp_size);
                    } else {
                        const char *comp_type = Type_To_Llvm(comp_ti);
                        const char *src_type = Expression_Llvm_Type(cg, others_expr);
                        val = Emit_Convert(cg, val, src_type, comp_type);
                        /* RM 4.3.1: check component value against subtype constraint */
                        if (comp_ti and Type_Is_Scalar(comp_ti) and not comp->is_discriminant)
                            val = Emit_Constraint_Check_With_Type(cg, val, comp_ti,
                                others_expr->type, comp_type);
                        Emit(cg, "  store %s %%t%u, ptr %%t%u\n", comp_type, val, ptr);
                    }
                    others_expr->type = saved_type;
                }
            }
        }

        return base;
    }

    fprintf(stderr, "warning: Generate_Aggregate: unhandled aggregate type kind=%d at %s:%u\n",
            agg_type->kind,
            node->location.filename ? node->location.filename : "<unknown>",
            node->location.line);
    return 0;
}

static uint32_t Generate_Qualified(Code_Generator *cg, Syntax_Node *node) {
    /* Type'(expression) - generate expression and convert to target type if needed */
    uint32_t result = Generate_Expression(cg, node->qualified.expression);

    /* Get source and destination types */
    Type_Info *src_type = node->qualified.expression ? node->qualified.expression->type : NULL;
    Type_Info *dst_type = node->qualified.subtype_mark ? node->qualified.subtype_mark->type : NULL;

    if (not dst_type) return result;

    const char *src_llvm = Expression_Llvm_Type(cg, node->qualified.expression);

    /* RM 4.7: Qualified expression checks value against subtype constraint */
    if (Type_Is_Scalar(dst_type)) {
        Emit_Constraint_Check_With_Type(cg, result, dst_type, src_type, src_llvm);
    }

    if (src_type and src_type != dst_type) {
        const char *dst_llvm = Type_To_Llvm(dst_type);
        if (strcmp(src_llvm, dst_llvm) != 0) {
            result = Emit_Convert(cg, result, src_llvm, dst_llvm);
        }
    }
    /* no widening — value stays at native type width.
     * Callers use Emit_Convert at use sites. */
    return result;
}

static void Emit_Task_Function_Name(Code_Generator *cg, Symbol *task_sym, String_Slice fallback_name);

static uint32_t Generate_Allocator(Code_Generator *cg, Syntax_Node *node) {
    /* new T or new T'(value) */
    Type_Info *access_type = node->type;  /* The access type being created */

    if (not access_type) {
        uint32_t t = Emit_Temp(cg);
        Emit(cg, "  %%t%u = call ptr @malloc(i64 8)\n", t);
        Temp_Set_Type(cg, t, "ptr");
        return t;
    }

    /* Check if this access type needs fat pointer representation.
     * Access to unconstrained arrays/STRING always use fat pointers,
     * but also check if the LLVM type is a fat pointer (for constrained
     * subtypes of unconstrained access types). */
    Type_Info *designated = Type_Is_Access(access_type) ?
                            access_type->access.designated_type : NULL;
    bool is_fat_ptr = (not Type_Is_Constrained_Array(designated) and Type_Is_String(designated)) or
                      Type_Is_Unconstrained_Array(designated);

    /* Note: if the designated type is a constrained subtype of an unconstrained
     * array (e.g., ACCESS ARRAY3(1..5)), we do NOT use fat pointer representation.
     * The bounds are known from the subtype constraint — plain ptr suffices.
     * This matches Type_To_Llvm which returns "ptr" for access-to-constrained. */

    if (is_fat_ptr and node->allocator.expression) {
        /* Access to unconstrained array with initializer */
        Type_Info *init_type = node->allocator.expression->type;

        /* Check what LLVM type the expression actually returns.
         * Constrained array aggregates return ptr, unconstrained return fat pointer.
         * For qualified expressions, look at the inner expression. */
        Syntax_Node *inner_expr = node->allocator.expression;
        if (inner_expr->kind == NK_QUALIFIED and inner_expr->qualified.expression) {
            inner_expr = inner_expr->qualified.expression;
        }
        const char *expr_llvm_type = Expression_Llvm_Type(cg, inner_expr);
        bool init_returns_ptr = Llvm_Type_Is_Pointer(expr_llvm_type);

        /* Also check if the aggregate is constrained */
        Type_Info *agg_type = inner_expr->type;
        if (not agg_type and inner_expr->kind == NK_AGGREGATE) {
            agg_type = node->allocator.expression->type;  /* Use outer type */
        }
        bool init_is_constrained = Type_Is_Constrained_Array(agg_type);

        uint32_t init_val = Generate_Expression(cg, node->allocator.expression);

        uint32_t src_data, low_t, high_t, len_t;

        if (init_returns_ptr or init_is_constrained) {
            /* Constrained array initializer: returns ptr, not fat pointer.
             * Extract bounds from the type and use the ptr directly. */
            src_data = init_val;  /* Already a pointer to array data */

            /* Get bounds from the constrained type.
             * Bounds must be in the designated type's bt for Emit_Fat_Pointer_Dynamic.
             * len_t stays as i64 since it's used for malloc/memcpy. */
            const char *con_bt = Array_Bound_Llvm_Type(designated);
            if (init_type->array.index_count > 0 and
                init_type->array.indices[0].low_bound.kind == BOUND_INTEGER and
                init_type->array.indices[0].high_bound.kind == BOUND_INTEGER) {
                int64_t lo = init_type->array.indices[0].low_bound.int_value;
                int64_t hi = init_type->array.indices[0].high_bound.int_value;
                low_t = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s 0, %lld\n", low_t, con_bt, (long long)lo);
                high_t = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s 0, %lld\n", high_t, con_bt, (long long)hi);
                len_t = Emit_Temp(cg);
                int64_t length = hi - lo + 1;
                uint32_t elem_size = init_type->array.element_type ?
                                     init_type->array.element_type->size : 1;
                if (elem_size == 0) elem_size = 1;
                Emit(cg, "  %%t%u = add %s 0, %lld\n", len_t, Integer_Arith_Type(cg), (long long)(length * elem_size));
            } else {
                /* Dynamic bounds - use 1-based defaults */
                low_t = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s 0, 1\n", low_t, con_bt);
                high_t = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s 0, 1\n", high_t, con_bt);
                len_t = Emit_Temp(cg);
                uint32_t elem_size = init_type->array.element_type ?
                                     init_type->array.element_type->size : 1;
                if (elem_size == 0) elem_size = 8;
                Emit(cg, "  %%t%u = add %s 0, %u\n", len_t, Integer_Arith_Type(cg), elem_size);
            }
        } else {
            /* Unconstrained array or string: returns fat pointer VALUE */
            const char *alloc_bt = Array_Bound_Llvm_Type(designated);
            src_data = Emit_Fat_Pointer_Data(cg, init_val, alloc_bt);
            low_t = Emit_Fat_Pointer_Low(cg, init_val, alloc_bt);
            high_t = Emit_Fat_Pointer_High(cg, init_val, alloc_bt);
            len_t = Emit_Fat_Pointer_Length(cg, init_val, alloc_bt);
        }

        /* Widen len to i64 for system calls (malloc/memcpy) */
        const char *new_bt = Array_Bound_Llvm_Type(designated);
        uint32_t len_t_64 = len_t;
        if (init_returns_ptr or init_is_constrained) {
            /* len_t is in Integer_Arith_Type (i32) from constrained path */
            len_t_64 = Emit_Extend_To_I64(cg, len_t, Integer_Arith_Type(cg));
        } else {
            /* len_t is in new_bt (native bound type) from Emit_Fat_Pointer_Length */
            len_t_64 = Emit_Extend_To_I64(cg, len_t, new_bt);
        }

        /* Allocate heap space for array data */
        uint32_t heap_ptr = Emit_Temp(cg);
        Emit(cg, "  %%t%u = call ptr @malloc(i64 %%t%u)\n", heap_ptr, len_t_64);

        /* Copy data: memcpy(heap_ptr, src_data, length) */
        Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)\n",
             heap_ptr, src_data, len_t_64);

        /* Build result fat pointer with allocated data */
        return Emit_Fat_Pointer_Dynamic(cg, heap_ptr, low_t, high_t, new_bt);
    }

    /* Handle NEW T(bounds) without initializer - allocate unconstrained array */
    if (is_fat_ptr and not node->allocator.expression and node->allocator.subtype_mark) {
        /* Get bounds from the subtype mark's type */
        Type_Info *subtype = node->allocator.subtype_mark->type;
        if (subtype and subtype->kind == TYPE_ARRAY and subtype->array.index_count > 0) {
            /* Generate bound values in the designated type's bt */
            const char *new_bt = Array_Bound_Llvm_Type(designated);
            uint32_t low_t = Emit_Single_Bound(cg, &subtype->array.indices[0].low_bound, new_bt);
            uint32_t high_t = Emit_Single_Bound(cg, &subtype->array.indices[0].high_bound, new_bt);

            /* Calculate size: (high - low + 1) * elem_size */
            const char *alloc_iat = Integer_Arith_Type(cg);
            uint32_t elem_size = subtype->array.element_type ?
                                 subtype->array.element_type->size : 8;
            if (elem_size == 0) elem_size = 8;

            uint32_t high_conv = Emit_Convert(cg, high_t, new_bt, alloc_iat);
            uint32_t low_conv = Emit_Convert(cg, low_t, new_bt, alloc_iat);
            uint32_t len_plus1 = Emit_Length_From_Bounds(cg, low_conv, high_conv, alloc_iat);
            uint32_t byte_size = Emit_Temp(cg);
            Emit(cg, "  %%t%u = mul %s %%t%u, %u\n", byte_size, alloc_iat, len_plus1, elem_size);

            /* Allocate heap space — widen to i64 for malloc ABI */
            uint32_t byte_size_64 = Emit_Extend_To_I64(cg, byte_size, alloc_iat);
            uint32_t heap_ptr = Emit_Temp(cg);
            Emit(cg, "  %%t%u = call ptr @malloc(i64 %%t%u)\n", heap_ptr, byte_size_64);

            /* Return fat pointer with bounds */
            return Emit_Fat_Pointer_Dynamic(cg, heap_ptr, low_t, high_t, new_bt);
        }
    }

    /* Simple allocation (constrained types, scalar access, or no initializer).
     * For composite designated types (arrays, records), allocate the designated
     * type's storage and memcpy the initializer.  For scalar types, use store. */
    uint64_t alloc_size = 8;  /* Default: pointer-sized */
    bool designated_is_composite = false;
    if (designated) {
        if (Type_Is_Constrained_Array(designated)) {
            /* Constrained array: compute actual byte size from element count */
            int128_t count = Array_Element_Count(designated);
            uint32_t elem_sz = designated->array.element_type ?
                               designated->array.element_type->size : 1;
            if (elem_sz == 0) elem_sz = 8;
            alloc_size = (uint64_t)(count > 0 ? count : 1) * elem_sz;
            designated_is_composite = true;
        } else if (Type_Is_Record(designated)) {
            alloc_size = designated->size > 0 ? designated->size : 8;
            designated_is_composite = true;
        } else {
            alloc_size = designated->size > 0 ? designated->size : 8;
        }
    }
    uint32_t t = Emit_Temp(cg);
    Emit(cg, "  %%t%u = call ptr @malloc(i64 %llu)\n", t, (unsigned long long)alloc_size);

    /* If there's an initializer, copy it into the allocated memory */
    if (node->allocator.expression) {
        uint32_t val = Generate_Expression(cg, node->allocator.expression);
        if (designated_is_composite) {
            /* Composite type: memcpy from initializer to heap */
            Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %llu, i1 false)\n",
                 t, val, (unsigned long long)alloc_size);
        } else {
            /* Scalar type: store value — convert to designated type if needed */
            const char *desg_llvm = designated ? Type_To_Llvm(designated) : Integer_Arith_Type(cg);
            const char *val_llvm = Expression_Llvm_Type(cg, node->allocator.expression);
            if (strcmp(val_llvm, desg_llvm) != 0) {
                val = Emit_Convert(cg, val, val_llvm, desg_llvm);
            }
            Emit(cg, "  store %s %%t%u, ptr %%t%u\n", desg_llvm, val, t);
        }
    } else if (designated and Type_Is_Record(designated)) {
        /* NEW T without initializer for record types (RM 4.8):
         * Initialize discriminant constraints and component defaults.
         * The designated type (or its subtype constraint) provides
         * discriminant values; component default_expr nodes provide defaults. */
        Type_Info *ty = designated;

        /* Zero-initialize first to handle unset fields cleanly */
        uint32_t sz64 = Emit_Temp(cg);
        Emit(cg, "  %%t%u = add i64 0, %llu\n", sz64, (unsigned long long)alloc_size);
        Emit(cg, "  call void @llvm.memset.p0.i64(ptr %%t%u, i8 0, i64 %%t%u, i1 false)"
             "  ; zero-init record\n", t, sz64);

        /* Initialize discriminant constraint values if constrained subtype */
        if (ty->record.has_disc_constraints and ty->record.disc_constraint_values) {
            for (uint32_t di = 0; di < ty->record.discriminant_count; di++) {
                Component_Info *dc = &ty->record.components[di];
                uint32_t dp = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %u  ; disc %.*s\n",
                     dp, t, dc->byte_offset, (int)dc->name.length, dc->name.data);
                const char *dt = Type_To_Llvm(dc->component_type);
                if (ty->record.disc_constraint_exprs and ty->record.disc_constraint_exprs[di]) {
                    uint32_t val = Generate_Expression(cg, ty->record.disc_constraint_exprs[di]);
                    val = Emit_Coerce_Default_Int(cg, val, dt);
                    Emit(cg, "  store %s %%t%u, ptr %%t%u\n", dt, val, dp);
                } else {
                    Emit(cg, "  store %s %lld, ptr %%t%u\n", dt,
                         (long long)ty->record.disc_constraint_values[di], dp);
                }
            }
        }

        /* Apply component defaults (RM 3.7) */
        for (uint32_t ci = 0; ci < ty->record.component_count; ci++) {
            Component_Info *comp = &ty->record.components[ci];
            if (not comp->default_expr) continue;
            if (comp->is_discriminant and ty->record.has_disc_constraints) continue;

            uint32_t val = Generate_Expression(cg, comp->default_expr);
            if (val == 0) continue;

            uint32_t comp_ptr = Emit_Temp(cg);
            if (ty->rt_global_id > 0) {
                uint32_t rt_off = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load i64, ptr @__rt_rec_%u_off%u\n",
                     rt_off, ty->rt_global_id, ci);
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %%t%u  ; %.*s rt default\n",
                     comp_ptr, t, rt_off,
                     (int)comp->name.length, comp->name.data);
            } else {
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %u  ; %.*s default\n",
                     comp_ptr, t, comp->byte_offset,
                     (int)comp->name.length, comp->name.data);
            }

            Type_Info *comp_type = comp->component_type;
            bool comp_is_composite = Type_Is_Composite(comp_type);
            bool has_rt_sz = comp_type and comp_type->rt_global_id > 0;

            if (comp_is_composite and (comp_type->size > 0 or has_rt_sz)) {
                uint32_t data_ptr = val;
                bool is_fat_agg = comp->default_expr->kind == NK_AGGREGATE and
                    comp_type and Type_Is_Array_Like(comp_type) and
                    (Type_Is_Unconstrained_Array(comp_type) or
                     Aggregate_Produces_Fat_Pointer(comp_type));
                if (is_fat_agg) {
                    uint32_t loaded = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = load " FAT_PTR_TYPE ", ptr %%t%u\n",
                         loaded, val);
                    data_ptr = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = extractvalue " FAT_PTR_TYPE
                         " %%t%u, 0\n", data_ptr, loaded);
                }
                if (has_rt_sz) {
                    uint32_t rtsz = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = load i64, ptr @__rt_type_%u_size\n",
                         rtsz, comp_type->rt_global_id);
                    Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)"
                         "  ; %.*s rt default memcpy\n",
                         comp_ptr, data_ptr, rtsz,
                         (int)comp->name.length, comp->name.data);
                } else {
                    Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %u, i1 false)"
                         "  ; %.*s default memcpy\n",
                         comp_ptr, data_ptr, comp_type->size,
                         (int)comp->name.length, comp->name.data);
                }
            } else if (comp_is_composite) {
                /* Skip 0-size composites */
            } else {
                const char *store_type = Type_To_Llvm(comp_type);
                const char *val_type = Temp_Get_Type(cg, val);
                if (not val_type or strlen(val_type) == 0) {
                    Type_Info *expr_type = comp->default_expr->type;
                    if (expr_type) val_type = Type_To_Llvm(expr_type);
                }
                if (not val_type or strlen(val_type) == 0)
                    val_type = Expression_Llvm_Type(cg, comp->default_expr);
                if (not store_type or strlen(store_type) == 0)
                    store_type = val_type;
                if (Type_Is_Float(comp_type)) {
                    const char *flt_ty = Float_Llvm_Type_Of(comp_type);
                    val = Emit_Convert(cg, val, val_type, flt_ty);
                    Emit(cg, "  store %s %%t%u, ptr %%t%u\n", flt_ty, val, comp_ptr);
                } else {
                    if (comp_type and comp_type->kind == TYPE_FIXED and
                        val_type and Is_Float_Type(val_type)) {
                        double small = comp_type->fixed.small;
                        if (small <= 0) small = comp_type->fixed.delta > 0 ? comp_type->fixed.delta : 1.0;
                        uint64_t sb; memcpy(&sb, &small, sizeof(sb));
                        uint32_t st = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = fadd double 0.0, 0x%016llX  ; small\n", st, (unsigned long long)sb);
                        uint32_t dv = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = fdiv %s %%t%u, %%t%u  ; rec default/small\n", dv, val_type, val, st);
                        val = dv;
                    }
                    val = Emit_Convert(cg, val, val_type, store_type);
                    Emit(cg, "  store %s %%t%u, ptr %%t%u\n", store_type, val, comp_ptr);
                }
            }
        }
    }

    /* RM 9.2: Allocating a task type via NEW activates the task immediately.
     * The allocated memory stores the thread handle (ptr-sized). */
    if (designated and Type_Is_Task(designated)) {
        uint32_t handle_tmp = Emit_Temp(cg);
        Emit(cg, "  %%t%u = call ptr @__ada_task_start(ptr @", handle_tmp);
        Emit_Task_Function_Name(cg, designated->defining_symbol, designated->name);
        Emit(cg, ", ");
        if (cg->current_nesting_level > 0) {
            Emit(cg, "ptr %%__frame_base)\n");
        } else {
            Emit(cg, "ptr null)\n");
        }
        Emit(cg, "  store ptr %%t%u, ptr %%t%u  ; store task handle\n", handle_tmp, t);
    }

    return t;
}

static uint32_t Generate_Expression(Code_Generator *cg, Syntax_Node *node) {
    if (not node) return 0;

    switch (node->kind) {
        case NK_INTEGER:    return Generate_Integer_Literal(cg, node);
        case NK_REAL:       return Generate_Real_Literal(cg, node);
        case NK_STRING:     return Generate_String_Literal(cg, node);
        case NK_CHARACTER:  {   /* Character literal - extract char from text "'X'" */
                             uint32_t t = Emit_Temp(cg);
                             int64_t ch = 0;
                             /* Check if resolved as enumeration literal */
                             if (node->symbol and node->symbol->kind == SYMBOL_LITERAL) {
                                 ch = node->symbol->frame_offset;
                             } else if (node->string_val.text.length >= 2) {
                                 ch = (unsigned char)node->string_val.text.data[1];
                                 /* If the node's type is a user-defined enumeration containing
                                  * character literals, use the position within the enumeration
                                  * rather than the ASCII code (RM 3.5.1). */
                                 Type_Info *etype = node->type;
                                 while (etype and (etype->parent_type or etype->base_type))
                                     etype = etype->parent_type ? etype->parent_type : etype->base_type;
                                 if (etype and etype->kind == TYPE_ENUMERATION and
                                     etype->enumeration.literals and etype->enumeration.literal_count > 0) {
                                     char target = node->string_val.text.data[1];
                                     for (uint32_t j = 0; j < etype->enumeration.literal_count; j++) {
                                         String_Slice lit = etype->enumeration.literals[j];
                                         if (lit.length == 3 and lit.data[0] == '\'' and
                                             lit.data[1] == target and lit.data[2] == '\'') {
                                             ch = (int64_t)j;
                                             break;
                                         }
                                     }
                                 }
                             }
                             /* character literals use native type width (i8),
                              * not Integer_Arith_Type. Widening at use sites. */
                             const char *ch_type = node->type ? Type_To_Llvm(node->type) : "i8";
                             Emit(cg, "  %%t%u = add %s 0, %lld\n", t, ch_type, (long long)ch);
                             Temp_Set_Type(cg, t, ch_type);
                             return t; }
        case NK_NULL:       { uint32_t t = Emit_Temp(cg);
                             Emit(cg, "  %%t%u = inttoptr i64 0 to ptr\n", t);
                             Temp_Set_Type(cg, t, "ptr");
                             return t; }
        case NK_IDENTIFIER: return Generate_Identifier(cg, node);
        case NK_SELECTED:   return Generate_Selected(cg, node);
        case NK_ATTRIBUTE:  return Generate_Attribute(cg, node);
        case NK_BINARY_OP:  return Generate_Binary_Op(cg, node);
        case NK_UNARY_OP:   return Generate_Unary_Op(cg, node);
        case NK_APPLY:      return Generate_Apply(cg, node);
        case NK_AGGREGATE:  return Generate_Aggregate(cg, node);
        case NK_QUALIFIED:  return Generate_Qualified(cg, node);
        case NK_ALLOCATOR:  return Generate_Allocator(cg, node);

        default:
            Report_Error(node->location, "unsupported expression kind %d in codegen",
                         (int)node->kind);
            return 0;
    }
}

/* ─────────────────────────────────────────────────────────────────────────
 * §13.4 Statement Code Generation
 *
 * Statements modify state while expressions compute values, a distinction Ada enforces.
 * ───────────────────────────────────────────────────────────────────────── */

static void Generate_Statement(Code_Generator *cg, Syntax_Node *node);

static void Generate_Statement_List(Code_Generator *cg, Node_List *list) {
    for (uint32_t i = 0; i < list->count; i++) {
        Syntax_Node *stmt = list->items[i];
        if (not stmt) continue;

        /* After a terminator (ret/br), we need a new basic block.
         * Labeled statements (NK_LABEL, NK_BLOCK with label, NK_LOOP with label)
         * emit their own labels. For unlabeled statements, emit a fresh label. */
        if (cg->block_terminated) {
            bool will_emit_label = stmt->kind == NK_LABEL or
                (stmt->kind == NK_BLOCK and stmt->block_stmt.label_symbol) or
                (stmt->kind == NK_LOOP and stmt->loop_stmt.label_symbol);
            if (not will_emit_label) {
                /* Emit a fresh basic block for unreachable code. The subsequent
                 * statement will generate instructions that fill this block. */
                uint32_t dead_label = cg->label_id++;
                Emit_Label_Here(cg, dead_label);
                cg->block_terminated = false;
            } else {
                /* The next statement emits its own label - reset block_terminated
                 * so it adds an instruction to its label block properly */
                cg->block_terminated = false;
            }
        }

        Generate_Statement(cg, stmt);
    }
}

static void Generate_Assignment(Code_Generator *cg, Syntax_Node *node) {
    Syntax_Node *target = node->assignment.target;

    /* Emit source location and assignment target info */
    Emit_Location(cg, node->location);
    if (target->symbol) {
        Emit(cg, "  ; ASSIGN %.*s :=\n",
             (int)target->symbol->name.length, target->symbol->name.data);
    } else if (target->kind == NK_SELECTED and target->selected.selector.length > 0) {
        Emit(cg, "  ; ASSIGN .%.*s :=\n",
             (int)target->selected.selector.length, target->selected.selector.data);
    } else if (target->kind == NK_APPLY) {
        Emit(cg, "  ; ASSIGN indexed/slice :=\n");
    }

    /* For RENAMES: redirect to the renamed object */
    if (target->kind == NK_IDENTIFIER and target->symbol and target->symbol->renamed_object) {
        target = target->symbol->renamed_object;
    }

    /* Handle indexed component target (array element or slice assignment) */
    if (target->kind == NK_APPLY) {
        Type_Info *prefix_type = target->apply.prefix->type;
        bool is_array_target = prefix_type and
            (prefix_type->kind == TYPE_ARRAY or prefix_type->kind == TYPE_STRING);

        if (is_array_target) {
            Symbol *array_sym = target->apply.prefix->symbol;
            if (not array_sym) return;

            /* For unconstrained (STRING / unconstrained array) the variable
             * holds a fat pointer — we must load it and extract the data ptr.
             * For constrained arrays the variable IS the data pointer. */
            bool target_is_uncon = (not Type_Is_Constrained_Array(prefix_type) and
                                    Type_Is_String(prefix_type)) or
                                   Type_Is_Unconstrained_Array(prefix_type);

            Syntax_Node *arg = target->apply.arguments.items[0];

            /* Check for slice assignment: ARR(low .. high) := source */
            if (arg->kind == NK_RANGE) {
                /* Array slice assignment using memcpy */
                Type_Info *elem_type_info = prefix_type->array.element_type;
                uint32_t elem_sz = elem_type_info ? elem_type_info->size : 1;
                if (elem_sz == 0) elem_sz = 1;

                /* Get destination base address */
                uint32_t dest_base;
                int128_t low_bound;
                if (target_is_uncon) {
                    /* Load fat pointer, extract data ptr and low bound */
                    const char *sa_bt = Array_Bound_Llvm_Type(prefix_type);
                    uint32_t fat = Emit_Load_Fat_Pointer(cg, array_sym, sa_bt);
                    dest_base = Emit_Fat_Pointer_Data(cg, fat, sa_bt);
                    /* Low bound comes from the fat pointer at runtime */
                    low_bound = 0;  /* We'll use dynamic low below */
                    const char *usa_t = Integer_Arith_Type(cg);
                    uint32_t fat_low = Emit_Fat_Pointer_Low(cg, fat, sa_bt);
                    uint32_t fat_low_conv = Emit_Convert(cg, fat_low, sa_bt, usa_t);

                    /* Calculate destination start offset from slice low bound */
                    uint32_t dest_low_expr = Generate_Expression(cg, arg->range.low);
                    /* Subtract dynamic low bound from fat pointer */
                    uint32_t adj = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u"
                         "  ; adjust for dynamic low bound\n",
                         adj, usa_t, dest_low_expr, fat_low_conv);
                    uint32_t dest_ptr = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s %%t%u\n",
                         dest_ptr, dest_base, usa_t, adj);

                    /* Generate source and copy */
                    Syntax_Node *src = node->assignment.value;
                    uint32_t dest_high_expr = Generate_Expression(cg, arg->range.high);
                    uint32_t length = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n",
                         length, usa_t, dest_high_expr, dest_low_expr);
                    uint32_t len_plus_one = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s %%t%u, 1\n", len_plus_one, usa_t, length);
                    uint32_t byte_len_nat = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = mul %s %%t%u, %u\n",
                         byte_len_nat, usa_t, len_plus_one, elem_sz);
                    uint32_t byte_len = Emit_Extend_To_I64(cg, byte_len_nat, usa_t);

                    /* Get source data */
                    uint32_t src_val = Generate_Expression(cg, src);
                    const char *src_llvm = Expression_Llvm_Type(cg, src);
                    uint32_t src_data;
                    if (Llvm_Type_Is_Fat_Pointer(src_llvm)) {
                        src_data = Emit_Fat_Pointer_Data(cg, src_val, Array_Bound_Llvm_Type(prefix_type));
                    } else {
                        src_data = src_val;
                    }

                    Emit(cg, "  call void @llvm.memcpy.p0.p0.i64("
                         "ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)"
                         "  ; uncon slice assignment\n",
                         dest_ptr, src_data, byte_len);
                    return;
                }

                /* Constrained array slice assignment (original code) */
                const char *csa_t = Integer_Arith_Type(cg);
                low_bound = Array_Low_Bound(prefix_type);

                /* Get destination base address */
                dest_base = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr i8, ptr ", dest_base);
                Emit_Symbol_Storage(cg, array_sym);
                Emit(cg, ", %s 0\n", csa_t);

                /* Evaluate slice bounds and compute copy length from original range.
                 * Length must use raw bounds (not index-adjusted) per Ada RM 5.2.1. */
                uint32_t dest_lo_raw = Generate_Expression(cg, arg->range.low);
                uint32_t dest_hi_raw = Generate_Expression(cg, arg->range.high);
                uint32_t length = Emit_Temp(cg);
                Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", length, csa_t, dest_hi_raw, dest_lo_raw);

                /* Destination pointer: adjust low bound to array-relative index */
                uint32_t dest_idx = dest_lo_raw;
                if (low_bound != 0) {
                    dest_idx = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = sub %s %%t%u, %s\n", dest_idx, csa_t, dest_lo_raw, I128_Decimal(low_bound));
                }
                uint32_t dest_ptr = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s %%t%u\n",
                     dest_ptr, dest_base, csa_t, dest_idx);

                /* Ada RM 5.2.1: sliding semantics — source slides to destination. */
                Syntax_Node *src = node->assignment.value;
                uint32_t len_plus_one = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s %%t%u, 1\n", len_plus_one, csa_t, length);
                uint32_t byte_len = Emit_Temp(cg);
                Emit(cg, "  %%t%u = mul %s %%t%u, %u\n", byte_len, csa_t, len_plus_one, elem_sz);
                uint32_t byte_len_64 = Emit_Extend_To_I64(cg, byte_len, csa_t);

                /* Determine source data pointer */
                uint32_t src_ptr;

                if (src->kind == NK_APPLY and src->apply.arguments.count > 0 and
                    src->apply.arguments.items[0]->kind == NK_RANGE) {
                    /* Source is a slice: SRC_ARR(lo..hi) */
                    Symbol *src_sym = src->apply.prefix->symbol;
                    Type_Info *src_type = src->apply.prefix->type;
                    Syntax_Node *src_range = src->apply.arguments.items[0];

                    if (src_sym and src_type and
                        (src_type->kind == TYPE_ARRAY or src_type->kind == TYPE_STRING)) {
                        int128_t src_low_bound = Array_Low_Bound(src_type);
                        uint32_t src_base;
                        uint32_t src_fat_low = 0;
                        const char *ssb = NULL;
                        bool src_is_uncon = (not Type_Is_Constrained_Array(src_type) and
                                              Type_Is_String(src_type)) or
                                             Type_Is_Unconstrained_Array(src_type);
                        if (src_is_uncon) {
                            ssb = Array_Bound_Llvm_Type(src_type);
                            uint32_t sfat = Emit_Load_Fat_Pointer(cg, src_sym, ssb);
                            src_base = Emit_Fat_Pointer_Data(cg, sfat, ssb);
                            src_fat_low = Emit_Fat_Pointer_Low(cg, sfat, ssb);
                        } else {
                            src_base = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = getelementptr i8, ptr ", src_base);
                            Emit_Symbol_Storage(cg, src_sym);
                            Emit(cg, ", %s 0\n", csa_t);
                        }
                        uint32_t src_start = Generate_Expression(cg, src_range->range.low);
                        if (src_is_uncon) {
                            uint32_t src_fat_cvt = Emit_Convert(cg, src_fat_low, ssb, csa_t);
                            uint32_t adj = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n",
                                 adj, csa_t, src_start, src_fat_cvt);
                            src_start = adj;
                        } else if (src_low_bound != 0) {
                            uint32_t adj = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = sub %s %%t%u, %s\n",
                                 adj, csa_t, src_start, I128_Decimal(src_low_bound));
                            src_start = adj;
                        }
                        src_ptr = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s %%t%u\n",
                             src_ptr, src_base, csa_t, src_start);
                    } else {
                        /* Fallback: evaluate as general expression */
                        goto general_slice_source;
                    }
                } else {
                general_slice_source:;
                    /* General source: identifier, string literal, function call, etc.
                     * Ada RM 5.2.1: source slides to destination index range.
                     * We evaluate the source, extract its data pointer, and memcpy. */
                    uint32_t src_val = Generate_Expression(cg, src);
                    const char *src_llvm = Expression_Llvm_Type(cg, src);
                    if (Llvm_Type_Is_Fat_Pointer(src_llvm)) {
                        src_ptr = Emit_Fat_Pointer_Data(cg, src_val,
                            Array_Bound_Llvm_Type(src->type ? src->type : prefix_type));
                    } else if (src->kind == NK_IDENTIFIER and src->symbol) {
                        /* Whole constrained array: get address of storage */
                        src_ptr = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = getelementptr i8, ptr ", src_ptr);
                        Emit_Symbol_Storage(cg, src->symbol);
                        Emit(cg, ", %s 0\n", csa_t);
                    } else {
                        /* Expression producing a value (aggregate, call, etc.) —
                         * spill to alloca, then use the alloca as source ptr */
                        uint32_t spill = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = alloca %s\n", spill, src_llvm);
                        Emit(cg, "  store %s %%t%u, ptr %%t%u\n", src_llvm, src_val, spill);
                        src_ptr = spill;
                    }
                }

                Emit(cg, "  call void @llvm.memcpy.p0.p0.i64("
                     "ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)"
                     "  ; slice assignment\n", dest_ptr, src_ptr, byte_len_64);
                return;
            }

            /* Array element assignment: DATA(I) := value
             * Generate_Lvalue handles both unconstrained (fat pointer) and
             * constrained arrays — computes element address in one call. */
            const char *elem_type_str = Type_To_Llvm(prefix_type->array.element_type);
            uint32_t elem_ptr = Generate_Lvalue(cg, target);
            uint32_t value = Generate_Expression(cg, node->assignment.value);
            const char *value_type = Expression_Llvm_Type(cg, node->assignment.value);
            value = Emit_Convert(cg, value, value_type, elem_type_str);
            Emit(cg, "  store %s %%t%u, ptr %%t%u  ; array element assign\n",
                 elem_type_str, value, elem_ptr);
            return;
        }

        /* Access-to-array implicit dereference + indexing: ACC_ARR(I) := val
         * where ACC_ARR is an access type whose designated type is an array.
         * Generate_Lvalue already handles this case properly. */
        if (prefix_type and Type_Is_Access(prefix_type) and
            prefix_type->access.designated_type) {
            Type_Info *desig = prefix_type->access.designated_type;
            if (desig->kind == TYPE_ARRAY or desig->kind == TYPE_STRING) {
                const char *elem_type_str = Type_To_Llvm(desig->array.element_type);
                uint32_t elem_ptr = Generate_Lvalue(cg, target);
                uint32_t value = Generate_Expression(cg, node->assignment.value);
                const char *value_type = Expression_Llvm_Type(cg, node->assignment.value);
                value = Emit_Convert(cg, value, value_type, elem_type_str);
                Emit(cg, "  store %s %%t%u, ptr %%t%u  ; access-array element assign\n",
                     elem_type_str, value, elem_ptr);
                return;
            }
        }
    }

    /* Handle .ALL dereference assignment (NK_UNARY_OP with TK_ALL) */
    if (target->kind == NK_UNARY_OP and target->unary.op == TK_ALL) {
        Syntax_Node *operand = target->unary.operand;
        Type_Info *operand_type = operand->type;

        if (Type_Is_Access(operand_type)) {
            Type_Info *designated = operand_type->access.designated_type;

            /* Generate_Lvalue loads the pointer value (the storage address) */
            uint32_t ptr = Generate_Lvalue(cg, target);

            /* Composite types: copy contents via memcpy (RM 5.2) */
            if (designated and (Type_Is_Record(designated) or
                (designated->kind == TYPE_ARRAY and designated->size > 0))) {
                uint32_t value = Generate_Expression(cg, node->assignment.value);
                uint32_t sz = designated->size > 0 ? designated->size : 8;
                Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %u, i1 false)  ; .ALL composite assign\n",
                     ptr, value, sz);
                return;
            }

            /* Scalar / access types: store value directly */
            const char *dest_type = Type_To_Llvm(designated);
            uint32_t value = Generate_Expression(cg, node->assignment.value);
            const char *value_type = Expression_Llvm_Type(cg, node->assignment.value);
            value = Emit_Convert(cg, value, value_type, dest_type);
            Emit(cg, "  store %s %%t%u, ptr %%t%u  ; .ALL assignment\n",
                 dest_type, value, ptr);
            return;
        }
    }

    /* Handle selected component target (record field assignment or .ALL)
     * Generate_Lvalue computes the storage address — we just determine
     * the store type and let Generate_Lvalue handle address computation. */
    if (target->kind == NK_SELECTED) {
        Syntax_Node *prefix = target->selected.prefix;
        Type_Info *prefix_type = prefix->type;

        /* Determine the target type being assigned to */
        Type_Info *assign_type = NULL;
        if (Type_Is_Access(prefix_type) and
            Slice_Equal_Ignore_Case(target->selected.selector, S("ALL"))) {
            /* .ALL dereference: target is designated type */
            assign_type = prefix_type->access.designated_type;
        } else {
            /* Record field: find component type */
            Type_Info *record_type = prefix_type;
            if (Type_Is_Access(prefix_type) and
                Type_Is_Record(prefix_type->access.designated_type)) {
                record_type = prefix_type->access.designated_type;
            }
            if (Type_Is_Record(record_type)) {
                for (uint32_t i = 0; i < record_type->record.component_count; i++) {
                    if (Slice_Equal_Ignore_Case(record_type->record.components[i].name,
                                                target->selected.selector)) {
                        assign_type = record_type->record.components[i].component_type;
                        break;
                    }
                }
            }
        }

        /* Generate_Lvalue handles .ALL dereference, implicit dereference,
         * and direct field offset — all address computation is unified. */
        uint32_t addr = Generate_Lvalue(cg, target);
        uint32_t value = Generate_Expression(cg, node->assignment.value);

        /* Composite types: copy contents via memcpy (RM 5.2) */
        if (assign_type and (Type_Is_Record(assign_type) or
            (assign_type->kind == TYPE_ARRAY and assign_type->size > 0))) {
            uint32_t sz = assign_type->size > 0 ? assign_type->size : 8;
            Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %u, i1 false)  ; composite selected assign\n",
                 addr, value, sz);
            return;
        }

        /* Discriminant-dependent array stored inline (size=0 at compile time).
         * RHS is a fat pointer {ptr,ptr} — extract data ptr and copy bytes
         * using the bounds from the fat pointer. (RM 5.2, 3.7.1) */
        if (assign_type and Type_Is_Array_Like(assign_type) and
            assign_type->size == 0 and Type_Has_Dynamic_Bounds(assign_type)) {
            const char *value_type = Expression_Llvm_Type(cg, node->assignment.value);
            uint32_t data_ptr;
            if (value_type and Llvm_Type_Is_Fat_Pointer(value_type)) {
                /* Extract data pointer and bounds from fat pointer */
                data_ptr = Emit_Temp(cg);
                Emit(cg, "  %%t%u = extractvalue %s %%t%u, 0\n", data_ptr, value_type, value);
                /* Get length from bounds */
                const char *bt = Array_Bound_Llvm_Type(assign_type);
                uint32_t bnd_ptr = Emit_Temp(cg);
                Emit(cg, "  %%t%u = extractvalue %s %%t%u, 1\n", bnd_ptr, value_type, value);
                uint32_t lo = Emit_Temp(cg), hi = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", lo, bt, bnd_ptr);
                uint32_t hi_gep = Emit_Temp(cg);
                int bt_sz = (strcmp(bt, "i32") == 0) ? 4 : (strcmp(bt, "i16") == 0) ? 2 : 4;
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %d\n", hi_gep, bnd_ptr, bt_sz);
                Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", hi, bt, hi_gep);
                uint32_t len = Emit_Temp(cg);
                Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", len, bt, hi, lo);
                uint32_t len1 = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s %%t%u, 1\n", len1, bt, len);
                uint32_t elem_sz = assign_type->array.element_type
                    ? assign_type->array.element_type->size : 1;
                if (elem_sz == 0) elem_sz = 1;
                uint32_t byte_cnt = len1;
                if (elem_sz > 1) {
                    byte_cnt = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = mul %s %%t%u, %u\n", byte_cnt, bt, len1, elem_sz);
                }
                /* Clamp to 0 for null arrays */
                uint32_t is_neg = Emit_Temp(cg), clamped = Emit_Temp(cg), sz64 = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp slt %s %%t%u, 0\n", is_neg, bt, byte_cnt);
                Emit(cg, "  %%t%u = select i1 %%t%u, %s 0, %s %%t%u\n", clamped, is_neg, bt, bt, byte_cnt);
                Emit(cg, "  %%t%u = sext %s %%t%u to i64\n", sz64, bt, clamped);
                Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)  ; disc-dep array assign\n",
                     addr, data_ptr, sz64);
            } else {
                /* Value is already a pointer to data — use memcpy with a safe size */
                data_ptr = value;
                Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 8, i1 false)  ; disc-dep array assign (ptr)\n",
                     addr, data_ptr);
            }
            return;
        }

        /* Scalar / access types: store value directly */
        const char *store_type = Type_To_Llvm(assign_type);
        const char *value_type = Expression_Llvm_Type(cg, node->assignment.value);
        value = Emit_Convert(cg, value, value_type, store_type);
        Emit(cg, "  store %s %%t%u, ptr %%t%u  ; selected assign\n",
             store_type, value, addr);
        return;
    }

    /* Simple variable target */
    Symbol *target_sym = target->symbol;
    if (not target_sym) {
        fprintf(stderr, "warning: assignment target has no symbol at %s:%u\n",
                target->location.filename ? target->location.filename : "<unknown>",
                target->location.line);
        return;
    }

    Type_Info *ty = target_sym->type;

    if (cg->current_instance)
        ty = Resolve_Generic_Actual_Type(cg, ty);

    /* Handle record assignment (use memcpy) (RM 5.2, 3.7.2) */
    if (Type_Is_Record(ty)) {
        uint32_t src_ptr = Generate_Expression(cg, node->assignment.value);
        uint32_t record_size = ty->size > 0 ? ty->size : 8;

        /* For constrained discriminated records, verify source discriminants match
         * target constraints before assignment (Constraint_Error if mismatch).
         * Mutable records (all_defaults, no constraint) allow discriminant change. */
        if (ty->record.has_discriminants and target_sym->is_disc_constrained) {
            /* Load each discriminant from source and compare with target */
            for (uint32_t di = 0; di < ty->record.discriminant_count; di++) {
                Component_Info *dc = &ty->record.components[di];
                const char *dt = Type_To_Llvm(dc->component_type);

                /* Load source discriminant */
                const char *iat_dc = Integer_Arith_Type(cg);
                uint32_t src_dp = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, %s %u\n",
                     src_dp, src_ptr, iat_dc, dc->byte_offset);
                uint32_t src_dv = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load %s, ptr %%t%u  ; src disc %.*s\n",
                     src_dv, dt, src_dp, (int)dc->name.length, dc->name.data);
                if (strcmp(dt, iat_dc) != 0) {
                    src_dv = Emit_Convert(cg, src_dv, dt, iat_dc);
                }

                /* Load target discriminant */
                uint32_t tgt_dp = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr i8, ptr ", tgt_dp);
                Emit_Symbol_Ref(cg, target_sym);
                Emit(cg, ", %s %u\n", iat_dc, dc->byte_offset);
                uint32_t tgt_dv = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load %s, ptr %%t%u  ; tgt disc %.*s\n",
                     tgt_dv, dt, tgt_dp, (int)dc->name.length, dc->name.data);
                if (strcmp(dt, iat_dc) != 0) {
                    tgt_dv = Emit_Convert(cg, tgt_dv, dt, iat_dc);
                }

                /* Compare and raise Constraint_Error on mismatch */
                uint32_t cmp = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp eq %s %%t%u, %%t%u  ; disc match?\n",
                     cmp, iat_dc, src_dv, tgt_dv);
                uint32_t lbl_ok = cg->label_id++;
                uint32_t lbl_fail = cg->label_id++;
                Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n", cmp, lbl_ok, lbl_fail);
                cg->block_terminated = true;
                Emit_Label_Here(cg, lbl_fail);
                Emit_Raise_Constraint_Error(cg, "discriminant mismatch in assignment");
                Emit_Label_Here(cg, lbl_ok);
            }
        }

        /* Copy record data (whole record for mutable, or non-discriminant part for constrained) */
        Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr ");
        Emit_Symbol_Ref(cg, target_sym);
        Emit(cg, ", ptr %%t%u, i64 %u, i1 false)  ; record assignment\n",
             src_ptr, record_size);
        return;
    }

    /* Handle constrained array assignment (use memcpy, not store) */
    if (Type_Is_Constrained_Array(ty)) {
        /* Check if source is unconstrained (fat pointer) or constrained (ptr).
         * Fat pointer sources: STRING type, unconstrained arrays, string literals,
         * concatenation results, and slice expressions. */
        Type_Info *src_type = node->assignment.value->type;
        if (cg->current_instance)
            src_type = Resolve_Generic_Actual_Type(cg, src_type);
        bool src_is_fat_ptr = Expression_Produces_Fat_Pointer(
            node->assignment.value, src_type);
        uint32_t src_ptr = Generate_Expression(cg, node->assignment.value);
        if (src_is_fat_ptr) {
            /* Source is unconstrained/string - extract data pointer from fat pointer */
            /* Length check: verify source length matches constrained target length */
            const char *ca_bt = Array_Bound_Llvm_Type(ty);
            uint32_t src_len = Emit_Fat_Pointer_Length(cg, src_ptr, ca_bt);
            if (ty->array.index_count > 0) {
                int128_t lo = Type_Bound_Value(ty->array.indices[0].low_bound);
                int128_t hi = Type_Bound_Value(ty->array.indices[0].high_bound);
                int128_t dst_length = hi - lo + 1;
                if (dst_length < 0) dst_length = 0;
                uint32_t dst_len = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s 0, %s  ; constrained target length\n",
                     dst_len, ca_bt, I128_Decimal(dst_length));
                Emit_Length_Check(cg, src_len, dst_len, ca_bt, ty);
            }
            Emit_Fat_Pointer_Copy_To_Name(cg, src_ptr, target_sym, ca_bt);
        } else {
            /* Source is constrained - memcpy directly */
            uint32_t array_size = ty->size > 0 ? ty->size : 8;
            Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr ");
            Emit_Symbol_Ref(cg, target_sym);
            Emit(cg, ", ptr %%t%u, i64 %u, i1 false)  ; array assignment\n",
                 src_ptr, array_size);
        }
        return;
    }

    /* Handle unconstrained array/STRING variable assignment.
     * These variables store a fat pointer { ptr, { bound, bound } }.
     * IMPORTANT: In Ada, unconstrained objects have fixed constraints
     * after elaboration.  Assignment copies data INTO the existing
     * data storage — it does NOT replace the fat pointer.
     * (Replacing the fat pointer would orphan the data alloca and
     * create dangling pointers to source storage.)
     *
     * Algorithm:
     *   1. Load existing fat pointer to get data pointer and length
     *   2. Generate source expression
     *   3. Extract source data pointer (from fat ptr or constrained ptr)
     *   4. memcpy source data to existing data storage */
    if ((not Type_Is_Constrained_Array(ty) and Type_Is_String(ty)) or
        Type_Is_Unconstrained_Array(ty)) {
        Syntax_Node *src = node->assignment.value;
        Type_Info *src_type = src->type;
        if (cg->current_instance)
            src_type = Resolve_Generic_Actual_Type(cg, src_type);
        bool src_is_fat = Expression_Produces_Fat_Pointer(src, src_type);

        /* Load existing fat pointer from the target variable */
        const char *ua_bt = Array_Bound_Llvm_Type(ty);
        uint32_t existing_fat = Emit_Load_Fat_Pointer(cg, target_sym, ua_bt);
        uint32_t dest_data = Emit_Fat_Pointer_Data(cg, existing_fat, ua_bt);
        uint32_t dest_len  = Emit_Fat_Pointer_Length(cg, existing_fat, ua_bt);
        uint32_t dest_len_64 = Emit_Extend_To_I64(cg, dest_len, ua_bt);

        /* Convert element count to byte count.  For STRING/CHARACTER
         * arrays the element size is 1, so this is a no-op.  For arrays
         * of larger types (INTEGER, records, etc.) we must scale. */
        uint32_t elem_sz = (ty->array.element_type and
                            ty->array.element_type->size > 0)
                         ? ty->array.element_type->size : 1;
        uint32_t dest_bytes_64 = dest_len_64;
        if (elem_sz > 1) {
            dest_bytes_64 = Emit_Temp(cg);
            Emit(cg, "  %%t%u = mul i64 %%t%u, %u"
                     "  ; elem_count * elem_size\n",
                 dest_bytes_64, dest_len_64, elem_sz);
        }

        /* Generate source and copy data to existing storage */
        uint32_t src_val = Generate_Expression(cg, src);

        /* Aggregates with unconstrained type return a fat pointer ALLOCA
         * (ptr to { ptr, ptr }), not a loaded value.  Promote to fat. */
        if (not src_is_fat and src->kind == NK_AGGREGATE and src_type and
            Type_Is_Array_Like(src_type) and not src_type->array.is_constrained) {
            uint32_t loaded_fat = Emit_Temp(cg);
            Emit(cg, "  %%t%u = load " FAT_PTR_TYPE ", ptr %%t%u"
                     "  ; load agg fat ptr alloca\n",
                 loaded_fat, src_val);
            src_val = loaded_fat;
            src_is_fat = true;
        }

        if (src_is_fat) {
            /* Source is fat pointer — extract data pointer, check length, copy */
            uint32_t src_len = Emit_Fat_Pointer_Length(cg, src_val, ua_bt);
            Emit_Length_Check(cg, src_len, dest_len, ua_bt, ty);
            uint32_t src_data = Emit_Fat_Pointer_Data(cg, src_val, ua_bt);
            Emit(cg, "  call void @llvm.memcpy.p0.p0.i64("
                 "ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)"
                 "  ; uncon array assign\n",
                 dest_data, src_data, dest_bytes_64);
        } else {
            /* Source is constrained (ptr) — memcpy directly */
            Emit(cg, "  call void @llvm.memcpy.p0.p0.i64("
                 "ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)"
                 "  ; uncon array assign from constrained\n",
                 dest_data, src_val, dest_bytes_64);
        }
        return;
    }

    uint32_t value = Generate_Expression(cg, node->assignment.value);

    const char *type_str = Type_To_Llvm(ty);

    /* Determine source type from the value expression.
     * Resolve through generic actuals so that a formal TYPE_PRIVATE is
     * treated as its actual representation (e.g., FLOAT > double). */
    Type_Info *value_type = node->assignment.value->type;
    if (cg->current_instance)
        value_type = Resolve_Generic_Actual_Type(cg, value_type);
    bool is_src_float = Type_Is_Float_Representation(value_type);
    bool is_dst_float = Type_Is_Float_Representation(ty);

    /* Convert between float and integer if needed */
    if (is_src_float and not is_dst_float) {
        /* Float to integer: use fptosi. For fixed-point targets, divide by
         * SMALL first to get the scaled integer representation (RM 4.5.5) */
        if (Type_Is_Fixed_Point(ty)) {
            double small = ty->fixed.small;
            if (small <= 0) small = ty->fixed.delta > 0 ? ty->fixed.delta : 1.0;
            uint64_t bits; memcpy(&bits, &small, sizeof(bits));
            uint32_t small_t = Emit_Temp(cg);
            Emit(cg, "  %%t%u = fadd double 0.0, 0x%016llX  ; small=%g\n",
                 small_t, (unsigned long long)bits, small);
            uint32_t div_t = Emit_Temp(cg);
            Emit(cg, "  %%t%u = fdiv double %%t%u, %%t%u\n", div_t, value, small_t);
            value = div_t;
        }
        const char *src_ftype = Float_Llvm_Type_Of(value_type);
        /* Ada RM 4.6: round to nearest before truncation */
        uint32_t rounded = Emit_Temp(cg);
        Emit(cg, "  %%t%u = call %s @llvm.round.%s(%s %%t%u)\n",
             rounded, src_ftype, src_ftype, src_ftype, value);
        uint32_t t = Emit_Temp(cg);
        Emit(cg, "  %%t%u = fptosi %s %%t%u to %s\n", t, src_ftype, rounded, type_str);
        value = t;
    } else if (not is_src_float and is_dst_float) {
        /* Integer to float: use sitofp — use native src/dst types */
        const char *src_type = Expression_Llvm_Type(cg, node->assignment.value);
        const char *dst_ftype = Float_Llvm_Type_Of(ty);
        uint32_t t = Emit_Temp(cg);
        Emit(cg, "  %%t%u = sitofp %s %%t%u to %s\n", t, src_type, value, dst_ftype);
        value = t;
    } else if (is_src_float and is_dst_float) {
        /* Float to float: may need conversion if sizes differ.
         * Determine actual source float type from the expression's type info. */
        const char *src_ftype = Float_Llvm_Type_Of(value_type);
        const char *dst_ftype = type_str;  /* actual storage type */
        if (strcmp(src_ftype, dst_ftype) != 0) {
            value = Emit_Convert(cg, value, src_ftype, dst_ftype);
        }
    } else {
        /* Integer/boolean to target type: use actual expression type.
         * constraint check BEFORE conversion, so the check
         * sees the value at its actual type (not yet converted). */
        const char *src_type_str = Expression_Llvm_Type(cg, node->assignment.value);
        if (ty and Type_Is_Scalar(ty)) {
            Type_Info *src_type_info = node->assignment.value->type;
            Emit_Constraint_Check_With_Type(cg, value, ty, src_type_info, src_type_str);
        }
        value = Emit_Convert(cg, value, src_type_str, type_str);
    }

    /* Float scalar constraint check — done after float conversion since
     * Emit_Constraint_Check's float path handles its own type conversion.
     * Pass actual_val_type so the check knows the current value width
     * (value may have been fptrunc'd/fpext'd above). */
    if (ty and Type_Is_Scalar(ty) and (is_src_float or is_dst_float)) {
        Type_Info *src_type_info = node->assignment.value->type;
        Emit_Constraint_Check_With_Type(cg, value, ty, src_type_info, type_str);
    }

    Emit(cg, "  store %s %%t%u, ptr ", type_str, value);
    Emit_Symbol_Storage(cg, target_sym);
    Emit(cg, "\n");
}

static void Generate_If_Statement(Code_Generator *cg, Syntax_Node *node) {
    Emit_Location(cg, node->location);
    Emit(cg, "  ; IF statement\n");

    uint32_t end_label = Emit_Label(cg);

    Emit(cg, "  ; -- evaluate condition\n");
    uint32_t cond = Generate_Expression(cg, node->if_stmt.condition);
    uint32_t then_label = Emit_Label(cg);
    uint32_t next_label = Emit_Label(cg);

    const char *cond_type = Expression_Llvm_Type(cg, node->if_stmt.condition);
    cond = Emit_Convert(cg, cond, cond_type, "i1");
    Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u  ; IF cond -> THEN / ELSE\n",
         cond, then_label, next_label);
    cg->block_terminated = true;

    Emit(cg, "\n  ; -- THEN branch\n");
    Emit_Label_Here(cg, then_label);
    Generate_Statement_List(cg, &node->if_stmt.then_stmts);
    Emit_Branch_If_Needed(cg, end_label);

    /* ELSIF parts: each is an NK_IF node with condition + then_stmts */
    for (uint32_t i = 0; i < node->if_stmt.elsif_parts.count; i++) {
        Syntax_Node *elsif = node->if_stmt.elsif_parts.items[i];
        Emit(cg, "\n  ; -- ELSIF #%u\n", i + 1);
        Emit_Location(cg, elsif->location);
        Emit_Label_Here(cg, next_label);

        uint32_t ec = Generate_Expression(cg, elsif->if_stmt.condition);
        uint32_t elsif_then = Emit_Label(cg);
        next_label = Emit_Label(cg);

        const char *ec_type = Expression_Llvm_Type(cg, elsif->if_stmt.condition);
        ec = Emit_Convert(cg, ec, ec_type, "i1");
        Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u  ; ELSIF cond\n",
             ec, elsif_then, next_label);
        cg->block_terminated = true;

        Emit_Label_Here(cg, elsif_then);
        Generate_Statement_List(cg, &elsif->if_stmt.then_stmts);
        Emit_Branch_If_Needed(cg, end_label);
    }

    Emit_Label_Here(cg, next_label);
    if (node->if_stmt.else_stmts.count > 0) {
        Emit(cg, "  ; -- ELSE branch\n");
        Generate_Statement_List(cg, &node->if_stmt.else_stmts);
    }
    Emit_Branch_If_Needed(cg, end_label);

    Emit(cg, "  ; -- END IF\n");
    Emit_Label_Here(cg, end_label);
}

static void Generate_Loop_Statement(Code_Generator *cg, Syntax_Node *node) {
    Emit_Location(cg, node->location);

    /* Emit LLVM label for Ada label (enables GOTO targeting this loop) */
    Symbol *label_sym = node->loop_stmt.label_symbol;
    if (label_sym) {
        Emit(cg, "  ; LOOP %.*s:\n",
             (int)label_sym->name.length, label_sym->name.data);
        if (label_sym->llvm_label_id == 0)
            label_sym->llvm_label_id = cg->label_id++;
        if (not cg->block_terminated) {
            Emit(cg, "  br label %%L%u\n", label_sym->llvm_label_id);
            cg->block_terminated = true;
        }
        Emit_Label_Here(cg, label_sym->llvm_label_id); /* loop label */
        cg->block_terminated = false;  /* New block started */
    } else {
        Emit(cg, "  ; LOOP (anonymous)\n");
    }

    uint32_t loop_start = Emit_Label(cg);
    uint32_t loop_body = Emit_Label(cg);
    uint32_t loop_end = Emit_Label(cg);

    uint32_t saved_exit = cg->loop_exit_label;
    uint32_t saved_cont = cg->loop_continue_label;
    cg->loop_exit_label = loop_end;
    cg->loop_continue_label = loop_start;

    /* Store exit label on loop symbol for named EXIT statements */
    if (label_sym) label_sym->loop_exit_label_id = loop_end;

    Emit_Branch_If_Needed(cg, loop_start);
    Emit(cg, "  ; -- loop header (L%u)\n", loop_start);
    Emit_Label_Here(cg, loop_start);

    /* Condition check for WHILE loops (FOR loops dispatched to Generate_For_Loop) */
    if (node->loop_stmt.iteration_scheme) {
        Emit(cg, "  ; -- WHILE condition\n");
        Syntax_Node *scheme = node->loop_stmt.iteration_scheme;
        uint32_t cond = Generate_Expression(cg, scheme);
        const char *cond_type = Expression_Llvm_Type(cg, scheme);
        cond = Emit_Convert(cg, cond, cond_type, "i1");
        Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u  ; WHILE cond -> body/exit\n",
             cond, loop_body, loop_end);
        cg->block_terminated = true;
    } else {
        Emit_Branch_If_Needed(cg, loop_body);
    }

    Emit(cg, "  ; -- loop body (L%u)\n", loop_body);
    Emit_Label_Here(cg, loop_body);
    Generate_Statement_List(cg, &node->loop_stmt.statements);
    Emit(cg, "  ; -- back to loop header\n");
    Emit_Branch_If_Needed(cg, loop_start);

    Emit(cg, "  ; -- END LOOP (L%u)\n", loop_end);
    Emit_Label_Here(cg, loop_end);

    cg->loop_exit_label = saved_exit;
    cg->loop_continue_label = saved_cont;
}

static void Generate_Return_Statement(Code_Generator *cg, Syntax_Node *node) {
    Emit_Location(cg, node->location);
    cg->has_return = true;

    /* Check if we're in a BIP function - result built into __BIPaccess */
    bool is_bip = BIP_In_BIP_Function();
    if (cg->current_function) {
        Emit(cg, "  ; RETURN from %.*s%s\n",
             (int)cg->current_function->name.length, cg->current_function->name.data,
             is_bip ? " (BIP)" : "");
    } else {
        Emit(cg, "  ; RETURN\n");
    }

    if (node->return_stmt.expression) {
        Syntax_Node *expr = node->return_stmt.expression;

        /* For BIP functions, build result directly into destination */
        if (is_bip and cg->current_function and cg->current_function->return_type) {
            Type_Info *ret_type = cg->current_function->return_type;

            /* Generate expression and copy to __BIPaccess destination */
            if (Type_Is_Record(ret_type) or Type_Is_Array_Like(ret_type)) {
                /* Composite: generate expression (gives ptr), memcpy to dest */
                uint32_t value = Generate_Expression(cg, expr);
                uint32_t size = ret_type->size > 0 ? ret_type->size : 8;
                Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%__BIPaccess, ptr %%t%u, i64 %u, i1 false)  ; BIP return\n",
                     value, size);
            } else {
                /* Scalar: generate, convert, store to destination */
                uint32_t value = Generate_Expression(cg, expr);
                const char *type_str = Type_To_Llvm_Sig(ret_type);
                const char *expr_type = Expression_Llvm_Type(cg, expr);
                value = Emit_Convert(cg, value, expr_type, type_str);
                Emit(cg, "  store %s %%t%u, ptr %%__BIPaccess  ; BIP scalar return\n",
                     type_str, value);
            }
            Emit(cg, "  ret void\n");
            cg->block_terminated = true;
            BIP_End_Function();
            return;
        }

        uint32_t value = Generate_Expression(cg, expr);
        const char *type_str = cg->current_function and cg->current_function->return_type
            ? Type_To_Llvm_Sig(cg->current_function->return_type) : Integer_Arith_Type(cg);
        /* Convert from expression type to return type */
        Type_Info *ret_type = cg->current_function ? cg->current_function->return_type : NULL;
        const char *actual_ty = Temp_Get_Type(cg, value);
        bool val_is_float = (actual_ty and Is_Float_Type(actual_ty)) or
                            Type_Is_Float_Representation(expr->type) or
                            (expr->type and expr->type->kind == TYPE_UNIVERSAL_REAL);
        if (ret_type and Type_Is_Fixed_Point(ret_type) and val_is_float) {
            /* Float expression > fixed-point return: divide by SMALL, fptosi */
            double small = ret_type->fixed.small;
            if (small <= 0) small = ret_type->fixed.delta > 0 ? ret_type->fixed.delta : 1.0;
            uint64_t bits; memcpy(&bits, &small, sizeof(bits));
            const char *src_fty = actual_ty ? actual_ty : "double";
            uint32_t small_t = Emit_Temp(cg);
            Emit(cg, "  %%t%u = fadd %s 0.0, 0x%016llX  ; small=%g\n",
                 small_t, src_fty, (unsigned long long)bits, small);
            uint32_t div_t = Emit_Temp(cg);
            Emit(cg, "  %%t%u = fdiv %s %%t%u, %%t%u\n", div_t, src_fty, value, small_t);
            uint32_t conv_t = Emit_Temp(cg);
            Emit(cg, "  %%t%u = fptosi %s %%t%u to %s\n", conv_t, src_fty, div_t, type_str);
            value = conv_t;
        } else {
            const char *expr_type = Expression_Llvm_Type(cg, expr);
            value = Emit_Convert(cg, value, expr_type, type_str);
        }
        /* RM 6.5: Check return value against function return subtype constraint */
        if (ret_type and Type_Is_Scalar(ret_type)) {
            Emit_Constraint_Check_With_Type(cg, value, ret_type, expr->type, type_str);
        }
        /* RM 6.5(3): For constrained access subtypes, check that the
         * designated object's discriminant/bounds match the constraint.
         * Apply_Type_Conversion with access target calls
         * Apply_Discriminant_Check on the designated object. */
        if (ret_type and Type_Is_Access(ret_type) and ret_type->access.designated_type) {
            Type_Info *des = ret_type->access.designated_type;
            if (des->kind == TYPE_RECORD and des->record.has_disc_constraints and
                des->record.discriminant_count > 0 and des->record.disc_constraint_values) {
                /* Non-null check first, then discriminant check */
                uint32_t is_null = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp eq ptr %%t%u, null\n", is_null, value);
                uint32_t skip_lbl = Emit_Label(cg);
                uint32_t chk_lbl  = Emit_Label(cg);
                Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n",
                     is_null, skip_lbl, chk_lbl);
                cg->block_terminated = true;
                Emit_Label_Here(cg, chk_lbl);
                /* Load discriminant from designated object (offset 0, first component) */
                Component_Info *dc = &des->record.components[0];
                const char *disc_ty = dc->component_type ? Type_To_Llvm(dc->component_type)
                                                         : Integer_Arith_Type(cg);
                uint32_t dp = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %u\n",
                     dp, value, dc->byte_offset);
                uint32_t dv = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", dv, disc_ty, dp);
                const char *iat = Integer_Arith_Type(cg);
                dv = Emit_Convert(cg, dv, disc_ty, iat);
                uint32_t ev = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s 0, %lld\n", ev, iat,
                     (long long)des->record.disc_constraint_values[0]);
                Emit_Discriminant_Check(cg, dv, ev, iat, des);
                Emit(cg, "  br label %%L%u\n", skip_lbl);
                cg->block_terminated = true;
                Emit_Label_Here(cg, skip_lbl);
                cg->block_terminated = false;
            }
            /* Array-constrained access: check bounds of designated array */
            if (Type_Is_Array_Like(des) and des->array.is_constrained and
                des->array.index_count > 0) {
                uint32_t is_null = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp eq ptr %%t%u, null\n", is_null, value);
                uint32_t skip_lbl = Emit_Label(cg);
                uint32_t chk_lbl  = Emit_Label(cg);
                Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n",
                     is_null, skip_lbl, chk_lbl);
                cg->block_terminated = true;
                Emit_Label_Here(cg, chk_lbl);
                /* Fat pointer access: bounds are in the fat ptr, not the object.
                 * For heap arrays the bounds are stored before the data. Load them
                 * and compare against the constrained subtype's bounds. */
                const char *bt = Array_Bound_Llvm_Type(des);
                int128_t exp_lo = Array_Low_Bound(des);
                int128_t exp_hi = (des->array.index_count > 0 and des->array.indices)
                    ? Type_Bound_Value(des->array.indices[0].high_bound) : 0;
                /* Load actual bounds: stored at [-16] and [-8] before data */
                uint32_t blo_p = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, i64 -2\n", blo_p, bt, value);
                uint32_t blo = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", blo, bt, blo_p);
                uint32_t bhi_p = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr %s, ptr %%t%u, i64 -1\n", bhi_p, bt, value);
                uint32_t bhi = Emit_Temp(cg);
                Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", bhi, bt, bhi_p);
                /* Compare lo and hi */
                const char *iat = Integer_Arith_Type(cg);
                blo = Emit_Convert(cg, blo, bt, iat);
                bhi = Emit_Convert(cg, bhi, bt, iat);
                uint32_t elo = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s 0, %s\n", elo, iat, I128_Decimal(exp_lo));
                uint32_t ehi = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s 0, %s\n", ehi, iat, I128_Decimal(exp_hi));
                uint32_t clo = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp ne %s %%t%u, %%t%u\n", clo, iat, blo, elo);
                uint32_t chi = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp ne %s %%t%u, %%t%u\n", chi, iat, bhi, ehi);
                uint32_t bad = Emit_Temp(cg);
                Emit(cg, "  %%t%u = or i1 %%t%u, %%t%u\n", bad, clo, chi);
                uint32_t raise_lbl = Emit_Label(cg);
                uint32_t ok_lbl = Emit_Label(cg);
                Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n", bad, raise_lbl, ok_lbl);
                cg->block_terminated = true;
                Emit_Label_Here(cg, raise_lbl);
                Emit_Raise_Constraint_Error(cg, "access array bounds check");
                Emit_Label_Here(cg, ok_lbl);
                Emit(cg, "  br label %%L%u\n", skip_lbl);
                cg->block_terminated = true;
                Emit_Label_Here(cg, skip_lbl);
                cg->block_terminated = false;
            }
        }
        /* RM 6.5: For unconstrained array returns, the data pointer in the fat
         * pointer points to a local alloca that becomes invalid after return.
         * Copy the data to the secondary stack so it survives (GNAT LLVM:
         * Build_Allocate_For_Return with secondary stack allocation). */
        if (ret_type and Type_Is_Array_Like(ret_type) and not ret_type->array.is_constrained and
            type_str and strstr(type_str, "{ ptr, ptr }") != NULL) {
            const char *rbt = Array_Bound_Llvm_Type(ret_type);
            uint32_t old_data = Emit_Fat_Pointer_Data(cg, value, rbt);
            /* Compute total byte size from bounds */
            uint32_t ndims = ret_type->array.index_count;
            if (ndims < 1) ndims = 1;
            uint32_t scalar_sz = ret_type->array.element_type ?
                                 ret_type->array.element_type->size : 1;
            uint32_t total = 0;
            for (uint32_t d = 0; d < ndims; d++) {
                uint32_t dl = Emit_Fat_Pointer_Low_Dim(cg, value, rbt, d);
                uint32_t dh = Emit_Fat_Pointer_High_Dim(cg, value, rbt, d);
                uint32_t dim_len = Emit_Length_From_Bounds(cg, dl, dh, rbt);
                uint32_t conv = Emit_Convert(cg, dim_len, rbt, Integer_Arith_Type(cg));
                if (d == 0) { total = conv; }
                else {
                    uint32_t p = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = mul %s %%t%u, %%t%u\n", p, Integer_Arith_Type(cg), total, conv);
                    total = p;
                }
            }
            uint32_t bsz = Emit_Temp(cg);
            Emit(cg, "  %%t%u = mul %s %%t%u, %u\n", bsz, Integer_Arith_Type(cg), total, scalar_sz);
            uint32_t bsz64 = Emit_Extend_To_I64(cg, bsz, Integer_Arith_Type(cg));
            uint32_t sec_data = Emit_Temp(cg);
            Emit(cg, "  %%t%u = call ptr @__ada_sec_stack_alloc(i64 %%t%u)\n", sec_data, bsz64);
            Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)\n",
                 sec_data, old_data, bsz64);
            /* Copy bounds to secondary stack too (also on callee stack) */
            uint32_t old_bnd = Emit_Temp(cg);
            Emit(cg, "  %%t%u = extractvalue " FAT_PTR_TYPE " %%t%u, 1\n", old_bnd, value);
            uint32_t bnd_bytes = ndims * 2 * (uint32_t)(strcmp(rbt, "i64") == 0 ? 8 : 4);
            uint32_t sec_bnd = Emit_Temp(cg);
            Emit(cg, "  %%t%u = call ptr @__ada_sec_stack_alloc(i64 %u)\n", sec_bnd, bnd_bytes);
            Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %u, i1 false)\n",
                 sec_bnd, old_bnd, bnd_bytes);
            /* Rebuild fat pointer with secondary stack data and bounds */
            uint32_t new_fp = Emit_Temp(cg);
            Emit(cg, "  %%t%u = insertvalue " FAT_PTR_TYPE " undef, ptr %%t%u, 0\n", new_fp, sec_data);
            uint32_t new_fp2 = Emit_Temp(cg);
            Emit(cg, "  %%t%u = insertvalue " FAT_PTR_TYPE " %%t%u, ptr %%t%u, 1\n", new_fp2, new_fp, sec_bnd);
            value = new_fp2;
        }
        Emit(cg, "  ret %s %%t%u\n", type_str, value);
        cg->block_terminated = true;
    } else if (cg->in_task_body) {
        /* Task entry points return ptr for pthread compatibility */
        Emit(cg, "  ret ptr null\n");
        cg->block_terminated = true;
    } else {
        Emit(cg, "  ret void\n");
        cg->block_terminated = true;
    }
}

static void Generate_Case_Statement(Code_Generator *cg, Syntax_Node *node) {
    /* CASE expr IS WHEN choice => stmts; ... END CASE; */
    Emit_Location(cg, node->location);
    Emit(cg, "  ; CASE statement\n");
    Emit(cg, "  ; -- evaluate selector expression\n");
    uint32_t selector = Generate_Expression(cg, node->case_stmt.expression);
    const char *case_type = Expression_Llvm_Type(cg, node->case_stmt.expression);
    /* Coerce selector to its declared type (arithmetic may widen to i32) */
    selector = Emit_Coerce(cg, selector, case_type);
    uint32_t end_label = Emit_Label(cg);

    /* Generate switch-like structure using branches */
    uint32_t num_alts = node->case_stmt.alternatives.count;
    uint32_t *alt_labels = Arena_Allocate(num_alts * sizeof(uint32_t));

    /* Allocate labels for each alternative */
    for (uint32_t i = 0; i < num_alts; i++) {
        alt_labels[i] = Emit_Label(cg);
    }

    /* Generate branching logic */
    Emit(cg, "  ; -- test %u alternative(s)\n", num_alts);
    for (uint32_t i = 0; i < num_alts; i++) {
        Syntax_Node *alt = node->case_stmt.alternatives.items[i];
        uint32_t next_check = (i + 1 < num_alts) ? Emit_Label(cg) : end_label;

        Emit(cg, "  ; -- WHEN alternative #%u (%u choice(s))\n",
             i + 1, alt->association.choices.count);
        /* Check each choice in this alternative */
        for (uint32_t j = 0; j < alt->association.choices.count; j++) {
            Syntax_Node *choice = alt->association.choices.items[j];

            if (choice->kind == NK_OTHERS) {
                /* OTHERS matches everything - jump to alternative */
                Emit(cg, "  br label %%L%u\n", alt_labels[i]);
            } else if (choice->kind == NK_RANGE) {
                /* Range check: low <= selector <= high */
                uint32_t low = Generate_Expression(cg, choice->range.low);
                uint32_t high = Generate_Expression(cg, choice->range.high);
                /* Normalize range bounds to selector type */
                const char *low_t = Expression_Llvm_Type(cg, choice->range.low);
                const char *high_t = Expression_Llvm_Type(cg, choice->range.high);
                if (strcmp(low_t, case_type) != 0)
                    low = Emit_Convert(cg, low, low_t, case_type);
                if (strcmp(high_t, case_type) != 0)
                    high = Emit_Convert(cg, high, high_t, case_type);
                uint32_t cmp1 = Emit_Temp(cg);
                uint32_t cmp2 = Emit_Temp(cg);
                uint32_t both = Emit_Temp(cg);

                Emit(cg, "  %%t%u = icmp sle %s %%t%u, %%t%u\n", cmp1, case_type, low, selector);
                Emit(cg, "  %%t%u = icmp sle %s %%t%u, %%t%u\n", cmp2, case_type, selector, high);
                Emit(cg, "  %%t%u = and i1 %%t%u, %%t%u\n", both, cmp1, cmp2);

                uint32_t next_choice = (j + 1 < alt->association.choices.count) ?
                                       Emit_Label(cg) : next_check;
                Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n",
                     both, alt_labels[i], next_choice);

                if (j + 1 < alt->association.choices.count) {
                    Emit_Label_Here(cg, next_choice);
                }
            } else if (choice->kind == NK_SUBTYPE_INDICATION) {
                /* Subtype range: WHEN T RANGE low..high => (RM 5.4) */
                uint32_t low, high;
                const char *bound_type = case_type;
                Syntax_Node *constraint = choice->subtype_ind.constraint;
                if (constraint and constraint->kind == NK_RANGE_CONSTRAINT and
                    constraint->range_constraint.range and
                    constraint->range_constraint.range->kind == NK_RANGE) {
                    low = Generate_Expression(cg, constraint->range_constraint.range->range.low);
                    high = Generate_Expression(cg, constraint->range_constraint.range->range.high);
                    bound_type = Expression_Llvm_Type(cg, constraint->range_constraint.range->range.low);
                } else {
                    /* Bare subtype name: WHEN SUBTYPE => use declared bounds */
                    Bound_Temps bounds = Emit_Bounds(cg, choice->type, 0);
                    low = bounds.low_temp;
                    high = bounds.high_temp;
                    bound_type = bounds.bound_type;
                }
                /* Coerce bounds to selector type for icmp */
                if (strcmp(bound_type, case_type) != 0) {
                    low = Emit_Convert(cg, low, bound_type, case_type);
                    high = Emit_Convert(cg, high, bound_type, case_type);
                }
                uint32_t cmp1 = Emit_Temp(cg);
                uint32_t cmp2 = Emit_Temp(cg);
                uint32_t both = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp sle %s %%t%u, %%t%u\n", cmp1, case_type, low, selector);
                Emit(cg, "  %%t%u = icmp sle %s %%t%u, %%t%u\n", cmp2, case_type, selector, high);
                Emit(cg, "  %%t%u = and i1 %%t%u, %%t%u\n", both, cmp1, cmp2);

                uint32_t next_choice = (j + 1 < alt->association.choices.count) ?
                                       Emit_Label(cg) : next_check;
                Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n",
                     both, alt_labels[i], next_choice);

                if (j + 1 < alt->association.choices.count) {
                    Emit_Label_Here(cg, next_choice);
                }
            } else if (choice->symbol and
                       (choice->symbol->kind == SYMBOL_TYPE or
                        choice->symbol->kind == SYMBOL_SUBTYPE) and
                       choice->symbol->type) {
                /* Bare subtype name as case choice (RM 5.4): range check */
                Bound_Temps bounds = Emit_Bounds(cg, choice->symbol->type, 0);
                uint32_t low = bounds.low_temp, high = bounds.high_temp;
                /* Coerce to selector type if needed */
                if (strcmp(bounds.bound_type, case_type) != 0) {
                    low = Emit_Convert(cg, low, bounds.bound_type, case_type);
                    high = Emit_Convert(cg, high, bounds.bound_type, case_type);
                }
                uint32_t cmp1 = Emit_Temp(cg), cmp2 = Emit_Temp(cg), both = Emit_Temp(cg);
                Emit(cg, "  %%t%u = icmp sle %s %%t%u, %%t%u\n", cmp1, case_type, low, selector);
                Emit(cg, "  %%t%u = icmp sle %s %%t%u, %%t%u\n", cmp2, case_type, selector, high);
                Emit(cg, "  %%t%u = and i1 %%t%u, %%t%u\n", both, cmp1, cmp2);
                uint32_t next_choice = (j + 1 < alt->association.choices.count) ?
                                       Emit_Label(cg) : next_check;
                Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n",
                     both, alt_labels[i], next_choice);
                if (j + 1 < alt->association.choices.count)
                    Emit_Label_Here(cg, next_choice);
            } else {
                /* Single value check */
                uint32_t val = Generate_Expression(cg, choice);
                /* Normalize choice value to selector type (e.g. boolean
                 * expressions produce i1 but BOOLEAN selector is i8). */
                const char *val_type = Expression_Llvm_Type(cg, choice);
                if (strcmp(val_type, case_type) != 0) {
                    val = Emit_Convert(cg, val, val_type, case_type);
                }
                uint32_t cmp = Emit_Temp(cg);

                Emit(cg, "  %%t%u = icmp eq %s %%t%u, %%t%u\n", cmp, case_type, selector, val);

                uint32_t next_choice = (j + 1 < alt->association.choices.count) ?
                                       Emit_Label(cg) : next_check;
                Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n",
                     cmp, alt_labels[i], next_choice);

                if (j + 1 < alt->association.choices.count) {
                    Emit_Label_Here(cg, next_choice);
                }
            }
        }

        if (i + 1 < num_alts) {
            Emit_Label_Here(cg, next_check);
        }
    }

    /* Generate alternative bodies - expression is a block with statements */
    Emit(cg, "  ; -- CASE alternative bodies\n");
    for (uint32_t i = 0; i < num_alts; i++) {
        Syntax_Node *alt = node->case_stmt.alternatives.items[i];
        Emit(cg, "  ; -- alternative #%u body (L%u)\n", i + 1, alt_labels[i]);
        Emit_Label_Here(cg, alt_labels[i]);
        if (alt->association.expression and
            alt->association.expression->kind == NK_BLOCK) {
            Generate_Statement_List(cg, &alt->association.expression->block_stmt.statements);
        }
        Emit_Branch_If_Needed(cg, end_label);
    }

    Emit(cg, "  ; -- END CASE (L%u)\n", end_label);
    Emit_Label_Here(cg, end_label);
}

static void Generate_For_Loop(Code_Generator *cg, Syntax_Node *node) {
    /* FOR loop with iteration variable - iteration_scheme is NK_BINARY_OP TK_IN */
    Syntax_Node *iter = node->loop_stmt.iteration_scheme;
    if (not iter or iter->kind != NK_BINARY_OP or iter->binary.op != TK_IN) {
        /* Not a FOR loop - fall back to simple loop */
        return;
    }

    Syntax_Node *loop_id = iter->binary.left;
    Syntax_Node *range = iter->binary.right;
    Symbol *loop_var = loop_id->symbol;
    bool is_reverse = node->loop_stmt.is_reverse;

    /* Emit source location and FOR loop header comment */
    Emit_Location(cg, node->location);
    Symbol *label_sym = node->loop_stmt.label_symbol;
    if (label_sym) {
        Emit(cg, "  ; FOR %.*s IN %s", (int)label_sym->name.length, label_sym->name.data,
             is_reverse ? "REVERSE" : "");
    } else if (loop_var) {
        Emit(cg, "  ; FOR %.*s IN %s", (int)loop_var->name.length, loop_var->name.data,
             is_reverse ? "REVERSE" : "");
    } else {
        Emit(cg, "  ; FOR <anon> IN %s", is_reverse ? "REVERSE" : "");
    }
    Emit(cg, " ... LOOP\n");

    uint32_t loop_start = Emit_Label(cg);
    uint32_t loop_body = Emit_Label(cg);
    uint32_t loop_end = Emit_Label(cg);

    /* Store exit label on loop symbol for named EXIT statements */
    if (label_sym) label_sym->loop_exit_label_id = loop_end;

    uint32_t saved_exit = cg->loop_exit_label;
    cg->loop_exit_label = loop_end;

    /* Allocate loop variable — use native Integer type, not i64 */
    const char *loop_type = Integer_Arith_Type(cg);
    if (loop_var) {
        Emit(cg, "  ; -- alloca loop variable %.*s\n",
             (int)loop_var->name.length, loop_var->name.data);
        Emit(cg, "  %%");
        Emit_Symbol_Name(cg, loop_var);
        Emit(cg, " = alloca %s\n", loop_type);
    }

    /* Get range bounds */
    Emit(cg, "  ; -- compute range bounds\n");
    uint32_t low_val, high_val;
    if (range and range->kind == NK_RANGE) {
        low_val = Generate_Expression(cg, range->range.low);
        high_val = Generate_Expression(cg, range->range.high);
        /* Convert bounds to loop_type — Generate_Expression may produce at
         * a narrower type (e.g. i8 for CHARACTER ranges). */
        low_val = Emit_Coerce(cg, low_val, loop_type);
        high_val = Emit_Coerce(cg, high_val, loop_type);
    } else if (range and range->kind == NK_ATTRIBUTE and
               Slice_Equal_Ignore_Case(range->attribute.name, S("RANGE"))) {
        /* X'RANGE attribute - need to generate both 'FIRST and 'LAST */
        Type_Info *prefix_type = range->attribute.prefix->type;
        Symbol *prefix_sym = range->attribute.prefix->symbol;

        /* Check if this is an unconstrained array needing runtime bounds */
        Syntax_Node *range_arg_f = range->attribute.arguments.count > 0
                                 ? range->attribute.arguments.items[0] : NULL;
        uint32_t for_dim = Get_Dimension_Index(range_arg_f);
        if (prefix_type and Type_Is_Unconstrained_Array(prefix_type) and
            prefix_sym and (prefix_sym->kind == SYMBOL_PARAMETER or
                           prefix_sym->kind == SYMBOL_VARIABLE or
                           prefix_sym->kind == SYMBOL_DISCRIMINANT)) {
            const char *loop_bt = Array_Bound_Llvm_Type(prefix_type);
            uint32_t fat = Emit_Load_Fat_Pointer(cg, prefix_sym, loop_bt);
            Bound_Temps bounds = Emit_Bounds_From_Fat_Dim(cg, fat, loop_bt, for_dim);
            /* Convert bounds from native bt to loop type */
            low_val = Emit_Convert(cg, bounds.low_temp, loop_bt, loop_type);
            high_val = Emit_Convert(cg, bounds.high_temp, loop_bt, loop_type);
        } else if (Type_Is_Array_Like(prefix_type)) {
            /* Constrained array - use compile-time bounds */
            Syntax_Node *range_arg = range->attribute.arguments.count > 0
                                   ? range->attribute.arguments.items[0] : NULL;
            uint32_t dim = Get_Dimension_Index(range_arg);
            if (dim < prefix_type->array.index_count) {
                Bound_Temps bounds = Emit_Bounds(cg, prefix_type, dim);
                low_val = bounds.low_temp;
                high_val = bounds.high_temp;
            } else {
                fprintf(stderr, "warning: FOR loop RANGE attribute dimension out of bounds, defaulting to 0\n");
                low_val = high_val = 0;
            }
        } else {
            /* ??? */
            low_val = Generate_Expression(cg, range);
            high_val = low_val;
        }
    } else if (range and range->kind == NK_SUBTYPE_INDICATION) {
        /* Subtype indication with constraint: SUBTYPE_NAME RANGE low..high
         * Per Ada RM 3.6.1(4)/5.5(9): the bounds of the discrete_range
         * must belong to the subtype — CONSTRAINT_ERROR is raised otherwise.
         * Apply_Range_Check on both low and high bounds. */
        Syntax_Node *constraint = range->subtype_ind.constraint;
        if (constraint and constraint->kind == NK_RANGE_CONSTRAINT and
            constraint->range_constraint.range) {
            Syntax_Node *actual_range = constraint->range_constraint.range;
            if (actual_range->kind == NK_RANGE) {
                low_val = Generate_Expression(cg, actual_range->range.low);
                high_val = Generate_Expression(cg, actual_range->range.high);
                low_val = Emit_Coerce(cg, low_val, loop_type);
                high_val = Emit_Coerce(cg, high_val, loop_type);

                /* RM 3.2.2(11): check range bounds against subtype ST.
                 * Null ranges (low > high) are always compatible.
                 * Apply_Range_Check on both bounds. */
                Type_Info *st = range->subtype_ind.subtype_mark
                              ? range->subtype_ind.subtype_mark->type : NULL;
                if (st) {
                    uint32_t is_null = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = icmp sgt %s %%t%u, %%t%u\n",
                         is_null, loop_type, low_val, high_val);
                    uint32_t chk_lbl = Emit_Label(cg);
                    uint32_t skip_lbl = Emit_Label(cg);
                    Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n",
                         is_null, skip_lbl, chk_lbl);
                    cg->block_terminated = true;
                    Emit_Label_Here(cg, chk_lbl);
                    Emit_Constraint_Check(cg, low_val, st, NULL);
                    Emit_Constraint_Check(cg, high_val, st, NULL);
                    Emit(cg, "  br label %%L%u\n", skip_lbl);
                    cg->block_terminated = true;
                    Emit_Label_Here(cg, skip_lbl);
                }
            } else {
                /* Range might be a name like T'RANGE */
                low_val = Generate_Expression(cg, actual_range);
                high_val = low_val;
            }
        } else {
            /* No range constraint - use the subtype's type bounds */
            Bound_Temps b = Emit_Bounds(cg, range->type, 0);
            low_val = b.low_temp;
            high_val = b.high_temp;
        }
    } else if (range and range->kind == NK_IDENTIFIER) {
        /* Just a type name: FOR I IN TYPE_NAME LOOP - iterate over type's range */
        Bound_Temps b = Emit_Bounds(cg, range->type, 0);
        low_val = b.low_temp;
        high_val = b.high_temp;
    } else {
        /* Other expression - evaluate as low bound, assume scalar with same high */
        low_val = Generate_Expression(cg, range);
        high_val = low_val;
    }

    /* Initialize loop variable */
    if (loop_var) {
        Emit(cg, "  ; -- init %.*s := %s bound\n",
             (int)loop_var->name.length, loop_var->name.data,
             is_reverse ? "high" : "low");
        Emit(cg, "  store %s %%t%u, ptr %%", loop_type, is_reverse ? high_val : low_val);
        Emit_Symbol_Name(cg, loop_var);
        Emit(cg, "\n");
    }

    /* Loop start - check condition */
    Emit(cg, "  ; -- loop header (L%u)\n", loop_start);
    Emit(cg, "  br label %%L%u\n", loop_start);
    cg->block_terminated = true;
    Emit_Label_Here(cg, loop_start);

    uint32_t cur = Emit_Temp(cg);
    if (loop_var) {
        Emit(cg, "  ; -- load current %.*s\n",
             (int)loop_var->name.length, loop_var->name.data);
        Emit(cg, "  %%t%u = load %s, ptr %%", cur, loop_type);
        Emit_Symbol_Name(cg, loop_var);
        Emit(cg, "\n");
    }

    uint32_t cond = Emit_Temp(cg);
    if (is_reverse) {
        Emit(cg, "  %%t%u = icmp sge %s %%t%u, %%t%u  ; %.*s >= low?\n",
             cond, loop_type, cur, low_val,
             loop_var ? (int)loop_var->name.length : 1,
             loop_var ? loop_var->name.data : "?");
    } else {
        Emit(cg, "  %%t%u = icmp sle %s %%t%u, %%t%u  ; %.*s <= high?\n",
             cond, loop_type, cur, high_val,
             loop_var ? (int)loop_var->name.length : 1,
             loop_var ? loop_var->name.data : "?");
    }
    Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u  ; -> body / end\n", cond, loop_body, loop_end);
    cg->block_terminated = true;

    /* Loop body */
    Emit(cg, "  ; -- loop body (L%u)\n", loop_body);
    Emit_Label_Here(cg, loop_body);
    Generate_Statement_List(cg, &node->loop_stmt.statements);

    /* Ada RM 5.5: loop parameter takes each value exactly once.
     * Must check if cur == final_value BEFORE incrementing to avoid
     * overflow when iterating up to TYPE'LAST or down to TYPE'FIRST. */
    Emit(cg, "  ; -- check if at final value before %s\n", is_reverse ? "decrement" : "increment");
    if (loop_var) {
        uint32_t at_end = Emit_Temp(cg);
        if (is_reverse) {
            Emit(cg, "  %%t%u = icmp eq %s %%t%u, %%t%u  ; %.*s = low? (exit before underflow)\n",
                 at_end, loop_type, cur, low_val,
                 (int)loop_var->name.length, loop_var->name.data);
        } else {
            Emit(cg, "  %%t%u = icmp eq %s %%t%u, %%t%u  ; %.*s = high? (exit before overflow)\n",
                 at_end, loop_type, cur, high_val,
                 (int)loop_var->name.length, loop_var->name.data);
        }
        uint32_t loop_inc = Emit_Label(cg);
        Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u  ; -> end / inc\n",
             at_end, loop_end, loop_inc);
        cg->block_terminated = true;
        Emit(cg, "  ; -- loop increment (L%u)\n", loop_inc);
        Emit_Label_Here(cg, loop_inc);

        uint32_t next = Emit_Temp(cg);
        if (is_reverse) {
            Emit(cg, "  %%t%u = sub %s %%t%u, 1  ; %.*s - 1\n",
                 next, loop_type, cur, (int)loop_var->name.length, loop_var->name.data);
        } else {
            Emit(cg, "  %%t%u = add %s %%t%u, 1  ; %.*s + 1\n",
                 next, loop_type, cur, (int)loop_var->name.length, loop_var->name.data);
        }
        Emit(cg, "  store %s %%t%u, ptr %%", loop_type, next);
        Emit_Symbol_Name(cg, loop_var);
        Emit(cg, "\n");
    }

    Emit(cg, "  ; -- back to loop header\n");
    Emit(cg, "  br label %%L%u\n", loop_start);
    cg->block_terminated = true;
    Emit(cg, "  ; -- END FOR LOOP (L%u)\n", loop_end);
    Emit_Label_Here(cg, loop_end);

    cg->loop_exit_label = saved_exit;
}

/* ─────────────────────────────────────────────────────────────────────────
 * §13.4.8 Exception Handling
 *
 * The stack unwinder's memory is what makes exceptions possible.
 * ───────────────────────────────────────────────────────────────────────── */

/* Forward declarations */
static void Generate_Declaration_List(Code_Generator *cg, Node_List *list);
static void Generate_Generic_Instance_Body(Code_Generator *cg, Symbol *inst_sym, Syntax_Node *template_body);
static void Generate_Task_Body(Code_Generator *cg, Syntax_Node *node);
static void Generate_Subprogram_Body(Code_Generator *cg, Syntax_Node *node);

static void Generate_Raise_Statement(Code_Generator *cg, Syntax_Node *node) {
    /* RAISE E; or RAISE; (reraise) */
    Emit_Location(cg, node->location);
    if (node->raise_stmt.exception_name) {
        Symbol *exc = node->raise_stmt.exception_name->symbol;
        if (exc) {
            Emit(cg, "  ; RAISE ");
            Emit_Symbol_Name(cg, exc);
            Emit(cg, "\n");

            /* Store exception identity and call __ada_raise */
            uint32_t exc_addr = Emit_Temp(cg);
            Emit(cg, "  %%t%u = ptrtoint ptr ", exc_addr);
            Emit_Exception_Ref(cg, exc);
            Emit(cg, " to i64\n");
            Emit(cg, "  call void @__ada_raise(i64 %%t%u)\n", exc_addr);
        }
    } else {
        /* Reraise current exception */
        Emit(cg, "  ; RAISE (reraise)\n");
        Emit(cg, "  call void @__ada_reraise()\n");
    }
    Emit(cg, "  unreachable\n");
}

static void Generate_Block_Statement(Code_Generator *cg, Syntax_Node *node) {
    /* Emit location and block info comment */
    Emit_Location(cg, node->location);
    Symbol *label_sym = node->block_stmt.label_symbol;
    if (label_sym) {
        Emit(cg, "  ; BLOCK %.*s:\n", (int)label_sym->name.length, label_sym->name.data);
    } else {
        Emit(cg, "  ; BLOCK (anonymous)\n");
    }

    /* Emit LLVM label for Ada label (enables GOTO targeting this block) */
    if (label_sym) {
        if (label_sym->llvm_label_id == 0)
            label_sym->llvm_label_id = cg->label_id++;
        if (not cg->block_terminated) {
            Emit(cg, "  br label %%L%u\n", label_sym->llvm_label_id);
            cg->block_terminated = true;
        }
        Emit(cg, "  ; -- block entry (L%u)\n", label_sym->llvm_label_id);
        Emit_Label_Here(cg, label_sym->llvm_label_id); /* block label */
        cg->block_terminated = false;  /* New block started */
    }

    /* Block with optional declarations and exception handlers */
    bool has_handlers = node->block_stmt.handlers.count > 0;

    if (has_handlers) {
        /* Per Ada RM: Exception handlers only cover the statement part,
         * NOT the declarative part. Exceptions in declarations propagate
         * to the enclosing block's handler. */
        Emit(cg, "  ; -- has %u exception handler(s)\n", node->block_stmt.handlers.count);

        /* Allocate handler frame first (needed for stack allocation order) */
        Emit(cg, "  ; -- alloca exception handler frame\n");
        uint32_t handler_frame = Emit_Temp(cg);
        Emit(cg, "  %%t%u = alloca { ptr, [200 x i8] }, align 16  ; handler frame\n", handler_frame);

        /* Generate declarations BEFORE setting up the exception handler.
         * This ensures exceptions in declarative part propagate outward. */
        Emit(cg, "  ; -- block declarations (not covered by handler)\n");
        Generate_Declaration_List(cg, &node->block_stmt.declarations);

        /* Now setup exception handling for the statement part only */
        Emit(cg, "  ; -- setup exception handler for statement part\n");
        uint32_t handler_label = Emit_Label(cg);
        uint32_t normal_label = Emit_Label(cg);
        uint32_t end_label = Emit_Label(cg);

        /* Push exception handler */
        Emit(cg, "  ; -- push handler and call setjmp\n");
        Emit(cg, "  call void @__ada_push_handler(ptr %%t%u)\n", handler_frame);

        /* Call setjmp on the jmp_buf field (field 1) */
        uint32_t jmp_buf = Emit_Temp(cg);
        Emit(cg, "  %%t%u = getelementptr { ptr, [200 x i8] }, ptr %%t%u, i32 0, i32 1\n",
             jmp_buf, handler_frame);
        uint32_t setjmp_result = Emit_Temp(cg);
        Emit(cg, "  %%t%u = call i32 @setjmp(ptr %%t%u)\n", setjmp_result, jmp_buf);

        /* Branch based on setjmp return */
        uint32_t is_normal = Emit_Temp(cg);
        Emit(cg, "  %%t%u = icmp eq i32 %%t%u, 0\n", is_normal, setjmp_result);
        Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n",
             is_normal, normal_label, handler_label);
        cg->block_terminated = true;  /* conditional branch terminates block */

        /* Normal execution path */
        Emit(cg, "  ; -- normal execution (L%u)\n", normal_label);
        Emit_Label_Here(cg, normal_label);

        /* Save and set exception context */
        uint32_t saved_handler = cg->exception_handler_label;
        uint32_t saved_jmp_buf = cg->exception_jmp_buf;
        bool saved_in_region = cg->in_exception_region;

        cg->exception_handler_label = handler_label;
        cg->exception_jmp_buf = jmp_buf;
        cg->in_exception_region = true;

        /* Generate block statements (handler covers only this part) */
        Emit(cg, "  ; -- BEGIN block statements (covered by handler)\n");
        Generate_Statement_List(cg, &node->block_stmt.statements);

        /* Pop handler on normal exit */
        Emit(cg, "  ; -- normal exit: pop handler\n");
        Emit(cg, "  call void @__ada_pop_handler()\n");
        Emit(cg, "  br label %%L%u\n", end_label);
        cg->block_terminated = true;  /* unconditional branch terminates block */

        /* Exception handler entry */
        Emit(cg, "  ; -- EXCEPTION handler entry (L%u)\n", handler_label);
        Emit_Label_Here(cg, handler_label);
        cg->block_terminated = false;
        Emit(cg, "  call void @__ada_pop_handler()\n");

        /* Get exception identity and dispatch to handlers */
        uint32_t exc_id = Emit_Current_Exception_Id(cg);
        Generate_Exception_Dispatch(cg, &node->block_stmt.handlers, exc_id, end_label);

        /* End of block */
        Emit(cg, "  ; -- END BLOCK (L%u)\n", end_label);
        Emit_Label_Here(cg, end_label);

        /* Restore exception context */
        cg->exception_handler_label = saved_handler;
        cg->exception_jmp_buf = saved_jmp_buf;
        cg->in_exception_region = saved_in_region;
    } else {
        /* Simple block without exception handlers */
        if (node->block_stmt.declarations.count > 0)
            Emit(cg, "  ; -- block declarations\n");
        Generate_Declaration_List(cg, &node->block_stmt.declarations);
        Emit(cg, "  ; -- block statements\n");
        Generate_Statement_List(cg, &node->block_stmt.statements);
        Emit(cg, "  ; -- END BLOCK\n");
    }
}

static void Generate_Statement(Code_Generator *cg, Syntax_Node *node) {
    if (not node) return;

    switch (node->kind) {
        case NK_ASSIGNMENT:
            Generate_Assignment(cg, node);
            break;

        case NK_CALL_STMT: {
            /* Procedure call - might be NK_APPLY, NK_IDENTIFIER (no args), or
             * NK_SELECTED (for entry calls like Task.Entry without args) */
            Emit_Location(cg, node->location);
            Syntax_Node *target = node->assignment.target;
            /* Emit procedure name comment if available */
            if (target->symbol) {
                Emit(cg, "  ; CALL %.*s\n",
                     (int)target->symbol->name.length, target->symbol->name.data);
            } else if (target->kind == NK_APPLY and target->apply.prefix and
                       target->apply.prefix->symbol) {
                Emit(cg, "  ; CALL %.*s(...)\n",
                     (int)target->apply.prefix->symbol->name.length,
                     target->apply.prefix->symbol->name.data);
            } else if (target->kind == NK_SELECTED) {
                Emit(cg, "  ; CALL (selected component)\n");
            } else {
                Emit(cg, "  ; CALL (expression)\n");
            }
            if (target->kind == NK_APPLY) {
                Generate_Expression(cg, target);
            } else if (target->kind == NK_SELECTED) {
                /* Selected component - might be a parameterless entry call like T.E1 */
                Symbol *entry_sym = target->symbol;
                if (entry_sym and entry_sym->kind == SYMBOL_ENTRY) {
                    /* Entry call without parameters - generate rendezvous */
                    Emit(cg, "  ; Entry call (no params): %.*s\n",
                         (int)entry_sym->name.length, entry_sym->name.data);

                    /* Allocate empty parameter block */
                    uint32_t param_block = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = inttoptr i64 0 to ptr  ; no parameters\n", param_block);

                    /* Get task object from prefix.
                     * For access-to-task, load the pointer (implicit dereference).
                     * For .ALL dereference (P.ALL.E1), unwrap to get the access var. */
                    uint32_t task_ptr = Emit_Temp(cg);
                    Syntax_Node *pfx = target->selected.prefix;
                    Symbol *task_sym = pfx->symbol;
                    /* Handle explicit .ALL: prefix is NK_UNARY_OP(TK_ALL) */
                    if (not task_sym and pfx->kind == NK_UNARY_OP and
                        pfx->unary.op == TK_ALL and pfx->unary.operand) {
                        task_sym = pfx->unary.operand->symbol;
                    }
                    if (task_sym and task_sym->type and Type_Is_Access(task_sym->type)) {
                        Emit(cg, "  %%t%u = load ptr, ptr ", task_ptr);
                        Emit_Symbol_Storage(cg, task_sym);
                        Emit(cg, "  ; access-to-task deref\n");
                    } else if (task_sym) {
                        Emit(cg, "  %%t%u = getelementptr i8, ptr ", task_ptr);
                        Emit_Symbol_Storage(cg, task_sym);
                        Emit(cg, ", i64 0  ; task object\n");
                    } else {
                        Emit(cg, "  %%t%u = inttoptr i64 0 to ptr  ; no task\n", task_ptr);
                    }

                    /* Get entry index (simple entry, not family) */
                    const char *eidx_t2 = Integer_Arith_Type(cg);
                    uint32_t entry_idx = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s 0, %u  ; entry index (simple entry)\n",
                         entry_idx, eidx_t2, entry_sym->entry_index * 1000);

                    /* Call runtime entry call function — widen entry index for RTS ABI */
                    uint32_t entry_idx_64 = Emit_Extend_To_I64(cg, entry_idx, eidx_t2);
                    Emit(cg, "  call void @__ada_entry_call(ptr %%t%u, i64 %%t%u, ptr %%t%u)\n",
                         task_ptr, entry_idx_64, param_block);
                } else if (entry_sym and (entry_sym->kind == SYMBOL_PROCEDURE or
                                         entry_sym->kind == SYMBOL_FUNCTION)) {
                    /* Qualified procedure call like Pkg.Proc - generate actual call */
                    Symbol *proc = entry_sym;
                    bool callee_is_nested = Subprogram_Needs_Static_Chain(proc);
                    uint32_t frame_pre = callee_is_nested ?
                        Precompute_Nested_Frame_Arg(cg, proc) : 0;

                    if (proc->kind == SYMBOL_FUNCTION) {
                        /* Function call - capture result */
                        const char *ret_type = proc->return_type ?
                            Type_To_Llvm_Sig(proc->return_type) : "i32";
                        uint32_t t = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = call %s @", t, ret_type);
                        Emit_Symbol_Name(cg, proc);
                        Emit(cg, "(");
                        if (callee_is_nested) {
                            Emit_Nested_Frame_Arg(cg, proc, frame_pre);
                        }
                        Emit(cg, ")\n");
                    } else {
                        /* Procedure call - void return */
                        Emit(cg, "  call void @");
                        Emit_Symbol_Name(cg, proc);
                        Emit(cg, "(");
                        if (callee_is_nested) {
                            Emit_Nested_Frame_Arg(cg, proc, frame_pre);
                        }
                        Emit(cg, ")\n");
                    }
                }
            } else if (target->kind == NK_IDENTIFIER) {
                /* Parameterless procedure/function call */
                Symbol *original_sym = target->symbol;  /* Keep for defaults */
                Symbol *proc = original_sym;

                /* Follow rename chain to get actual target for function name */
                while (proc and proc->renamed_object and
                       (proc->kind == SYMBOL_FUNCTION or proc->kind == SYMBOL_PROCEDURE)) {
                    Symbol *renamed_target = (Symbol *)proc->renamed_object;
                    if (renamed_target->kind == SYMBOL_FUNCTION or
                        renamed_target->kind == SYMBOL_PROCEDURE) {
                        proc = renamed_target;
                    } else {
                        break;
                    }
                }

                if (proc and (proc->kind == SYMBOL_PROCEDURE or proc->kind == SYMBOL_FUNCTION)) {
                    /* Check if calling a nested function (transitively inside another subprogram) */
                    bool callee_is_nested = Subprogram_Needs_Static_Chain(proc);

                    /* Pre-compute default arguments BEFORE building the call
                     * instruction, so complex expressions (record/array aggregates)
                     * don't interleave their IR with the call text. */
                    #define MAX_DEFAULT_ARGS 32
                    uint32_t default_vals[MAX_DEFAULT_ARGS];
                    const char *default_types[MAX_DEFAULT_ARGS];
                    uint32_t n_defaults = 0;
                    if (original_sym->parameter_count > 0) {
                        for (uint32_t i = 0; i < original_sym->parameter_count and
                             i < MAX_DEFAULT_ARGS; i++) {
                            if (original_sym->parameters[i].default_value) {
                                uint32_t val = Generate_Expression(cg,
                                    original_sym->parameters[i].default_value);
                                Type_Info *pt = original_sym->parameters[i].param_type;
                                bool is_composite = pt && (pt->kind == TYPE_RECORD ||
                                    pt->kind == TYPE_ARRAY || pt->kind == TYPE_STRING ||
                                    pt->kind == TYPE_TASK);
                                bool is_access = pt && (pt->kind == TYPE_ACCESS);
                                if (is_composite) {
                                    /* Composite default is already a ptr (alloca) */
                                    default_vals[i] = val;
                                    default_types[i] = "ptr";
                                    /* Array constraint check: compare aggregate element
                                     * count per dimension against the formal parameter
                                     * type's runtime bounds (RM 6.4.1). */
                                    Syntax_Node *def_expr = original_sym->parameters[i].default_value;
                                    if (pt &&
                                        (pt->kind == TYPE_ARRAY || pt->kind == TYPE_STRING) &&
                                        pt->array.index_count > 0 && pt->array.indices &&
                                        def_expr->kind == NK_AGGREGATE) {
                                        const char *iat = Integer_Arith_Type(cg);
                                        /* Count elements per dimension from aggregate literal.
                                         * For OTHERS-only aggregates, skip the length check
                                         * since OTHERS inherently matches the type's range. */
                                        uint32_t agg_dim_lengths[8] = {0};
                                        bool agg_is_others_only[8] = {false};
                                        uint32_t agg_ndims = 0;
                                        Syntax_Node *cur_agg = def_expr;
                                        for (uint32_t d = 0; d < pt->array.index_count && d < 8; d++) {
                                            if (!cur_agg || cur_agg->kind != NK_AGGREGATE) break;
                                            agg_dim_lengths[d] = cur_agg->aggregate.items.count;
                                            /* Detect OTHERS-only aggregates */
                                            if (cur_agg->aggregate.items.count == 1) {
                                                Syntax_Node *only = cur_agg->aggregate.items.items[0];
                                                if (only->kind == NK_ASSOCIATION &&
                                                    only->association.choices.count > 0 &&
                                                    Is_Others_Choice(only->association.choices.items[0]))
                                                    agg_is_others_only[d] = true;
                                            }
                                            agg_ndims = d + 1;
                                            if (cur_agg->aggregate.items.count > 0) {
                                                Syntax_Node *first = cur_agg->aggregate.items.items[0];
                                                if (first && first->kind == NK_ASSOCIATION)
                                                    first = first->association.expression;
                                                cur_agg = first;
                                            } else {
                                                cur_agg = NULL;
                                            }
                                        }
                                        for (uint32_t d = 0; d < agg_ndims && d < pt->array.index_count; d++) {
                                            if (agg_is_others_only[d]) continue;  /* OTHERS matches any range */
                                            Index_Info *fi = &pt->array.indices[d];
                                            uint32_t f_lo = Emit_Bound_Value(cg, &fi->low_bound);
                                            uint32_t f_hi = Emit_Bound_Value(cg, &fi->high_bound);
                                            if (f_lo && f_hi) {
                                                uint32_t fl = Emit_Temp(cg);
                                                Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", fl, iat,
                                                     Emit_Convert(cg, f_hi, iat, iat),
                                                     Emit_Convert(cg, f_lo, iat, iat));
                                                uint32_t fl1 = Emit_Temp(cg);
                                                Emit(cg, "  %%t%u = add %s %%t%u, 1\n", fl1, iat, fl);
                                                /* Clamp to 0 for null ranges (RM 3.6.1) */
                                                uint32_t neg = Emit_Temp(cg);
                                                Emit(cg, "  %%t%u = icmp slt %s %%t%u, 0\n", neg, iat, fl1);
                                                uint32_t clamped = Emit_Temp(cg);
                                                Emit(cg, "  %%t%u = select i1 %%t%u, %s 0, %s %%t%u\n",
                                                     clamped, neg, iat, iat, fl1);
                                                uint32_t al = Emit_Temp(cg);
                                                Emit(cg, "  %%t%u = add %s 0, %u  ; agg dim %u count\n",
                                                     al, iat, agg_dim_lengths[d], d);
                                                Emit_Length_Check(cg, al, clamped, iat, pt);
                                            }
                                        }
                                    }
                                    Type_Info *def_type = original_sym->parameters[i].default_value->type;
                                    /* Record discriminant constraint check (RM 3.7.2) */
                                    if (pt && pt->kind == TYPE_RECORD &&
                                        pt->record.has_disc_constraints &&
                                        pt->record.disc_constraint_values &&
                                        def_type && def_type->kind == TYPE_RECORD) {
                                        for (uint32_t d = 0; d < pt->record.discriminant_count; d++) {
                                            Component_Info *dc = &pt->record.components[d];
                                            if (!dc->component_type) continue;
                                            const char *dt = Type_To_Llvm(dc->component_type);
                                            /* Load discriminant from aggregate */
                                            uint32_t dp = Emit_Temp(cg);
                                            Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %u\n",
                                                 dp, val, dc->byte_offset);
                                            uint32_t dv = Emit_Temp(cg);
                                            Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", dv, dt, dp);
                                            /* Get constraint value */
                                            uint32_t cv;
                                            if (pt->record.disc_constraint_exprs &&
                                                pt->record.disc_constraint_exprs[d]) {
                                                cv = Generate_Expression(cg,
                                                    pt->record.disc_constraint_exprs[d]);
                                                cv = Emit_Convert(cg, cv,
                                                    Integer_Arith_Type(cg), dt);
                                            } else {
                                                cv = Emit_Temp(cg);
                                                Emit(cg, "  %%t%u = add %s 0, %lld\n", cv, dt,
                                                     (long long)pt->record.disc_constraint_values[d]);
                                            }
                                            /* Compare */
                                            uint32_t cmp = Emit_Temp(cg);
                                            Emit(cg, "  %%t%u = icmp ne %s %%t%u, %%t%u\n",
                                                 cmp, dt, dv, cv);
                                            uint32_t rl = cg->label_id++;
                                            uint32_t cl = cg->label_id++;
                                            Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n",
                                                 cmp, rl, cl);
                                            cg->block_terminated = true;
                                            Emit_Label_Here(cg, rl);
                                            Emit_Raise_Constraint_Error(cg, "discriminant check");
                                            Emit_Label_Here(cg, cl);
                                            cg->block_terminated = false;
                                        }
                                    }
                                    /* Record component constraint check (RM 3.3.2) */
                                    if (pt && pt->kind == TYPE_RECORD && def_type &&
                                        def_type->kind == TYPE_RECORD) {
                                        for (uint32_t ci = 0; ci < pt->record.component_count; ci++) {
                                            Component_Info *comp = &pt->record.components[ci];
                                            if (comp->is_discriminant || !comp->component_type) continue;
                                            Type_Info *ct = comp->component_type;
                                            if (!Type_Is_Scalar(ct)) continue;
                                            bool has_bounds = (ct->low_bound.kind == BOUND_INTEGER ||
                                                ct->low_bound.kind == BOUND_FLOAT ||
                                                ct->low_bound.kind == BOUND_EXPR) &&
                                                (ct->high_bound.kind == BOUND_INTEGER ||
                                                ct->high_bound.kind == BOUND_FLOAT ||
                                                ct->high_bound.kind == BOUND_EXPR);
                                            if (!has_bounds) continue;
                                            const char *ct_llvm = Type_To_Llvm(ct);
                                            /* Load component value from aggregate */
                                            uint32_t cp = Emit_Temp(cg);
                                            Emit(cg, "  %%t%u = getelementptr i8, ptr %%t%u, i64 %u\n",
                                                 cp, val, comp->byte_offset);
                                            uint32_t cv2 = Emit_Temp(cg);
                                            Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", cv2, ct_llvm, cp);
                                            Emit_Constraint_Check_With_Type(cg, cv2, ct, NULL, ct_llvm);
                                        }
                                    }
                                } else if (is_access) {
                                    /* Access type default is already a ptr */
                                    default_vals[i] = val;
                                    default_types[i] = "ptr";
                                } else {
                                    const char *param_type = pt ?
                                        Type_To_Llvm(pt) : Integer_Arith_Type(cg);
                                    val = Emit_Convert(cg, val, Integer_Arith_Type(cg), param_type);
                                    /* Scalar constraint check (RM 6.4.1) */
                                    val = Emit_Constraint_Check_With_Type(cg, val, pt,
                                        original_sym->parameters[i].default_value->type,
                                        param_type);
                                    default_vals[i] = val;
                                    default_types[i] = param_type;
                                }
                            } else {
                                default_vals[i] = 0;
                                default_types[i] = Integer_Arith_Type(cg);
                            }
                        }
                        n_defaults = original_sym->parameter_count < MAX_DEFAULT_ARGS
                            ? original_sym->parameter_count : MAX_DEFAULT_ARGS;
                    }

                    /* Precompute static chain pointer before call (RM 8.3) */
                    uint32_t frame_pre = callee_is_nested ?
                        Precompute_Nested_Frame_Arg(cg, proc) : 0;

                    if (proc->return_type) {
                        Emit(cg, "  call %s @", Type_To_Llvm_Sig(proc->return_type));
                    } else {
                        Emit(cg, "  call void @");
                    }
                    Emit_Symbol_Name(cg, proc);
                    Emit(cg, "(");

                    /* Pass frame pointer to nested functions (RM 8.3 static chain) */
                    bool frame_emitted = false;
                    if (callee_is_nested) {
                        frame_emitted = Emit_Nested_Frame_Arg(cg, proc, frame_pre);
                    }

                    /* Emit pre-computed default arguments */
                    for (uint32_t i = 0; i < n_defaults; i++) {
                        if (frame_emitted or i > 0) Emit(cg, ", ");
                        if (default_vals[i]) {
                            Emit(cg, "%s %%t%u", default_types[i], default_vals[i]);
                        } else {
                            Emit(cg, "%s 0", default_types[i]);
                        }
                    }
                    Emit(cg, ")\n");
                }
            }
        } break;

        case NK_RETURN:
            Generate_Return_Statement(cg, node);
            break;

        case NK_IF:
            Generate_If_Statement(cg, node);
            break;

        case NK_LOOP:
            if (node->loop_stmt.iteration_scheme and
                node->loop_stmt.iteration_scheme->kind == NK_BINARY_OP and
                node->loop_stmt.iteration_scheme->binary.op == TK_IN) {
                Generate_For_Loop(cg, node);
            } else {
                Generate_Loop_Statement(cg, node);
            }
            break;

        case NK_CASE:
            Generate_Case_Statement(cg, node);
            break;

        case NK_EXIT:
            {
                /* Named EXIT targets a specific loop; unnamed exits innermost */
                Emit_Location(cg, node->location);
                Symbol *tgt = node->exit_stmt.target;
                if (tgt) {
                    Emit(cg, "  ; EXIT %.*s", (int)tgt->name.length, tgt->name.data);
                } else {
                    Emit(cg, "  ; EXIT (innermost loop)");
                }
                if (node->exit_stmt.condition)
                    Emit(cg, " WHEN ...\n");
                else
                    Emit(cg, "\n");

                uint32_t exit_label = cg->loop_exit_label;
                if (tgt and tgt->loop_exit_label_id)
                    exit_label = tgt->loop_exit_label_id;
                if (node->exit_stmt.condition) {
                    Syntax_Node *exit_cond = node->exit_stmt.condition;
                    Emit(cg, "  ; -- evaluate exit condition\n");
                    uint32_t cond = Generate_Expression(cg, exit_cond);
                    const char *cond_type = Expression_Llvm_Type(cg, exit_cond);
                    cond = Emit_Convert(cg, cond, cond_type, "i1");
                    uint32_t cont = Emit_Label(cg);
                    Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u  ; WHEN true -> exit / continue\n",
                         cond, exit_label, cont);
                    cg->block_terminated = true;
                    Emit_Label_Here(cg, cont);
                } else {
                    Emit(cg, "  br label %%L%u  ; unconditional exit\n", exit_label);
                    cg->block_terminated = true;
                }
            }
            break;

        case NK_NULL_STMT:
            /* No code needed */
            break;

        case NK_BLOCK:
            Generate_Block_Statement(cg, node);
            break;

        case NK_RAISE:
            Generate_Raise_Statement(cg, node);
            break;

        case NK_DELAY:
            {
                /* DELAY expression — sleep for specified duration */
                /* Expression should be in seconds, convert to microseconds */
                uint32_t val = Generate_Expression(cg, node->delay_stmt.expression);
                /* If expression is fixed-point (e.g. DURATION), convert from
                 * scaled integer to seconds: sitofp then multiply by SMALL */
                Type_Info *delay_type = node->delay_stmt.expression->type;
                if (delay_type and Type_Is_Fixed_Point(delay_type)) {
                    const char *fix_llvm = Type_To_Llvm(delay_type);
                    uint32_t dbl_val = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = sitofp %s %%t%u to double\n", dbl_val, fix_llvm, val);
                    double small = delay_type->fixed.small;
                    if (small <= 0) small = delay_type->fixed.delta > 0 ? delay_type->fixed.delta : 1.0;
                    uint64_t sbits; memcpy(&sbits, &small, sizeof(sbits));
                    uint32_t sec_val = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = fmul double %%t%u, 0x%016llX  ; * SMALL\n",
                         sec_val, dbl_val, (unsigned long long)sbits);
                    val = sec_val;
                }
                /* Convert to microseconds (assuming Duration in seconds) */
                uint32_t us = Emit_Temp(cg);
                Emit(cg, "  %%t%u = fmul double %%t%u, 1.0e6\n", us, val);
                uint32_t us_int = Emit_Temp(cg);
                Emit(cg, "  %%t%u = fptoui double %%t%u to i64\n", us_int, us);
                Emit(cg, "  call void @__ada_delay(i64 %%t%u)\n", us_int);
            }
            break;

        case NK_ACCEPT:
            {
                /* ACCEPT statement — rendezvous with caller (Ada 83 9.5)
                 * Runtime: wait for entry call, execute body, complete rendezvous */
                Emit(cg, "  ; ACCEPT %.*s\n",
                     (int)node->accept_stmt.entry_name.length,
                     node->accept_stmt.entry_name.data);

                /* Get entry index - combine entry_sym's base index with family offset.
                 * For entry families: entry_idx = base * 1000 + family_arg
                 * For simple entries: entry_idx = base * 1000 */
                const char *acc_eidx_t = Integer_Arith_Type(cg);
                uint32_t entry_idx = Emit_Temp(cg);
                uint32_t base_idx = node->accept_stmt.entry_sym ?
                                    node->accept_stmt.entry_sym->entry_index : 0;
                if (node->accept_stmt.index) {
                    uint32_t idx_val = Generate_Expression(cg, node->accept_stmt.index);
                    const char *idx_t = Expression_Llvm_Type(cg, node->accept_stmt.index);
                    idx_val = Emit_Convert(cg, idx_val, idx_t, acc_eidx_t);
                    Emit(cg, "  %%t%u = add %s %u, %%t%u  ; entry index (base + family)\n",
                         entry_idx, acc_eidx_t, base_idx * 1000, idx_val);
                } else {
                    Emit(cg, "  %%t%u = add %s 0, %u  ; entry index (simple entry)\n",
                         entry_idx, acc_eidx_t, base_idx * 1000);
                }

                /* Wait for entry call — widen entry index for RTS ABI */
                uint32_t entry_idx_64 = Emit_Extend_To_I64(cg, entry_idx, acc_eidx_t);
                uint32_t caller_ptr = Emit_Temp(cg);
                Emit(cg, "  %%t%u = call ptr @__ada_accept_wait(i64 %%t%u)\n",
                     caller_ptr, entry_idx_64);

                /* Generate parameters - allocate space and copy from caller's parameter block */
                uint32_t param_idx = 0;
                for (uint32_t i = 0; i < node->accept_stmt.parameters.count; i++) {
                    Syntax_Node *param = node->accept_stmt.parameters.items[i];
                    if (param and param->kind == NK_PARAM_SPEC) {
                        for (uint32_t j = 0; j < param->param_spec.names.count; j++) {
                            Syntax_Node *name = param->param_spec.names.items[j];
                            if (name and name->symbol) {
                                /* Allocate space for the parameter */
                                Emit(cg, "  %%");
                                Emit_Symbol_Name(cg, name->symbol);
                                Emit(cg, " = alloca i64, align 8\n");

                                /* Load value from caller's parameter block */
                                uint32_t param_ptr = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = getelementptr i64, ptr %%t%u, i64 %u\n",
                                     param_ptr, caller_ptr, param_idx);
                                uint32_t param_val = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = load i64, ptr %%t%u\n", param_val, param_ptr);

                                /* Store to allocated space */
                                Emit(cg, "  store i64 %%t%u, ptr %%", param_val);
                                Emit_Symbol_Name(cg, name->symbol);
                                Emit(cg, "\n");

                                param_idx++;
                            }
                        }
                    }
                }

                /* Execute accept body */
                Generate_Statement_List(cg, &node->accept_stmt.statements);

                /* Complete rendezvous - unblocks the caller */
                Emit(cg, "  call void @__ada_accept_complete(ptr %%t%u)\n", caller_ptr);
            }
            break;

        case NK_SELECT:
            /* SELECT statement — selective wait (Ada 83 9.7)
             * Forms: selective_wait, conditional_entry_call, timed_entry_call
             * Runtime: check open alternatives, wait or execute else */
            {
                uint32_t done_label = cg->label_id++;
                bool has_else = (node->select_stmt.else_part != NULL);
                bool has_delay = false;
                uint32_t delay_label = 0;

                /* Check for delay and terminate alternatives */
                bool has_terminate = false;
                uint32_t retry_label = 0;
                for (uint32_t i = 0; i < node->select_stmt.alternatives.count; i++) {
                    if (node->select_stmt.alternatives.items[i]->kind == NK_DELAY) {
                        has_delay = true;
                        delay_label = cg->label_id++;
                    }
                    if (node->select_stmt.alternatives.items[i]->kind == NK_NULL_STMT) {
                        has_terminate = true;
                    }
                }
                if (has_terminate) {
                    retry_label = cg->label_id++;
                    Emit(cg, "  br label %%L%u\n", retry_label);
                    cg->block_terminated = true;
                    Emit_Label_Here(cg, retry_label); /* selective wait retry */
                }
                bool delay_label_emitted = false;
                bool skipped_delay = false;  /* Track if current iteration was a skipped delay */

                /* Generate alternatives */
                for (uint32_t i = 0; i < node->select_stmt.alternatives.count; i++) {
                    Syntax_Node *alt = node->select_stmt.alternatives.items[i];
                    uint32_t next_label = cg->label_id++;
                    skipped_delay = false;

                    switch (alt->kind) {
                        case NK_ASSOCIATION:
                            /* Guarded alternative: WHEN cond => stmt */
                            {
                                Syntax_Node *guard_expr = alt->association.choices.items[0];
                                uint32_t guard = Generate_Expression(cg, guard_expr);
                                const char *guard_type = Expression_Llvm_Type(cg, guard_expr);
                                guard = Emit_Convert(cg, guard, guard_type, "i1");
                                Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n",
                                     guard, cg->label_id, next_label);
                                cg->block_terminated = true;
                                Emit_Label_Here(cg, cg->label_id++);
                                if (alt->association.expression)
                                    Generate_Statement(cg, alt->association.expression);
                                Emit(cg, "  br label %%L%u\n", done_label);
                            }
                            break;

                        case NK_ACCEPT:
                            /* Accept alternative */
                            {
                                Emit(cg, "  ; accept alternative: %.*s\n",
                                     (int)alt->accept_stmt.entry_name.length,
                                     alt->accept_stmt.entry_name.data);

                                /* Get entry index - combine base index with family index.
                                 * Formula: entry_idx = base * 1000 + family_arg */
                                const char *sel_eidx_t = Integer_Arith_Type(cg);
                                uint32_t entry_idx = Emit_Temp(cg);
                                uint32_t sel_base_idx = alt->accept_stmt.entry_sym ?
                                                        alt->accept_stmt.entry_sym->entry_index : 0;
                                if (alt->accept_stmt.index) {
                                    uint32_t idx_val = Generate_Expression(cg, alt->accept_stmt.index);
                                    const char *idx_t = Expression_Llvm_Type(cg, alt->accept_stmt.index);
                                    idx_val = Emit_Convert(cg, idx_val, idx_t, sel_eidx_t);
                                    Emit(cg, "  %%t%u = add %s %u, %%t%u  ; entry index (base + family)\n",
                                         entry_idx, sel_eidx_t, sel_base_idx * 1000, idx_val);
                                } else {
                                    Emit(cg, "  %%t%u = add %s 0, %u  ; entry index (simple entry)\n",
                                         entry_idx, sel_eidx_t, sel_base_idx * 1000);
                                }

                                /* Check if entry call is pending — widen for RTS ABI */
                                uint32_t entry_idx_64 = Emit_Extend_To_I64(cg, entry_idx, sel_eidx_t);
                                uint32_t caller_ptr = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = call ptr @__ada_accept_try(i64 %%t%u)\n",
                                     caller_ptr, entry_idx_64);
                                uint32_t has_caller = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = icmp ne ptr %%t%u, null\n",
                                     has_caller, caller_ptr);
                                Emit(cg, "  br i1 %%t%u, label %%L%u, label %%L%u\n",
                                     has_caller, cg->label_id, next_label);
                                cg->block_terminated = true;
                                Emit_Label_Here(cg, cg->label_id++);

                                /* Load parameters from caller */
                                uint32_t sel_param_idx = 0;
                                for (uint32_t pi = 0; pi < alt->accept_stmt.parameters.count; pi++) {
                                    Syntax_Node *param = alt->accept_stmt.parameters.items[pi];
                                    if (param and param->kind == NK_PARAM_SPEC) {
                                        for (uint32_t pj = 0; pj < param->param_spec.names.count; pj++) {
                                            Syntax_Node *pname = param->param_spec.names.items[pj];
                                            if (pname and pname->symbol) {
                                                /* Allocate space for the parameter */
                                                Emit(cg, "  %%");
                                                Emit_Symbol_Name(cg, pname->symbol);
                                                Emit(cg, " = alloca i64, align 8\n");

                                                /* Load value from caller's parameter block */
                                                uint32_t param_ptr = Emit_Temp(cg);
                                                Emit(cg, "  %%t%u = getelementptr i64, ptr %%t%u, i64 %u\n",
                                                     param_ptr, caller_ptr, sel_param_idx);
                                                uint32_t param_val = Emit_Temp(cg);
                                                Emit(cg, "  %%t%u = load i64, ptr %%t%u\n", param_val, param_ptr);

                                                /* Store to allocated space */
                                                Emit(cg, "  store i64 %%t%u, ptr %%", param_val);
                                                Emit_Symbol_Name(cg, pname->symbol);
                                                Emit(cg, "\n");

                                                sel_param_idx++;
                                            }
                                        }
                                    }
                                }

                                /* Execute accept body */
                                Generate_Statement_List(cg, &alt->accept_stmt.statements);

                                /* Complete rendezvous */
                                Emit(cg, "  call void @__ada_accept_complete(ptr %%t%u)\n", caller_ptr);
                                Emit(cg, "  br label %%L%u\n", done_label);
                            }
                            break;

                        case NK_DELAY:
                            /* Delay alternative - only emit code once for multiple delays.
                             * In Ada, multiple delays would pick the shortest, but we simplify
                             * by using the first delay's duration for all. */
                            if (not delay_label_emitted) {
                                Emit_Label_Here(cg, delay_label); /* delay alternative */
                                delay_label_emitted = true;
                                {
                                    uint32_t dur = Generate_Expression(cg, alt->delay_stmt.expression);
                                    /* Convert fixed-point to double seconds */
                                    Type_Info *dur_type = alt->delay_stmt.expression->type;
                                    if (dur_type and Type_Is_Fixed_Point(dur_type)) {
                                        const char *fix_llvm = Type_To_Llvm(dur_type);
                                        uint32_t dbl_val = Emit_Temp(cg);
                                        Emit(cg, "  %%t%u = sitofp %s %%t%u to double\n", dbl_val, fix_llvm, dur);
                                        double sm = dur_type->fixed.small;
                                        if (sm <= 0) sm = dur_type->fixed.delta > 0 ? dur_type->fixed.delta : 1.0;
                                        uint64_t sb; memcpy(&sb, &sm, sizeof(sb));
                                        uint32_t sec = Emit_Temp(cg);
                                        Emit(cg, "  %%t%u = fmul double %%t%u, 0x%016llX  ; * SMALL\n",
                                             sec, dbl_val, (unsigned long long)sb);
                                        dur = sec;
                                    }
                                    uint32_t us = Emit_Temp(cg);
                                    Emit(cg, "  %%t%u = fmul double %%t%u, 1.0e6\n", us, dur);
                                    uint32_t us_int = Emit_Temp(cg);
                                    Emit(cg, "  %%t%u = fptoui double %%t%u to i64\n", us_int, us);
                                    Emit(cg, "  call void @__ada_delay(i64 %%t%u)\n", us_int);
                                }
                                Emit(cg, "  br label %%L%u\n", done_label);
                            } else {
                                /* Subsequent delays: skip code generation entirely */
                                skipped_delay = true;
                            }
                            break;

                        case NK_NULL_STMT:
                            /* Terminate alternative (RM 9.7.1):
                             * Instead of immediately terminating, loop back
                             * to re-check accept alternatives.  The task will
                             * be terminated when the master scope completes
                             * and calls exit(), ending the process. */
                            Emit(cg, "  ; terminate alternative - sleep and retry\n");
                            Emit(cg, "  %%_usel%u = call i32 @usleep(i32 1000)\n",
                                 cg->label_id);
                            Emit(cg, "  br label %%L%u\n", retry_label);
                            break;

                        default:
                            break;
                    }
                    /* For skipped delay alternatives, don't emit next_label since
                     * we've already branched to delay_label and this would be unreachable */
                    if (not skipped_delay) {
                        /* Emit the next_label for branches that skip this alternative */
                        Emit_Label_Here(cg, next_label);
                        /* If this isn't the last alternative, fall through to next;
                         * otherwise go to delay or done */
                        bool is_last = (i == node->select_stmt.alternatives.count - 1);
                        if (not is_last) {
                            /* Check if next alternative is delay - branch to delay_label instead */
                            Syntax_Node *next_alt = node->select_stmt.alternatives.items[i + 1];
                            if (next_alt and next_alt->kind == NK_DELAY and has_delay) {
                                Emit(cg, "  br label %%L%u\n", delay_label);
                            }
                            /* Otherwise fall through (no br needed, will hit next iteration's code) */
                        }
                    }
                }

                /* Else clause or fall through to delay */
                if (has_else) {
                    Generate_Statement(cg, node->select_stmt.else_part);
                } else if (has_delay) {
                    /* Already branched to delay_label above */
                }
                Emit(cg, "  br label %%L%u\n", done_label);
                cg->block_terminated = true;
                Emit_Label_Here(cg, done_label);
            }
            break;

        case NK_ABORT:
            /* ABORT statement — abort named tasks (Ada 83 9.10) */
            for (uint32_t i = 0; i < node->abort_stmt.task_names.count; i++) {
                Syntax_Node *task_name = node->abort_stmt.task_names.items[i];
                uint32_t task_ptr = Generate_Expression(cg, task_name);
                Emit(cg, "  call void @__ada_task_abort(ptr %%t%u)\n", task_ptr);
            }
            break;

        case NK_LABEL:
            {
                /* Ada label - allocate LLVM label ID and emit label */
                Symbol *label_sym = node->label_node.symbol;
                if (label_sym) {
                    if (label_sym->llvm_label_id == 0)
                        label_sym->llvm_label_id = cg->label_id++;
                    /* Need a branch to the label to terminate previous block (if not already) */
                    if (not cg->block_terminated) {
                        Emit(cg, "  br label %%L%u\n", label_sym->llvm_label_id);
                        cg->block_terminated = true;
                    }
                    Emit_Label_Here(cg, label_sym->llvm_label_id); /* user label */
                    cg->block_terminated = false;  /* New block started */
                }
                /* Generate the labeled statement */
                if (node->label_node.statement) {
                    Generate_Statement(cg, node->label_node.statement);
                }
            }
            break;

        case NK_GOTO:
            {
                /* GOTO statement - use resolved target label and branch */
                Symbol *label_sym = node->goto_stmt.target;
                if (label_sym) {
                    if (label_sym->llvm_label_id == 0) {
                        label_sym->llvm_label_id = cg->label_id++;
                    }
                    Emit(cg, "  br label %%L%u  ; goto %.*s\n",
                         label_sym->llvm_label_id,
                         (int)node->goto_stmt.name.length,
                         node->goto_stmt.name.data);
                    cg->block_terminated = true;  /* br is a terminator */
                } else {
                    Emit(cg, "  ; ERROR: undefined label %.*s\n",
                         (int)node->goto_stmt.name.length,
                         node->goto_stmt.name.data);
                }
            }
            break;

        default:
            fprintf(stderr, "warning: unhandled statement kind %d at %s:%u\n",
                    node->kind,
                    node->location.filename ? node->location.filename : "<unknown>",
                    node->location.line);
            break;
    }
}

/* ─────────────────────────────────────────────────────────────────────────
 * §13.5 Declaration Code Generation
 *
 * Names get bound to meanings, and those bindings are what we generate.
 * ───────────────────────────────────────────────────────────────────────── */

static void Generate_Declaration(Code_Generator *cg, Syntax_Node *node);
/* Check if external name is a builtin/runtime function (already defined) */
static bool Is_Builtin_Function(String_Slice name) {
    /* Strip quotes if present */
    if (name.length >= 2 and name.data[0] == '"' and name.data[name.length-1] == '"') {
        name.data++;
        name.length -= 2;
    }
    const char *builtins[] = {
        /* Custom text_io helpers */
        "__text_io_new_line", "__text_io_put_char", "__text_io_put",
        "__text_io_put_line", "__text_io_put_int", "__text_io_put_float",
        "__text_io_get_char", "__text_io_get_line",
        "__ada_stdin", "__ada_stdout", "__ada_stderr",
        /* Standard C library functions (declared in runtime preamble) */
        "memcmp", "setjmp", "longjmp", "exit", "malloc", "realloc", "free",
        "usleep", "printf", "putchar", "strtod", "snprintf", "strlen",
        "fputc", "fputs", "fgetc", "fgets", "fprintf",
        "fopen", "fclose", "fflush", "feof", "ftell", "fseek",
        "ungetc", "remove", "getchar",
        NULL
    };
    for (int i = 0; builtins[i]; i++) {
        if (name.length == strlen(builtins[i]) and
            memcmp(name.data, builtins[i], name.length) == 0) {
            return true;
        }
    }
    return false;
}

/* Emit function signature for extern declaration */
static void Emit_Extern_Subprogram(Code_Generator *cg, Symbol *sym) {
    if (not sym) return;
    if (sym->kind != SYMBOL_FUNCTION and sym->kind != SYMBOL_PROCEDURE) return;

    /* Skip if already emitted */
    if (sym->extern_emitted) return;
    sym->extern_emitted = true;

    /* Skip if this is a builtin function that we've already defined */
    if (sym->is_imported and sym->external_name.length > 0) {
        if (Is_Builtin_Function(sym->external_name)) {
            return;
        }
    }

    /* Get return type */
    const char *ret_type = sym->return_type ? Type_To_Llvm_Sig(sym->return_type) : "void";

    Emit(cg, "declare %s @", ret_type);
    Emit_Symbol_Name(cg, sym);
    Emit(cg, "(");

    /* Emit parameter types */
    for (uint32_t i = 0; i < sym->parameter_count; i++) {
        if (i > 0) Emit(cg, ", ");
        /* Handle ALI-loaded symbols without full parameter info */
        Type_Info *ty = (sym->parameters and i < sym->parameter_count)
                        ? sym->parameters[i].param_type : NULL;
        if (ty) {
            Emit(cg, "%s", Type_To_Llvm_Sig(ty));
        } else {
            Emit(cg, "%s", Integer_Arith_Type(cg));  /* Derive from INTEGER for missing param types */
        }
    }
    Emit(cg, ")\n");
}


static void Generate_Declaration_List(Code_Generator *cg, Node_List *list) {
    for (uint32_t i = 0; i < list->count; i++) {
        Generate_Declaration(cg, list->items[i]);
    }
}

static void Generate_Object_Declaration(Code_Generator *cg, Syntax_Node *node) {
    /* cg->current_nesting_level is repurposed: 1 = has nested functions, use frame */
    bool use_frame = cg->current_nesting_level > 0;
    bool is_package_level = (cg->current_function == NULL);

    /* Emit source location for the object declaration */
    Emit_Location(cg, node->location);

    for (uint32_t i = 0; i < node->object_decl.names.count; i++) {
        Syntax_Node *name = node->object_decl.names.items[i];
        Symbol *sym = name->symbol;
        if (not sym) continue;

        /* Emit declaration info comment */
        Emit(cg, "  ; %s %.*s : %s\n",
             node->object_decl.is_constant ? "CONST" : "VAR",
             (int)sym->name.length, sym->name.data,
             sym->type ? Type_To_Llvm(sym->type) : "?");

        Type_Info *ty = sym->type;

        if (cg->current_instance)
            ty = Resolve_Generic_Actual_Type(cg, ty);

        /* Named numbers (constants without explicit type) don't need storage.
         * They are compile-time values that get inlined when referenced.
         * Per RM 3.2.2: Named numbers are not objects and have no storage. */
        if (sym->is_named_number) {
            continue;  /* Skip storage allocation for named numbers */
        }

        const char *type_str = Type_To_Llvm(ty);

        /* Check if this is an array type (constrained or unconstrained).
         * is_any_array: true for any array-like type INCLUDING TYPE_STRING,
         * used for aggregate/string initialization.
         * is_constrained_array: true only for constrained, used for allocation */
        bool is_any_array = ty and (ty->kind == TYPE_ARRAY or ty->kind == TYPE_STRING);
        bool is_constrained_array = is_any_array and ty->array.is_constrained;
        int128_t array_count = is_constrained_array ? Array_Element_Count(ty) : 0;
        const char *elem_type = NULL;
        uint32_t elem_size = 0;
        bool elem_is_composite = false;
        if (is_any_array and ty->array.element_type) {
            Type_Info *et = ty->array.element_type;
            /* Check if element is record or another constrained array */
            if (Type_Is_Record(et) or Type_Is_Constrained_Array(et)) {
                elem_is_composite = true;
                elem_size = et->size;
                /* Fallback: if composite elem has unknown size (dynamic bounds),
                 * still set elem_type so alloca doesn't emit (null). */
                if (elem_size == 0)
                    elem_type = Type_To_Llvm(et);
            } else {
                elem_type = Type_To_Llvm(et);
            }
        }

        /* Check if this is a record type */
        bool is_record = Type_Is_Record(ty);
        uint32_t record_size = is_record ? ty->size : 0;

        /* Package-level variables are globals, local variables use alloca */
        if (is_package_level) {
            /* Skip if global was already emitted (e.g., from spec + body) */
            if (sym->extern_emitted) continue;
            sym->extern_emitted = true;
            /* Global variable at package level */
            Emit(cg, "@");
            Emit_Symbol_Name(cg, sym);
            if (node->object_decl.is_constant and node->object_decl.init) {
                /* Constant with initializer - emit as constant */
                if (node->object_decl.init->kind == NK_INTEGER) {
                    sym->extern_emitted = true;
                    Emit(cg, " = linkonce_odr constant %s %lld\n", type_str,
                         (long long)node->object_decl.init->integer_lit.value);
                    continue;
                }
                /* String constant - emit fat pointer global */
                if (node->object_decl.init->kind == NK_STRING) {
                    sym->extern_emitted = true;
                    String_Slice str = node->object_decl.init->string_val.text;
                    int64_t str_len = (int64_t)str.length;
                    /* Emit string data first: @SYMNAME.data = ... */
                    Emit(cg, ".data = linkonce_odr constant [%lld x i8] c\"",
                         (long long)str_len);
                    /* Emit escaped string contents */
                    for (uint32_t j = 0; j < str.length; j++) {
                        char c = str.data[j];
                        if (c >= 32 and c < 127 and c != '"' and c != '\\') {
                            Emit(cg, "%c", c);
                        } else {
                            Emit(cg, "\\%02X", (unsigned char)c);
                        }
                    }
                    Emit(cg, "\"\n");
                    /* Emit bounds global: @SYMNAME.bounds = { i64 1, i64 N } */
                    Emit(cg, "@");
                    Emit_Symbol_Name(cg, sym);
                    Emit(cg, ".bounds = linkonce_odr constant { i64, i64 } "
                         "{ i64 1, i64 %d }\n", (int)str_len);
                    /* Emit fat pointer global: { ptr @X.data, ptr @X.bounds } */
                    Emit(cg, "@");
                    Emit_Symbol_Name(cg, sym);
                    Emit(cg, " = linkonce_odr constant " FAT_PTR_TYPE " "
                         "{ ptr @");
                    Emit_Symbol_Name(cg, sym);
                    Emit(cg, ".data, ptr @");
                    Emit_Symbol_Name(cg, sym);
                    Emit(cg, ".bounds }\n");
                    continue;
                }
            }
            /* Mark as emitted so extern declarations are suppressed */
            sym->extern_emitted = true;
            /* Variable - emit as global, using static initializer when available.
             * Per Ada RM 3.2.1: object declarations with static init expressions
             * can be folded into the global initializer directly. */
            int64_t  init_ival = 0;
            double   init_fval = 0.0;
            bool     has_static_init = false;
            if (node->object_decl.init) {
                Syntax_Node *init = node->object_decl.init;
                if (init->kind == NK_INTEGER) {
                    init_ival = init->integer_lit.value;
                    has_static_init = true;
                } else if (init->kind == NK_REAL) {
                    init_fval = init->real_lit.value;
                    has_static_init = true;
                } else if (init->kind == NK_IDENTIFIER and init->symbol
                           and init->symbol->is_named_number) {
                    init_ival = (int64_t)Eval_Const_Numeric(init);
                    has_static_init = true;
                }
            }
            if (is_constrained_array and array_count > 0) {
                if (elem_is_composite and elem_size > 0) {
                    Emit(cg, " = linkonce_odr global [%s x [%u x i8]] zeroinitializer\n",
                         I128_Decimal(array_count), elem_size);
                } else {
                    Emit(cg, " = linkonce_odr global [%s x %s] zeroinitializer\n",
                         I128_Decimal(array_count), elem_type);
                }
            } else if (is_record and record_size > 0) {
                Emit(cg, " = linkonce_odr global [%u x i8] zeroinitializer\n", record_size);
            } else {
                if (Llvm_Type_Is_Fat_Pointer(type_str)) {
                    Emit(cg, " = linkonce_odr global %s zeroinitializer\n", type_str);
                } else if (Type_Is_Float_Representation(ty)) {
                    Emit(cg, " = linkonce_odr global %s %a\n", type_str,
                         has_static_init ? init_fval : 0.0);
                } else if (strcmp(type_str, "ptr") == 0) {
                    Emit(cg, " = linkonce_odr global ptr null\n");
                } else {
                    Emit(cg, " = linkonce_odr global %s %lld\n", type_str,
                         (long long)(has_static_init ? init_ival : 0));
                }
            }
            continue;
        }

        /* Local variable allocation */
        if (use_frame) {
            /* Skip symbols that aren't actually in the current function's scope.
             * This happens with package spec private part declarations: the AST
             * nodes have orphaned symbol references (parent==NULL, frame_offset==0)
             * while the proper symbols are already allocated in the frame under
             * their package-qualified names. Emitting these would create duplicate
             * or conflicting IR definitions. */
            if (cg->current_function and cg->current_function->scope and
                not sym->parent and sym->frame_offset == 0) {
                bool found_in_scope = false;
                Scope *scope = cg->current_function->scope;
                for (uint32_t j = 0; j < scope->symbol_count; j++) {
                    if (scope->symbols[j] == sym) { found_in_scope = true; break; }
                }
                if (not found_in_scope) {
                    for (uint32_t j = 0; j < scope->frame_var_count; j++) {
                        if (scope->frame_vars[j] == sym) { found_in_scope = true; break; }
                    }
                }
                if (not found_in_scope) continue;
            }

            /* In generic instance bodies, find the instance symbol which has
             * the correct frame_offset (template symbols have offset 0). */
            int64_t offset = sym->frame_offset;
            if (cg->current_instance) {
                Symbol *inst_sym = Find_Instance_Local(cg, sym);
                if (inst_sym) offset = inst_sym->frame_offset;
            }
            Emit(cg, "  %%");
            Emit_Symbol_Name(cg, sym);
            Emit(cg, " = getelementptr i8, ptr %%__frame_base, i64 %lld\n",
                 (long long)offset);
        } else if (sym->needs_fat_ptr_storage or
                   (is_any_array and Type_Has_Dynamic_Bounds(ty))) {
            /* Dynamic-bound arrays need fat pointer storage ({ ptr, ptr }).
             * Must check BEFORE static constrained array path to avoid
             * allocating undersized storage when bounds resolve late. */
            Emit(cg, "  %%");
            Emit_Symbol_Name(cg, sym);
            Emit(cg, " = alloca " FAT_PTR_TYPE "\n");
            sym->needs_fat_ptr_storage = true;
        } else if (is_constrained_array and array_count > 0) {
            /* Constrained array with static bounds: allocate [N x element_type] */
            Emit(cg, "  %%");
            Emit_Symbol_Name(cg, sym);
            if (elem_is_composite and elem_size > 0) {
                /* Element is record or constrained array - use byte array */
                Emit(cg, " = alloca [%s x [%u x i8]]\n", I128_Decimal(array_count), elem_size);
            } else {
                Emit(cg, " = alloca [%s x %s]\n", I128_Decimal(array_count), elem_type);
            }
        } else if (is_record and ty and ty->rt_global_id > 0) {
            /* Record with dynamic-sized components: load runtime size */
            uint32_t rtsz = Emit_Temp(cg);
            Emit(cg, "  %%t%u = load i64, ptr @__rt_rec_%u_size\n",
                 rtsz, ty->rt_global_id);
            Emit(cg, "  %%");
            Emit_Symbol_Name(cg, sym);
            Emit(cg, " = alloca i8, i64 %%t%u  ; record rt alloca\n", rtsz);
            /* Zero-init so memcmp-based equality sees clean padding */
            Emit(cg, "  call void @llvm.memset.p0.i64(ptr %%");
            Emit_Symbol_Name(cg, sym);
            Emit(cg, ", i8 0, i64 %%t%u, i1 false)\n", rtsz);
        } else if (is_record and record_size > 0) {
            /* Record type: allocate [N x i8] for the record size */
            Emit(cg, "  %%");
            Emit_Symbol_Name(cg, sym);
            Emit(cg, " = alloca [%u x i8]  ; record type\n", record_size);
            /* Zero-init records with discriminants so that equality comparison
             * (memcmp on discriminant-dependent array slots) sees consistent
             * padding bytes beyond the active portion (RM 4.5.2). */
            if (ty and Type_Is_Record(ty) and ty->record.discriminant_count > 0) {
                Emit(cg, "  call void @llvm.memset.p0.i64(ptr %%");
                Emit_Symbol_Name(cg, sym);
                Emit(cg, ", i8 0, i64 %u, i1 false)\n", record_size);
            }
        } else {
            Emit(cg, "  %%");
            Emit_Symbol_Name(cg, sym);
            Emit(cg, " = alloca %s\n", type_str);

            /* For unconstrained array/string variables with explicit index
             * constraints (e.g. S : STRING(1..N)), allocate data storage
             * and initialize the fat pointer so it's valid before any use.
             * Without this, the fat pointer is { null, null } and any
             * access to bounds causes a crash. (RM 3.6.1) */
            if (is_any_array and not is_constrained_array and
                node->object_decl.object_type and
                node->object_decl.object_type->kind == NK_SUBTYPE_INDICATION and
                node->object_decl.object_type->subtype_ind.constraint and
                node->object_decl.object_type->subtype_ind.constraint->kind == NK_INDEX_CONSTRAINT) {
                Syntax_Node *constraint = node->object_decl.object_type->subtype_ind.constraint;
                Node_List *ranges = &constraint->index_constraint.ranges;
                if (ranges->count > 0) {
                    const char *bt = Array_Bound_Llvm_Type(ty);
                    uint32_t ndims = ranges->count;
                    uint32_t dim_lo[8], dim_hi[8];  /* support up to 8 dimensions */
                    if (ndims > 8) ndims = 8;
                    bool all_ok = true;
                    for (uint32_t d = 0; d < ndims; d++) {
                        Syntax_Node *rng = ranges->items[d];
                        if (rng and rng->kind == NK_RANGE and rng->range.low and rng->range.high) {
                            dim_lo[d] = Generate_Expression(cg, rng->range.low);
                            dim_hi[d] = Generate_Expression(cg, rng->range.high);
                        } else {
                            all_ok = false;
                            break;
                        }
                    }
                    if (all_ok) {
                        /* Compute total element count = product of all dimension lengths */
                        uint32_t total_len = 0;
                        for (uint32_t d = 0; d < ndims; d++) {
                            uint32_t diff_d = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", diff_d, bt, dim_hi[d], dim_lo[d]);
                            uint32_t len_d = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add %s %%t%u, 1\n", len_d, bt, diff_d);
                            if (d == 0) {
                                total_len = len_d;
                            } else {
                                uint32_t prod = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = mul %s %%t%u, %%t%u\n", prod, bt, total_len, len_d);
                                total_len = prod;
                            }
                        }
                        /* Multiply by element size */
                        uint32_t elem_sz = ty->array.element_type ? ty->array.element_type->size : 4;
                        if (elem_sz == 0) elem_sz = 4;
                        uint32_t byte_len = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = mul %s %%t%u, %u  ; total bytes\n",
                             byte_len, bt, total_len, elem_sz);
                        uint32_t byte_len64 = Emit_Extend_To_I64(cg, byte_len, bt);
                        /* Allocate data storage */
                        uint32_t data_alloc = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = alloca i8, i64 %%t%u  ; constrained uncon array data\n",
                             data_alloc, byte_len64);
                        /* Build fat pointer with multi-dim bounds */
                        uint32_t fat;
                        if (ndims > 1) {
                            fat = Emit_Fat_Pointer_MultiDim(cg, data_alloc, dim_lo, dim_hi, ndims, bt);
                        } else {
                            fat = Emit_Fat_Pointer_Dynamic(cg, data_alloc, dim_lo[0], dim_hi[0], bt);
                        }
                        Emit_Store_Fat_Pointer_To_Symbol(cg, fat, sym, bt);
                    }
                }
            }
        }

        /* Start task if this is a task type object */
        if (Type_Is_Task(ty)) {
            /* Task objects are started immediately at elaboration.
             * The task body function is named @task_TYPENAME where TYPENAME
             * is the task type name (not the object name).
             * For task types defined outside the generic, no instance prefix.
             * For single tasks inside generics, the body has an instance prefix. */
            uint32_t handle_tmp = Emit_Temp(cg);
            Emit(cg, "  %%t%u = call ptr @__ada_task_start(ptr @", handle_tmp);
            Emit_Task_Function_Name(cg, ty->defining_symbol, ty->name);
            Emit(cg, ", ");
            /* Pass parent frame for uplevel access, or null if at package level.
             * use_frame indicates the parent is using frame-based allocation. */
            if (use_frame) {
                Emit(cg, "ptr %%__frame_base)\n");
            } else {
                Emit(cg, "ptr null)\n");
            }
            /* Store thread handle in task object for later join/abort */
            Emit(cg, "  store ptr %%t%u, ptr %%", handle_tmp);
            Emit_Symbol_Name(cg, sym);
            Emit(cg, "\n");
        }

        /* Initialize if provided */
        if (node->object_decl.init) {
            if (is_any_array and ty->array.element_type == cg->sm->type_character) {
                /* String/character array initialization.
                 * NK_STRING always yields a fat pointer.
                 * Unconstrained array identifiers yield fat pointer values.
                 * Constrained array identifiers yield plain ptr — use memcpy.
                 *
                 * CRITICAL: When the destination is unconstrained (STRING variable),
                 * the alloca holds a fat pointer descriptor { ptr, { bound, bound } }.
                 * We must NOT memcpy data into that descriptor.  Instead:
                 *   1. Allocate separate local data storage (dynamic alloca)
                 *   2. Copy data from source to local storage
                 *   3. Build a fat pointer { local_data, { low, high } }
                 *   4. Store the fat pointer into the variable
                 * This is "constrained by initialization" — GNAT does the same. */
                Syntax_Node *init = node->object_decl.init;
                Type_Info *init_ty = init->type;
                int init_is_constrained = Type_Is_Constrained_Array(init_ty);
                bool dest_needs_fat_storage = not is_constrained_array or
                    sym->needs_fat_ptr_storage;

                if (init->kind == NK_STRING or not init_is_constrained) {
                    /* Source produces a fat pointer value */
                    uint32_t fat_ptr = Generate_Expression(cg, init);
                    const char *init_bt = Array_Bound_Llvm_Type(ty);

                    if (dest_needs_fat_storage) {
                        /* Destination needs fat pointer storage (unconstrained or dynamic bounds).
                         * Storage is { ptr, { bound, bound } }.  We need separate
                         * data storage on the stack, then store the fat pointer. */
                        uint32_t src_data = Emit_Fat_Pointer_Data(cg, fat_ptr, init_bt);
                        uint32_t src_low  = Emit_Fat_Pointer_Low(cg, fat_ptr, init_bt);
                        uint32_t src_high = Emit_Fat_Pointer_High(cg, fat_ptr, init_bt);
                        uint32_t len      = Emit_Fat_Pointer_Length(cg, fat_ptr, init_bt);
                        uint32_t len_64   = Emit_Extend_To_I64(cg, len, init_bt);

                        /* Allocate local data storage sized by source bounds */
                        uint32_t local_data = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = alloca i8, i64 %%t%u"
                             "  ; constrained-by-init data\n", local_data, len_64);

                        /* Copy source data to local storage */
                        Emit(cg, "  call void @llvm.memcpy.p0.p0.i64("
                             "ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)\n",
                             local_data, src_data, len_64);

                        /* Build fat pointer pointing to local data with source bounds */
                        uint32_t new_fat = Emit_Fat_Pointer_Dynamic(cg,
                            local_data, src_low, src_high, init_bt);

                        /* Store fat pointer into variable */
                        Emit_Store_Fat_Pointer_To_Symbol(cg, new_fat, sym, init_bt);
                    } else {
                        /* Destination is constrained — just copy data bytes */
                        Emit_Fat_Pointer_Copy_To_Name(cg, fat_ptr, sym, init_bt);
                    }
                } else {
                    /* Source is a constrained character array — usually plain ptr.
                     * But may be a fat pointer if source has dynamic bounds. */
                    uint32_t src_ptr = Generate_Expression(cg, init);
                    const char *src_llvm_init = Expression_Llvm_Type(cg, init);
                    bool src_is_fat = Llvm_Type_Is_Fat_Pointer(src_llvm_init);
                    if (src_is_fat) {
                        /* Source produced a fat pointer — extract data pointer */
                        const char *init_bt2 = Array_Bound_Llvm_Type(ty);
                        src_ptr = Emit_Fat_Pointer_Data(cg, src_ptr, init_bt2);
                    }

                    if (dest_needs_fat_storage and init_ty and
                        init_ty->array.index_count > 0) {
                        /* Dest is unconstrained but source is constrained.
                         * Build fat pointer from source's static bounds.
                         * For multidimensional arrays, use product of all extents. */
                        int128_t byte_len = 1;
                        for (uint32_t d = 0; d < init_ty->array.index_count; d++) {
                            int128_t dlo = Type_Bound_Value(init_ty->array.indices[d].low_bound);
                            int128_t dhi = Type_Bound_Value(init_ty->array.indices[d].high_bound);
                            int128_t dim_cnt = (dhi >= dlo) ? (dhi - dlo + 1) : 0;
                            byte_len *= dim_cnt;
                        }
                        uint32_t el_sz_c2u = (init_ty->array.element_type and
                            init_ty->array.element_type->size > 0) ?
                            init_ty->array.element_type->size : 1;
                        byte_len *= el_sz_c2u;
                        int128_t lo = Type_Bound_Value(
                            init_ty->array.indices[0].low_bound);
                        int128_t hi = Type_Bound_Value(
                            init_ty->array.indices[0].high_bound);

                        /* Allocate local data storage */
                        uint32_t local_data = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = alloca i8, i64 %s"
                             "  ; con-to-uncon data\n",
                             local_data, I128_Decimal(byte_len));

                        /* Copy data */
                        Emit(cg, "  call void @llvm.memcpy.p0.p0.i64("
                             "ptr %%t%u, ptr %%t%u, i64 %s, i1 false)\n",
                             local_data, src_ptr, I128_Decimal(byte_len));

                        /* Build fat pointer */
                        const char *ci_bt = Array_Bound_Llvm_Type(ty);
                        uint32_t new_fat = Emit_Fat_Pointer(cg,
                            local_data, lo, hi, ci_bt);

                        /* Store fat pointer into variable */
                        Emit_Store_Fat_Pointer_To_Symbol(cg, new_fat, sym, ci_bt);
                    } else {
                        /* Both constrained — simple memcpy using target bounds.
                         * For multidimensional arrays, compute total byte count
                         * as product of all dimension extents * element size. */
                        int128_t total_elems = 1;
                        for (uint32_t d = 0; d < ty->array.index_count; d++) {
                            int128_t lo = Type_Bound_Value(ty->array.indices[d].low_bound);
                            int128_t hi = Type_Bound_Value(ty->array.indices[d].high_bound);
                            int128_t dim_cnt = (hi >= lo) ? (hi - lo + 1) : 0;
                            total_elems *= dim_cnt;
                        }
                        uint32_t el_sz = (ty->array.element_type and
                            ty->array.element_type->size > 0) ?
                            ty->array.element_type->size : 1;
                        int128_t byte_len = total_elems * el_sz;
                        Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%");
                        Emit_Symbol_Name(cg, sym);
                        Emit(cg, ", ptr %%t%u, i64 %s, i1 false)\n",
                             src_ptr, I128_Decimal(byte_len));
                    }
                }
            } else if (Type_Is_Fixed_Point(ty) and
                       node->object_decl.init->kind == NK_REAL) {
                /* Fixed-point initialization from real literal:
                 * Convert real value to scaled integer at compile time
                 * Use Big_Real for precise scaling when available */
                double real_val = node->object_decl.init->real_lit.value;
                double small = ty->fixed.small > 0 ? ty->fixed.small : ty->fixed.delta;
                int64_t scaled_val;
                Big_Real *big_val = node->object_decl.init->real_lit.big_value;
                if (big_val and small != 0) {
                    /* Precise scaling: scaled = significand * 10^exponent / small
                     * For best precision, compute in arbitrary precision then round */
                    Big_Real *small_br = Big_Real_New();
                    small_br->significand = Big_Integer_New(4);
                    small_br->significand->limbs[0] = (uint64_t)(small * 1e15 + 0.5);
                    small_br->significand->count = 1;
                    small_br->exponent = -15;
                    /* Use double for final division - Big_Real provides precise numerator.
                     * Use round() for correct rounding of negative values. */
                    scaled_val = (int64_t)round(Big_Real_To_Double(big_val) / small);
                } else {
                    scaled_val = (int64_t)round(real_val / small);
                }
                uint32_t init = Emit_Temp(cg);
                const char *fix_store_type = Type_To_Llvm(ty);
                Emit(cg, "  %%t%u = add %s 0, %lld  ; fixed-point scaled (small=%g)\n",
                     init, fix_store_type, (long long)scaled_val, small);
                /* RM 3.3.2: Scalar constraint check on initialization */
                Emit_Constraint_Check_With_Type(cg, init, ty, NULL, fix_store_type);
                Emit(cg, "  store %s %%t%u, ptr %%", fix_store_type, init);
                Emit_Symbol_Name(cg, sym);
                Emit(cg, "\n");
            } else if (is_record and node->object_decl.init->kind == NK_AGGREGATE) {
                /* Record aggregate initialization - copy from aggregate to variable */
                uint32_t agg_ptr = Generate_Expression(cg, node->object_decl.init);
                Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%");
                Emit_Symbol_Name(cg, sym);
                Emit(cg, ", ptr %%t%u, i64 %u, i1 false)\n", agg_ptr, record_size);

                /* If the type has discriminant constraints, store constraint values (RM 3.7.2)
                 * This ensures discriminant fields are correctly set even after aggregate copy */
                if (ty->record.has_disc_constraints and ty->record.disc_constraint_values) {
                    for (uint32_t di = 0; di < ty->record.discriminant_count; di++) {
                        Component_Info *dc = &ty->record.components[di];
                        uint32_t dp = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = getelementptr i8, ptr %%", dp);
                        Emit_Symbol_Name(cg, sym);
                        Emit(cg, ", i64 %u  ; disc %.*s\n", dc->byte_offset,
                             (int)dc->name.length, dc->name.data);
                        const char *dt = Type_To_Llvm(dc->component_type);
                        if (ty->record.disc_constraint_exprs and ty->record.disc_constraint_exprs[di]) {
                            uint32_t val = Generate_Expression(cg, ty->record.disc_constraint_exprs[di]);
                            val = Emit_Coerce_Default_Int(cg, val, dt);
                            Emit(cg, "  store %s %%t%u, ptr %%t%u  ; disc runtime\n", dt, val, dp);
                        } else {
                            Emit(cg, "  store %s %lld, ptr %%t%u\n", dt,
                                 (long long)ty->record.disc_constraint_values[di], dp);
                        }
                    }
                    sym->is_disc_constrained = true;
                }
            } else if (is_any_array and node->object_decl.init->kind == NK_AGGREGATE) {
                /* Array aggregate initialization - copy from aggregate to variable.
                 * Works for both constrained and unconstrained arrays with aggregate initializers.
                 * For arrays with dynamic bounds, the aggregate already returns a fat pointer. */
                Type_Info *agg_type = node->object_decl.init->type;
                bool dest_needs_fat = Type_Has_Dynamic_Bounds(ty) or Type_Is_Unconstrained_Array(ty);
                /* Generate_Aggregate returns a fat ptr alloca when the aggregate
                 * type is unconstrained OR has dynamic bounds in ANY dimension.
                 * Detect this so we copy the fat ptr instead of re-wrapping. */
                bool agg_returns_fat = agg_type and
                    (not agg_type->array.is_constrained or
                     Type_Has_Dynamic_Bounds(agg_type));

                uint32_t agg_ptr = Generate_Expression(cg, node->object_decl.init);

                if (dest_needs_fat and agg_returns_fat) {
                    /* Aggregate already returns a fat pointer alloca.
                     * Load it and store to the destination variable. */
                    uint32_t loaded = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = load " FAT_PTR_TYPE ", ptr %%t%u  ; load agg fat ptr\n",
                         loaded, agg_ptr);
                    Emit(cg, "  store " FAT_PTR_TYPE " %%t%u, ptr %%", loaded);
                    Emit_Symbol_Name(cg, sym);
                    Emit(cg, "  ; store fat ptr to var\n");
                } else if (dest_needs_fat and agg_type and agg_type->array.index_count > 0) {
                    /* Destination needs a fat pointer { ptr, { bound, bound, ... } }.
                     * agg_ptr is the data pointer (static bounds), construct the fat pointer. */
                    const char *iat_agg = Integer_Arith_Type(cg);
                    const char *agg_abt = Array_Bound_Llvm_Type(ty);
                    uint32_t agg_ndims = agg_type->array.index_count;
                    if (agg_ndims > 1) {
                        /* Multi-dim: store all dimension bounds */
                        uint32_t agg_mlo[8], agg_mhi[8];
                        if (agg_ndims > 8) agg_ndims = 8;
                        for (uint32_t d = 0; d < agg_ndims; d++) {
                            Type_Bound lo_b = agg_type->array.indices[d].low_bound;
                            Type_Bound hi_b = agg_type->array.indices[d].high_bound;
                            agg_mlo[d] = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add %s 0, %s\n", agg_mlo[d], iat_agg,
                                 lo_b.kind == BOUND_INTEGER ? I128_Decimal(lo_b.int_value) : "1");
                            Temp_Set_Type(cg, agg_mlo[d], iat_agg);
                            agg_mhi[d] = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add %s 0, %s\n", agg_mhi[d], iat_agg,
                                 hi_b.kind == BOUND_INTEGER ? I128_Decimal(hi_b.int_value) : "0");
                            Temp_Set_Type(cg, agg_mhi[d], iat_agg);
                        }
                        uint32_t fat = Emit_Fat_Pointer_MultiDim(cg, agg_ptr, agg_mlo, agg_mhi, agg_ndims, agg_abt);
                        Emit_Store_Fat_Pointer_To_Symbol(cg, fat, sym, agg_abt);
                    } else {
                        Type_Bound low_b = agg_type->array.indices[0].low_bound;
                        Type_Bound high_b = agg_type->array.indices[0].high_bound;
                        uint32_t low_val, high_val;
                        if (low_b.kind == BOUND_INTEGER) {
                            low_val = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add %s 0, %s\n", low_val, iat_agg, I128_Decimal(low_b.int_value));
                        } else {
                            low_val = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add %s 0, 1\n", low_val, iat_agg);
                        }
                        Temp_Set_Type(cg, low_val, iat_agg);
                        if (high_b.kind == BOUND_INTEGER) {
                            high_val = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add %s 0, %s\n", high_val, iat_agg, I128_Decimal(high_b.int_value));
                        } else {
                            high_val = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add %s 0, 0\n", high_val, iat_agg);
                        }
                        Temp_Set_Type(cg, high_val, iat_agg);
                        Emit_Store_Fat_Pointer_Fields_To_Symbol(cg, agg_ptr, low_val, high_val, sym, agg_abt);
                    }
                } else if (ty->size > 0) {
                    /* Static size known at compile time */
                    Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%");
                    Emit_Symbol_Name(cg, sym);
                    Emit(cg, ", ptr %%t%u, i64 %u, i1 false)  ; array init\n", agg_ptr, ty->size);
                } else {
                    /* Dynamic size - compute from bounds at runtime */
                    uint32_t elem_sz = elem_size > 0 ? elem_size :
                                       (ty->array.element_type ? ty->array.element_type->size : 8);
                    if (elem_sz == 0) elem_sz = 8;

                    /* Get bounds from aggregate type if available */
                    if (agg_type and agg_type->array.index_count > 0 and
                        agg_type->array.indices[0].low_bound.kind == BOUND_INTEGER and
                        agg_type->array.indices[0].high_bound.kind == BOUND_INTEGER) {
                        /* Bounds are static integers in the aggregate - use ALL dimensions */
                        int64_t count = 1;
                        for (uint32_t d = 0; d < agg_type->array.index_count; d++) {
                            if (agg_type->array.indices[d].low_bound.kind == BOUND_INTEGER and
                                agg_type->array.indices[d].high_bound.kind == BOUND_INTEGER) {
                                int64_t lo = agg_type->array.indices[d].low_bound.int_value;
                                int64_t hi = agg_type->array.indices[d].high_bound.int_value;
                                int64_t dim_count = hi - lo + 1;
                                if (dim_count > 0) count *= dim_count;
                            }
                        }
                        if (count > 0) {
                            Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%");
                            Emit_Symbol_Name(cg, sym);
                            Emit(cg, ", ptr %%t%u, i64 %lld, i1 false)  ; array init\n",
                                 agg_ptr, (long long)(count * elem_sz));
                        }
                    } else {
                        /* Fallback: use element size as minimum */
                        Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%");
                        Emit_Symbol_Name(cg, sym);
                        Emit(cg, ", ptr %%t%u, i64 %u, i1 false)  ; array init (min)\n",
                             agg_ptr, elem_sz);
                    }
                }
            } else if (is_any_array and not is_constrained_array and
                       node->object_decl.init->kind != NK_AGGREGATE) {
                /* Unconstrained non-character array init from expression (e.g. function call).
                 * The source produces a fat pointer.  We need to:
                 * 1. Allocate local data storage from source bounds
                 * 2. Copy data to local storage
                 * 3. Build new fat pointer with local data
                 * 4. Store fat pointer into variable */
                uint32_t fat_ptr = Generate_Expression(cg, node->object_decl.init);
                const char *src_llvm = Expression_Llvm_Type(cg, node->object_decl.init);

                const char *uai_bt = Array_Bound_Llvm_Type(ty);
                if (Llvm_Type_Is_Fat_Pointer(src_llvm)) {
                    /* Source is fat pointer — unpack, alloca, copy, rebuild */
                    uint32_t src_data = Emit_Fat_Pointer_Data(cg, fat_ptr, uai_bt);
                    uint32_t src_low  = Emit_Fat_Pointer_Low(cg, fat_ptr, uai_bt);
                    uint32_t src_high = Emit_Fat_Pointer_High(cg, fat_ptr, uai_bt);
                    uint32_t len      = Emit_Fat_Pointer_Length(cg, fat_ptr, uai_bt);

                    uint32_t e_sz = elem_size > 0 ? elem_size :
                        (ty->array.element_type ? ty->array.element_type->size : 1);
                    if (e_sz == 0) e_sz = 1;

                    const char *uai_iat = Integer_Arith_Type(cg);
                    uint32_t len_cvt = Emit_Convert(cg, len, uai_bt, uai_iat);
                    uint32_t byte_len = Emit_Temp(cg);
                    if (e_sz == 1) {
                        Emit(cg, "  %%t%u = add %s %%t%u, 0  ; byte_len\n",
                             byte_len, uai_iat, len_cvt);
                    } else {
                        Emit(cg, "  %%t%u = mul %s %%t%u, %u  ; byte_len\n",
                             byte_len, uai_iat, len_cvt, e_sz);
                    }

                    /* Widen byte_len to i64 for alloca and memcpy intrinsics */
                    uint32_t byte_len_64 = Emit_Extend_To_I64(cg, byte_len, uai_iat);
                    uint32_t local_data = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = alloca i8, i64 %%t%u"
                         "  ; uncon array init data\n", local_data, byte_len_64);

                    Emit(cg, "  call void @llvm.memcpy.p0.p0.i64("
                         "ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)\n",
                         local_data, src_data, byte_len_64);

                    uint32_t new_fat = Emit_Fat_Pointer_Dynamic(cg,
                        local_data, src_low, src_high, uai_bt);

                    Emit_Store_Fat_Pointer_To_Symbol(cg, new_fat, sym, uai_bt);
                } else {
                    /* Source is ptr (constrained) — wrap with bounds */
                    Type_Info *init_ty = node->object_decl.init->type;
                    if (init_ty and init_ty->array.index_count > 0) {
                        int128_t lo = Type_Bound_Value(
                            init_ty->array.indices[0].low_bound);
                        int128_t hi = Type_Bound_Value(
                            init_ty->array.indices[0].high_bound);
                        uint32_t new_fat = Emit_Fat_Pointer(cg, fat_ptr, lo, hi, uai_bt);
                        Emit_Store_Fat_Pointer_To_Symbol(cg, new_fat, sym, uai_bt);
                    } else {
                        /* Fallback: store as fat pointer with unknown bounds */
                        Emit_Store_Fat_Pointer_To_Symbol(cg, fat_ptr, sym, uai_bt);
                    }
                }
            } else if (is_record) {
                /* Record initialized with non-aggregate expression (function call,
                 * qualified expression, type conversion, etc.).  Generate_Expression
                 * returns a ptr to the result; memcpy into the variable.  RM 3.3.1 */
                uint32_t init_ptr = Generate_Expression(cg, node->object_decl.init);
                if (record_size > 0) {
                    Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%");
                    Emit_Symbol_Name(cg, sym);
                    Emit(cg, ", ptr %%t%u, i64 %u, i1 false)  ; record init from expr\n",
                         init_ptr, record_size);
                }
            } else if (is_any_array and is_constrained_array) {
                /* Constrained array initialized with non-aggregate expression
                 * (function call, slice, type conversion, etc.).  Similar to
                 * record case — result is a ptr, memcpy into the variable. */
                uint32_t init_ptr = Generate_Expression(cg, node->object_decl.init);
                uint32_t copy_sz = ty->size > 0 ? ty->size : elem_size;
                if (copy_sz > 0) {
                    Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%");
                    Emit_Symbol_Name(cg, sym);
                    Emit(cg, ", ptr %%t%u, i64 %u, i1 false)  ; constrained array init from expr\n",
                         init_ptr, copy_sz);
                }
            } else if (not is_any_array and not is_record) {
                uint32_t init = Generate_Expression(cg, node->object_decl.init);
                /* Use Expression_Llvm_Type to get correct type for all expressions
                 * including pointers, floats, and integers */
                const char *src_type_str = Expression_Llvm_Type(cg, node->object_decl.init);

                /* RM 3.5(3): Check dynamic subtype constraint bounds against base type */
                Emit_Subtype_Constraint_Compat_Check(cg, ty);

                /* RM 3.3.2: Scalar constraint check on initialization.
                 * check BEFORE conversion so value is at source type. */
                if (ty and Type_Is_Scalar(ty)) {
                    Type_Info *init_src_type = node->object_decl.init->type;
                    Emit_Constraint_Check_With_Type(cg, init, ty, init_src_type, src_type_str);
                }

                /* Float > fixed-point: scale by SMALL before integer conversion.
                 * Fixed-point values are stored as scaled integers: val / SMALL.
                 * Without this, fptosi would just truncate the float value. */
                if (ty and Type_Is_Fixed_Point(ty) and Is_Float_Type(src_type_str)) {
                    double small = ty->fixed.small;
                    if (small <= 0) small = ty->fixed.delta > 0 ? ty->fixed.delta : 1.0;
                    uint64_t sb; memcpy(&sb, &small, sizeof(sb));
                    uint32_t small_t = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = fadd double 0.0, 0x%016llX  ; small=%g\n",
                         small_t, (unsigned long long)sb, small);
                    uint32_t div_t = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = fdiv %s %%t%u, %%t%u  ; float/SMALL for fixed-point\n",
                         div_t, src_type_str, init, small_t);
                    init = div_t;
                }

                /* Convert if types differ, then store */
                init = Emit_Convert(cg, init, src_type_str, type_str);

                Emit(cg, "  store %s %%t%u, ptr %%", type_str, init);
                Emit_Symbol_Name(cg, sym);
                Emit(cg, "\n");
            }
        } else if (is_any_array and Type_Has_Dynamic_Bounds(ty) and ty->array.index_count > 0) {
            /* Uninitialized array with dynamic bounds - still need to set up fat pointer.
             * The array contents are uninitialized but bounds are known from the type.
             * This handles cases like: A2 : ARR1 (1 .. F * 1000); */
            const char *iat_decl = Integer_Arith_Type(cg);
            uint32_t ndims_decl = ty->array.index_count;
            if (ndims_decl > 8) ndims_decl = 8;
            uint32_t dim_lo_decl[8], dim_hi_decl[8];

            for (uint32_t d = 0; d < ndims_decl; d++) {
                Type_Bound low_b = ty->array.indices[d].low_bound;
                Type_Bound high_b = ty->array.indices[d].high_bound;

                /* Get low bound */
                if (low_b.kind == BOUND_INTEGER) {
                    dim_lo_decl[d] = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s 0, %s\n", dim_lo_decl[d], iat_decl, I128_Decimal(low_b.int_value));
                    Temp_Set_Type(cg, dim_lo_decl[d], iat_decl);
                } else if (low_b.kind == BOUND_EXPR and low_b.expr) {
                    dim_lo_decl[d] = Generate_Expression(cg, low_b.expr);
                    if (not Type_Is_Float_Representation(low_b.expr->type)) {
                        const char *low_llvm = Expression_Llvm_Type(cg, low_b.expr);
                        if (strcmp(low_llvm, iat_decl) != 0 and !Llvm_Type_Is_Pointer(low_llvm))
                            dim_lo_decl[d] = Emit_Convert(cg, dim_lo_decl[d], low_llvm, iat_decl);
                    }
                    Temp_Set_Type(cg, dim_lo_decl[d], iat_decl);
                } else if (ty->array.indices[d].index_type) {
                    /* Derive from index type's low bound (e.g., BOOLEAN'FIRST=0, NI'FIRST=-3) */
                    Type_Info *idx_ty = ty->array.indices[d].index_type;
                    if (idx_ty->low_bound.kind == BOUND_EXPR and idx_ty->low_bound.expr) {
                        dim_lo_decl[d] = Generate_Expression(cg, idx_ty->low_bound.expr);
                        const char *vty = Expression_Llvm_Type(cg, idx_ty->low_bound.expr);
                        if (strcmp(vty, iat_decl) != 0 and vty[0] == 'i')
                            dim_lo_decl[d] = Emit_Convert(cg, dim_lo_decl[d], vty, iat_decl);
                    } else {
                        dim_lo_decl[d] = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = add %s 0, %s\n", dim_lo_decl[d], iat_decl,
                             I128_Decimal(Type_Bound_Value(idx_ty->low_bound)));
                    }
                    Temp_Set_Type(cg, dim_lo_decl[d], iat_decl);
                } else {
                    dim_lo_decl[d] = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s 0, 1\n", dim_lo_decl[d], iat_decl);
                    Temp_Set_Type(cg, dim_lo_decl[d], iat_decl);
                }

                /* Get high bound */
                if (high_b.kind == BOUND_INTEGER) {
                    dim_hi_decl[d] = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s 0, %s\n", dim_hi_decl[d], iat_decl, I128_Decimal(high_b.int_value));
                    Temp_Set_Type(cg, dim_hi_decl[d], iat_decl);
                } else if (high_b.kind == BOUND_EXPR and high_b.expr) {
                    dim_hi_decl[d] = Generate_Expression(cg, high_b.expr);
                    if (not Type_Is_Float_Representation(high_b.expr->type)) {
                        const char *high_llvm = Expression_Llvm_Type(cg, high_b.expr);
                        if (strcmp(high_llvm, iat_decl) != 0 and !Llvm_Type_Is_Pointer(high_llvm))
                            dim_hi_decl[d] = Emit_Convert(cg, dim_hi_decl[d], high_llvm, iat_decl);
                    }
                    Temp_Set_Type(cg, dim_hi_decl[d], iat_decl);
                } else if (ty->array.indices[d].index_type) {
                    /* Derive from index type's high bound */
                    Type_Info *idx_ty = ty->array.indices[d].index_type;
                    if (idx_ty->high_bound.kind == BOUND_EXPR and idx_ty->high_bound.expr) {
                        dim_hi_decl[d] = Generate_Expression(cg, idx_ty->high_bound.expr);
                        const char *vty = Expression_Llvm_Type(cg, idx_ty->high_bound.expr);
                        if (strcmp(vty, iat_decl) != 0 and vty[0] == 'i')
                            dim_hi_decl[d] = Emit_Convert(cg, dim_hi_decl[d], vty, iat_decl);
                    } else {
                        dim_hi_decl[d] = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = add %s 0, %s\n", dim_hi_decl[d], iat_decl,
                             I128_Decimal(Type_Bound_Value(idx_ty->high_bound)));
                    }
                    Temp_Set_Type(cg, dim_hi_decl[d], iat_decl);
                } else {
                    dim_hi_decl[d] = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add %s 0, 0\n", dim_hi_decl[d], iat_decl);
                    Temp_Set_Type(cg, dim_hi_decl[d], iat_decl);
                }
            }

            /* Allocate array data: total_bytes = product(len_d) * elem_size */
            uint32_t elem_sz = elem_size > 0 ? elem_size :
                               (ty->array.element_type ? ty->array.element_type->size : 8);
            if (elem_sz == 0) elem_sz = 8;

            uint32_t total_count = 0;
            for (uint32_t d = 0; d < ndims_decl; d++) {
                uint32_t count_d = Emit_Temp(cg);
                Emit(cg, "  %%t%u = sub %s %%t%u, %%t%u\n", count_d, iat_decl, dim_hi_decl[d], dim_lo_decl[d]);
                uint32_t len_d = Emit_Temp(cg);
                Emit(cg, "  %%t%u = add %s %%t%u, 1\n", len_d, iat_decl, count_d);
                if (d == 0) {
                    total_count = len_d;
                } else {
                    uint32_t prod = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = mul %s %%t%u, %%t%u\n", prod, iat_decl, total_count, len_d);
                    total_count = prod;
                }
            }
            uint32_t byte_size = Emit_Temp(cg);
            Emit(cg, "  %%t%u = mul %s %%t%u, %u\n", byte_size, iat_decl, total_count, elem_sz);

            uint32_t data_ptr = Emit_Temp(cg);
            Emit(cg, "  %%t%u = alloca i8, %s %%t%u  ; dynamic uninit array\n", data_ptr, iat_decl, byte_size);

            /* Construct fat pointer with multi-dim bounds */
            if (ndims_decl > 1) {
                uint32_t fat = Emit_Fat_Pointer_MultiDim(cg, data_ptr, dim_lo_decl, dim_hi_decl, ndims_decl,
                                                          Array_Bound_Llvm_Type(ty));
                Emit_Store_Fat_Pointer_To_Symbol(cg, fat, sym, Array_Bound_Llvm_Type(ty));
            } else {
                Emit_Store_Fat_Pointer_Fields_To_Symbol(cg, data_ptr, dim_lo_decl[0], dim_hi_decl[0], sym, Array_Bound_Llvm_Type(ty));
            }
        } else if (is_record and ty->record.component_count > 0) {
            /* Record without explicit initializer (RM 3.7):
             * 1. If constrained subtype, initialize discriminants from constraints
             * 2. Apply component defaults for discriminants and regular components */

            /* Initialize discriminant constraints if type is constrained (RM 3.7.2) */
            if (ty->record.has_disc_constraints and ty->record.disc_constraint_values) {
                for (uint32_t di = 0; di < ty->record.discriminant_count; di++) {
                    Component_Info *dc = &ty->record.components[di];
                    uint32_t dp = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = getelementptr i8, ptr %%", dp);
                    Emit_Symbol_Name(cg, sym);
                    Emit(cg, ", i64 %u  ; disc %.*s init\n", dc->byte_offset,
                         (int)dc->name.length, dc->name.data);
                    const char *dt = Type_To_Llvm(dc->component_type);
                    /* Use runtime expression if available, else static value */
                    if (ty->record.disc_constraint_exprs and ty->record.disc_constraint_exprs[di]) {
                        uint32_t val = Generate_Expression(cg, ty->record.disc_constraint_exprs[di]);
                        val = Emit_Coerce_Default_Int(cg, val, dt);
                        Emit(cg, "  store %s %%t%u, ptr %%t%u  ; disc runtime init\n", dt, val, dp);
                    } else {
                        Emit(cg, "  store %s %lld, ptr %%t%u\n", dt,
                             (long long)ty->record.disc_constraint_values[di], dp);
                    }
                }
                sym->is_disc_constrained = true;
            }

            /* Initialize discriminant constraints of record subcomponents (RM 3.7.2).
             * E.g., for TYPE R2(D2: POSITIVE) IS RECORD C : R1(2); END RECORD;
             * we must also initialize C.D1 = 2 at the appropriate offset. */
            for (uint32_t ci = ty->record.discriminant_count;
                 ci < ty->record.component_count; ci++) {
                Component_Info *comp = &ty->record.components[ci];
                Type_Info *ct = comp->component_type;
                if (not ct or ct->kind != TYPE_RECORD) continue;
                if (not ct->record.has_disc_constraints or
                    not ct->record.disc_constraint_values) continue;
                for (uint32_t di = 0; di < ct->record.discriminant_count; di++) {
                    Component_Info *dc = &ct->record.components[di];
                    uint32_t dp = Emit_Temp(cg);
                    uint32_t abs_offset = comp->byte_offset + dc->byte_offset;
                    Emit(cg, "  %%t%u = getelementptr i8, ptr %%", dp);
                    Emit_Symbol_Name(cg, sym);
                    Emit(cg, ", i64 %u  ; subcomponent disc %.*s.%.*s init\n",
                         abs_offset,
                         (int)comp->name.length, comp->name.data,
                         (int)dc->name.length, dc->name.data);
                    const char *dt = Type_To_Llvm(dc->component_type);
                    if (ct->record.disc_constraint_exprs and
                        ct->record.disc_constraint_exprs[di]) {
                        /* Check if the constraint expression references a discriminant
                         * of the parent record — if so, load from the record variable
                         * at the discriminant's offset rather than via Generate_Expression
                         * (the discriminant has no standalone alloca, RM 3.7.2). */
                        Syntax_Node *cexpr = ct->record.disc_constraint_exprs[di];
                        uint32_t val = 0;
                        bool found_parent_disc = false;
                        if (cexpr->kind == NK_IDENTIFIER and cexpr->symbol) {
                            for (uint32_t pdi = 0; pdi < ty->record.discriminant_count; pdi++) {
                                Component_Info *pdc = &ty->record.components[pdi];
                                if (Slice_Equal_Ignore_Case(pdc->name, cexpr->symbol->name)) {
                                    val = Emit_Temp(cg);
                                    Emit(cg, "  %%t%u = getelementptr i8, ptr %%", val);
                                    Emit_Symbol_Name(cg, sym);
                                    Emit(cg, ", i64 %u\n", pdc->byte_offset);
                                    uint32_t ld = Emit_Temp(cg);
                                    Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", ld, dt, val);
                                    val = ld;
                                    found_parent_disc = true;
                                    break;
                                }
                            }
                        }
                        if (not found_parent_disc)
                            val = Generate_Expression(cg, cexpr);
                        val = Emit_Coerce_Default_Int(cg, val, dt);
                        Emit(cg, "  store %s %%t%u, ptr %%t%u  ; subcomp disc runtime init\n",
                             dt, val, dp);
                    } else {
                        Emit(cg, "  store %s %lld, ptr %%t%u\n", dt,
                             (long long)ct->record.disc_constraint_values[di], dp);
                    }
                }
            }

            /* Apply component defaults (RM 3.7) - includes discriminant defaults
             * for mutable records (all discriminants have defaults, no explicit constraint) */
            bool has_any_default = false;
            for (uint32_t ci = 0; ci < ty->record.component_count; ci++) {
                if (ty->record.components[ci].default_expr) {
                    has_any_default = true;
                    break;
                }
            }
            if (has_any_default) {
                for (uint32_t ci = 0; ci < ty->record.component_count; ci++) {
                    Component_Info *comp = &ty->record.components[ci];
                    if (not comp->default_expr) continue;

                    /* Skip discriminant defaults if constraint values already set */
                    if (comp->is_discriminant and ty->record.has_disc_constraints) continue;

                    /* Generate value for default expression */
                    uint32_t val = Generate_Expression(cg, comp->default_expr);
                    if (val == 0) continue;  /* Expression generation failed */

                    /* Check default value against component subtype constraint (RM 3.3.2).
                     * E.g., A : INTEGER RANGE 1..10 := IDENT_INT(0) must raise
                     * CONSTRAINT_ERROR because 0 is not in 1..10. */
                    Emit_Constraint_Check(cg, val, comp->component_type,
                                          comp->default_expr->type);

                    /* Get pointer to component within record — use runtime
                     * offset for records with dynamic-sized components. */
                    uint32_t comp_ptr = Emit_Temp(cg);
                    if (ty and ty->rt_global_id > 0) {
                        uint32_t rt_off = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = load i64, ptr @__rt_rec_%u_off%u\n",
                             rt_off, ty->rt_global_id, ci);
                        Emit(cg, "  %%t%u = getelementptr i8, ptr %%", comp_ptr);
                        Emit_Symbol_Name(cg, sym);
                        Emit(cg, ", i64 %%t%u  ; %.*s rt default\n", rt_off,
                             (int)comp->name.length, comp->name.data);
                    } else {
                        Emit(cg, "  %%t%u = getelementptr i8, ptr %%", comp_ptr);
                        Emit_Symbol_Name(cg, sym);
                        Emit(cg, ", i64 %u  ; %.*s default\n", comp->byte_offset,
                             (int)comp->name.length, comp->name.data);
                    }

                    /* Store default value into component, handling composites
                     * (arrays/records) with memcpy instead of scalar store. */
                    Type_Info *comp_type = comp->component_type;
                    bool comp_is_composite = Type_Is_Composite(comp_type);
                    bool has_rt_size = comp_type and comp_type->rt_global_id > 0;

                    if (comp_is_composite and (comp_type->size > 0 or has_rt_size)) {
                        /* Composite default: expression returns a data pointer.
                         * For dynamic-bound aggregates that produce fat pointers,
                         * extract the data pointer first. */
                        uint32_t data_ptr = val;
                        bool is_fat_agg = comp->default_expr->kind == NK_AGGREGATE and
                            comp_type and Type_Is_Array_Like(comp_type) and
                            (Type_Is_Unconstrained_Array(comp_type) or
                             Aggregate_Produces_Fat_Pointer(comp_type));
                        if (is_fat_agg) {
                            uint32_t loaded = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = load " FAT_PTR_TYPE ", ptr %%t%u\n",
                                 loaded, val);
                            data_ptr = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = extractvalue " FAT_PTR_TYPE
                                 " %%t%u, 0\n", data_ptr, loaded);
                        }
                        if (has_rt_size) {
                            uint32_t rtsz = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = load i64, ptr @__rt_type_%u_size\n",
                                 rtsz, comp_type->rt_global_id);
                            Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %%t%u, i1 false)"
                                 "  ; %.*s rt default memcpy\n",
                                 comp_ptr, data_ptr, rtsz,
                                 (int)comp->name.length, comp->name.data);
                        } else {
                            Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%t%u, ptr %%t%u, i64 %u, i1 false)"
                                 "  ; %.*s default memcpy\n",
                                 comp_ptr, data_ptr, comp_type->size,
                                 (int)comp->name.length, comp->name.data);
                        }
                    } else if (comp_is_composite) {
                        /* 0-size composite without rt_global: skip */
                    } else {
                        const char *store_type = Type_To_Llvm(comp_type);
                        const char *val_type = Temp_Get_Type(cg, val);
                        if (not val_type or strlen(val_type) == 0) {
                            Type_Info *expr_type = comp->default_expr->type;
                            if (expr_type)
                                val_type = Type_To_Llvm(expr_type);
                        }
                        if (not val_type or strlen(val_type) == 0)
                            val_type = Expression_Llvm_Type(cg, comp->default_expr);
                        if (not store_type or strlen(store_type) == 0)
                            store_type = val_type;
                        if (Type_Is_Float(comp_type)) {
                            const char *flt_ty = Float_Llvm_Type_Of(comp_type);
                            val = Emit_Convert(cg, val, val_type, flt_ty);
                            Emit(cg, "  store %s %%t%u, ptr %%t%u\n", flt_ty, val, comp_ptr);
                        } else {
                            if (comp_type and comp_type->kind == TYPE_FIXED and
                                val_type and Is_Float_Type(val_type)) {
                                double small = comp_type->fixed.small;
                                if (small <= 0) small = comp_type->fixed.delta > 0 ? comp_type->fixed.delta : 1.0;
                                uint64_t sb; memcpy(&sb, &small, sizeof(sb));
                                uint32_t st = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = fadd double 0.0, 0x%016llX  ; small\n", st, (unsigned long long)sb);
                                uint32_t dv = Emit_Temp(cg);
                                Emit(cg, "  %%t%u = fdiv %s %%t%u, %%t%u  ; rec default/small\n", dv, val_type, val, st);
                                val = dv;
                            }
                            val = Emit_Convert(cg, val, val_type, store_type);
                            Emit(cg, "  store %s %%t%u, ptr %%t%u\n", store_type, val, comp_ptr);
                        }
                    }
                }
            }
        }
    }
}

/* Forward declare for recursive search */
static bool Has_Nested_Subprograms(Node_List *declarations, Node_List *statements);

static bool Has_Nested_In_Statements(Node_List *statements) {
    if (not statements) return false;
    for (uint32_t i = 0; i < statements->count; i++) {
        Syntax_Node *stmt = statements->items[i];
        if (not stmt) continue;
        if (stmt->kind == NK_BLOCK) {
            /* DECLARE block - check its declarations and nested statements */
            if (Has_Nested_Subprograms(&stmt->block_stmt.declarations,
                                        &stmt->block_stmt.statements)) {
                return true;
            }
        } else if (stmt->kind == NK_IF) {
            /* Check all branches of IF */
            if (Has_Nested_In_Statements(&stmt->if_stmt.then_stmts)) return true;
            for (uint32_t j = 0; j < stmt->if_stmt.elsif_parts.count; j++) {
                Syntax_Node *elsif = stmt->if_stmt.elsif_parts.items[j];
                if (elsif and Has_Nested_In_Statements(&elsif->if_stmt.then_stmts)) return true;
            }
            if (Has_Nested_In_Statements(&stmt->if_stmt.else_stmts)) return true;
        } else if (stmt->kind == NK_LOOP) {
            if (Has_Nested_In_Statements(&stmt->loop_stmt.statements)) return true;
        } else if (stmt->kind == NK_CASE) {
            for (uint32_t j = 0; j < stmt->case_stmt.alternatives.count; j++) {
                Syntax_Node *alt = stmt->case_stmt.alternatives.items[j];
                if (alt and alt->kind == NK_ASSOCIATION and
                    alt->association.expression and
                    alt->association.expression->kind == NK_BLOCK) {
                    if (Has_Nested_In_Statements(&alt->association.expression->block_stmt.statements)) {
                        return true;
                    }
                }
            }
        }
    }
    return false;
}

static bool Has_Nested_Subprograms(Node_List *declarations, Node_List *statements) {
    /* Check declarations for procedure/function/task bodies.
     * Task bodies access enclosing scope variables just like nested
     * subprograms (RM 9.1), so the enclosing scope needs frame allocation.
     * Also check inside nested packages - their subprograms need frame access too. */
    if (declarations) {
        for (uint32_t i = 0; i < declarations->count; i++) {
            Syntax_Node *decl = declarations->items[i];
            if (!decl) continue;
            if (decl->kind == NK_PROCEDURE_BODY ||
                decl->kind == NK_FUNCTION_BODY ||
                decl->kind == NK_TASK_BODY ||
                decl->kind == NK_GENERIC_INST) {
                return true;
            }
            /* Check inside nested package specs for procedure/function declarations */
            if (decl->kind == NK_PACKAGE_SPEC) {
                Node_List *pkg_visible = &decl->package_spec.visible_decls;
                Node_List *pkg_private = &decl->package_spec.private_decls;
                for (uint32_t j = 0; j < pkg_visible->count; j++) {
                    Syntax_Node *pd = pkg_visible->items[j];
                    if (pd && (pd->kind == NK_PROCEDURE_SPEC ||
                              pd->kind == NK_FUNCTION_SPEC ||
                              pd->kind == NK_PROCEDURE_BODY ||
                              pd->kind == NK_FUNCTION_BODY))
                        return true;
                }
                for (uint32_t j = 0; j < pkg_private->count; j++) {
                    Syntax_Node *pd = pkg_private->items[j];
                    if (pd && (pd->kind == NK_PROCEDURE_SPEC ||
                              pd->kind == NK_FUNCTION_SPEC ||
                              pd->kind == NK_PROCEDURE_BODY ||
                              pd->kind == NK_FUNCTION_BODY))
                        return true;
                }
            }
            /* Check inside nested package bodies for procedure/function bodies */
            if (decl->kind == NK_PACKAGE_BODY) {
                Node_List *pkg_decls = &decl->package_body.declarations;
                for (uint32_t j = 0; j < pkg_decls->count; j++) {
                    Syntax_Node *pd = pkg_decls->items[j];
                    if (pd && (pd->kind == NK_PROCEDURE_BODY ||
                              pd->kind == NK_FUNCTION_BODY))
                        return true;
                }
            }
        }
    }
    /* Check statements for DECLARE blocks that might contain nested subprograms */
    return Has_Nested_In_Statements(statements);
}

/* ─────────────────────────────────────────────────────────────────────────
 * Emit LLVM function header: define <ret> @<name>([ptr %__parent_frame,] params...) {
 * Extracted from three near-identical blocks in Generate_Subprogram_Body,
 * Generate_Generic_Instance_Body, and Generate_Task_Body.
 *
 * For BIP functions (returning limited types), we prepend extra parameters:
 *   i32 %__BIPalloc   - Allocation form selector
 *   ptr %__BIPaccess  - Pointer to result destination
 * The function returns void since result is built into __BIPaccess. */
static void Emit_Function_Header(Code_Generator *cg, Symbol *sym, bool is_nested) {
    bool is_function = (sym->kind == SYMBOL_FUNCTION);
    bool is_bip = BIP_Is_BIP_Function(sym);

    /* BIP functions return void - result is built into __BIPaccess */
    if (is_bip) {
        Emit(cg, "define void @");
    } else {
        Emit(cg, "define %s @", is_function ? Type_To_Llvm_Sig(sym->return_type) : "void");
    }
    Emit_Symbol_Name(cg, sym);
    Emit(cg, "(");

    bool need_comma = false;

    /* Static chain for nested functions */
    if (is_nested) {
        Emit(cg, "ptr %%__parent_frame");
        need_comma = true;
    }

    /* BIP extra formals: __BIPalloc (allocation form) and __BIPaccess (dest ptr)
     * Additional formals for task components: __BIPmaster, __BIPchain */
    if (is_bip) {
        uint32_t bip_count = BIP_Extra_Formal_Count(sym);
        if (need_comma) Emit(cg, ", ");
        Emit(cg, "i32 %%__BIPalloc, ptr %%__BIPaccess");
        need_comma = true;
        /* Emit task formals if return type has task components */
        if (bip_count > 2) {
            Emit(cg, ", i32 %%__BIPmaster, ptr %%__BIPchain");
        }
    }

    /* Regular parameters */
    for (uint32_t i = 0; i < sym->parameter_count; i++) {
        if (need_comma) Emit(cg, ", ");
        need_comma = true;
        if (Param_Is_By_Reference(sym->parameters[i].mode))
            Emit(cg, "ptr %%p%u", i);
        else
            Emit(cg, "%s %%p%u", Type_To_Llvm_Sig(sym->parameters[i].param_type), i);
    }
    Emit(cg, ") {\nentry:\n");

    /* Initialize BIP state for code generator */
    BIP_Begin_Function(sym);
}

/* Find the Nth homograph body matching export name in a package body.
 * Extracted from two identical 25-line blocks in Generate_Declaration. */
static Syntax_Node *Find_Homograph_Body(Symbol **exports, uint32_t idx,
                                         String_Slice name, Node_List *body_decls) {
    /* Count preceding exports with the same name to get homograph index */
    uint32_t homograph_idx = 0;
    for (uint32_t k = 0; k < idx; k++) {
        Symbol *prev = exports[k];
        if (prev and (prev->kind == SYMBOL_FUNCTION or prev->kind == SYMBOL_PROCEDURE) and
            Slice_Equal_Ignore_Case(prev->name, name))
            homograph_idx++;
    }
    /* Walk body declarations to find the Nth body with this name */
    uint32_t body_idx = 0;
    for (uint32_t j = 0; j < body_decls->count; j++) {
        Syntax_Node *decl = body_decls->items[j];
        if (not decl) continue;
        if (decl->kind == NK_PROCEDURE_BODY or decl->kind == NK_FUNCTION_BODY)
            if (Slice_Equal_Ignore_Case(
                    decl->subprogram_body.specification->subprogram_spec.name, name))
                if (body_idx++ == homograph_idx) return decl;
    }
    return NULL;
}

/* Process_Deferred_Bodies: Emit deferred nested subprogram/task/generic bodies.
 * Called at end of enclosing function/task/generic instance after restoring context.
 * Processes all bodies deferred since saved_deferred_count. */
static void Process_Deferred_Bodies(Code_Generator *cg, uint32_t saved_deferred_count) {
    while (cg->deferred_count > saved_deferred_count) {
        Syntax_Node *deferred = cg->deferred_bodies[--cg->deferred_count];
        if (deferred->kind == NK_GENERIC_INST) {
            Symbol *inst = deferred->symbol;
            if (inst and inst->generic_template and inst->generic_template->generic_body) {
                Symbol *saved = cg->current_instance;
                cg->current_instance = inst;
                Set_Generic_Type_Map(inst);
                Generate_Generic_Instance_Body(cg, inst, inst->generic_template->generic_body);
                cg->current_instance = saved;
                Set_Generic_Type_Map(saved);
            }
        } else if (deferred->kind == NK_TASK_BODY) {
            Generate_Task_Body(cg, deferred);
        } else {
            Generate_Subprogram_Body(cg, deferred);
        }
    }
}

static void Generate_Subprogram_Body(Code_Generator *cg, Syntax_Node *node) {
    /* Skip stub bodies (PROCEDURE X IS SEPARATE;) - the actual body
     * will be provided by a separate subunit compilation */
    if (node->subprogram_body.is_separate) {
        return;
    }

    /* Skip if code already generated for this body (prevents duplicates) */
    if (node->subprogram_body.code_generated) return;
    node->subprogram_body.code_generated = true;

    Syntax_Node *spec = node->subprogram_body.specification;
    Symbol *sym = spec ? spec->symbol : NULL;
    if (not sym) return;

    /* Mark this symbol as having been defined - prevents duplicate
     * 'declare' statements for functions defined in the same file */
    sym->extern_emitted = true;

    bool is_function = sym->kind == SYMBOL_FUNCTION;
    uint32_t saved_deferred_count = cg->deferred_count;

    /* Check if this is a nested function (has enclosing function).
     * This handles nested packages: a subprogram inside a package inside
     * a procedure needs static chain access to the outermost procedure's frame. */
    Symbol *saved_enclosing = cg->enclosing_function;
    bool saved_is_nested = cg->is_nested;

    /* Find nearest enclosing function/procedure (walks through packages) */
    Symbol *enclosing_subprog = Find_Enclosing_Subprogram(sym);
    bool is_nested = (enclosing_subprog != NULL);
    cg->is_nested = is_nested;
    cg->enclosing_function = enclosing_subprog;

    /* Emit comment showing function/procedure being generated */
    Emit(cg, "\n; ============================================================\n");
    Emit(cg, "; %s %.*s", is_function ? "FUNCTION" : "PROCEDURE",
         (int)sym->name.length, sym->name.data);
    if (is_nested)
        Emit(cg, " (nested)");
    Emit(cg, "\n");
    Emit_Location(cg, node->location);
    Emit(cg, "; ============================================================\n");

    Emit_Function_Header(cg, sym, is_nested);

    Symbol *saved_current_function = cg->current_function;
    cg->current_function = sym;
    cg->has_return = false;
    cg->block_terminated = false;  /* Reset for new function */

    /* Check if this function has nested subprograms (in declarations or DECLARE blocks) */
    bool has_nested = Has_Nested_Subprograms(&node->subprogram_body.declarations,
                                              &node->subprogram_body.statements);

    /* If this function has nested subprograms, allocate a frame base.
     * When also nested itself, reserve 8 extra bytes at the end to store
     * the received __parent_frame (static chain pointer for RM 8.3). */
    if (has_nested) {
        int64_t frame_size = (sym->scope and sym->scope->frame_size > 0)
            ? sym->scope->frame_size : 8;
        int64_t alloca_size = is_nested ? frame_size + 8 : frame_size;
        Emit(cg, "  ; Frame for nested function access\n");
        Emit(cg, "  %%__frame_base = alloca i8, i64 %lld\n", (long long)alloca_size);
        if (is_nested) {
            /* Store static chain: parent's frame at offset frame_size */
            uint32_t slot = Emit_Temp(cg);
            Emit(cg, "  %%t%u = getelementptr i8, ptr %%__frame_base, i64 %lld\n",
                 slot, (long long)frame_size);
            Emit(cg, "  store ptr %%__parent_frame, ptr %%t%u\n", slot);
        }
    }

    /* If nested, create aliases for accessing enclosing scope variables via frame */
    if (is_nested and enclosing_subprog and enclosing_subprog->scope) {
        /* Create pointer aliases to parent scope variables.
         * Must include all storage-bearing symbol kinds: variables, parameters,
         * discriminants, and constants (non-named-number constants like
         * "X : INTEGER := 2" have stack storage and can be modified).
         * Track emitted names to avoid duplicate definitions when the same
         * mangled name appears from both symbols[] and frame_vars[]. */
        Scope *parent_scope = enclosing_subprog->scope;

        /* Track emitted frame alias unique_ids to prevent duplicates.
         * Note: cannot store String_Slice from Symbol_Mangle_Name because
         * it returns pointers into a rotating static buffer (4 slots). */
        #define MAX_FRAME_ALIASES 512
        uint32_t emitted_ids[MAX_FRAME_ALIASES];
        uint32_t emitted_count = 0;

        for (uint32_t i = 0; i < parent_scope->symbol_count; i++) {
            Symbol *var = parent_scope->symbols[i];
            if (var and (var->kind == SYMBOL_VARIABLE or var->kind == SYMBOL_PARAMETER or
                        var->kind == SYMBOL_DISCRIMINANT or
                        (var->kind == SYMBOL_CONSTANT and not var->is_named_number))) {
                /* Check for duplicate unique_id */
                bool already_emitted = false;
                for (uint32_t j = 0; j < emitted_count; j++) {
                    if (var->unique_id == emitted_ids[j]) {
                        already_emitted = true;
                        break;
                    }
                }
                if (already_emitted) continue;
                if (emitted_count < MAX_FRAME_ALIASES) {
                    emitted_ids[emitted_count++] = var->unique_id;
                }
                Emit(cg, "  %%__frame.");
                Emit_Symbol_Name(cg, var);
                Emit(cg, " = getelementptr i8, ptr %%__parent_frame, i64 %lld\n",
                     (long long)(var->frame_offset));
            }
        }
        /* Also create aliases for variables from child scopes (DECLARE blocks, etc.)
         * that share the same function frame but were in deeper scopes.
         * Skip symbols whose mangled name was already emitted above. */
        for (uint32_t i = 0; i < parent_scope->frame_var_count; i++) {
            Symbol *var = parent_scope->frame_vars[i];
            if (not var) continue;
            bool already_emitted = false;
            for (uint32_t j = 0; j < emitted_count; j++) {
                if (var->unique_id == emitted_ids[j]) {
                    already_emitted = true;
                    break;
                }
            }
            if (not already_emitted) {
                if (emitted_count < MAX_FRAME_ALIASES) {
                    emitted_ids[emitted_count++] = var->unique_id;
                }
                Emit(cg, "  %%__frame.");
                Emit_Symbol_Name(cg, var);
                Emit(cg, " = getelementptr i8, ptr %%__parent_frame, i64 %lld\n",
                     (long long)(var->frame_offset));
            }
        }
        #undef MAX_FRAME_ALIASES
    }

    /* Allocate and store parameters to local stack slots
     * For OUT/IN OUT: param is already a pointer, use directly
     * For IN: allocate local slot and copy value */
    for (uint32_t i = 0; i < sym->parameter_count; i++) {
        Symbol *param_sym = sym->parameters[i].param_sym;
        if (param_sym) {
            const char *type_str = Type_To_Llvm_Sig(sym->parameters[i].param_type);
            Parameter_Mode mode = sym->parameters[i].mode;

            /* Check if this IN parameter is a constrained composite type
             * (array/record/string) passed as a raw pointer. These need by-ref
             * treatment since the caller passes a pointer to the data, not the
             * data itself. Unconstrained arrays/strings use fat pointers
             * {ptr, ptr} and should be stored in alloca like scalars. */
            Type_Info *pt = sym->parameters[i].param_type;
            bool is_composite_in = false;
            if (mode == PARAM_IN and pt) {
                if (pt->kind == TYPE_RECORD or pt->kind == TYPE_TASK) {
                    is_composite_in = true;
                } else if ((pt->kind == TYPE_ARRAY or pt->kind == TYPE_STRING) and
                           pt->array.is_constrained and not Type_Has_Dynamic_Bounds(pt)) {
                    is_composite_in = true;
                }
            }

            if (Param_Is_By_Reference(mode) or is_composite_in) {
                /* OUT/IN OUT or IN composite: %p is already a pointer to data.
                 * Create an alias so the parameter name points to caller's storage */
                Emit(cg, "  %%");
                Emit_Symbol_Name(cg, param_sym);
                Emit(cg, " = getelementptr i8, ptr %%p%u, i64 0  ; by-ref param\n", i);
            } else if (has_nested and sym->scope) {
                /* IN param with nested functions: allocate in frame */
                Emit(cg, "  %%");
                Emit_Symbol_Name(cg, param_sym);
                Emit(cg, " = getelementptr i8, ptr %%__frame_base, i64 %lld\n",
                     (long long)param_sym->frame_offset);
                Emit(cg, "  store %s %%p%u, ptr %%", type_str, i);
                Emit_Symbol_Name(cg, param_sym);
                Emit(cg, "\n");
            } else {
                /* IN param: allocate local and copy value */
                Emit(cg, "  %%");
                Emit_Symbol_Name(cg, param_sym);
                Emit(cg, " = alloca %s\n", type_str);
                Emit(cg, "  store %s %%p%u, ptr %%", type_str, i);
                Emit_Symbol_Name(cg, param_sym);
                Emit(cg, "\n");
            }
        }
    }

    /* Generate local declarations, passing has_nested flag via cg for frame allocation.
     * Keep has_nested active for statements too (DECLARE blocks need it). */
    bool saved_has_nested = cg->current_nesting_level > 0;  /* Repurpose field temporarily */
    cg->current_nesting_level = has_nested ? 1 : 0;
    Generate_Declaration_List(cg, &node->subprogram_body.declarations);
    /* Don't reset yet - statements may have DECLARE blocks with tasks needing frame */

    /* Check if subprogram has exception handlers */
    bool has_exc_handlers = node->subprogram_body.handlers.count > 0;

    if (has_exc_handlers) {
        /* Setup exception handling using consolidated helper */
        uint32_t end_label = Emit_Label(cg);
        Exception_Setup exc = Emit_Exception_Handler_Setup(cg);

        /* Normal execution path */
        Emit_Label_Here(cg, exc.normal_label);
        Generate_Statement_List(cg, &node->subprogram_body.statements);
        Emit(cg, "  call void @__ada_pop_handler()\n");
        Emit(cg, "  br label %%L%u\n", end_label);

        /* Exception handler entry */
        Emit_Label_Here(cg, exc.handler_label);
        cg->block_terminated = false;
        Emit(cg, "  call void @__ada_pop_handler()\n");

        /* Dispatch to exception handlers */
        uint32_t exc_id = Emit_Current_Exception_Id(cg);
        Generate_Exception_Dispatch(cg, &node->subprogram_body.handlers, exc_id, end_label);

        /* End label - normal return point */
        Emit_Label_Here(cg, end_label);
    } else {
        /* Generate statements without exception handling */
        Generate_Statement_List(cg, &node->subprogram_body.statements);
    }

    /* Restore nesting level now that all code for this subprogram is generated */
    cg->current_nesting_level = saved_has_nested ? 1 : 0;

    /* Default return if block is not terminated */
    if (not cg->block_terminated) {
        if (is_function) {
            /* BIP functions return void, but missing return is still PROGRAM_ERROR */
            bool func_is_bip = BIP_Is_BIP_Function(sym);
            if (func_is_bip) {
                /* For BIP: raise error first, then ret void (unreachable) */
                Emit_Raise_Program_Error(cg, "missing return");
                Emit(cg, "  ret void  ; unreachable after raise\n");
            } else {
                /* RM 6.4(11): raise PROGRAM_ERROR if function completes without RETURN */
                Emit_Raise_Program_Error(cg, "missing return");
            }
        } else {
            Emit(cg, "  ret void\n");
        }
    }

    /* Clean up BIP state */
    BIP_End_Function();

    Emit(cg, "}\n\n");
    cg->current_function = saved_current_function;
    cg->is_nested = saved_is_nested;
    cg->enclosing_function = saved_enclosing;

    Process_Deferred_Bodies(cg, saved_deferred_count);
}

/* Generate code for a generic instance body */
static void Generate_Generic_Instance_Body(Code_Generator *cg, Symbol *inst_sym,
                                           Syntax_Node *template_body) {
    if (not inst_sym or not template_body) return;

    /* Handle package instantiation specially: generate package body declarations
     * (global variables), then iterate through exported subprograms. */
    if (inst_sym->kind == SYMBOL_PACKAGE and template_body->kind == NK_PACKAGE_BODY) {
        /* Set current instance so names are prefixed with instance name */
        Symbol *saved_instance = cg->current_instance;
        cg->current_instance = inst_sym;
        Set_Generic_Type_Map(inst_sym);

        /* First, emit any global declarations from the package body
         * (e.g., FILES, BUFFERS, NEXT_FD in DIRECT_IO). These need unique names
         * based on the instance to avoid collisions. */
        for (uint32_t i = 0; i < template_body->package_body.declarations.count; i++) {
            Syntax_Node *decl = template_body->package_body.declarations.items[i];
            if (not decl) continue;
            /* Only generate non-subprogram declarations (variables, types) */
            if (decl->kind != NK_PROCEDURE_BODY and decl->kind != NK_FUNCTION_BODY and
                decl->kind != NK_PROCEDURE_SPEC and decl->kind != NK_FUNCTION_SPEC) {
                Generate_Declaration(cg, decl);
            }
        }

        /* Then generate the subprogram bodies */
        for (uint32_t i = 0; i < inst_sym->exported_count; i++) {
            Symbol *exp = inst_sym->exported[i];
            if (not exp) continue;
            if (exp->kind != SYMBOL_FUNCTION and exp->kind != SYMBOL_PROCEDURE)
                continue;

            Syntax_Node *subp_body = Find_Homograph_Body(
                inst_sym->exported, i, exp->name,
                &template_body->package_body.declarations);
            if (subp_body)
                Generate_Generic_Instance_Body(cg, exp, subp_body);
        }
        /* Restore previous instance context */
        cg->current_instance = saved_instance;
        Set_Generic_Type_Map(saved_instance);
        return;
    }

    bool is_function = inst_sym->kind == SYMBOL_FUNCTION;
    uint32_t saved_deferred_count = cg->deferred_count;

    /* Set current instance for formal subprogram substitution during codegen */
    Symbol *saved_current_instance = cg->current_instance;
    cg->current_instance = inst_sym;
    Set_Generic_Type_Map(inst_sym);

    /* For generic instances, determine nesting from instance parent */
    Symbol *saved_enclosing = cg->enclosing_function;
    bool saved_is_nested = cg->is_nested;

    /* Find nearest enclosing function/procedure (walks through packages) */
    Symbol *enclosing_subprog = Find_Enclosing_Subprogram(inst_sym);
    bool is_nested = (enclosing_subprog != NULL);
    cg->is_nested = is_nested;
    cg->enclosing_function = enclosing_subprog;

    Emit_Function_Header(cg, inst_sym, is_nested);

    Symbol *saved_current_function = cg->current_function;
    cg->current_function = inst_sym;
    cg->has_return = false;
    cg->block_terminated = false;  /* Reset for new function */

    /* Get parameter symbols from template body's specification (they have
     * the unique_ids that match the body's code references) */
    Syntax_Node *body_spec = template_body->subprogram_body.specification;
    uint32_t param_idx = 0;
    if (body_spec) {
        Node_List *params = &body_spec->subprogram_spec.parameters;
        for (uint32_t i = 0; i < params->count and param_idx < inst_sym->parameter_count; i++) {
            Syntax_Node *ps = params->items[i];
            if (ps and ps->kind == NK_PARAM_SPEC) {
                for (uint32_t j = 0; j < ps->param_spec.names.count and param_idx < inst_sym->parameter_count; j++) {
                    Syntax_Node *pname = ps->param_spec.names.items[j];
                    Symbol *param_sym = pname->symbol;
                    if (param_sym) {
                        const char *type_str = Type_To_Llvm(inst_sym->parameters[param_idx].param_type);
                        Parameter_Mode mode = inst_sym->parameters[param_idx].mode;

                        if (Param_Is_By_Reference(mode)) {
                            /* OUT/IN OUT: %p is already a pointer to caller's variable
                             * Create an alias so the parameter name points to caller's storage */
                            Emit(cg, "  %%");
                            Emit_Symbol_Name(cg, param_sym);
                            Emit(cg, " = getelementptr i8, ptr %%p%u, i64 0  ; by-ref param\n", param_idx);
                        } else {
                            /* IN param: allocate local and copy value */
                            Emit(cg, "  %%");
                            Emit_Symbol_Name(cg, param_sym);
                            Emit(cg, " = alloca %s\n", type_str);
                            Emit(cg, "  store %s %%p%u, ptr %%", type_str, param_idx);
                            Emit_Symbol_Name(cg, param_sym);
                            Emit(cg, "\n");
                        }
                    }
                    param_idx++;
                }
            }
        }
    }

    /* Allocate and initialize generic formal object parameters (RM 12.4).
     * These are variables visible inside the generic body but not subprogram
     * parameters — they carry the actual values provided at instantiation. */
    {
        Symbol *tmpl = inst_sym->generic_template;
        Syntax_Node *gen_decl = tmpl ? tmpl->declaration : NULL;
        if (gen_decl and gen_decl->kind == NK_GENERIC_DECL) {
            Node_List *formals = &gen_decl->generic_decl.formals;
            uint32_t ai = 0;
            for (uint32_t fi = 0; fi < formals->count; fi++) {
                Syntax_Node *formal = formals->items[fi];
                if (formal->kind == NK_GENERIC_OBJECT_PARAM) {
                    for (uint32_t j = 0; j < formal->generic_object_param.names.count; j++) {
                        Syntax_Node *fname = formal->generic_object_param.names.items[j];
                        Symbol *obj_sym = fname ? fname->symbol : NULL;
                        Syntax_Node *actual_expr = (ai < inst_sym->generic_actual_count)
                            ? inst_sym->generic_actuals[ai].actual_expr : NULL;
                        if (obj_sym and actual_expr) {
                            Type_Info *obj_type = obj_sym->type;
                            const char *ts = Type_To_Llvm(obj_type);
                            bool is_fat = Llvm_Type_Is_Fat_Pointer(ts);
                            Emit(cg, "  %%");
                            Emit_Symbol_Name(cg, obj_sym);
                            Emit(cg, " = alloca %s  ; generic formal object\n", ts);
                            uint32_t val = Generate_Expression(cg, actual_expr);
                            if (val > 0) {
                                if (is_fat) {
                                    Emit(cg, "  store { ptr, ptr } %%t%u, ptr %%", val);
                                } else {
                                    Emit(cg, "  store %s %%t%u, ptr %%", ts, val);
                                }
                                Emit_Symbol_Name(cg, obj_sym);
                                Emit(cg, "\n");
                            }
                        }
                        ai++;
                    }
                } else {
                    ai++;
                }
            }
        }
    }

    /* Generate the body statements with type substitution.
     * Per Ada RM 11.4, exception handlers in the generic template body
     * apply to each instantiation.  Emit_Subprogram_Body
     * handles exception parts identically for generic instances. */
    Syntax_Node *body = template_body;

    /* Generate local declarations */
    Generate_Declaration_List(cg, &body->subprogram_body.declarations);

    /* Check for exception handlers in the template body */
    bool has_exc = body->subprogram_body.handlers.count > 0;

    if (has_exc) {
        Exception_Setup setup = Emit_Exception_Handler_Setup(cg);
        uint32_t end_lbl = Emit_Label(cg);

        /* Normal execution path */
        Emit_Label_Here(cg, setup.normal_label);
        Generate_Statement_List(cg, &body->subprogram_body.statements);
        if (not cg->block_terminated)
            Emit(cg, "  call void @__ada_pop_handler()\n");
        Emit_Branch_If_Needed(cg, end_lbl);

        /* Exception handler entry */
        Emit_Label_Here(cg, setup.handler_label);
        cg->block_terminated = false;
        Emit(cg, "  call void @__ada_pop_handler()\n");

        uint32_t exc_id = Emit_Current_Exception_Id(cg);
        Generate_Exception_Dispatch(cg, &body->subprogram_body.handlers, exc_id, end_lbl);

        Emit_Label_Here(cg, end_lbl);
        cg->block_terminated = false;
    } else {
        for (uint32_t i = 0; i < body->subprogram_body.statements.count; i++) {
            Syntax_Node *stmt = body->subprogram_body.statements.items[i];
            if (stmt) Generate_Statement(cg, stmt);
        }
    }

    /* Default return if block is not terminated */
    if (not cg->block_terminated) {
        if (is_function) {
            /* BIP functions return void, but missing return is still PROGRAM_ERROR */
            bool inst_is_bip = BIP_Is_BIP_Function(inst_sym);
            if (inst_is_bip) {
                Emit_Raise_Program_Error(cg, "missing return");
                Emit(cg, "  ret void  ; unreachable after raise\n");
            } else {
                /* RM 6.4(11): raise PROGRAM_ERROR if function completes without RETURN */
                Emit_Raise_Program_Error(cg, "missing return");
            }
        } else {
            Emit(cg, "  ret void\n");
        }
    }

    /* Clean up BIP state */
    BIP_End_Function();

    Emit(cg, "}\n\n");
    cg->current_function = saved_current_function;
    cg->is_nested = saved_is_nested;
    cg->enclosing_function = saved_enclosing;
    cg->current_instance = saved_current_instance;
    Set_Generic_Type_Map(saved_current_instance);

    Process_Deferred_Bodies(cg, saved_deferred_count);
}

/* Emit the task body function name for a task type symbol.
 * Resolves to the task TYPE's defining_symbol for consistency between
 * task body definitions and task_start call sites.
 * The name format is: task_MANGLED_NAME */
static void Emit_Task_Function_Name(Code_Generator *cg, Symbol *task_sym, String_Slice fallback_name) {
    Emit(cg, "task_");
    /* Prefer the task TYPE's defining_symbol for consistency.
     * The task body's own symbol and the task type's defining_symbol
     * may have different _sN suffixes; using the type's symbol ensures
     * the define and call sites match. */
    Symbol *resolved = NULL;
    if (task_sym and task_sym->type and task_sym->type->defining_symbol) {
        resolved = task_sym->type->defining_symbol;
    } else if (task_sym) {
        resolved = task_sym;
    }
    if (resolved) {
        Emit_Symbol_Name(cg, resolved);
    } else {
        for (uint32_t i = 0; i < fallback_name.length; i++) {
            char c = fallback_name.data[i];
            if (c >= 'A' and c <= 'Z') c = c - 'A' + 'a';
            fputc(c, cg->output);
        }
    }
}

static void Generate_Task_Body(Code_Generator *cg, Syntax_Node *node) {
    /* Skip stub bodies (TASK BODY X IS SEPARATE;) - the actual body
     * will be provided by a separate subunit compilation */
    if (node->task_body.is_separate) {
        Emit(cg, "\n; Task body stub: %.*s (defined in separate subunit)\n",
             (int)node->task_body.name.length, node->task_body.name.data);
        return;
    }

    Emit(cg, "\n; Task body: %.*s\n",
         (int)node->task_body.name.length, node->task_body.name.data);

    /* Generate task entry point function - receives parent frame pointer
     * for uplevel variable access (task bodies access enclosing scope).
     * For task bodies inside generic instances, prefix with instance name
     * to make the function name unique across multiple instantiations. */
    Emit(cg, "define ptr @");
    Emit_Task_Function_Name(cg, node->symbol, node->task_body.name);
    Emit(cg, "(ptr %%__parent_frame) {\n");
    Emit(cg, "entry:\n");

    /* Save and set context - task body is like a nested function */
    Symbol *saved_current_function = cg->current_function;
    bool saved_is_nested = cg->is_nested;
    Symbol *saved_enclosing = cg->enclosing_function;
    bool saved_in_task_body = cg->in_task_body;
    cg->current_function = node->symbol;
    cg->is_nested = true;  /* Task bodies are nested in enclosing scope */
    cg->enclosing_function = saved_current_function;  /* Access parent's vars */
    cg->in_task_body = true;  /* Task entry points return ptr for pthread */

    /* Reset temp counter for new function */
    uint32_t saved_temp = cg->temp_id;
    cg->temp_id = 1;
    memset(cg->temp_types, 0, sizeof(cg->temp_types));
    memset(cg->temp_type_keys, 0, sizeof(cg->temp_type_keys));

    /* Create frame aliases for accessing enclosing scope variables.
     * Task bodies can reference variables from the enclosing scope
     * (RM 9.1). The parent passed %__parent_frame pointing to its frame.
     * Use the task symbol's defining_scope to get the correct scope
     * (important for tasks in DECLARE blocks which have their own scope). */
    Scope *parent_scope = node->symbol ? node->symbol->defining_scope : NULL;
    if (parent_scope) {
        /* Dedup by unique_id (same approach as Generate_Subprogram_Body) */
        #define MAX_TASK_FRAME_ALIASES 512
        uint32_t task_emitted_ids[MAX_TASK_FRAME_ALIASES];
        uint32_t task_emitted_count = 0;

        for (uint32_t i = 0; i < parent_scope->symbol_count; i++) {
            Symbol *var = parent_scope->symbols[i];
            if (var and (var->kind == SYMBOL_VARIABLE or var->kind == SYMBOL_PARAMETER or
                        var->kind == SYMBOL_DISCRIMINANT)) {
                bool dup = false;
                for (uint32_t j = 0; j < task_emitted_count; j++)
                    if (var->unique_id == task_emitted_ids[j]) { dup = true; break; }
                if (dup) continue;
                if (task_emitted_count < MAX_TASK_FRAME_ALIASES)
                    task_emitted_ids[task_emitted_count++] = var->unique_id;
                Emit(cg, "  %%__frame.");
                Emit_Symbol_Name(cg, var);
                Emit(cg, " = getelementptr i8, ptr %%__parent_frame, i64 %lld\n",
                     (long long)(var->frame_offset));
            }
        }
        /* Also include variables from child scopes (DECLARE blocks). */
        for (uint32_t i = 0; i < parent_scope->frame_var_count; i++) {
            Symbol *var = parent_scope->frame_vars[i];
            if (not var) continue;
            bool dup = false;
            for (uint32_t j = 0; j < task_emitted_count; j++)
                if (var->unique_id == task_emitted_ids[j]) { dup = true; break; }
            if (dup) continue;
            if (task_emitted_count < MAX_TASK_FRAME_ALIASES)
                task_emitted_ids[task_emitted_count++] = var->unique_id;
            Emit(cg, "  %%__frame.");
            Emit_Symbol_Name(cg, var);
            Emit(cg, " = getelementptr i8, ptr %%__parent_frame, i64 %lld\n",
                 (long long)(var->frame_offset));
        }
        #undef MAX_TASK_FRAME_ALIASES
    }

    /* Push exception handler for task using consolidated helper */
    Exception_Setup exc = Emit_Exception_Handler_Setup(cg);

    /* Normal execution path */
    Emit_Label_Here(cg, exc.normal_label);
    cg->block_terminated = false;  /* Reset after br target label */
    Generate_Declaration_List(cg, &node->task_body.declarations);
    Generate_Statement_List(cg, &node->task_body.statements);
    Emit(cg, "  call void @__ada_pop_handler()\n");
    Emit(cg, "  ret ptr null\n");

    /* Exception handler path */
    Emit_Label_Here(cg, exc.handler_label);
    Emit(cg, "  call void @__ada_pop_handler()\n");
    /* Task terminates silently on unhandled exception */
    Emit(cg, "  ret ptr null\n");

    Emit(cg, "}\n\n");

    /* Restore context */
    cg->temp_id = saved_temp;
    cg->current_function = saved_current_function;
    cg->is_nested = saved_is_nested;
    cg->enclosing_function = saved_enclosing;
    cg->in_task_body = saved_in_task_body;
}

static void Generate_Declaration(Code_Generator *cg, Syntax_Node *node) {
    if (not node) return;

    switch (node->kind) {
        case NK_OBJECT_DECL:
            Generate_Object_Declaration(cg, node);
            break;

        case NK_PROCEDURE_SPEC:
        case NK_FUNCTION_SPEC:
            /* Forward declaration - if imported, emit extern declaration */
            if (node->symbol and node->symbol->is_imported) {
                Emit_Extern_Subprogram(cg, node->symbol);
            }
            break;

        case NK_PACKAGE_SPEC:
            /* Nested package spec: emit object declarations for variables and
             * constants declared in the visible and private parts.
             * Without this, variables from package specs without bodies
             * would never be allocated, causing undefined value errors. */
            {
                for (uint32_t j = 0; j < node->package_spec.visible_decls.count; j++) {
                    Syntax_Node *decl = node->package_spec.visible_decls.items[j];
                    if (decl) Generate_Declaration(cg, decl);
                }
                for (uint32_t j = 0; j < node->package_spec.private_decls.count; j++) {
                    Syntax_Node *decl = node->package_spec.private_decls.items[j];
                    if (decl) Generate_Declaration(cg, decl);
                }
            }
            break;

        case NK_PROCEDURE_BODY:
        case NK_FUNCTION_BODY:
            /* Defer nested subprogram bodies - emit after enclosing function */
            /* Skip if already generated (prevents duplicates from re-processing) */
            if (node->subprogram_body.code_generated) break;
            if (cg->current_function and cg->deferred_count < 64) {
                /* Check for duplicate in deferred list */
                bool already_deferred = false;
                for (uint32_t d = 0; d < cg->deferred_count; d++) {
                    if (cg->deferred_bodies[d] == node) {
                        already_deferred = true;
                        break;
                    }
                }
                if (not already_deferred) {
                    cg->deferred_bodies[cg->deferred_count++] = node;
                }
            } else {
                Generate_Subprogram_Body(cg, node);
            }
            break;

        case NK_PACKAGE_BODY:
            {
                Symbol *pkg_sym = node->symbol;  /* Use symbol from semantic analysis */

                /* Skip generic package bodies - code is generated only for instances */
                if (pkg_sym and pkg_sym->kind == SYMBOL_GENERIC) {
                    break;
                }

                /* For library-level package bodies (separate compilation), emit the
                 * associated spec's visible/private declarations as globals.  The spec
                 * is loaded from a separate .ads file and never visited by codegen,
                 * so constants like LEGAL_FILE_NAME must be emitted here.
                 * Skip this for nested packages — their specs are already in the
                 * enclosing scope's declaration list and have already been emitted. */
                if (not cg->current_function and pkg_sym and
                    pkg_sym->declaration and
                    pkg_sym->declaration->kind == NK_PACKAGE_SPEC) {
                    Syntax_Node *spec = pkg_sym->declaration;
                    Generate_Declaration_List(cg, &spec->package_spec.visible_decls);
                    Generate_Declaration_List(cg, &spec->package_spec.private_decls);
                }

                Generate_Declaration_List(cg, &node->package_body.declarations);

            /* Check if the package spec has any single task declarations that
             * need starting at elaboration (RM 9.2: tasks are activated at the
             * end of the declarative region containing the task declaration). */
            bool has_pkg_tasks = false;
            Syntax_Node *pkg_spec_node = (pkg_sym and pkg_sym->declaration and
                pkg_sym->declaration->kind == NK_PACKAGE_SPEC) ? pkg_sym->declaration : NULL;
            if (not cg->current_function and pkg_spec_node) {
                for (uint32_t ti = 0; ti < pkg_spec_node->package_spec.visible_decls.count; ti++) {
                    Syntax_Node *d = pkg_spec_node->package_spec.visible_decls.items[ti];
                    if (d and d->kind == NK_TASK_SPEC and not d->task_spec.is_type) {
                        has_pkg_tasks = true;
                        break;
                    }
                }
            }

            /* Generate initialization/elaboration function if the package has
             * init statements OR package-level tasks that need starting.
             * For nested packages (inside a function), emit statements inline
             * in the enclosing function — Ada RM 7.2: elaboration occurs at the
             * point of the package body in the enclosing declarative region.
             * For library-level packages, create a separate __elab function. */
            bool has_init_stmts = node->package_body.statements.count > 0;
            if (has_init_stmts and cg->current_function) {
                /* Nested package: emit initialization inline.
                 * If the package body has exception handlers (RM 11.4),
                 * wrap the statements in setjmp/longjmp like subprograms. */
                bool has_pkg_exc = node->package_body.handlers.count > 0;
                Emit(cg, "  ; Package body initialization (inline)\n");
                if (has_pkg_exc) {
                    Exception_Setup setup = Emit_Exception_Handler_Setup(cg);
                    uint32_t end_lbl = Emit_Label(cg);

                    /* Normal execution path */
                    Emit_Label_Here(cg, setup.normal_label);
                    Generate_Statement_List(cg, &node->package_body.statements);
                    if (not cg->block_terminated)
                        Emit(cg, "  call void @__ada_pop_handler()\n");
                    Emit_Branch_If_Needed(cg, end_lbl);

                    /* Exception handler entry */
                    Emit_Label_Here(cg, setup.handler_label);
                    cg->block_terminated = false;
                    Emit(cg, "  call void @__ada_pop_handler()\n");

                    uint32_t exc_id = Emit_Current_Exception_Id(cg);
                    Generate_Exception_Dispatch(cg, &node->package_body.handlers, exc_id, end_lbl);

                    Emit_Label_Here(cg, end_lbl);
                    cg->block_terminated = false;
                } else {
                    Generate_Statement_List(cg, &node->package_body.statements);
                }
            } else if (not cg->current_function and (has_init_stmts or has_pkg_tasks)) {
                /* Library-level package: emit elaboration function that starts
                 * package-level tasks and runs any initialization statements. */
                Emit(cg, "\n; Package body elaboration\n");
                Emit(cg, "define void @");
                if (pkg_sym) {
                    Emit_Symbol_Name(cg, pkg_sym);
                } else {
                    for (uint32_t i = 0; i < node->package_body.name.length; i++) {
                        char c = node->package_body.name.data[i];
                        Emit(cg, "%c", (c >= 'A' and c <= 'Z') ? c + 32 : c);
                    }
                }
                Emit(cg, "___elab() {\n");
                Emit(cg, "entry:\n");

                Symbol *saved_current_function = cg->current_function;
                uint32_t saved_temp = cg->temp_id;
                cg->current_function = pkg_sym;
                cg->block_terminated = false;
                cg->temp_id = 1;
                memset(cg->temp_types, 0, sizeof(cg->temp_types));
    memset(cg->temp_type_keys, 0, sizeof(cg->temp_type_keys));

                /* Start package-level tasks */
                if (has_pkg_tasks and pkg_spec_node) {
                    for (uint32_t ti = 0; ti < pkg_spec_node->package_spec.visible_decls.count; ti++) {
                        Syntax_Node *d = pkg_spec_node->package_spec.visible_decls.items[ti];
                        if (not d or d->kind != NK_TASK_SPEC or d->task_spec.is_type or not d->symbol)
                            continue;
                        /* Find the task object variable symbol */
                        Symbol *task_obj = NULL;
                        Scope *tscope = d->symbol->defining_scope;
                        if (tscope) {
                            for (uint32_t si = 0; si < tscope->symbol_count; si++) {
                                Symbol *s = tscope->symbols[si];
                                if (s and s->kind == SYMBOL_VARIABLE and
                                    Type_Is_Task(s->type) and
                                    Slice_Equal_Ignore_Case(s->name, d->task_spec.name)) {
                                    task_obj = s;
                                    break;
                                }
                            }
                        }
                        if (not task_obj) continue;
                        /* Start the task and store handle in the global */
                        uint32_t handle_tmp = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = call ptr @__ada_task_start(ptr @", handle_tmp);
                        Emit_Task_Function_Name(cg, d->symbol, d->task_spec.name);
                        Emit(cg, ", ptr null)\n");
                        Emit(cg, "  store ptr %%t%u, ptr @", handle_tmp);
                        Emit_Symbol_Name(cg, task_obj);
                        Emit(cg, "\n");
                    }
                }

                /* Run initialization statements if any */
                if (has_init_stmts) {
                    Generate_Statement_List(cg, &node->package_body.statements);
                }

                if (not cg->block_terminated) {
                    Emit(cg, "  ret void\n");
                }
                Emit(cg, "}\n\n");

                cg->temp_id = saved_temp;
                cg->current_function = saved_current_function;

                /* Track this elaboration function for calling from main.
                 * Also register with the §15.7 elaboration graph for
                 * proper dependency-ordered elaboration. */
                if (pkg_sym and cg->elab_func_count < 64) {
                    cg->elab_funcs[cg->elab_func_count++] = pkg_sym;

                    /* Register unit in elaboration graph (§15.7) */
                    Elab_Register_Unit(pkg_sym->name, /*is_body=*/true, pkg_sym,
                                       /*is_preelaborate=*/false,
                                       /*is_pure=*/false,
                                       /*has_elab_code=*/true);
                }
            }
            }
            break;

        case NK_GENERIC_INST:
            /* Generate code for generic instantiation. Per Ada RM 12.3: "The
             * elaboration of a generic instantiation declares an instance" */
            {
                Symbol *inst_sym = node->symbol;
                if (not inst_sym or not inst_sym->generic_template) break;

                Symbol *template = inst_sym->generic_template;
                Symbol *saved_instance = cg->current_instance;
                cg->current_instance = inst_sym;
                Set_Generic_Type_Map(inst_sym);

                /* Spec reference and elab flag, used both in global emission
                 * and in the spec-only elaboration path below. */
                Syntax_Node *gen_spec = inst_sym->expanded_spec;
                if (not gen_spec) gen_spec = template->generic_unit;
                bool needs_elab = false;

                /* For library-level package instances, emit global variables for
                 * exported objects REGARDLESS of whether there's a body. Generic
                 * packages may have just a spec with object declarations. */
                if (not cg->current_function and inst_sym->kind == SYMBOL_PACKAGE) {

                    for (uint32_t i = 0; i < inst_sym->exported_count; i++) {
                        Symbol *exp = inst_sym->exported[i];
                        if (not exp) continue;
                        if (exp->kind != SYMBOL_VARIABLE and exp->kind != SYMBOL_CONSTANT)
                            continue;
                        Type_Info *ty = exp->type;
                        const char *type_str = Type_To_Llvm(ty);
                        bool is_array = Type_Is_Constrained_Array(ty);
                        bool is_record = Type_Is_Record(ty);

                        /* Look for initializer in the expanded spec's visible decls.
                         * With expanded_spec, formal params are already substituted
                         * with actual expressions, so we can evaluate directly. */
                        int64_t init_val = 0;
                        bool has_init = false;
                        bool this_needs_elab = false;
                        if (gen_spec and gen_spec->kind == NK_PACKAGE_SPEC) {
                            for (uint32_t j = 0; j < gen_spec->package_spec.visible_decls.count; j++) {
                                Syntax_Node *decl = gen_spec->package_spec.visible_decls.items[j];
                                if (not decl or decl->kind != NK_OBJECT_DECL) continue;
                                for (uint32_t k = 0; k < decl->object_decl.names.count; k++) {
                                    Syntax_Node *nm = decl->object_decl.names.items[k];
                                    if (nm and Slice_Equal_Ignore_Case(nm->string_val.text, exp->name)) {
                                        Syntax_Node *init = decl->object_decl.init;
                                        if (init and init->kind == NK_INTEGER) {
                                            init_val = init->integer_lit.value;
                                            has_init = true;
                                        } else if (init) {
                                            this_needs_elab = true;
                                            needs_elab = true;
                                        }
                                        break;
                                    }
                                }
                                if (has_init or this_needs_elab) break;
                            }
                        }

                        exp->extern_emitted = true;
                        Emit(cg, "@");
                        Emit_Symbol_Name(cg, exp);
                        if (is_array) {
                            int128_t cnt = Array_Element_Count(ty);
                            const char *elem_type = Type_To_Llvm(ty->array.element_type);
                            Emit(cg, " = linkonce_odr global [%s x %s] zeroinitializer\n",
                                 I128_Decimal(cnt), elem_type);
                        } else if (is_record) {
                            Emit(cg, " = linkonce_odr global [%u x i8] zeroinitializer\n", ty->size);
                        } else if (Type_Is_Float_Representation(ty)) {
                            Emit(cg, " = linkonce_odr global %s 0.0\n", type_str);
                        } else if (strcmp(type_str, "ptr") == 0) {
                            Emit(cg, " = linkonce_odr global ptr null\n");
                        } else {
                            Emit(cg, " = linkonce_odr global %s %lld\n", type_str,
                                 (long long)init_val);
                        }
                    }
                }

                /* Prefer expanded_body (with substitutions already applied)
                 * over template->generic_body (requires runtime substitution) */
                Syntax_Node *generic_body = inst_sym->expanded_body;
                if (not generic_body) generic_body = template->generic_body;
                if (not generic_body) {
                    /* Spec-only generic: if any init needs runtime evaluation,
                     * emit an elab function. Use generic_actuals (resolved in the
                     * instantiation context) rather than cloned template AST. */
                    if (needs_elab) {
                        /* Build map: for each variable whose init references a
                         * generic formal, pair it with the formal's actual_expr. */
                        Emit(cg, "\n; Generic instance spec elaboration\n");
                        Emit(cg, "define void @");
                        Emit_Symbol_Name(cg, inst_sym);
                        Emit(cg, "___elab() {\nentry:\n");
                        Symbol *saved_func = cg->current_function;
                        uint32_t saved_temp = cg->temp_id;
                        cg->current_function = inst_sym;
                        cg->block_terminated = false;
                        cg->temp_id = 1;
                        memset(cg->temp_types, 0, sizeof(cg->temp_types));
                        memset(cg->temp_type_keys, 0, sizeof(cg->temp_type_keys));
                        /* For each non-static exported var, find the generic actual
                         * that corresponds to its init expression and evaluate it. */
                        Syntax_Node *tmpl_spec = template->generic_unit;
                        if (tmpl_spec and tmpl_spec->kind == NK_PACKAGE_SPEC) {
                            for (uint32_t j = 0; j < tmpl_spec->package_spec.visible_decls.count; j++) {
                                Syntax_Node *decl = tmpl_spec->package_spec.visible_decls.items[j];
                                if (not decl or decl->kind != NK_OBJECT_DECL or not decl->object_decl.init)
                                    continue;
                                Syntax_Node *init = decl->object_decl.init;
                                if (init->kind == NK_INTEGER) continue;
                                /* init is likely NK_IDENTIFIER referencing formal C.
                                 * Find the actual expression from generic_actuals. */
                                Syntax_Node *actual_expr = NULL;
                                if (init->kind == NK_IDENTIFIER) {
                                    for (uint32_t ai = 0; ai < inst_sym->generic_actual_count; ai++) {
                                        if (Slice_Equal_Ignore_Case(
                                                inst_sym->generic_actuals[ai].formal_name,
                                                init->string_val.text)) {
                                            actual_expr = inst_sym->generic_actuals[ai].actual_expr;
                                            break;
                                        }
                                    }
                                }
                                if (not actual_expr) continue;
                                /* Find exported symbol for this variable */
                                for (uint32_t k = 0; k < decl->object_decl.names.count; k++) {
                                    Syntax_Node *nm = decl->object_decl.names.items[k];
                                    if (not nm) continue;
                                    Symbol *target = NULL;
                                    for (uint32_t ei = 0; ei < inst_sym->exported_count; ei++) {
                                        if (inst_sym->exported[ei] and
                                            Slice_Equal_Ignore_Case(inst_sym->exported[ei]->name,
                                                                    nm->string_val.text)) {
                                            target = inst_sym->exported[ei];
                                            break;
                                        }
                                    }
                                    if (not target) continue;
                                    uint32_t val = Generate_Expression(cg, actual_expr);
                                    const char *ts = Type_To_Llvm(target->type);
                                    Emit(cg, "  store %s %%t%u, ptr @", ts, val);
                                    Emit_Symbol_Name(cg, target);
                                    Emit(cg, "\n");
                                }
                            }
                        }
                        if (not cg->block_terminated) Emit(cg, "  ret void\n");
                        Emit(cg, "}\n\n");
                        cg->temp_id = saved_temp;
                        cg->current_function = saved_func;
                        if (cg->elab_func_count < 64) {
                            cg->elab_funcs[cg->elab_func_count++] = inst_sym;

                            /* Register generic instance in elaboration graph (§15.7) */
                            Elab_Register_Unit(inst_sym->name, /*is_body=*/true, inst_sym,
                                               /*is_preelaborate=*/false,
                                               /*is_pure=*/false,
                                               /*has_elab_code=*/true);
                        }
                    }
                    cg->current_instance = saved_instance;
                    Set_Generic_Type_Map(saved_instance);
                    break;
                }

                /* Generate instantiated body using the instance's symbol */
                if (cg->current_function and inst_sym->kind == SYMBOL_PACKAGE) {
                    /* Local generic package instance: allocate storage for exported
                     * variables/constants NOW (as local allocas), but defer subprogram
                     * bodies for later. Per Ada RM 12.3: "The elaboration of a generic
                     * instantiation declares an instance... and elaborates the instance" */
                    for (uint32_t i = 0; i < inst_sym->exported_count; i++) {
                        Symbol *exp = inst_sym->exported[i];
                        if (not exp) continue;
                        if (exp->kind == SYMBOL_VARIABLE or exp->kind == SYMBOL_CONSTANT) {
                            /* Allocate local storage for package variable */
                            Type_Info *ty = exp->type;
                            const char *type_str = Type_To_Llvm(ty);
                            bool is_array = Type_Is_Constrained_Array(ty);
                            bool is_record = Type_Is_Record(ty);
                            Emit(cg, "  %%");
                            Emit_Symbol_Name(cg, exp);
                            if (is_array) {
                                int128_t cnt = Array_Element_Count(ty);
                                const char *elem_type = Type_To_Llvm(ty->array.element_type);
                                Emit(cg, " = alloca [%s x %s]  ; local pkg var\n", I128_Decimal(cnt), elem_type);
                            } else if (is_record) {
                                Emit(cg, " = alloca [%u x i8]  ; local pkg record\n", ty->size);
                            } else {
                                Emit(cg, " = alloca %s  ; local pkg var\n", type_str);
                            }
                            /* Initialize from package body if present */
                            if (generic_body and generic_body->kind == NK_PACKAGE_BODY) {
                                /* Look for assignment in BEGIN..END section targeting this var.
                                 * Compare by name since body symbol differs from exported symbol. */
                                for (uint32_t j = 0; j < generic_body->package_body.statements.count; j++) {
                                    Syntax_Node *stmt = generic_body->package_body.statements.items[j];
                                    if (not stmt or stmt->kind != NK_ASSIGNMENT) continue;
                                    Syntax_Node *tgt = stmt->assignment.target;
                                    if (not tgt) continue;
                                    String_Slice tgt_name = {0};
                                    if (tgt->kind == NK_IDENTIFIER)
                                        tgt_name = tgt->string_val.text;
                                    else if (tgt->symbol)
                                        tgt_name = tgt->symbol->name;
                                    if (tgt_name.data and Slice_Equal_Ignore_Case(tgt_name, exp->name)) {
                                        /* Redirect target to use local exported symbol */
                                        tgt->symbol = exp;
                                        Generate_Statement(cg, stmt);
                                        break;
                                    }
                                }
                            }
                        }
                    }
                    /* Start any task objects declared in the generic spec.
                     * Task variables (SYMBOL_VARIABLE with TYPE_TASK) need
                     * __ada_task_start called after their alloca. */
                    for (uint32_t i = 0; i < inst_sym->exported_count; i++) {
                        Symbol *exp = inst_sym->exported[i];
                        if (not exp or exp->kind != SYMBOL_VARIABLE) continue;
                        if (not Type_Is_Task(exp->type)) continue;
                        /* Start the task */
                        uint32_t handle_tmp = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = call ptr @__ada_task_start(ptr @", handle_tmp);
                        Emit_Task_Function_Name(cg, exp->type ? exp->type->defining_symbol : NULL,
                                                exp->type ? exp->type->name : exp->name);
                        Emit(cg, ", ");
                        if (cg->current_nesting_level > 0) {
                            Emit(cg, "ptr %%__frame_base)\n");
                        } else {
                            Emit(cg, "ptr null)\n");
                        }
                        Emit(cg, "  store ptr %%t%u, ptr %%", handle_tmp);
                        Emit_Symbol_Name(cg, exp);
                        Emit(cg, "\n");
                    }
                    /* Defer subprogram bodies for later */
                    if (cg->deferred_count < 64)
                        cg->deferred_bodies[cg->deferred_count++] = node;
                } else if (cg->current_function and cg->deferred_count < 64) {
                    /* Defer nested generic subprogram instance */
                    cg->deferred_bodies[cg->deferred_count++] = node;
                } else if (inst_sym->kind == SYMBOL_PACKAGE) {
                    /* Global variables already emitted above. Now generate subprogram
                     * bodies, matching by homograph index. */
                    if (generic_body->kind == NK_PACKAGE_BODY) {
                        for (uint32_t i = 0; i < inst_sym->exported_count; i++) {
                            Symbol *exp = inst_sym->exported[i];
                            if (not exp) continue;
                            if (exp->kind != SYMBOL_FUNCTION and exp->kind != SYMBOL_PROCEDURE)
                                continue;

                            Syntax_Node *subp_body = Find_Homograph_Body(
                                inst_sym->exported, i, exp->name,
                                &generic_body->package_body.declarations);
                            if (subp_body)
                                Generate_Generic_Instance_Body(cg, exp, subp_body);
                        }
                    }
                } else {
                    Generate_Generic_Instance_Body(cg, inst_sym, generic_body);
                }

                cg->current_instance = saved_instance;
                Set_Generic_Type_Map(saved_instance);
            }
            break;

        case NK_GENERIC_DECL:
            /* Generic declarations don't generate code - only instances do */
            break;

        case NK_TASK_SPEC:
            /* Task type/object specification - record entry points */
            Emit(cg, "; Task spec: %.*s (entries registered at runtime)\n",
                 (int)node->task_spec.name.length, node->task_spec.name.data);
            /* For single tasks (not task types), allocate task control block storage
             * and start the task body in a separate thread */
            if (not node->task_spec.is_type and node->symbol) {
                /* Find the variable symbol in the type symbol's defining scope.
                 * The type and variable were both added to the same scope during
                 * semantic analysis. Use defining_scope instead of sm->current_scope
                 * since current_scope may have changed during code generation. */
                Symbol *obj_sym = NULL;
                Scope *scope = node->symbol->defining_scope;
                if (scope) {
                    for (uint32_t i = 0; i < scope->symbol_count; i++) {
                        Symbol *s = scope->symbols[i];
                        if (s and s->kind == SYMBOL_VARIABLE and
                            Type_Is_Task(s->type) and
                            Slice_Equal_Ignore_Case(s->name, node->task_spec.name)) {
                            obj_sym = s;
                            break;
                        }
                    }
                }
                if (obj_sym) {
                    if (obj_sym->unique_id == 0) {
                        obj_sym->unique_id = cg->sm->next_unique_id++;
                    }

                    /* Package-level tasks need global storage, not alloca.
                     * alloca is only valid inside a function.  For package-level
                     * tasks, emit a global variable here and defer the task_start
                     * to the package body elaboration function (RM 9.2). */
                    if (not cg->current_function) {
                        /* Emit global variable for the task control block (once only) */
                        if (not obj_sym->extern_emitted) {
                            obj_sym->extern_emitted = true;
                            Emit(cg, "@");
                            Emit_Symbol_Name(cg, obj_sym);
                            Emit(cg, " = global ptr null  ; package-level task object\n");
                        }
                        /* Task start is deferred to package body elaboration */
                    } else {
                    /* Allocate task object - use frame if nested, else stack */
                    bool use_frame = cg->current_nesting_level > 0;
                    if (use_frame) {
                        Emit(cg, "  %%");
                        Emit_Symbol_Name(cg, obj_sym);
                        Emit(cg, " = getelementptr i8, ptr %%__frame_base, i64 %lld  ; task in frame\n",
                             (long long)obj_sym->frame_offset);
                    } else {
                        Emit(cg, "  %%");
                        Emit_Symbol_Name(cg, obj_sym);
                        Emit(cg, " = alloca ptr  ; task control block\n");
                    }

                    /* Start the task body in a separate thread.
                     * Pass frame_base if nested, or null if at module level. */
                    uint32_t handle_tmp = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = call ptr @__ada_task_start(ptr @", handle_tmp);
                    Emit_Task_Function_Name(cg, node->symbol, node->task_spec.name);
                    Emit(cg, ", ");
                    /* Pass parent frame for uplevel access, or null if at module level.
                     * Use frame_base only if the current function has nested subprograms. */
                    if (cg->current_nesting_level > 0) {
                        Emit(cg, "ptr %%__frame_base)\n");
                    } else {
                        Emit(cg, "ptr null)\n");
                    }
                    /* Store thread handle in task control block */
                    Emit(cg, "  store ptr %%t%u, ptr %%", handle_tmp);
                    Emit_Symbol_Name(cg, obj_sym);
                    Emit(cg, "\n");
                    }
                }
            }
            break;

        case NK_TASK_BODY:
            /* Defer task body generation when inside another function */
            if (cg->current_function and cg->deferred_count < 64) {
                cg->deferred_bodies[cg->deferred_count++] = node;
            } else {
                Generate_Task_Body(cg, node);
            }
            break;

        /* RM §3.3.1: Type elaboration.  For types with static bounds,
         * no code is needed.  For constrained array types whose bounds are
         * runtime expressions (BOUND_EXPR), evaluate bounds at elaboration
         * time and store in globals for use by record layouts, alloca, etc.
         * For record types with dynamic-sized components, compute and store
         * cumulative byte offsets and total size in globals. */
        case NK_TYPE_DECL:
        {
            Symbol *type_sym = node->symbol;
            Type_Info *elab_ty = type_sym ? type_sym->type : NULL;

            /* ── Array type with expression bounds ── */
            if (elab_ty and Type_Is_Array_Like(elab_ty) and
                elab_ty->array.is_constrained and Type_Has_Dynamic_Bounds(elab_ty)) {
                Ensure_Runtime_Type_Globals(cg, elab_ty);
                if (elab_ty->rt_global_id > 0) {
                    uint32_t rtid = elab_ty->rt_global_id;
                    uint32_t ndims = elab_ty->array.index_count;
                    uint32_t esz = (elab_ty->array.element_type and
                                    elab_ty->array.element_type->size > 0)
                                   ? elab_ty->array.element_type->size : 4;
                    uint32_t count_reg = 0;
                    for (uint32_t d = 0; d < ndims; d++) {
                        Type_Bound lo = elab_ty->array.indices[d].low_bound;
                        Type_Bound hi = elab_ty->array.indices[d].high_bound;
                        if (lo.kind == BOUND_NONE and elab_ty->array.indices[d].index_type)
                            lo = elab_ty->array.indices[d].index_type->low_bound;
                        if (hi.kind == BOUND_NONE and elab_ty->array.indices[d].index_type)
                            hi = elab_ty->array.indices[d].index_type->high_bound;

                        /* Evaluate or materialise each bound as i64 */
                        uint32_t lo_r, hi_r;
                        if (lo.kind == BOUND_EXPR and lo.expr) {
                            lo_r = Generate_Expression(cg, lo.expr);
                            lo_r = Emit_Coerce_Default_Int(cg, lo_r, "i64");
                        } else {
                            lo_r = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add i64 0, %lld\n",
                                 lo_r, (long long)Type_Bound_Value(lo));
                        }
                        if (hi.kind == BOUND_EXPR and hi.expr) {
                            hi_r = Generate_Expression(cg, hi.expr);
                            hi_r = Emit_Coerce_Default_Int(cg, hi_r, "i64");
                        } else {
                            hi_r = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add i64 0, %lld\n",
                                 hi_r, (long long)Type_Bound_Value(hi));
                        }
                        Emit(cg, "  store i64 %%t%u, ptr @__rt_type_%u_lo%u\n", lo_r, rtid, d);
                        Emit(cg, "  store i64 %%t%u, ptr @__rt_type_%u_hi%u\n", hi_r, rtid, d);

                        /* dim_count = max(hi - lo + 1, 0) */
                        uint32_t diff = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = sub i64 %%t%u, %%t%u\n", diff, hi_r, lo_r);
                        uint32_t cnt = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = add i64 %%t%u, 1\n", cnt, diff);
                        uint32_t neg = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = icmp slt i64 %%t%u, 0\n", neg, cnt);
                        uint32_t clamped = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = select i1 %%t%u, i64 0, i64 %%t%u\n",
                             clamped, neg, cnt);
                        if (d == 0) {
                            count_reg = clamped;
                        } else {
                            uint32_t prod = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = mul i64 %%t%u, %%t%u\n",
                                 prod, count_reg, clamped);
                            count_reg = prod;
                        }
                    }
                    uint32_t total = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = mul i64 %%t%u, %u  ; type elab size\n",
                         total, count_reg, esz);
                    Emit(cg, "  store i64 %%t%u, ptr @__rt_type_%u_size\n", total, rtid);
                }
            }

            /* ── Record type with dynamic-sized components ── */
            if (elab_ty and Type_Is_Record(elab_ty)) {
                bool has_dyn = false;
                for (uint32_t ci = 0; ci < elab_ty->record.component_count; ci++) {
                    Type_Info *ct = elab_ty->record.components[ci].component_type;
                    if (ct and ct->size == 0 and Type_Is_Array_Like(ct)
                        and ct->array.is_constrained and Type_Has_Dynamic_Bounds(ct)) {
                        Ensure_Runtime_Type_Globals(cg, ct);
                        if (ct->rt_global_id > 0)
                            has_dyn = true;
                    }
                }
                if (has_dyn and elab_ty->rt_global_id == 0) {
                    uint32_t rid = ++cg->rt_type_counter;
                    elab_ty->rt_global_id = rid;
                    Emit_String_Const(cg, "@__rt_rec_%u_size = internal global i64 0\n", rid);
                    for (uint32_t ci = 0; ci < elab_ty->record.component_count; ci++)
                        Emit_String_Const(cg, "@__rt_rec_%u_off%u = internal global i64 0\n",
                                          rid, ci);
                }
                if (elab_ty->rt_global_id > 0) {
                    uint32_t rid = elab_ty->rt_global_id;
                    uint32_t off_r = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = add i64 0, 0  ; rec elab base\n", off_r);
                    for (uint32_t ci = 0; ci < elab_ty->record.component_count; ci++) {
                        Emit(cg, "  store i64 %%t%u, ptr @__rt_rec_%u_off%u\n",
                             off_r, rid, ci);
                        Type_Info *ct = elab_ty->record.components[ci].component_type;
                        uint32_t csz;
                        if (ct and ct->rt_global_id > 0) {
                            csz = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = load i64, ptr @__rt_type_%u_size\n",
                                 csz, ct->rt_global_id);
                        } else {
                            uint32_t s = ct ? ct->size : 0;
                            csz = Emit_Temp(cg);
                            Emit(cg, "  %%t%u = add i64 0, %u\n", csz, s);
                        }
                        uint32_t noff = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = add i64 %%t%u, %%t%u\n", noff, off_r, csz);
                        off_r = noff;
                    }
                    Emit(cg, "  store i64 %%t%u, ptr @__rt_rec_%u_size\n", off_r, rid);
                }
            }
            break;
        }

        case NK_SUBTYPE_DECL:
        {
            /* Subtype elaboration constraint check (RM 3.3.2(7)):
             * For "subtype S is T range L..H", check that L and H are
             * within T's range. Raise CONSTRAINT_ERROR if not. */
            Symbol *sub_sym = node->symbol;
            Type_Info *sub_type = sub_sym ? sub_sym->type : NULL;
            if (sub_type and sub_type->base_type) {
                Type_Info *parent = sub_type->base_type;
                bool is_scalar = (sub_type->kind == TYPE_INTEGER or
                                  sub_type->kind == TYPE_ENUMERATION or
                                  sub_type->kind == TYPE_FLOAT or
                                  sub_type->kind == TYPE_FIXED or
                                  sub_type->kind == TYPE_CHARACTER or
                                  sub_type->kind == TYPE_MODULAR);
                /* Only check scalar subtypes with both bounds known */
                bool sub_lo_ok = (sub_type->low_bound.kind == BOUND_INTEGER or
                                  sub_type->low_bound.kind == BOUND_FLOAT);
                bool sub_hi_ok = (sub_type->high_bound.kind == BOUND_INTEGER or
                                  sub_type->high_bound.kind == BOUND_FLOAT);
                bool par_lo_ok = (parent->low_bound.kind == BOUND_INTEGER or
                                  parent->low_bound.kind == BOUND_FLOAT);
                bool par_hi_ok = (parent->high_bound.kind == BOUND_INTEGER or
                                  parent->high_bound.kind == BOUND_FLOAT);
                if (is_scalar and sub_lo_ok and sub_hi_ok and par_lo_ok and par_hi_ok) {
                    /* Check if subtype range is a non-null range */
                    int64_t sub_lo = sub_type->low_bound.kind == BOUND_INTEGER ?
                        (int64_t)sub_type->low_bound.int_value : (int64_t)sub_type->low_bound.float_value;
                    int64_t sub_hi = sub_type->high_bound.kind == BOUND_INTEGER ?
                        (int64_t)sub_type->high_bound.int_value : (int64_t)sub_type->high_bound.float_value;
                    int64_t par_lo = parent->low_bound.kind == BOUND_INTEGER ?
                        (int64_t)parent->low_bound.int_value : (int64_t)parent->low_bound.float_value;
                    int64_t par_hi = parent->high_bound.kind == BOUND_INTEGER ?
                        (int64_t)parent->high_bound.int_value : (int64_t)parent->high_bound.float_value;
                    /* Only non-null ranges need checking (RM 3.3.2(8)) */
                    if (sub_lo <= sub_hi) {
                        if (sub_lo < par_lo or sub_hi > par_hi) {
                            /* Static violation: always raise */
                            Emit_Raise_Constraint_Error(cg, "subtype elaboration check");
                            uint32_t cont = Emit_Label(cg);
                            Emit(cg, "L%u:\n", cont);
                            cg->block_terminated = false;
                        }
                    }
                }
            }
            break;
        }

        /* Other declaration kinds that need no codegen */
        case NK_EXCEPTION_DECL:
        case NK_USE_CLAUSE:
        case NK_WITH_CLAUSE:
        case NK_PRAGMA:
        case NK_REPRESENTATION_CLAUSE:
        case NK_EXCEPTION_HANDLER:
        case NK_ENTRY_DECL:
        case NK_SUBPROGRAM_RENAMING:
        case NK_PACKAGE_RENAMING:
        case NK_EXCEPTION_RENAMING:
            break;

        default:
            fprintf(stderr, "warning: unhandled declaration kind %d at %s:%u\n",
                    node->kind,
                    node->location.filename ? node->location.filename : "<unknown>",
                    node->location.line);
            break;
    }
}

/* ─────────────────────────────────────────────────────────────────────────
 * §13.6 Implicit Equality Function Generation
 *
 * Generate equality functions for composite types at freeze points.
 * Per RM 4.5.2, equality is predefined for all non-limited types.
 * The RM specifies the semantics and the compiler provides the implementation.
 * ───────────────────────────────────────────────────────────────────────── */

static void Generate_Type_Equality_Function(Code_Generator *cg, Type_Info *t) {
    if (not t or not t->equality_func_name) return;

    const char *func_name = t->equality_func_name;

    /* Determine parameter type: unconstrained and dynamic-bound constrained
     * arrays are represented as fat pointers { ptr, ptr } at runtime. */
    bool is_fat = Type_Is_Unconstrained_Array(t) or
                  (Type_Is_Array_Like(t) and Type_Has_Dynamic_Bounds(t));
    const char *eq_bt = is_fat ? Array_Bound_Llvm_Type(t) : "i32";
    const char *param_type = is_fat ? FAT_PTR_TYPE : "ptr";

    /* Emit function definition with linkonce_odr for linker deduplication */
    Emit(cg, "\n; Implicit equality for type %.*s\n",
         (int)t->name.length, t->name.data);
    Emit(cg, "define linkonce_odr i1 @%s(%s %%0, %s %%1) {\n", func_name, param_type, param_type);
    Emit(cg, "entry:\n");

    /* Save and reset temp counter for this function */
    uint32_t saved_temp = cg->temp_id;
    cg->temp_id = 2;  /* Start after %0 and %1 */
    memset(cg->temp_types, 0, sizeof(cg->temp_types));
    memset(cg->temp_type_keys, 0, sizeof(cg->temp_type_keys));

    if (Type_Is_Record(t)) {
        if (t->record.component_count == 0) {
            /* Empty record - always equal */
            Emit(cg, "  ret i1 1\n");
        } else {
            uint32_t result = 0;
            for (uint32_t i = 0; i < t->record.component_count; i++) {
                Component_Info *comp = &t->record.components[i];
                const char *comp_llvm_type = Type_To_Llvm(comp->component_type);

                /* Get pointers to components */
                uint32_t left_gep = Emit_Temp(cg);
                uint32_t right_gep = Emit_Temp(cg);
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%0, i64 %u\n",
                     left_gep, comp->byte_offset);
                Emit(cg, "  %%t%u = getelementptr i8, ptr %%1, i64 %u\n",
                     right_gep, comp->byte_offset);

                /* Compare component - handle arrays/strings specially */
                uint32_t cmp;
                Type_Info *ct = comp->component_type;
                bool is_fat_ptr_access = Type_Needs_Fat_Pointer(ct);

                if (Type_Is_Unconstrained_Array(ct) or
                    (not Type_Is_Constrained_Array(ct) and Type_Is_String(ct))) {
                    /* Unconstrained array/string - load fat pointer values from storage */
                    const char *eqf_bt = Array_Bound_Llvm_Type(ct);
                    uint32_t left_fat = Emit_Load_Fat_Pointer_From_Temp(cg, left_gep, eqf_bt);
                    uint32_t right_fat = Emit_Load_Fat_Pointer_From_Temp(cg, right_gep, eqf_bt);
                    cmp = Generate_Array_Equality(cg, left_fat, right_fat, ct);
                } else if (Type_Is_Constrained_Array(ct) and Type_Has_Dynamic_Bounds(ct)) {
                    /* Constrained array with dynamic bounds (discriminant-dependent).
                     * Compute runtime byte size from discriminant value. */
                    uint32_t elem_size = ct->array.element_type ? ct->array.element_type->size : 1;
                    if (elem_size == 0) elem_size = 1;
                    int64_t low_val = 1;
                    if (ct->array.index_count > 0 and ct->array.indices[0].low_bound.kind == BOUND_INTEGER)
                        low_val = (int64_t)ct->array.indices[0].low_bound.int_value;
                    uint32_t disc_offset = 0;
                    const char *disc_llvm = "i32";
                    if (ct->array.index_count > 0 and ct->array.indices[0].high_bound.kind == BOUND_EXPR
                        and ct->array.indices[0].high_bound.expr) {
                        Symbol *bsym = ct->array.indices[0].high_bound.expr->symbol;
                        for (uint32_t d = 0; d < t->record.discriminant_count; d++) {
                            Component_Info *dc = &t->record.components[d];
                            if (bsym and Slice_Equal_Ignore_Case(dc->name, bsym->name)) {
                                disc_offset = dc->byte_offset;
                                disc_llvm = Type_To_Llvm(dc->component_type);
                                if (not disc_llvm) disc_llvm = "i32";
                                break;
                            }
                        }
                    }
                    uint32_t dp = Emit_Temp(cg), dv = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = getelementptr i8, ptr %%0, i64 %u\n", dp, disc_offset);
                    Emit(cg, "  %%t%u = load %s, ptr %%t%u\n", dv, disc_llvm, dp);
                    uint32_t cnt = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = sub %s %%t%u, %lld\n", cnt, disc_llvm, dv, (long long)(low_val - 1));
                    if (elem_size > 1) {
                        uint32_t mul = Emit_Temp(cg);
                        Emit(cg, "  %%t%u = mul %s %%t%u, %u\n", mul, disc_llvm, cnt, elem_size);
                        cnt = mul;
                    }
                    uint32_t is_neg = Emit_Temp(cg), clamped = Emit_Temp(cg), sz64 = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = icmp slt %s %%t%u, 0\n", is_neg, disc_llvm, cnt);
                    Emit(cg, "  %%t%u = select i1 %%t%u, %s 0, %s %%t%u\n", clamped, is_neg, disc_llvm, disc_llvm, cnt);
                    Emit(cg, "  %%t%u = sext %s %%t%u to i64\n", sz64, disc_llvm, clamped);
                    uint32_t mc_result = Emit_Temp(cg);
                    uint32_t mc_cmp = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = call i32 @memcmp(ptr %%t%u, ptr %%t%u, i64 %%t%u)\n",
                         mc_result, left_gep, right_gep, sz64);
                    Emit(cg, "  %%t%u = icmp eq i32 %%t%u, 0\n", mc_cmp, mc_result);
                    cmp = mc_cmp;
                } else if (Type_Is_Constrained_Array(ct)) {
                    /* Constrained array with static bounds - use array equality */
                    cmp = Generate_Array_Equality(cg, left_gep, right_gep, ct);
                } else if (Type_Is_Record(ct)) {
                    /* Nested record - recurse */
                    cmp = Generate_Record_Equality(cg, left_gep, right_gep, ct);
                } else if (is_fat_ptr_access) {
                    /* ACCESS to unconstrained array - compare fat pointer identity */
                    const char *acc_eqf_bt = Array_Bound_Llvm_Type(ct->access.designated_type);
                    uint32_t left_val = Emit_Load_Fat_Pointer_From_Temp(cg, left_gep, acc_eqf_bt);
                    uint32_t right_val = Emit_Load_Fat_Pointer_From_Temp(cg, right_gep, acc_eqf_bt);
                    cmp = Emit_Fat_Pointer_Compare(cg, left_val, right_val, acc_eqf_bt);
                } else {
                    /* Scalar type - load and compare */
                    uint32_t left_val = Emit_Temp(cg);
                    uint32_t right_val = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = load %s, ptr %%t%u\n",
                         left_val, comp_llvm_type, left_gep);
                    Emit(cg, "  %%t%u = load %s, ptr %%t%u\n",
                         right_val, comp_llvm_type, right_gep);

                    cmp = Emit_Temp(cg);
                    if (Type_Is_Float_Representation(ct)) {
                        Emit(cg, "  %%t%u = fcmp oeq %s %%t%u, %%t%u\n",
                             cmp, comp_llvm_type, left_val, right_val);
                    } else {
                        Emit(cg, "  %%t%u = icmp eq %s %%t%u, %%t%u\n",
                             cmp, comp_llvm_type, left_val, right_val);
                    }
                }

                /* AND with previous results */
                if (i == 0) {
                    result = cmp;
                } else {
                    uint32_t and_result = Emit_Temp(cg);
                    Emit(cg, "  %%t%u = and i1 %%t%u, %%t%u\n",
                         and_result, result, cmp);
                    result = and_result;
                }
            }
            Emit(cg, "  ret i1 %%t%u\n", result);
        }
    } else if (Type_Is_Array_Like(t)) {
        if (t->array.is_constrained and not Type_Has_Dynamic_Bounds(t)) {
            /* Constrained array with static bounds - use memcmp */
            int128_t count = Array_Element_Count(t);
            uint32_t elem_size = t->array.element_type ?
                                 t->array.element_type->size : 4;
            int64_t total_size = count * elem_size;

            uint32_t result = Emit_Temp(cg);
            uint32_t cmp = Emit_Temp(cg);
            Emit(cg, "  %%t%u = call i32 @memcmp(ptr %%0, ptr %%1, i64 %lld)\n",
                 result, (long long)total_size);
            Emit(cg, "  %%t%u = icmp eq i32 %%t%u, 0\n", cmp, result);
            Emit(cg, "  ret i1 %%t%u\n", cmp);
        } else {
            /*
             * Unconstrained array equality (per RM 4.5.2):
             * Fat pointer layout: { ptr data, ptr bounds }
             * where bounds > { bt low, bt high }
             * Compare lengths first, then data if lengths match.
             */
            uint32_t elem_size = t->array.element_type ?
                                 t->array.element_type->size : 1;
            const char *eq_bst = Bounds_Type_For(eq_bt);

            /* Extract data pointers (field 0) */
            Emit(cg, "  %%left_data = extractvalue " FAT_PTR_TYPE " %%0, 0\n");
            Emit(cg, "  %%right_data = extractvalue " FAT_PTR_TYPE " %%1, 0\n");

            /* Extract bounds pointers (field 1) */
            Emit(cg, "  %%left_bptr = extractvalue " FAT_PTR_TYPE " %%0, 1\n");
            Emit(cg, "  %%right_bptr = extractvalue " FAT_PTR_TYPE " %%1, 1\n");

            /* Load bounds from left fat pointer in native bt */
            Emit(cg, "  %%left_lo_gep = getelementptr %s, ptr %%left_bptr, i32 0, i32 0\n", eq_bst);
            Emit(cg, "  %%left_low = load %s, ptr %%left_lo_gep\n", eq_bt);
            Emit(cg, "  %%left_hi_gep = getelementptr %s, ptr %%left_bptr, i32 0, i32 1\n", eq_bst);
            Emit(cg, "  %%left_high = load %s, ptr %%left_hi_gep\n", eq_bt);
            Emit(cg, "  %%left_len = sub %s %%left_high, %%left_low\n", eq_bt);
            Emit(cg, "  %%left_len1 = add %s %%left_len, 1\n", eq_bt);

            /* Load bounds from right fat pointer in native bt */
            Emit(cg, "  %%right_lo_gep = getelementptr %s, ptr %%right_bptr, i32 0, i32 0\n", eq_bst);
            Emit(cg, "  %%right_low = load %s, ptr %%right_lo_gep\n", eq_bt);
            Emit(cg, "  %%right_hi_gep = getelementptr %s, ptr %%right_bptr, i32 0, i32 1\n", eq_bst);
            Emit(cg, "  %%right_high = load %s, ptr %%right_hi_gep\n", eq_bt);
            Emit(cg, "  %%right_len = sub %s %%right_high, %%right_low\n", eq_bt);
            Emit(cg, "  %%right_len1 = add %s %%right_len, 1\n", eq_bt);

            /* Compare lengths in native bt */
            Emit(cg, "  %%len_eq = icmp eq %s %%left_len1, %%right_len1\n", eq_bt);

            /* Convert to INTEGER width for memcmp byte size computation */
            const char *iat_eq = Integer_Arith_Type(cg);
            if (strcmp(eq_bt, iat_eq) != 0) {
                int eq_bits = Type_Bits(eq_bt), iat_bits = Type_Bits(iat_eq);
                const char *conv_op = (iat_bits > eq_bits) ? "sext" : "trunc";
                Emit(cg, "  %%left_len1_w = %s %s %%left_len1 to %s\n", conv_op, eq_bt, iat_eq);
                Emit(cg, "  %%byte_size = mul %s %%left_len1_w, %u\n", iat_eq, elem_size);
            } else {
                Emit(cg, "  %%byte_size = mul %s %%left_len1, %u\n", iat_eq, elem_size);
            }
            /* memcmp requires i64 for size_t — extend if needed */
            if (strcmp(iat_eq, "i64") != 0) {
                Emit(cg, "  %%byte_size64 = sext %s %%byte_size to i64\n", iat_eq);
                Emit(cg, "  %%memcmp_res = call i32 @memcmp(ptr %%left_data, ptr %%right_data, i64 %%byte_size64)\n");
            } else {
                Emit(cg, "  %%memcmp_res = call i32 @memcmp(ptr %%left_data, ptr %%right_data, i64 %%byte_size)\n");
            }
            Emit(cg, "  %%data_eq = icmp eq i32 %%memcmp_res, 0\n");

            /* Result: lengths match AND data matches */
            Emit(cg, "  %%result = and i1 %%len_eq, %%data_eq\n");
            Emit(cg, "  ret i1 %%result\n");
        }
    } else {
        /* Unknown composite type - conservatively return false (not equal).
         * This is safer than the previous "always equal" default. */
        fprintf(stderr, "warning: equality for unknown composite type '%.*s', assuming not equal\n",
                (int)t->name.length, t->name.data);
        Emit(cg, "  ret i1 0\n");
    }

    Emit(cg, "}\n");
    cg->temp_id = saved_temp;  /* Restore temp counter */
}

static void Generate_Implicit_Operators(Code_Generator *cg) {
    /* Generate equality functions for all frozen composite types */
    for (uint32_t i = 0; i < Frozen_Composite_Count; i++) {
        Generate_Type_Equality_Function(cg, Frozen_Composite_Types[i]);
    }
}

/* Generate global constants for exception identities */
static void Generate_Exception_Globals(Code_Generator *cg) {
    /* Generate globals for all registered exceptions (from declarations).
     * Dedup by mangled name to avoid redefinition when the same exception
     * is declared in multiple WITH'd packages. */
    if (Exception_Symbol_Count > 0) {
        Emit(cg, "; Exception identity globals\n");
        char exc_emitted[256][256];
        uint32_t exc_emitted_count = 0;
        for (uint32_t i = 0; i < Exception_Symbol_Count; i++) {
            Symbol *sym = Exception_Symbols[i];
            /* Get mangled name to check for duplicates */
            FILE *real_out = cg->output;
            char buf[256];
            FILE *mem = fmemopen(buf, sizeof(buf) - 1, "w");
            cg->output = mem;
            Emit_Symbol_Name(cg, sym);
            fflush(mem);
            long len = ftell(mem);
            fclose(mem);
            buf[len] = '\0';
            cg->output = real_out;
            bool dup = false;
            for (uint32_t j = 0; j < exc_emitted_count; j++) {
                if (strcmp(buf, exc_emitted[j]) == 0) { dup = true; break; }
            }
            if (dup) continue;
            if (exc_emitted_count < 256) {
                strncpy(exc_emitted[exc_emitted_count], buf, 255);
                exc_emitted[exc_emitted_count][255] = '\0';
                exc_emitted_count++;
            }
            Emit(cg, "@__exc.%s = private constant i8 0\n", buf);
        }
        Emit(cg, "\n");
    }

    /* Also emit globals for all referenced exception names that weren't
     * already emitted above (e.g., instance-prefixed exceptions from
     * generic instantiations like SEQ_IO.NAME_ERROR). */
    if (cg->exc_ref_count > 0) {
        /* Build set of already-emitted names for dedup */
        char emitted_names[256][256];
        uint32_t emitted_count = 0;
        for (uint32_t i = 0; i < Exception_Symbol_Count && emitted_count < 256; i++) {
            FILE *real_out = cg->output;
            char buf[256];
            FILE *mem = fmemopen(buf, sizeof(buf) - 1, "w");
            cg->output = mem;
            Emit_Symbol_Name(cg, Exception_Symbols[i]);
            fflush(mem);
            long len = ftell(mem);
            fclose(mem);
            buf[len] = '\0';
            cg->output = real_out;
            strncpy(emitted_names[emitted_count], buf, 255);
            emitted_names[emitted_count][255] = '\0';
            emitted_count++;
        }

        /* Also include standard exception names */
        static const char *std_exc[] = {
            "constraint_error", "numeric_error", "program_error",
            "storage_error", "tasking_error", NULL
        };

        for (uint32_t i = 0; i < cg->exc_ref_count; i++) {
            const char *name = cg->exc_refs[i];
            bool already = false;
            /* Check against emitted declaration names */
            for (uint32_t j = 0; j < emitted_count; j++) {
                if (strcmp(name, emitted_names[j]) == 0) { already = true; break; }
            }
            /* Check against standard exceptions */
            if (!already) {
                for (int j = 0; std_exc[j]; j++) {
                    if (strcmp(name, std_exc[j]) == 0) { already = true; break; }
                }
            }
            /* Also check against previously emitted exc_refs (dedup within the list) */
            if (!already) {
                for (uint32_t j = 0; j < i; j++) {
                    if (strcmp(name, cg->exc_refs[j]) == 0) { already = true; break; }
                }
            }
            if (!already) {
                Emit(cg, "@__exc.%s = private constant i8 0\n", name);
            }
        }
    }
}

/* Generate extern declarations for all loaded package specs */
static void Generate_Extern_Declarations(Code_Generator *cg, Syntax_Node *node) {
    if (not node or not node->compilation_unit.context) return;

    Syntax_Node *ctx = node->compilation_unit.context;
    bool emitted_header = false;

    /* Iterate through WITH'd packages */
    for (uint32_t i = 0; i < ctx->context.with_clauses.count; i++) {
        Syntax_Node *with_node = ctx->context.with_clauses.items[i];
        for (uint32_t j = 0; j < with_node->use_clause.names.count; j++) {
            Syntax_Node *pkg_name = with_node->use_clause.names.items[j];
            if (pkg_name->kind != NK_IDENTIFIER) continue;

            Symbol *pkg_sym = pkg_name->symbol;
            if (not pkg_sym or pkg_sym->kind != SYMBOL_PACKAGE) continue;

            /* Skip extern declarations for packages whose bodies will be code-generated.
             * Those symbols will be defined, not external. */
            if (Body_Already_Loaded(pkg_sym->name)) continue;

            /* For ALI-loaded packages without declaration, use exported[] array */
            if (not pkg_sym->declaration and pkg_sym->exported_count > 0) {
                for (uint32_t k = 0; k < pkg_sym->exported_count; k++) {
                    Symbol *sym = pkg_sym->exported[k];
                    if (not sym) continue;
                    if (sym->kind == SYMBOL_FUNCTION or sym->kind == SYMBOL_PROCEDURE) {
                        if (not emitted_header) {
                            Emit(cg, "\n; External Ada subprogram declarations\n");
                            emitted_header = true;
                        }
                        Emit_Extern_Subprogram(cg, sym);
                    } else if (sym->kind == SYMBOL_VARIABLE or sym->kind == SYMBOL_CONSTANT) {
                        if (not sym->is_named_number and not sym->extern_emitted) {
                            sym->extern_emitted = true;
                            Type_Info *ty = sym->type;
                            const char *type_str = Type_To_Llvm(ty);
                            bool is_string = (not Type_Is_Constrained_Array(ty) and Type_Is_String(ty)) or
                                (Type_Is_Unconstrained_Array(ty) and
                                 Type_Is_Character(ty->array.element_type));
                            if (is_string) type_str = FAT_PTR_TYPE;
                            Emit(cg, "@");
                            Emit_Symbol_Name(cg, sym);
                            Emit(cg, " = external global %s\n", type_str);
                        }
                    }
                }
                continue;  /* Done with this package */
            }

            if (not pkg_sym->declaration) continue;

            Syntax_Node *pkg_decl = pkg_sym->declaration;
            if (pkg_decl->kind != NK_PACKAGE_SPEC) continue;

            /* Emit extern for each subprogram and object in the package */
            for (uint32_t k = 0; k < pkg_decl->package_spec.visible_decls.count; k++) {
                Syntax_Node *decl = pkg_decl->package_spec.visible_decls.items[k];
                if (not decl) continue;

                if (decl->kind == NK_PROCEDURE_SPEC or decl->kind == NK_FUNCTION_SPEC) {
                    if (not emitted_header) {
                        Emit(cg, "\n; External Ada subprogram declarations\n");
                        emitted_header = true;
                    }
                    Emit_Extern_Subprogram(cg, decl->symbol);
                }
                /* Emit extern for object declarations (constants/variables) */
                if (decl->kind == NK_OBJECT_DECL) {
                    for (uint32_t m = 0; m < decl->object_decl.names.count; m++) {
                        Syntax_Node *name = decl->object_decl.names.items[m];
                        Symbol *sym = name ? name->symbol : NULL;
                        if (not sym or sym->is_named_number) continue;
                        if (sym->extern_emitted) continue;
                        sym->extern_emitted = true;
                        Type_Info *ty = sym->type;
                        const char *type_str = Type_To_Llvm(ty);
                        /* String constants use fat pointer type */
                        bool is_string = (not Type_Is_Constrained_Array(ty) and Type_Is_String(ty)) or
                            (Type_Is_Unconstrained_Array(ty) and
                             Type_Is_Character(ty->array.element_type));
                        if (is_string) type_str = FAT_PTR_TYPE;
                        Emit(cg, "@");
                        Emit_Symbol_Name(cg, sym);
                        Emit(cg, " = external global %s\n", type_str);
                    }
                }
            }
        }
    }
    if (emitted_header) Emit(cg, "\n");
}

/* ─────────────────────────────────────────────────────────────────────────
 * §13.7 Compilation Unit Code Generation
 *
 * A compilation unit is the quantum of separate compilation.
 * ───────────────────────────────────────────────────────────────────────── */

static void Generate_Compilation_Unit(Code_Generator *cg, Syntax_Node *node) {
    if (not node) return;

    /* Generate LLVM module header (only once per file) */
    if (not cg->header_emitted) {
    Emit(cg, "; Ada83 Compiler Output\n");
    Emit(cg, "target datalayout = \"e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128\"\n");
    Emit(cg, "target triple = \"x86_64-pc-linux-gnu\"\n\n");

    /* External C library and LLVM intrinsic declarations */
    Emit(cg, "; External declarations\n");
    Emit(cg, "declare i32 @memcmp(ptr, ptr, i64)\n");
    Emit(cg, "declare i32 @strncasecmp(ptr, ptr, i64)\n");
    Emit(cg, "declare i32 @setjmp(ptr) returns_twice\n");
    Emit(cg, "declare void @longjmp(ptr, i32) noreturn\n");
    Emit(cg, "declare void @exit(i32)\n");
    Emit(cg, "declare ptr @malloc(i64)\n");
    Emit(cg, "declare ptr @realloc(ptr, i64)\n");
    Emit(cg, "declare void @free(ptr)\n");
    Emit(cg, "declare i32 @usleep(i32)\n");
    Emit(cg, "declare i32 @pthread_create(ptr, ptr, ptr, ptr)\n");
    Emit(cg, "declare i32 @pthread_join(ptr, ptr)\n");
    Emit(cg, "declare void @pthread_exit(ptr)\n");
    Emit(cg, "declare i32 @printf(ptr, ...)\n");
    Emit(cg, "declare i32 @putchar(i32)\n");
    Emit(cg, "declare i32 @getchar()\n");
    /* C file I/O (for TEXT_IO pragma Import) */
    Emit(cg, "declare ptr @fopen(ptr, ptr)\n");
    Emit(cg, "declare i32 @fclose(ptr)\n");
    Emit(cg, "declare i32 @fputc(i32, ptr)\n");
    Emit(cg, "declare i32 @fgetc(ptr)\n");
    Emit(cg, "declare i32 @ungetc(i32, ptr)\n");
    Emit(cg, "declare i32 @feof(ptr)\n");
    Emit(cg, "declare i32 @fflush(ptr)\n");
    Emit(cg, "declare i32 @remove(ptr)\n");
    Emit(cg, "declare i64 @ftell(ptr)\n");
    Emit(cg, "declare i32 @fseek(ptr, i64, i32)\n");
    Emit(cg, "declare void @llvm.memcpy.p0.p0.i64(ptr, ptr, i64, i1)\n");
    Emit(cg, "declare void @llvm.memset.p0.i64(ptr, i8, i64, i1)\n");
    Emit(cg, "declare double @llvm.pow.f64(double, double)\n\n");

    /* LLVM overflow intrinsics for GNAT-style arithmetic overflow checks (RM 4.5).
     * Signed add/sub/mul with overflow detection at each standard width. */
    Emit(cg, "; Signed overflow intrinsics\n");
    Emit(cg, "declare {i8,  i1} @llvm.sadd.with.overflow.i8(i8, i8)\n");
    Emit(cg, "declare {i8,  i1} @llvm.ssub.with.overflow.i8(i8, i8)\n");
    Emit(cg, "declare {i8,  i1} @llvm.smul.with.overflow.i8(i8, i8)\n");
    Emit(cg, "declare {i16, i1} @llvm.sadd.with.overflow.i16(i16, i16)\n");
    Emit(cg, "declare {i16, i1} @llvm.ssub.with.overflow.i16(i16, i16)\n");
    Emit(cg, "declare {i16, i1} @llvm.smul.with.overflow.i16(i16, i16)\n");
    Emit(cg, "declare {i32, i1} @llvm.sadd.with.overflow.i32(i32, i32)\n");
    Emit(cg, "declare {i32, i1} @llvm.ssub.with.overflow.i32(i32, i32)\n");
    Emit(cg, "declare {i32, i1} @llvm.smul.with.overflow.i32(i32, i32)\n");
    Emit(cg, "declare {i64, i1} @llvm.sadd.with.overflow.i64(i64, i64)\n");
    Emit(cg, "declare {i64, i1} @llvm.ssub.with.overflow.i64(i64, i64)\n");
    Emit(cg, "declare {i64, i1} @llvm.smul.with.overflow.i64(i64, i64)\n");
    Emit(cg, "declare {i128, i1} @llvm.sadd.with.overflow.i128(i128, i128)\n");
    Emit(cg, "declare {i128, i1} @llvm.ssub.with.overflow.i128(i128, i128)\n");
    Emit(cg, "declare {i128, i1} @llvm.smul.with.overflow.i128(i128, i128)\n\n");

    /* Integer'VALUE - parse string to integer.
     * Bound type derived from STRING's index type via type system. */
    const char *rts_sbt = String_Bound_Type(cg);
    const char *iat = Integer_Arith_Type(cg);
    /* Integer'VALUE helper — Ada RM 3.5.5: full parsing with based literals.
     * Handles: [spaces] [sign] decimal_literal | based_literal [spaces]
     * decimal_literal ::= digit {[_] digit} [exponent]
     * based_literal   ::= base # hex_digit {[_] hex_digit} # [exponent]
     * exponent        ::= E [+] digit {[_] digit}
     * Raises CONSTRAINT_ERROR on any malformed input. */
    Emit(cg, "; Integer'VALUE helper (based literals + validation)\n");
    Emit(cg, "define linkonce_odr %s @__ada_integer_value(" FAT_PTR_TYPE " %%str) {\n", iat);
    Emit(cg, "entry:\n");
    Emit_Fat_Pointer_Extractvalue_Named(cg, "str", "data", "low_bt", "high_bt", rts_sbt);
    Emit(cg, "  %%len = sub %s %%high_bt, %%low_bt\n", rts_sbt);
    Emit(cg, "  %%len1 = add %s %%len, 1\n", rts_sbt);
    /* Copy to NUL-terminated C buffer for sscanf-like processing in C helper */
    Emit(cg, "  %%len64 = sext %s %%len1 to i64\n", rts_sbt);
    Emit(cg, "  %%buf = alloca i8, i64 %%len64\n");
    Emit(cg, "  call void @llvm.memcpy.p0.p0.i64(ptr %%buf, ptr %%data, i64 %%len64, i1 false)\n");
    Emit(cg, "  %%result = call %s @__ada_parse_integer(ptr %%buf, %s %%len1)\n", iat, rts_sbt);
    Emit(cg, "  ret %s %%result\n", iat);
    Emit(cg, "}\n\n");
    /* The actual parser is a C-callable function emitted as LLVM IR.
     * It handles spaces, sign, decimal, based literals, exponent, underscores,
     * and raises CONSTRAINT_ERROR on any validation failure. */
    Emit(cg, "define linkonce_odr %s @__ada_parse_integer(ptr %%buf, %s %%len) {\n", iat, rts_sbt);
    Emit(cg, "entry:\n");
    /* Phase 1: skip leading spaces (only ASCII 32; HT/other > error) */
    Emit(cg, "  br label %%skip_lead\n");
    Emit(cg, "skip_lead:\n");
    Emit(cg, "  %%sl_i = phi %s [ 0, %%entry ], [ %%sl_ni, %%sl_cont ]\n", rts_sbt);
    Emit(cg, "  %%sl_done = icmp sge %s %%sl_i, %%len\n", rts_sbt);
    Emit(cg, "  br i1 %%sl_done, label %%bad, label %%sl_body\n");
    Emit(cg, "sl_body:\n");
    Emit(cg, "  %%sl_p = getelementptr i8, ptr %%buf, %s %%sl_i\n", rts_sbt);
    Emit(cg, "  %%sl_c = load i8, ptr %%sl_p\n");
    Emit(cg, "  %%sl_sp = icmp eq i8 %%sl_c, 32\n");
    Emit(cg, "  br i1 %%sl_sp, label %%sl_cont, label %%got_start\n");
    Emit(cg, "sl_cont:\n");
    Emit(cg, "  %%sl_ni = add %s %%sl_i, 1\n", rts_sbt);
    Emit(cg, "  br label %%skip_lead\n");

    /* Phase 2: find end (skip trailing spaces; HT/other at end > error) */
    Emit(cg, "got_start:\n");
    Emit(cg, "  %%end_init = sub %s %%len, 1\n", rts_sbt);
    Emit(cg, "  br label %%skip_trail\n");
    Emit(cg, "skip_trail:\n");
    Emit(cg, "  %%st_i = phi %s [ %%end_init, %%got_start ], [ %%st_ni, %%st_cont ]\n", rts_sbt);
    Emit(cg, "  %%st_le = icmp sle %s %%st_i, %%sl_i\n", rts_sbt);
    Emit(cg, "  br i1 %%st_le, label %%bad, label %%st_body\n");
    Emit(cg, "st_body:\n");
    Emit(cg, "  %%st_p = getelementptr i8, ptr %%buf, %s %%st_i\n", rts_sbt);
    Emit(cg, "  %%st_c = load i8, ptr %%st_p\n");
    Emit(cg, "  %%st_sp = icmp eq i8 %%st_c, 32\n");
    Emit(cg, "  br i1 %%st_sp, label %%st_cont, label %%trimmed\n");
    Emit(cg, "st_cont:\n");
    Emit(cg, "  %%st_ni = sub %s %%st_i, 1\n", rts_sbt);
    Emit(cg, "  br label %%skip_trail\n");

    /* Now sl_i..st_i is the trimmed content (inclusive) */
    Emit(cg, "trimmed:\n");
    Emit(cg, "  %%end = add %s %%st_i, 1\n", rts_sbt); /* exclusive end */
    /* Phase 3: check for sign */
    Emit(cg, "  %%s_p = getelementptr i8, ptr %%buf, %s %%sl_i\n", rts_sbt);
    Emit(cg, "  %%s_c = load i8, ptr %%s_p\n");
    Emit(cg, "  %%is_neg = icmp eq i8 %%s_c, 45\n");
    Emit(cg, "  %%is_pos = icmp eq i8 %%s_c, 43\n");
    Emit(cg, "  %%has_sign = or i1 %%is_neg, %%is_pos\n");
    Emit(cg, "  %%dig_start_s = add %s %%sl_i, 1\n", rts_sbt);
    Emit(cg, "  %%dig_start = select i1 %%has_sign, %s %%dig_start_s, %s %%sl_i\n", rts_sbt, rts_sbt);

    /* Phase 4: Parse digit sequence, looking for '#' or ':' (based literal delimiter) */
    Emit(cg, "  br label %%d1loop\n");
    Emit(cg, "d1loop:\n");
    Emit(cg, "  %%d1_i = phi %s [ %%dig_start, %%trimmed ], [ %%d1_ni, %%d1_cont ]\n", rts_sbt);
    Emit(cg, "  %%d1_val = phi %s [ 0, %%trimmed ], [ %%d1_nv, %%d1_cont ]\n", iat);
    Emit(cg, "  %%d1_last_under = phi i1 [ false, %%trimmed ], [ %%d1_is_under, %%d1_cont ]\n");
    Emit(cg, "  %%d1_done = icmp sge %s %%d1_i, %%end\n", rts_sbt);
    Emit(cg, "  br i1 %%d1_done, label %%apply_sign, label %%d1_body\n");
    Emit(cg, "d1_body:\n");
    Emit(cg, "  %%d1_p = getelementptr i8, ptr %%buf, %s %%d1_i\n", rts_sbt);
    Emit(cg, "  %%d1_ch = load i8, ptr %%d1_p\n");
    /* Check for '#' or ':' > based literal */
    Emit(cg, "  %%d1_sharp = icmp eq i8 %%d1_ch, 35\n");
    Emit(cg, "  %%d1_colon = icmp eq i8 %%d1_ch, 58\n");
    Emit(cg, "  %%d1_delim = or i1 %%d1_sharp, %%d1_colon\n");
    Emit(cg, "  br i1 %%d1_delim, label %%start_based, label %%d1_check_exp\n");
    /* Check for E/e > exponent */
    Emit(cg, "d1_check_exp:\n");
    Emit(cg, "  %%d1_isE = icmp eq i8 %%d1_ch, 69\n");
    Emit(cg, "  %%d1_ise = icmp eq i8 %%d1_ch, 101\n");
    Emit(cg, "  %%d1_exp = or i1 %%d1_isE, %%d1_ise\n");
    Emit(cg, "  br i1 %%d1_exp, label %%exp_start_d, label %%d1_check_under\n");
    /* Check for underscore */
    Emit(cg, "d1_check_under:\n");
    Emit(cg, "  %%d1_is_under = icmp eq i8 %%d1_ch, 95\n");
    Emit(cg, "  br i1 %%d1_is_under, label %%d1_under, label %%d1_digit\n");
    Emit(cg, "d1_under:\n");
    /* Consecutive underscores or leading underscore > error */
    Emit(cg, "  %%d1_consec = and i1 %%d1_last_under, %%d1_is_under\n");
    Emit(cg, "  %%d1_leading = icmp eq %s %%d1_i, %%dig_start\n", rts_sbt);
    Emit(cg, "  %%d1_bad_u = or i1 %%d1_consec, %%d1_leading\n");
    Emit(cg, "  br i1 %%d1_bad_u, label %%bad, label %%d1_cont\n");
    /* Parse decimal digit */
    Emit(cg, "d1_digit:\n");
    Emit(cg, "  %%d1_ge0 = icmp uge i8 %%d1_ch, 48\n");
    Emit(cg, "  %%d1_le9 = icmp ule i8 %%d1_ch, 57\n");
    Emit(cg, "  %%d1_isdig = and i1 %%d1_ge0, %%d1_le9\n");
    Emit(cg, "  br i1 %%d1_isdig, label %%d1_accum, label %%bad\n");
    Emit(cg, "d1_accum:\n");
    Emit(cg, "  %%d1_d = sub i8 %%d1_ch, 48\n");
    Emit(cg, "  %%d1_dw = zext i8 %%d1_d to %s\n", iat);
    Emit(cg, "  %%d1_mul = mul %s %%d1_val, 10\n", iat);
    Emit(cg, "  %%d1_nv_a = add %s %%d1_mul, %%d1_dw\n", iat);
    Emit(cg, "  br label %%d1_cont\n");
    Emit(cg, "d1_cont:\n");
    Emit(cg, "  %%d1_nv = phi %s [ %%d1_nv_a, %%d1_accum ], [ %%d1_val, %%d1_under ]\n", iat);
    Emit(cg, "  %%d1_ni = add %s %%d1_i, 1\n", rts_sbt);
    Emit(cg, "  br label %%d1loop\n");

    /* Based literal: d1_val is the base, parse digits in that base until '#'/':' */
    Emit(cg, "start_based:\n");
    Emit(cg, "  %%base = add %s %%d1_val, 0\n", iat); /* copy */
    /* Validate base: 2..16 */
    Emit(cg, "  %%base_lo = icmp slt %s %%base, 2\n", iat);
    Emit(cg, "  %%base_hi = icmp sgt %s %%base, 16\n", iat);
    Emit(cg, "  %%base_bad = or i1 %%base_lo, %%base_hi\n");
    Emit(cg, "  br i1 %%base_bad, label %%bad, label %%based_ok\n");
    Emit(cg, "based_ok:\n");
    Emit(cg, "  %%b_delim = add i8 %%d1_ch, 0\n"); /* remember delimiter */
    Emit(cg, "  %%b_start = add %s %%d1_i, 1\n", rts_sbt);
    Emit(cg, "  br label %%bloop\n");
    Emit(cg, "bloop:\n");
    Emit(cg, "  %%b_i = phi %s [ %%b_start, %%based_ok ], [ %%b_ni, %%b_cont ]\n", rts_sbt);
    Emit(cg, "  %%b_val = phi %s [ 0, %%based_ok ], [ %%b_nv, %%b_cont ]\n", iat);
    Emit(cg, "  %%b_last_under = phi i1 [ false, %%based_ok ], [ %%b_is_under, %%b_cont ]\n");
    Emit(cg, "  %%b_done = icmp sge %s %%b_i, %%end\n", rts_sbt);
    Emit(cg, "  br i1 %%b_done, label %%bad, label %%b_body\n"); /* missing closing delimiter */
    Emit(cg, "b_body:\n");
    Emit(cg, "  %%b_p = getelementptr i8, ptr %%buf, %s %%b_i\n", rts_sbt);
    Emit(cg, "  %%b_ch = load i8, ptr %%b_p\n");
    /* Check for closing delimiter */
    Emit(cg, "  %%b_close = icmp eq i8 %%b_ch, %%b_delim\n");
    Emit(cg, "  br i1 %%b_close, label %%based_done, label %%b_check_under\n");
    /* Check underscore */
    Emit(cg, "b_check_under:\n");
    Emit(cg, "  %%b_is_under = icmp eq i8 %%b_ch, 95\n");
    Emit(cg, "  br i1 %%b_is_under, label %%b_under, label %%b_hexdig\n");
    Emit(cg, "b_under:\n");
    Emit(cg, "  %%b_consec = and i1 %%b_last_under, %%b_is_under\n");
    Emit(cg, "  %%b_leading_u = icmp eq %s %%b_i, %%b_start\n", rts_sbt);
    Emit(cg, "  %%b_bad_u = or i1 %%b_consec, %%b_leading_u\n");
    Emit(cg, "  br i1 %%b_bad_u, label %%bad, label %%b_cont\n");
    /* Parse hex digit (0-9, A-F, a-f) */
    Emit(cg, "b_hexdig:\n");
    Emit(cg, "  %%b_ge0 = icmp uge i8 %%b_ch, 48\n");
    Emit(cg, "  %%b_le9 = icmp ule i8 %%b_ch, 57\n");
    Emit(cg, "  %%b_09 = and i1 %%b_ge0, %%b_le9\n");
    Emit(cg, "  br i1 %%b_09, label %%b_d09, label %%b_check_af\n");
    Emit(cg, "b_d09:\n");
    Emit(cg, "  %%b_d09v = sub i8 %%b_ch, 48\n");
    Emit(cg, "  br label %%b_accum\n");
    Emit(cg, "b_check_af:\n");
    Emit(cg, "  %%b_geA = icmp uge i8 %%b_ch, 65\n");
    Emit(cg, "  %%b_leF = icmp ule i8 %%b_ch, 70\n");
    Emit(cg, "  %%b_AF = and i1 %%b_geA, %%b_leF\n");
    Emit(cg, "  br i1 %%b_AF, label %%b_dAF, label %%b_check_af2\n");
    Emit(cg, "b_dAF:\n");
    Emit(cg, "  %%b_dAFv = sub i8 %%b_ch, 55\n"); /* 'A'-10 = 55 */
    Emit(cg, "  br label %%b_accum\n");
    Emit(cg, "b_check_af2:\n");
    Emit(cg, "  %%b_gea = icmp uge i8 %%b_ch, 97\n");
    Emit(cg, "  %%b_lef = icmp ule i8 %%b_ch, 102\n");
    Emit(cg, "  %%b_af = and i1 %%b_gea, %%b_lef\n");
    Emit(cg, "  br i1 %%b_af, label %%b_daf, label %%bad\n");
    Emit(cg, "b_daf:\n");
    Emit(cg, "  %%b_dafv = sub i8 %%b_ch, 87\n"); /* 'a'-10 = 87 */
    Emit(cg, "  br label %%b_accum\n");
    Emit(cg, "b_accum:\n");
    Emit(cg, "  %%b_digit = phi i8 [ %%b_d09v, %%b_d09 ], [ %%b_dAFv, %%b_dAF ], [ %%b_dafv, %%b_daf ]\n");
    Emit(cg, "  %%b_dw = zext i8 %%b_digit to %s\n", iat);
    /* Check digit < base */
    Emit(cg, "  %%b_inrange = icmp slt %s %%b_dw, %%base\n", iat);
    Emit(cg, "  br i1 %%b_inrange, label %%b_ok_dig, label %%bad\n");
    Emit(cg, "b_ok_dig:\n");
    Emit(cg, "  %%b_mul = mul %s %%b_val, %%base\n", iat);
    Emit(cg, "  %%b_nv_a = add %s %%b_mul, %%b_dw\n", iat);
    Emit(cg, "  br label %%b_cont\n");
    Emit(cg, "b_cont:\n");
    Emit(cg, "  %%b_nv = phi %s [ %%b_nv_a, %%b_ok_dig ], [ %%b_val, %%b_under ]\n", iat);
    Emit(cg, "  %%b_ni = add %s %%b_i, 1\n", rts_sbt);
    Emit(cg, "  br label %%bloop\n");

    /* After closing '#'/':' — check for optional exponent */
    Emit(cg, "based_done:\n");
    Emit(cg, "  %%bd_ni = add %s %%b_i, 1\n", rts_sbt);
    Emit(cg, "  %%bd_more = icmp slt %s %%bd_ni, %%end\n", rts_sbt);
    Emit(cg, "  br i1 %%bd_more, label %%bd_check_exp, label %%apply_sign_based\n");
    Emit(cg, "bd_check_exp:\n");
    Emit(cg, "  %%bd_ep = getelementptr i8, ptr %%buf, %s %%bd_ni\n", rts_sbt);
    Emit(cg, "  %%bd_ec = load i8, ptr %%bd_ep\n");
    Emit(cg, "  %%bd_isE = icmp eq i8 %%bd_ec, 69\n");
    Emit(cg, "  %%bd_ise = icmp eq i8 %%bd_ec, 101\n");
    Emit(cg, "  %%bd_exp = or i1 %%bd_isE, %%bd_ise\n");
    Emit(cg, "  br i1 %%bd_exp, label %%exp_start_b, label %%bad\n"); /* trailing junk */

    /* Exponent for based literal: exp_start_b, base is still %%base */
    Emit(cg, "exp_start_b:\n");
    Emit(cg, "  %%eb_s = add %s %%bd_ni, 1\n", rts_sbt);
    Emit(cg, "  br label %%ebloop\n");
    Emit(cg, "ebloop:\n");
    Emit(cg, "  %%eb_i = phi %s [ %%eb_s, %%exp_start_b ], [ %%eb_ni, %%eb_cont ]\n", rts_sbt);
    Emit(cg, "  %%eb_v = phi %s [ 0, %%exp_start_b ], [ %%eb_nv, %%eb_cont ]\n", iat);
    Emit(cg, "  %%eb_done = icmp sge %s %%eb_i, %%end\n", rts_sbt);
    Emit(cg, "  br i1 %%eb_done, label %%apply_exp_based, label %%eb_body\n");
    Emit(cg, "eb_body:\n");
    Emit(cg, "  %%eb_p = getelementptr i8, ptr %%buf, %s %%eb_i\n", rts_sbt);
    Emit(cg, "  %%eb_c = load i8, ptr %%eb_p\n");
    Emit(cg, "  %%eb_ge0 = icmp uge i8 %%eb_c, 48\n");
    Emit(cg, "  %%eb_le9 = icmp ule i8 %%eb_c, 57\n");
    Emit(cg, "  %%eb_isdig = and i1 %%eb_ge0, %%eb_le9\n");
    Emit(cg, "  br i1 %%eb_isdig, label %%eb_accum, label %%eb_skip\n");
    Emit(cg, "eb_accum:\n");
    Emit(cg, "  %%eb_d = sub i8 %%eb_c, 48\n");
    Emit(cg, "  %%eb_dw = zext i8 %%eb_d to %s\n", iat);
    Emit(cg, "  %%eb_mul = mul %s %%eb_v, 10\n", iat);
    Emit(cg, "  %%eb_nv_a = add %s %%eb_mul, %%eb_dw\n", iat);
    Emit(cg, "  br label %%eb_cont\n");
    Emit(cg, "eb_skip:\n"); /* skip + sign */
    Emit(cg, "  br label %%eb_cont\n");
    Emit(cg, "eb_cont:\n");
    Emit(cg, "  %%eb_nv = phi %s [ %%eb_nv_a, %%eb_accum ], [ %%eb_v, %%eb_skip ]\n", iat);
    Emit(cg, "  %%eb_ni = add %s %%eb_i, 1\n", rts_sbt);
    Emit(cg, "  br label %%ebloop\n");

    /* Apply exponent for based literal: result = b_val * base^exp */
    Emit(cg, "apply_exp_based:\n");
    Emit(cg, "  br label %%bpow_loop\n");
    Emit(cg, "bpow_loop:\n");
    Emit(cg, "  %%bp_acc = phi %s [ 1, %%apply_exp_based ], [ %%bp_next, %%bpow_body ]\n", iat);
    Emit(cg, "  %%bp_rem = phi %s [ %%eb_v, %%apply_exp_based ], [ %%bp_dec, %%bpow_body ]\n", iat);
    Emit(cg, "  %%bp_done = icmp sle %s %%bp_rem, 0\n", iat);
    Emit(cg, "  br i1 %%bp_done, label %%apply_sign_based_e, label %%bpow_body\n");
    Emit(cg, "bpow_body:\n");
    Emit(cg, "  %%bp_next = mul %s %%bp_acc, %%base\n", iat);
    Emit(cg, "  %%bp_dec = sub %s %%bp_rem, 1\n", iat);
    Emit(cg, "  br label %%bpow_loop\n");

    Emit(cg, "apply_sign_based_e:\n");
    Emit(cg, "  %%based_scaled = mul %s %%b_val, %%bp_acc\n", iat);
    Emit(cg, "  %%neg_based_e = sub %s 0, %%based_scaled\n", iat);
    Emit(cg, "  %%ret_based_e = select i1 %%is_neg, %s %%neg_based_e, %s %%based_scaled\n", iat, iat);
    Emit(cg, "  ret %s %%ret_based_e\n", iat);

    Emit(cg, "apply_sign_based:\n");
    Emit(cg, "  %%neg_based = sub %s 0, %%b_val\n", iat);
    Emit(cg, "  %%ret_based = select i1 %%is_neg, %s %%neg_based, %s %%b_val\n", iat, iat);
    Emit(cg, "  ret %s %%ret_based\n", iat);

    /* Decimal exponent path */
    Emit(cg, "exp_start_d:\n");
    /* Check for trailing underscore before E */
    Emit(cg, "  br i1 %%d1_last_under, label %%bad, label %%exp_d_ok\n");
    Emit(cg, "exp_d_ok:\n");
    Emit(cg, "  %%ed_s = add %s %%d1_i, 1\n", rts_sbt);
    /* Check first char after E: must be digit or '+'; '-' > error */
    Emit(cg, "  %%ed_first_p = getelementptr i8, ptr %%buf, %s %%ed_s\n", rts_sbt);
    Emit(cg, "  %%ed_first_done = icmp sge %s %%ed_s, %%end\n", rts_sbt);
    Emit(cg, "  br i1 %%ed_first_done, label %%bad, label %%ed_check_first\n");
    Emit(cg, "ed_check_first:\n");
    Emit(cg, "  %%ed_fc = load i8, ptr %%ed_first_p\n");
    Emit(cg, "  %%ed_fc_minus = icmp eq i8 %%ed_fc, 45\n");
    Emit(cg, "  br i1 %%ed_fc_minus, label %%bad, label %%ed_fc_plus\n");
    Emit(cg, "ed_fc_plus:\n");
    Emit(cg, "  %%ed_fc_isplus = icmp eq i8 %%ed_fc, 43\n");
    Emit(cg, "  %%ed_s2 = add %s %%ed_s, 1\n", rts_sbt);
    Emit(cg, "  %%ed_real_s = select i1 %%ed_fc_isplus, %s %%ed_s2, %s %%ed_s\n", rts_sbt, rts_sbt);
    /* First char after E (or E+) must be a digit, not underscore or other */
    Emit(cg, "  %%ed_fc_ge0 = icmp uge i8 %%ed_fc, 48\n");
    Emit(cg, "  %%ed_fc_le9 = icmp ule i8 %%ed_fc, 57\n");
    Emit(cg, "  %%ed_fc_isdig = and i1 %%ed_fc_ge0, %%ed_fc_le9\n");
    Emit(cg, "  %%ed_fc_ok = or i1 %%ed_fc_isplus, %%ed_fc_isdig\n");
    Emit(cg, "  br i1 %%ed_fc_ok, label %%edloop, label %%bad\n");
    Emit(cg, "edloop:\n");
    Emit(cg, "  %%ed_i = phi %s [ %%ed_real_s, %%ed_fc_plus ], [ %%ed_ni, %%ed_cont ]\n", rts_sbt);
    Emit(cg, "  %%ed_v = phi %s [ 0, %%ed_fc_plus ], [ %%ed_nv, %%ed_cont ]\n", iat);
    Emit(cg, "  %%ed_had_dig = phi i1 [ false, %%ed_fc_plus ], [ true, %%ed_cont ]\n");
    Emit(cg, "  %%ed_done = icmp sge %s %%ed_i, %%end\n", rts_sbt);
    Emit(cg, "  br i1 %%ed_done, label %%ed_check_end, label %%ed_body\n");
    Emit(cg, "ed_check_end:\n");
    /* Must have seen at least one digit */
    Emit(cg, "  br i1 %%ed_had_dig, label %%apply_exp_d, label %%bad\n");
    Emit(cg, "ed_body:\n");
    Emit(cg, "  %%ed_p = getelementptr i8, ptr %%buf, %s %%ed_i\n", rts_sbt);
    Emit(cg, "  %%ed_c = load i8, ptr %%ed_p\n");
    Emit(cg, "  %%ed_ge0 = icmp uge i8 %%ed_c, 48\n");
    Emit(cg, "  %%ed_le9 = icmp ule i8 %%ed_c, 57\n");
    Emit(cg, "  %%ed_isdig = and i1 %%ed_ge0, %%ed_le9\n");
    Emit(cg, "  br i1 %%ed_isdig, label %%ed_accum, label %%ed_check_u\n");
    Emit(cg, "ed_check_u:\n");
    /* Only underscore allowed in exponent digits (not consecutive/leading/trailing) */
    Emit(cg, "  %%ed_is_u = icmp eq i8 %%ed_c, 95\n");
    Emit(cg, "  br i1 %%ed_is_u, label %%ed_cont, label %%bad\n");
    Emit(cg, "ed_accum:\n");
    Emit(cg, "  %%ed_d = sub i8 %%ed_c, 48\n");
    Emit(cg, "  %%ed_dw = zext i8 %%ed_d to %s\n", iat);
    Emit(cg, "  %%ed_mul = mul %s %%ed_v, 10\n", iat);
    Emit(cg, "  %%ed_nv_a = add %s %%ed_mul, %%ed_dw\n", iat);
    Emit(cg, "  br label %%ed_cont\n");
    Emit(cg, "ed_cont:\n");
    Emit(cg, "  %%ed_nv = phi %s [ %%ed_nv_a, %%ed_accum ], [ %%ed_v, %%ed_check_u ]\n", iat);
    Emit(cg, "  %%ed_ni = add %s %%ed_i, 1\n", rts_sbt);
    Emit(cg, "  br label %%edloop\n");

    /* Apply decimal exponent: result = mantissa * 10^exp */
    Emit(cg, "apply_exp_d:\n");
    Emit(cg, "  br label %%dpow_loop\n");
    Emit(cg, "dpow_loop:\n");
    Emit(cg, "  %%dp_acc = phi %s [ 1, %%apply_exp_d ], [ %%dp_next, %%dpow_body ]\n", iat);
    Emit(cg, "  %%dp_rem = phi %s [ %%ed_v, %%apply_exp_d ], [ %%dp_dec, %%dpow_body ]\n", iat);
    Emit(cg, "  %%dp_done = icmp sle %s %%dp_rem, 0\n", iat);
    Emit(cg, "  br i1 %%dp_done, label %%apply_sign_de, label %%dpow_body\n");
    Emit(cg, "dpow_body:\n");
    Emit(cg, "  %%dp_next = mul %s %%dp_acc, 10\n", iat);
    Emit(cg, "  %%dp_dec = sub %s %%dp_rem, 1\n", iat);
    Emit(cg, "  br label %%dpow_loop\n");
    Emit(cg, "apply_sign_de:\n");
    Emit(cg, "  %%de_scaled = mul %s %%d1_val, %%dp_acc\n", iat);
    Emit(cg, "  %%neg_de = sub %s 0, %%de_scaled\n", iat);
    Emit(cg, "  %%ret_de = select i1 %%is_neg, %s %%neg_de, %s %%de_scaled\n", iat, iat);
    Emit(cg, "  ret %s %%ret_de\n", iat);

    /* Simple decimal result (no exponent, no base) — apply sign */
    Emit(cg, "apply_sign:\n");
    /* Check for trailing underscore */
    Emit(cg, "  br i1 %%d1_last_under, label %%bad, label %%apply_sign_ok\n");
    Emit(cg, "apply_sign_ok:\n");
    Emit(cg, "  %%neg_d = sub %s 0, %%d1_val\n", iat);
    Emit(cg, "  %%ret_d = select i1 %%is_neg, %s %%neg_d, %s %%d1_val\n", iat, iat);
    Emit(cg, "  ret %s %%ret_d\n", iat);

    /* Error: raise CONSTRAINT_ERROR */
    Emit(cg, "bad:\n");
    Emit(cg, "  %%exc_ptr_bad = ptrtoint ptr @__exc.constraint_error to i64\n");
    Emit(cg, "  call void @__ada_raise(i64 %%exc_ptr_bad)\n");
    Emit(cg, "  unreachable\n");
    Emit(cg, "}\n\n");

    /* Float'VALUE - declare as external for now (can be implemented similarly) */
    Emit(cg, "; Float'VALUE declaration (to be implemented)\n");
    Emit(cg, "declare double @strtod(ptr, ptr)\n");
    Emit(cg, "define linkonce_odr double @__ada_float_value(" FAT_PTR_TYPE " %%str) {\n");
    Emit(cg, "entry:\n");
    Emit_Fat_Pointer_Extractvalue_Named(cg, "str", "data", "fv_low", "fv_high", rts_sbt);
    Emit(cg, "  %%result = call double @strtod(ptr %%data, ptr null)\n");
    Emit(cg, "  ret double %%result\n");
    Emit(cg, "}\n\n");

    /* Integer power function — signed, overflow-checked (RM 4.5.6).
     * Uses binary exponentiation (O(log n)) with overflow checking.
     * Raises Constraint_Error on negative exponent or overflow. */
    Emit(cg, "; Integer exponentiation helper (signed, overflow-checked, binary exp)\n");
    Emit(cg, "define linkonce_odr %s @__ada_integer_pow(%s %%base, %s %%exp) {\n", iat, iat, iat);
    Emit(cg, "entry:\n");
    /* Check for negative exponent */
    Emit(cg, "  %%is_neg = icmp slt %s %%exp, 0\n", iat);
    Emit(cg, "  br i1 %%is_neg, label %%neg_exp, label %%check_zero\n");
    Emit(cg, "neg_exp:\n");
    Emit(cg, "  %%exc_ptr_neg = ptrtoint ptr @__exc.constraint_error to i64\n");
    Emit(cg, "  call void @__ada_raise(i64 %%exc_ptr_neg)\n");
    Emit(cg, "  unreachable  ; negative exponent for integer (RM 4.5.6)\n");
    Emit(cg, "check_zero:\n");
    /* exp == 0 -> return 1 */
    Emit(cg, "  %%is_zero = icmp eq %s %%exp, 0\n", iat);
    Emit(cg, "  br i1 %%is_zero, label %%ret_one, label %%loop\n");
    Emit(cg, "ret_one:\n");
    Emit(cg, "  ret %s 1\n", iat);
    /* Binary exponentiation loop: result *= b when e is odd, b *= b, e /= 2 */
    Emit(cg, "loop:\n");
    Emit(cg, "  %%result = phi %s [ 1, %%check_zero ], [ %%new_result, %%cont ]\n", iat);
    Emit(cg, "  %%b = phi %s [ %%base, %%check_zero ], [ %%new_b, %%cont ]\n", iat);
    Emit(cg, "  %%e = phi %s [ %%exp, %%check_zero ], [ %%new_e, %%cont ]\n", iat);
    /* Check if e is odd: e & 1 */
    Emit(cg, "  %%is_odd = and %s %%e, 1\n", iat);
    Emit(cg, "  %%odd_bit = icmp ne %s %%is_odd, 0\n", iat);
    Emit(cg, "  br i1 %%odd_bit, label %%mult_result, label %%square_base\n");
    /* Multiply result by base (overflow checked) */
    Emit(cg, "mult_result:\n");
    Emit(cg, "  %%pair_r = call {%s, i1} @llvm.smul.with.overflow.%s(%s %%result, %s %%b)\n", iat, iat, iat, iat);
    Emit(cg, "  %%mult_r = extractvalue {%s, i1} %%pair_r, 0\n", iat);
    Emit(cg, "  %%ovf_r = extractvalue {%s, i1} %%pair_r, 1\n", iat);
    Emit(cg, "  br i1 %%ovf_r, label %%overflow, label %%square_base\n");
    /* Square the base for next iteration */
    Emit(cg, "square_base:\n");
    Emit(cg, "  %%result_sq = phi %s [ %%result, %%loop ], [ %%mult_r, %%mult_result ]\n", iat);
    /* Halve exponent */
    Emit(cg, "  %%new_e = lshr %s %%e, 1\n", iat);
    /* Check if done (e == 0 after shift) */
    Emit(cg, "  %%done = icmp eq %s %%new_e, 0\n", iat);
    Emit(cg, "  br i1 %%done, label %%exit, label %%do_square\n");
    /* Actually compute b*b (only if we need it for next iteration) */
    Emit(cg, "do_square:\n");
    Emit(cg, "  %%pair_b = call {%s, i1} @llvm.smul.with.overflow.%s(%s %%b, %s %%b)\n", iat, iat, iat, iat);
    Emit(cg, "  %%sq_b = extractvalue {%s, i1} %%pair_b, 0\n", iat);
    Emit(cg, "  %%ovf_b = extractvalue {%s, i1} %%pair_b, 1\n", iat);
    Emit(cg, "  br i1 %%ovf_b, label %%overflow, label %%cont\n");
    Emit(cg, "cont:\n");
    Emit(cg, "  %%new_result = phi %s [ %%result_sq, %%do_square ]\n", iat);
    Emit(cg, "  %%new_b = phi %s [ %%sq_b, %%do_square ]\n", iat);
    Emit(cg, "  br label %%loop\n");
    Emit(cg, "overflow:\n");
    Emit(cg, "  %%exc_ptr = ptrtoint ptr @__exc.constraint_error to i64\n");
    Emit(cg, "  call void @__ada_raise(i64 %%exc_ptr)\n");
    Emit(cg, "  unreachable\n");
    Emit(cg, "exit:\n");
    Emit(cg, "  ret %s %%result_sq\n", iat);
    Emit(cg, "}\n\n");

    /* Modular power function — unsigned, wrapping (RM 3.5.4).
     * Uses binary exponentiation (O(log n)), no overflow check as modular wraps. */
    Emit(cg, "; Modular exponentiation helper (unsigned, wrapping, binary exp)\n");
    Emit(cg, "define linkonce_odr %s @__ada_modular_pow(%s %%base, %s %%exp) {\n", iat, iat, iat);
    Emit(cg, "entry:\n");
    Emit(cg, "  %%is_zero = icmp eq %s %%exp, 0\n", iat);
    Emit(cg, "  br i1 %%is_zero, label %%ret_one, label %%loop\n");
    Emit(cg, "ret_one:\n");
    Emit(cg, "  ret %s 1\n", iat);
    /* Binary exponentiation loop */
    Emit(cg, "loop:\n");
    Emit(cg, "  %%result = phi %s [ 1, %%entry ], [ %%new_result, %%cont ]\n", iat);
    Emit(cg, "  %%b = phi %s [ %%base, %%entry ], [ %%new_b, %%cont ]\n", iat);
    Emit(cg, "  %%e = phi %s [ %%exp, %%entry ], [ %%new_e, %%cont ]\n", iat);
    Emit(cg, "  %%is_odd = and %s %%e, 1\n", iat);
    Emit(cg, "  %%odd_bit = icmp ne %s %%is_odd, 0\n", iat);
    Emit(cg, "  br i1 %%odd_bit, label %%mult, label %%square\n");
    Emit(cg, "mult:\n");
    Emit(cg, "  %%mult_r = mul %s %%result, %%b\n", iat);
    Emit(cg, "  br label %%square\n");
    Emit(cg, "square:\n");
    Emit(cg, "  %%result_s = phi %s [ %%result, %%loop ], [ %%mult_r, %%mult ]\n", iat);
    Emit(cg, "  %%new_e = lshr %s %%e, 1\n", iat);
    Emit(cg, "  %%done = icmp eq %s %%new_e, 0\n", iat);
    Emit(cg, "  br i1 %%done, label %%exit, label %%cont\n");
    Emit(cg, "cont:\n");
    Emit(cg, "  %%new_result = phi %s [ %%result_s, %%square ]\n", iat);
    Emit(cg, "  %%new_b = mul %s %%b, %%b\n", iat);
    Emit(cg, "  br label %%loop\n");
    Emit(cg, "exit:\n");
    Emit(cg, "  ret %s %%result_s\n", iat);
    Emit(cg, "}\n\n");

    /* String trim helpers for Enum'VALUE (Ada RM 3.5): count leading/trailing
     * spaces so the comparison uses the trimmed content only. */
    {   /* Always emitted — linkonce_odr deduplicates, and codegen sets
         * needs_trim_helpers too late (after header emission). */
        Emit(cg, "; String trim helpers for VALUE attribute\n");
        /* count_leading_spaces(ptr data, iN len) -> iN */
        Emit(cg, "define linkonce_odr %s @__ada_count_leading_spaces(ptr %%d, %s %%len) {\n", iat, iat);
        Emit(cg, "entry:\n  br label %%loop\n");
        Emit(cg, "loop:\n");
        Emit(cg, "  %%i = phi %s [ 0, %%entry ], [ %%ni, %%cont ]\n", iat);
        Emit(cg, "  %%done = icmp sge %s %%i, %%len\n", iat);
        Emit(cg, "  br i1 %%done, label %%exit, label %%body\n");
        Emit(cg, "body:\n");
        Emit(cg, "  %%p = getelementptr i8, ptr %%d, %s %%i\n", iat);
        Emit(cg, "  %%c = load i8, ptr %%p\n");
        Emit(cg, "  %%sp = icmp eq i8 %%c, 32\n");
        Emit(cg, "  br i1 %%sp, label %%cont, label %%exit\n");
        Emit(cg, "cont:\n");
        Emit(cg, "  %%ni = add %s %%i, 1\n", iat);
        Emit(cg, "  br label %%loop\n");
        Emit(cg, "exit:\n");
        Emit(cg, "  %%r = phi %s [ %%i, %%loop ], [ %%i, %%body ]\n", iat);
        Emit(cg, "  ret %s %%r\n", iat);
        Emit(cg, "}\n\n");

        /* count_trailing_spaces(ptr data, iN len) -> iN */
        Emit(cg, "define linkonce_odr %s @__ada_count_trailing_spaces(ptr %%d, %s %%len) {\n", iat, iat);
        Emit(cg, "entry:\n");
        Emit(cg, "  %%start = sub %s %%len, 1\n", iat);
        Emit(cg, "  br label %%loop\n");
        Emit(cg, "loop:\n");
        Emit(cg, "  %%i = phi %s [ %%start, %%entry ], [ %%ni, %%cont ]\n", iat);
        Emit(cg, "  %%done = icmp slt %s %%i, 0\n", iat);
        Emit(cg, "  br i1 %%done, label %%exit, label %%body\n");
        Emit(cg, "body:\n");
        Emit(cg, "  %%p = getelementptr i8, ptr %%d, %s %%i\n", iat);
        Emit(cg, "  %%c = load i8, ptr %%p\n");
        Emit(cg, "  %%sp = icmp eq i8 %%c, 32\n");
        Emit(cg, "  br i1 %%sp, label %%cont, label %%exit\n");
        Emit(cg, "cont:\n");
        Emit(cg, "  %%ni = sub %s %%i, 1\n", iat);
        Emit(cg, "  br label %%loop\n");
        Emit(cg, "exit:\n");
        /* trailing count = len - 1 - i (when i is last non-space index) or len (all spaces) */
        Emit(cg, "  %%last = phi %s [ -1, %%loop ], [ %%i, %%body ]\n", iat);
        Emit(cg, "  %%r = sub %s %%len, %%last\n", iat);
        Emit(cg, "  %%r2 = sub %s %%r, 1\n", iat);
        Emit(cg, "  ret %s %%r2\n", iat);
        Emit(cg, "}\n\n");
    }

    /* Runtime globals */
    Emit(cg, "; Runtime globals\n");
    Emit(cg, "@__ss_base = linkonce_odr global ptr null\n");
    Emit(cg, "@__ss_ptr = linkonce_odr global i64 0\n");
    Emit(cg, "@__ss_size = linkonce_odr global i64 0\n");
    Emit(cg, "@__eh_cur = linkonce_odr global ptr null\n");
    Emit(cg, "@__ex_cur = linkonce_odr global i64 0\n");
    Emit(cg, "@__fin_list = linkonce_odr global ptr null\n");
    Emit(cg, "@__entry_queue = linkonce_odr global ptr null\n");
    Emit(cg, "@.fmt_ue = linkonce_odr constant [27 x i8] c\"Unhandled exception: %%lld\\0A\\00\"\n\n");

    /* Standard exceptions (RM 11.1) — names lowercase to match mangled symbols */
    Emit(cg, "; Standard exception identities\n");
    Emit(cg, "@__exc.constraint_error = linkonce_odr constant i64 1\n");
    Emit(cg, "@__exc.numeric_error = linkonce_odr constant i64 2\n");
    Emit(cg, "@__exc.program_error = linkonce_odr constant i64 3\n");
    Emit(cg, "@__exc.storage_error = linkonce_odr constant i64 4\n");
    Emit(cg, "@__exc.tasking_error = linkonce_odr constant i64 5\n\n");

    /* Secondary stack initialization */
    Emit(cg, "; Secondary stack runtime\n");
    Emit(cg, "define linkonce_odr void @__ada_ss_init() {\n");
    Emit(cg, "  %%p = call ptr @malloc(i64 1048576)\n");
    Emit(cg, "  store ptr %%p, ptr @__ss_base\n");
    Emit(cg, "  store i64 1048576, ptr @__ss_size\n");
    Emit(cg, "  store i64 0, ptr @__ss_ptr\n");
    Emit(cg, "  ret void\n");
    Emit(cg, "}\n\n");

    /* Secondary stack mark */
    Emit(cg, "define linkonce_odr i64 @__ada_sec_stack_mark() {\n");
    Emit(cg, "  %%m = load i64, ptr @__ss_ptr\n");
    Emit(cg, "  ret i64 %%m\n");
    Emit(cg, "}\n\n");

    /* Secondary stack release */
    Emit(cg, "define linkonce_odr void @__ada_sec_stack_release(i64 %%m) {\n");
    Emit(cg, "  store i64 %%m, ptr @__ss_ptr\n");
    Emit(cg, "  ret void\n");
    Emit(cg, "}\n\n");

    /* Secondary stack allocate */
    Emit(cg, "define linkonce_odr ptr @__ada_sec_stack_alloc(i64 %%sz) {\n");
    Emit(cg, "entry:\n");
    Emit(cg, "  %%1 = load ptr, ptr @__ss_base\n");
    Emit(cg, "  %%2 = icmp eq ptr %%1, null\n");
    Emit(cg, "  br i1 %%2, label %%init, label %%alloc\n");
    Emit(cg, "init:\n");
    Emit(cg, "  call void @__ada_ss_init()\n");
    Emit(cg, "  %%3 = load ptr, ptr @__ss_base\n");
    Emit(cg, "  br label %%alloc\n");
    Emit(cg, "alloc:\n");
    Emit(cg, "  %%p = phi ptr [%%1, %%entry], [%%3, %%init]\n");
    Emit(cg, "  %%4 = load i64, ptr @__ss_ptr\n");
    Emit(cg, "  %%5 = add i64 %%sz, 7\n");
    Emit(cg, "  %%6 = and i64 %%5, -8\n");
    Emit(cg, "  %%7 = add i64 %%4, %%6\n");
    Emit(cg, "  %%8 = load i64, ptr @__ss_size\n");
    Emit(cg, "  %%9 = icmp ult i64 %%7, %%8\n");
    Emit(cg, "  br i1 %%9, label %%ok, label %%grow\n");
    Emit(cg, "grow:\n");
    Emit(cg, "  %%10 = mul i64 %%8, 2\n");
    Emit(cg, "  store i64 %%10, ptr @__ss_size\n");
    Emit(cg, "  %%11 = call ptr @realloc(ptr %%p, i64 %%10)\n");
    Emit(cg, "  store ptr %%11, ptr @__ss_base\n");
    Emit(cg, "  br label %%ok\n");
    Emit(cg, "ok:\n");
    Emit(cg, "  %%12 = phi ptr [%%p, %%alloc], [%%11, %%grow]\n");
    Emit(cg, "  %%13 = getelementptr i8, ptr %%12, i64 %%4\n");
    Emit(cg, "  store i64 %%7, ptr @__ss_ptr\n");
    Emit(cg, "  ret ptr %%13\n");
    Emit(cg, "}\n\n");

    /* Exception handling: push handler
     * Handler frame structure: { ptr prev, [200 x i8] jmp_buf }
     * Field 0 = link to previous handler
     * Field 1 = jmp_buf for setjmp/longjmp */
    Emit(cg, "; Exception handling runtime\n");
    Emit(cg, "define linkonce_odr void @__ada_push_handler(ptr %%h) {\n");
    Emit(cg, "  %%old = load ptr, ptr @__eh_cur\n");
    Emit(cg, "  %%link = getelementptr { ptr, [200 x i8] }, ptr %%h, i32 0, i32 0\n");
    Emit(cg, "  store ptr %%old, ptr %%link\n");
    Emit(cg, "  store ptr %%h, ptr @__eh_cur\n");
    Emit(cg, "  ret void\n");
    Emit(cg, "}\n\n");

    /* Exception handling: pop handler */
    Emit(cg, "define linkonce_odr void @__ada_pop_handler() {\n");
    Emit(cg, "  %%cur = load ptr, ptr @__eh_cur\n");
    Emit(cg, "  %%is_null = icmp eq ptr %%cur, null\n");
    Emit(cg, "  br i1 %%is_null, label %%done, label %%pop\n");
    Emit(cg, "pop:\n");
    Emit(cg, "  %%link = getelementptr { ptr, [200 x i8] }, ptr %%cur, i32 0, i32 0\n");
    Emit(cg, "  %%prev = load ptr, ptr %%link\n");
    Emit(cg, "  store ptr %%prev, ptr @__eh_cur\n");
    Emit(cg, "  br label %%done\n");
    Emit(cg, "done:\n");
    Emit(cg, "  ret void\n");
    Emit(cg, "}\n\n");

    /* Exception handling: raise */
    Emit(cg, "define linkonce_odr void @__ada_raise(i64 %%exc_id) {\n");
    Emit(cg, "  store i64 %%exc_id, ptr @__ex_cur\n");
    Emit(cg, "  %%frame = load ptr, ptr @__eh_cur\n");
    Emit(cg, "  %%is_null = icmp eq ptr %%frame, null\n");
    Emit(cg, "  br i1 %%is_null, label %%unhandled, label %%jump\n");
    Emit(cg, "jump:\n");
    Emit(cg, "  %%jb = getelementptr { ptr, [200 x i8] }, ptr %%frame, i32 0, i32 1\n");
    Emit(cg, "  call void @longjmp(ptr %%jb, i32 1)\n");
    Emit(cg, "  unreachable\n");
    Emit(cg, "unhandled:\n");
    Emit(cg, "  call i32 (ptr, ...) @printf(ptr @.fmt_ue, i64 %%exc_id)\n");
    Emit(cg, "  call void @exit(i32 1)\n");
    Emit(cg, "  unreachable\n");
    Emit(cg, "}\n\n");

    /* Exception handling: reraise */
    Emit(cg, "define linkonce_odr void @__ada_reraise() {\n");
    Emit(cg, "  %%exc = load i64, ptr @__ex_cur\n");
    Emit(cg, "  call void @__ada_raise(i64 %%exc)\n");
    Emit(cg, "  unreachable\n");
    Emit(cg, "}\n\n");

    /* Exception handling: get current exception */
    Emit(cg, "define linkonce_odr i64 @__ada_current_exception() {\n");
    Emit(cg, "  %%exc = load i64, ptr @__ex_cur\n");
    Emit(cg, "  ret i64 %%exc\n");
    Emit(cg, "}\n\n");

    /* Integer power function */
    Emit(cg, "; Arithmetic runtime\n");
    Emit(cg, "define linkonce_odr i64 @__ada_powi(i64 %%base, i64 %%exp) {\n");
    Emit(cg, "entry:\n");
    Emit(cg, "  %%result = alloca i64\n");
    Emit(cg, "  store i64 1, ptr %%result\n");
    Emit(cg, "  %%e = alloca i64\n");
    Emit(cg, "  store i64 %%exp, ptr %%e\n");
    Emit(cg, "  br label %%loop\n");
    Emit(cg, "loop:\n");
    Emit(cg, "  %%ev = load i64, ptr %%e\n");
    Emit(cg, "  %%cmp = icmp sgt i64 %%ev, 0\n");
    Emit(cg, "  br i1 %%cmp, label %%body, label %%done\n");
    Emit(cg, "body:\n");
    Emit(cg, "  %%rv = load i64, ptr %%result\n");
    Emit(cg, "  %%nv = mul i64 %%rv, %%base\n");
    Emit(cg, "  store i64 %%nv, ptr %%result\n");
    Emit(cg, "  %%ev2 = load i64, ptr %%e\n");
    Emit(cg, "  %%ev3 = sub i64 %%ev2, 1\n");
    Emit(cg, "  store i64 %%ev3, ptr %%e\n");
    Emit(cg, "  br label %%loop\n");
    Emit(cg, "done:\n");
    Emit(cg, "  %%final = load i64, ptr %%result\n");
    Emit(cg, "  ret i64 %%final\n");
    Emit(cg, "}\n\n");

    /* Delay statement support */
    Emit(cg, "; Tasking runtime\n");
    Emit(cg, "define linkonce_odr void @__ada_delay(i64 %%us) {\n");
    Emit(cg, "  %%t = trunc i64 %%us to i32\n");
    Emit(cg, "  call i32 @usleep(i32 %%t)\n");
    Emit(cg, "  ret void\n");
    Emit(cg, "}\n\n");

    /* Task abort: signal task to terminate (simplified: just sets flag) - is this right ??? */
    Emit(cg, "define linkonce_odr void @__ada_task_abort(ptr %%task) {\n");
    Emit(cg, "entry:\n");
    Emit(cg, "  %%1 = icmp eq ptr %%task, null\n");
    Emit(cg, "  br i1 %%1, label %%done, label %%abort\n");
    Emit(cg, "abort:\n");
    Emit(cg, "  ; In full impl: set abort flag, signal condition\n");
    Emit(cg, "  store i8 1, ptr %%task  ; Mark abort pending\n");
    Emit(cg, "  br label %%done\n");
    Emit(cg, "done:\n");
    Emit(cg, "  ret void\n");
    Emit(cg, "}\n\n");

    /* Task terminate: graceful task termination (for terminate alternative).
     * Per RM 9.7.1: a terminate alternative is selected when the task's
     * master has completed and all sibling tasks are terminated or waiting
     * at terminate alternatives.  We terminate just this task's thread. */
    Emit(cg, "define linkonce_odr void @__ada_task_terminate() {\n");
    Emit(cg, "  call void @pthread_exit(ptr null)\n");
    Emit(cg, "  unreachable\n");
    Emit(cg, "}\n\n");

    /* Task Control Block (TCB) layout:
     *   offset  0: ptr  func          (task body function)
     *   offset  8: ptr  parent_frame  (enclosing scope frame)
     *   offset 16: ptr  thread_handle (pthread_t)
     *   offset 24: i8   completed     (0=running, 1=done)
     * Total 25 bytes, rounded to 32 by malloc. */

    /* Task wrapper: calls actual task body then sets completed flag. */
    Emit(cg, "define linkonce_odr ptr @__ada_task_wrapper(ptr %%tcb) {\n");
    Emit(cg, "entry:\n");
    Emit(cg, "  %%func = load ptr, ptr %%tcb\n");
    Emit(cg, "  %%1 = getelementptr ptr, ptr %%tcb, i64 1\n");
    Emit(cg, "  %%frame = load ptr, ptr %%1\n");
    Emit(cg, "  %%_r = call ptr %%func(ptr %%frame)\n");
    Emit(cg, "  %%2 = getelementptr i8, ptr %%tcb, i64 24\n");
    Emit(cg, "  store i8 1, ptr %%2  ; mark completed\n");
    Emit(cg, "  ret ptr null\n");
    Emit(cg, "}\n\n");

    /* Task start: allocate TCB, spawn wrapper thread. Returns TCB ptr. */
    Emit(cg, "define linkonce_odr ptr @__ada_task_start(ptr %%task_func, ptr %%parent_frame) {\n");
    Emit(cg, "entry:\n");
    Emit(cg, "  %%tcb = call ptr @malloc(i64 32)\n");
    Emit(cg, "  store ptr %%task_func, ptr %%tcb\n");
    Emit(cg, "  %%1 = getelementptr ptr, ptr %%tcb, i64 1\n");
    Emit(cg, "  store ptr %%parent_frame, ptr %%1\n");
    Emit(cg, "  %%2 = getelementptr i8, ptr %%tcb, i64 24\n");
    Emit(cg, "  store i8 0, ptr %%2  ; not completed\n");
    Emit(cg, "  %%tid_slot = getelementptr ptr, ptr %%tcb, i64 2\n");
    Emit(cg, "  %%_rc = call i32 @pthread_create(ptr %%tid_slot, ptr null, ptr @__ada_task_wrapper, ptr %%tcb)\n");
    Emit(cg, "  ret ptr %%tcb\n");
    Emit(cg, "}\n\n");

    /* T'CALLABLE (RM 9.9): task is callable iff not completed */
    Emit(cg, "define linkonce_odr i8 @__ada_task_callable(ptr %%tcb) {\n");
    Emit(cg, "entry:\n");
    Emit(cg, "  %%1 = icmp eq ptr %%tcb, null\n");
    Emit(cg, "  br i1 %%1, label %%nil, label %%check\n");
    Emit(cg, "nil:\n  ret i8 0\n");
    Emit(cg, "check:\n");
    Emit(cg, "  %%2 = getelementptr i8, ptr %%tcb, i64 24\n");
    Emit(cg, "  %%3 = load i8, ptr %%2\n");
    Emit(cg, "  %%4 = xor i8 %%3, 1\n");
    Emit(cg, "  ret i8 %%4\n");
    Emit(cg, "}\n\n");

    /* Entry call: caller side of rendezvous (blocks until accept completes) */
    Emit(cg, "define linkonce_odr void @__ada_entry_call(ptr %%task, i64 %%entry_idx, ptr %%params) {\n");
    Emit(cg, "entry:\n");
    Emit(cg, "  ; Allocate rendezvous record: { task_ptr, entry_idx, params, complete_flag, next }\n");
    Emit(cg, "  %%rv = call ptr @malloc(i64 40)\n");
    Emit(cg, "  store ptr %%task, ptr %%rv\n");
    Emit(cg, "  %%1 = getelementptr i64, ptr %%rv, i64 1\n");
    Emit(cg, "  store i64 %%entry_idx, ptr %%1\n");
    Emit(cg, "  %%2 = getelementptr ptr, ptr %%rv, i64 2\n");
    Emit(cg, "  store ptr %%params, ptr %%2\n");
    Emit(cg, "  %%3 = getelementptr i8, ptr %%rv, i64 24\n");
    Emit(cg, "  store i8 0, ptr %%3  ; complete = false\n");
    Emit(cg, "  ; Enqueue to task's entry queue (append to @__entry_queue)\n");
    Emit(cg, "  %%4 = load ptr, ptr @__entry_queue\n");
    Emit(cg, "  %%5 = getelementptr ptr, ptr %%rv, i64 4\n");
    Emit(cg, "  store ptr %%4, ptr %%5\n");
    Emit(cg, "  store ptr %%rv, ptr @__entry_queue\n");
    Emit(cg, "  br label %%wait\n");
    Emit(cg, "wait:\n");
    Emit(cg, "  ; Spin-wait for complete flag (yield to scheduler)\n");
    Emit(cg, "  %%_u1 = call i32 @usleep(i32 100)\n");
    Emit(cg, "  %%6 = load i8, ptr %%3\n");
    Emit(cg, "  %%7 = icmp eq i8 %%6, 0\n");
    Emit(cg, "  br i1 %%7, label %%wait, label %%done\n");
    Emit(cg, "done:\n");
    Emit(cg, "  call void @free(ptr %%rv)\n");
    Emit(cg, "  ret void\n");
    Emit(cg, "}\n\n");

    /* Accept wait: acceptor blocks until entry call arrives */
    Emit(cg, "define linkonce_odr ptr @__ada_accept_wait(i64 %%entry_idx) {\n");
    Emit(cg, "entry:\n");
    Emit(cg, "  br label %%wait\n");
    Emit(cg, "wait:\n");
    Emit(cg, "  ; Scan entry queue for matching entry index\n");
    Emit(cg, "  %%q = load ptr, ptr @__entry_queue\n");
    Emit(cg, "  %%is_empty = icmp eq ptr %%q, null\n");
    Emit(cg, "  br i1 %%is_empty, label %%spin, label %%check\n");
    Emit(cg, "spin:\n");
    Emit(cg, "  %%_u2 = call i32 @usleep(i32 100)\n");
    Emit(cg, "  br label %%wait\n");
    Emit(cg, "check:\n");
    Emit(cg, "  ; Check if first entry matches\n");
    Emit(cg, "  %%1 = getelementptr i64, ptr %%q, i64 1\n");
    Emit(cg, "  %%2 = load i64, ptr %%1\n");
    Emit(cg, "  %%3 = icmp eq i64 %%2, %%entry_idx\n");
    Emit(cg, "  br i1 %%3, label %%found, label %%spin\n");
    Emit(cg, "found:\n");
    Emit(cg, "  ; Dequeue and return caller's parameter block\n");
    Emit(cg, "  %%4 = getelementptr ptr, ptr %%q, i64 4\n");
    Emit(cg, "  %%5 = load ptr, ptr %%4\n");
    Emit(cg, "  store ptr %%5, ptr @__entry_queue\n");
    Emit(cg, "  %%6 = getelementptr ptr, ptr %%q, i64 2\n");
    Emit(cg, "  %%params = load ptr, ptr %%6\n");
    Emit(cg, "  ret ptr %%q\n");
    Emit(cg, "}\n\n");

    /* Accept try: non-blocking check for pending entry call (for SELECT) */
    Emit(cg, "define linkonce_odr ptr @__ada_accept_try(i64 %%entry_idx) {\n");
    Emit(cg, "entry:\n");
    Emit(cg, "  %%q = load ptr, ptr @__entry_queue\n");
    Emit(cg, "  %%is_empty = icmp eq ptr %%q, null\n");
    Emit(cg, "  br i1 %%is_empty, label %%none, label %%check\n");
    Emit(cg, "check:\n");
    Emit(cg, "  %%1 = getelementptr i64, ptr %%q, i64 1\n");
    Emit(cg, "  %%2 = load i64, ptr %%1\n");
    Emit(cg, "  %%3 = icmp eq i64 %%2, %%entry_idx\n");
    Emit(cg, "  br i1 %%3, label %%found, label %%none\n");
    Emit(cg, "found:\n");
    Emit(cg, "  ; Dequeue and return caller's parameter block\n");
    Emit(cg, "  %%4 = getelementptr ptr, ptr %%q, i64 4\n");
    Emit(cg, "  %%5 = load ptr, ptr %%4\n");
    Emit(cg, "  store ptr %%5, ptr @__entry_queue\n");
    Emit(cg, "  ret ptr %%q\n");
    Emit(cg, "none:\n");
    Emit(cg, "  ret ptr null\n");
    Emit(cg, "}\n\n");

    /* Accept complete: signal rendezvous completion to caller */
    Emit(cg, "define linkonce_odr void @__ada_accept_complete(ptr %%rv) {\n");
    Emit(cg, "entry:\n");
    Emit(cg, "  %%1 = getelementptr i8, ptr %%rv, i64 24\n");
    Emit(cg, "  store i8 1, ptr %%1  ; complete = true\n");
    Emit(cg, "  ret void\n");
    Emit(cg, "}\n\n");

    /* Finalization support */
    Emit(cg, "; Finalization runtime\n");
    Emit(cg, "define linkonce_odr void @__ada_finalize(ptr %%obj, ptr %%fn) {\n");
    Emit(cg, "  %%1 = call ptr @malloc(i64 24)\n");
    Emit(cg, "  %%2 = getelementptr ptr, ptr %%1, i64 0\n");
    Emit(cg, "  store ptr %%obj, ptr %%2\n");
    Emit(cg, "  %%3 = getelementptr ptr, ptr %%1, i64 1\n");
    Emit(cg, "  store ptr %%fn, ptr %%3\n");
    Emit(cg, "  %%4 = load ptr, ptr @__fin_list\n");
    Emit(cg, "  %%5 = getelementptr ptr, ptr %%1, i64 2\n");
    Emit(cg, "  store ptr %%4, ptr %%5\n");
    Emit(cg, "  store ptr %%1, ptr @__fin_list\n");
    Emit(cg, "  ret void\n");
    Emit(cg, "}\n\n");

    Emit(cg, "define linkonce_odr void @__ada_finalize_all() {\n");
    Emit(cg, "entry:\n");
    Emit(cg, "  %%1 = load ptr, ptr @__fin_list\n");
    Emit(cg, "  br label %%loop\n");
    Emit(cg, "loop:\n");
    Emit(cg, "  %%p = phi ptr [%%1, %%entry], [%%9, %%fin]\n");
    Emit(cg, "  %%2 = icmp eq ptr %%p, null\n");
    Emit(cg, "  br i1 %%2, label %%done, label %%fin\n");
    Emit(cg, "fin:\n");
    Emit(cg, "  %%3 = getelementptr ptr, ptr %%p, i64 0\n");
    Emit(cg, "  %%4 = load ptr, ptr %%3\n");
    Emit(cg, "  %%5 = getelementptr ptr, ptr %%p, i64 1\n");
    Emit(cg, "  %%6 = load ptr, ptr %%5\n");
    Emit(cg, "  call void %%6(ptr %%4)\n");
    Emit(cg, "  %%8 = getelementptr ptr, ptr %%p, i64 2\n");
    Emit(cg, "  %%9 = load ptr, ptr %%8\n");
    Emit(cg, "  call void @free(ptr %%p)\n");
    Emit(cg, "  br label %%loop\n");
    Emit(cg, "done:\n");
    Emit(cg, "  ret void\n");
    Emit(cg, "}\n\n");

    /* TEXT_IO inline implementation (Ada 83 Chapter 14) */
    Emit(cg, "; TEXT_IO runtime\n");
    Emit(cg, "@stdin = external global ptr\n");
    Emit(cg, "@stdout = external global ptr\n");
    Emit(cg, "@stderr = external global ptr\n");

    /* Wrapper functions for pragma Import(C, ..., "__ada_stdin") etc. in text_io.adb */
    Emit(cg, "define linkonce_odr i64 @__ada_stdin() {\n");
    Emit(cg, "  %%1 = load ptr, ptr @stdin\n");
    Emit(cg, "  %%2 = ptrtoint ptr %%1 to i64\n");
    Emit(cg, "  ret i64 %%2\n");
    Emit(cg, "}\n\n");

    Emit(cg, "define linkonce_odr i64 @__ada_stdout() {\n");
    Emit(cg, "  %%1 = load ptr, ptr @stdout\n");
    Emit(cg, "  %%2 = ptrtoint ptr %%1 to i64\n");
    Emit(cg, "  ret i64 %%2\n");
    Emit(cg, "}\n\n");

    Emit(cg, "define linkonce_odr i64 @__ada_stderr() {\n");
    Emit(cg, "  %%1 = load ptr, ptr @stderr\n");
    Emit(cg, "  %%2 = ptrtoint ptr %%1 to i64\n");
    Emit(cg, "  ret i64 %%2\n");
    Emit(cg, "}\n\n");

    /* Note: fputc, fgetc declared in main preamble; add remaining here */
    Emit(cg, "declare i32 @fputs(ptr, ptr)\n");
    Emit(cg, "declare ptr @fgets(ptr, i32, ptr)\n");
    Emit(cg, "declare i32 @fprintf(ptr, ptr, ...)\n");
    /* Format string depends on INTEGER width: %d for i32, %lld for i64 */
    if (strcmp(iat, "i32") == 0)
        Emit(cg, "@.fmt_d = linkonce_odr constant [3 x i8] c\"%%d\\00\"\n");
    else
        Emit(cg, "@.fmt_d = linkonce_odr constant [5 x i8] c\"%%lld\\00\"\n");
    Emit(cg, "@.fmt_s = linkonce_odr constant [3 x i8] c\"%%s\\00\"\n");
    Emit(cg, "@.fmt_f = linkonce_odr constant [3 x i8] c\"%%g\\00\"\n");
    Emit(cg, "@.fmt_c = linkonce_odr constant [3 x i8] c\"%%c\\00\"\n\n");

    /* NEW_LINE: output line terminator */
    Emit(cg, "define linkonce_odr void @__text_io_new_line() {\n");
    Emit(cg, "  %%out = load ptr, ptr @stdout\n");
    Emit(cg, "  call i32 @fputc(i32 10, ptr %%out)\n");
    Emit(cg, "  ret void\n");
    Emit(cg, "}\n\n");

    /* PUT_CHAR: output single character */
    Emit(cg, "define linkonce_odr void @__text_io_put_char(i8 %%c) {\n");
    Emit(cg, "  %%out = load ptr, ptr @stdout\n");
    Emit(cg, "  %%ci = zext i8 %%c to i32\n");
    Emit(cg, "  call i32 @fputc(i32 %%ci, ptr %%out)\n");
    Emit(cg, "  ret void\n");
    Emit(cg, "}\n\n");

    /* PUT: output string (ptr + bounds in native STRING bound type).
     * Bound type derived from STRING's index type via type system. */
    Emit(cg, "define linkonce_odr void @__text_io_put(ptr %%data, %s %%lo, %s %%hi) {\n",
         rts_sbt, rts_sbt);
    Emit(cg, "entry:\n");
    Emit(cg, "  %%out = load ptr, ptr @stdout\n");
    Emit(cg, "  %%i.init = sub %s %%lo, 1\n", rts_sbt);
    Emit(cg, "  br label %%loop\n");
    Emit(cg, "loop:\n");
    Emit(cg, "  %%i = phi %s [ %%i.init, %%entry ], [ %%i.next, %%body ]\n", rts_sbt);
    Emit(cg, "  %%i.next = add %s %%i, 1\n", rts_sbt);
    Emit(cg, "  %%done = icmp sgt %s %%i.next, %%hi\n", rts_sbt);
    Emit(cg, "  br i1 %%done, label %%exit, label %%body\n");
    Emit(cg, "body:\n");
    Emit(cg, "  %%idx_bt = sub %s %%i.next, %%lo\n", rts_sbt);
    Emit_Widen_Named_For_Intrinsic(cg, "idx_bt", "idx", rts_sbt);
    Emit(cg, "  %%ptr = getelementptr i8, ptr %%data, %s %%idx\n", iat);
    Emit(cg, "  %%ch = load i8, ptr %%ptr\n");
    Emit(cg, "  %%chi = zext i8 %%ch to i32\n");
    Emit(cg, "  call i32 @fputc(i32 %%chi, ptr %%out)\n");
    Emit(cg, "  br label %%loop\n");
    Emit(cg, "exit:\n");
    Emit(cg, "  ret void\n");
    Emit(cg, "}\n\n");

    /* PUT_LINE: output string followed by newline */
    Emit(cg, "define linkonce_odr void @__text_io_put_line(ptr %%data, %s %%lo, %s %%hi) {\n",
         rts_sbt, rts_sbt);
    Emit(cg, "  call void @__text_io_put(ptr %%data, %s %%lo, %s %%hi)\n",
         rts_sbt, rts_sbt);
    Emit(cg, "  call void @__text_io_new_line()\n");
    Emit(cg, "  ret void\n");
    Emit(cg, "}\n\n");

    /* PUT_INTEGER: output integer with optional width */
    Emit(cg, "define linkonce_odr void @__text_io_put_int(%s %%val, i32 %%width) {\n", iat);
    Emit(cg, "  %%out = load ptr, ptr @stdout\n");
    Emit(cg, "  call i32 (ptr, ptr, ...) @fprintf(ptr %%out, ptr @.fmt_d, %s %%val)\n", iat);
    Emit(cg, "  ret void\n");
    Emit(cg, "}\n\n");

    /* PUT_FLOAT: output float value */
    Emit(cg, "define linkonce_odr void @__text_io_put_float(double %%val) {\n");
    Emit(cg, "  %%out = load ptr, ptr @stdout\n");
    Emit(cg, "  call i32 (ptr, ptr, ...) @fprintf(ptr %%out, ptr @.fmt_f, double %%val)\n");
    Emit(cg, "  ret void\n");
    Emit(cg, "}\n\n");

    /* GET_CHAR: read single character */
    Emit(cg, "define linkonce_odr i8 @__text_io_get_char() {\n");
    Emit(cg, "  %%inp = load ptr, ptr @stdin\n");
    Emit(cg, "  %%c = call i32 @fgetc(ptr %%inp)\n");
    Emit(cg, "  %%c8 = trunc i32 %%c to i8\n");
    Emit(cg, "  ret i8 %%c8\n");
    Emit(cg, "}\n\n");

    /* GET_LINE: read line into buffer, return fat pointer.
     * Bounds use STRING bound type derived from type system. */
    {
        char lo_expr[64], hi_empty_expr[64];
        snprintf(lo_expr, sizeof(lo_expr), "%s 1", rts_sbt);
        snprintf(hi_empty_expr, sizeof(hi_empty_expr), "%s 0", rts_sbt);

        Emit(cg, "define linkonce_odr " FAT_PTR_TYPE " @__text_io_get_line() {\n");
        Emit(cg, "entry:\n");
        Emit(cg, "  %%buf = call ptr @__ada_sec_stack_alloc(i64 256)\n");
        Emit(cg, "  %%inp = load ptr, ptr @stdin\n");
        Emit(cg, "  %%res = call ptr @fgets(ptr %%buf, i32 255, ptr %%inp)\n");
        Emit(cg, "  %%iseof = icmp eq ptr %%res, null\n");
        Emit(cg, "  br i1 %%iseof, label %%empty, label %%gotline\n");
        Emit(cg, "empty:\n");
        Emit_Fat_Pointer_Insertvalue_Named(cg, "e", "ptr %buf", lo_expr, hi_empty_expr, rts_sbt);
        Emit(cg, "  ret " FAT_PTR_TYPE " %%e2\n");
        Emit(cg, "gotline:\n");
        Emit(cg, "  %%len = call i64 @strlen(ptr %%buf)\n");
        Emit(cg, "  ; Strip trailing newline if present\n");
        Emit(cg, "  %%lastidx = sub i64 %%len, 1\n");
        Emit(cg, "  %%lastptr = getelementptr i8, ptr %%buf, i64 %%lastidx\n");
        Emit(cg, "  %%lastch = load i8, ptr %%lastptr\n");
        Emit(cg, "  %%isnl = icmp eq i8 %%lastch, 10\n");
        Emit(cg, "  %%adjlen = select i1 %%isnl, i64 %%lastidx, i64 %%len\n");
        /* adjlen is i64 from strlen; trunc directly to bound type */
        Emit(cg, "  %%adjlen_bt = trunc i64 %%adjlen to %s\n", rts_sbt);
        {
            char hi_expr[64];
            snprintf(hi_expr, sizeof(hi_expr), "%s %%adjlen_bt", rts_sbt);
            Emit_Fat_Pointer_Insertvalue_Named(cg, "f", "ptr %buf", lo_expr, hi_expr, rts_sbt);
        }
        Emit(cg, "  ret " FAT_PTR_TYPE " %%f2\n");
        Emit(cg, "}\n\n");
    }

    /* 'IMAGE runtime: Integer'IMAGE(x) returns string representation */
    Emit(cg, "; Attribute runtime support\n");
    Emit(cg, "declare i32 @snprintf(ptr, i64, ptr, ...)\n");
    Emit(cg, "declare i64 @strlen(ptr)\n");
    if (strcmp(iat, "i32") == 0)
        Emit(cg, "@.img_fmt_d = linkonce_odr constant [4 x i8] c\"%% d\\00\"\n");
    else
        Emit(cg, "@.img_fmt_d = linkonce_odr constant [6 x i8] c\"%% lld\\00\"\n");
    Emit(cg, "@.img_fmt_c = linkonce_odr constant [3 x i8] c\"%%c\\00\"\n");
    Emit(cg, "@.img_fmt_f = linkonce_odr constant [5 x i8] c\"%%.6g\\00\"\n\n");

    /* Integer'IMAGE - convert integer to string fat pointer.
     * Bounds use STRING bound type derived from type system. */
    {
        char lo_expr[64], hi_expr[64], const3_expr[64];
        snprintf(lo_expr, sizeof(lo_expr), "%s 1", rts_sbt);

        Emit(cg, "define linkonce_odr " FAT_PTR_TYPE " @__ada_integer_image(%s %%val) {\n", iat);
        Emit(cg, "entry:\n");
        Emit(cg, "  %%buf = call ptr @__ada_sec_stack_alloc(i64 24)\n");
        Emit(cg, "  %%len32 = call i32 (ptr, i64, ptr, ...) @snprintf(ptr %%buf, i64 24, ptr @.img_fmt_d, %s %%val)\n", iat);
        Emit_Widen_Named_For_Intrinsic(cg, "len32", "len64", "i32");  /* snprintf returns i32 */
        Emit_Narrow_Named_From_Intrinsic(cg, "len64", "len_bt", rts_sbt);
        snprintf(hi_expr, sizeof(hi_expr), "%s %%len_bt", rts_sbt);
        Emit_Fat_Pointer_Insertvalue_Named(cg, "fat", "ptr %buf", lo_expr, hi_expr, rts_sbt);
        Emit(cg, "  ret " FAT_PTR_TYPE " %%fat2\n");
        Emit(cg, "}\n\n");

        /* Character'IMAGE - single char to string (3 chars: 'x') */
        snprintf(const3_expr, sizeof(const3_expr), "%s 3", rts_sbt);
        Emit(cg, "define linkonce_odr " FAT_PTR_TYPE " @__ada_character_image(i8 %%val) {\n");
        Emit(cg, "entry:\n");
        Emit(cg, "  %%buf = call ptr @__ada_sec_stack_alloc(i64 4)\n");
        Emit(cg, "  %%p0 = getelementptr i8, ptr %%buf, i64 0\n");
        Emit(cg, "  store i8 39, ptr %%p0  ; single quote\n");
        Emit(cg, "  %%p1 = getelementptr i8, ptr %%buf, i64 1\n");
        Emit(cg, "  store i8 %%val, ptr %%p1\n");
        Emit(cg, "  %%p2 = getelementptr i8, ptr %%buf, i64 2\n");
        Emit(cg, "  store i8 39, ptr %%p2  ; single quote\n");
        Emit_Fat_Pointer_Insertvalue_Named(cg, "fat", "ptr %buf", lo_expr, const3_expr, rts_sbt);
        Emit(cg, "  ret " FAT_PTR_TYPE " %%fat2\n");
        Emit(cg, "}\n\n");

        /* Float'IMAGE - convert float to string */
        Emit(cg, "define linkonce_odr " FAT_PTR_TYPE " @__ada_float_image(double %%val) {\n");
        Emit(cg, "entry:\n");
        Emit(cg, "  %%buf = call ptr @__ada_sec_stack_alloc(i64 32)\n");
        Emit(cg, "  %%len32 = call i32 (ptr, i64, ptr, ...) @snprintf(ptr %%buf, i64 32, ptr @.img_fmt_f, double %%val)\n");
        Emit_Widen_Named_For_Intrinsic(cg, "len32", "flen64", "i32");  /* snprintf returns i32 */
        Emit_Narrow_Named_From_Intrinsic(cg, "flen64", "flen_bt", rts_sbt);
        snprintf(hi_expr, sizeof(hi_expr), "%s %%flen_bt", rts_sbt);
        Emit_Fat_Pointer_Insertvalue_Named(cg, "fat", "ptr %buf", lo_expr, hi_expr, rts_sbt);
        Emit(cg, "  ret " FAT_PTR_TYPE " %%fat2\n");
        Emit(cg, "}\n\n");
    }

    /* Generate exception identity globals */
    Generate_Exception_Globals(cg);

    /* Generate implicit operators for frozen composite types */
    Generate_Implicit_Operators(cg);
    Emit(cg, "\n");

    cg->header_emitted = true;
    }  /* End of header emission block */

    /* Generate extern declarations for WITH'd packages */
    Generate_Extern_Declarations(cg, node);

    /* Generate declarations */
    if (node->compilation_unit.unit) {
        Generate_Declaration(cg, node->compilation_unit.unit);
    }

    /* Emit buffered string constants at module level */
    if (cg->string_const_size > 0) {
        Emit(cg, "\n; String constants\n");
        fprintf(cg->output, "%s", cg->string_const_buffer);
        Emit(cg, "\n");
        cg->string_const_size = 0;  /* Reset buffer for next compilation unit */
    }

    /* Generate main function if this is a main program (library-level procedure).
     * Emit @main() for the LAST parameterless library-level procedure in the file.
     * We track main_candidate and emit at end of Compile_File instead. */
    Syntax_Node *unit = node->compilation_unit.unit;
    if (unit and unit->kind == NK_PROCEDURE_BODY and unit->symbol) {
        Symbol *main_sym = unit->symbol;
        /* Check if this is a library-level procedure (no parameters)
         * and NOT a SEPARATE subunit */
        if (main_sym->parameter_count == 0 and not unit->subprogram_body.is_separate) {
            cg->main_candidate = main_sym;
        }
    }
}

/* ═══════════════════════════════════════════════════════════════════════════
 * §17. MAIN DRIVER
 * ═══════════════════════════════════════════════════════════════════════════
 */

static void Compile_File(const char *input_path, const char *output_path) {
    /* Reset loaded bodies for this compilation */
    Loaded_Body_Count = 0;
    Loaded_Body_Names_Count = 0;

    size_t source_size;
    char *source = Read_File(input_path, &source_size);

    if (not source) {
        fprintf(stderr, "Error: cannot read file '%s'\n", input_path);
        return;
    }

    /* Parse all compilation units in the file */
    Parser parser = Parser_New(source, source_size, input_path);
    Syntax_Node *units[64];
    int unit_count = 0;

    while (parser.current_token.kind != TK_EOF and unit_count < 64 and not parser.had_error) {
        units[unit_count++] = Parse_Compilation_Unit(&parser);
    }

    if (parser.had_error) {
        fprintf(stderr, "Parsing failed with %d error(s)\n", Error_Count);
        free(source);
        return;
    }

    /* Semantic analysis for all units */
    Symbol_Manager *sm = Symbol_Manager_New();
    for (int i = 0; i < unit_count; i++) {
        Resolve_Compilation_Unit(sm, units[i]);
    }

    if (Error_Count > 0) {
        fprintf(stderr, "Semantic analysis failed with %d error(s)\n", Error_Count);
        free(source);
        return;
    }

    /* Code generation */
    FILE *out_file;
    bool close_output = false;

    if (output_path) {
        out_file = fopen(output_path, "w");
        if (not out_file) {
            fprintf(stderr, "Error: cannot open output file '%s'\n", output_path);
            free(source);
            return;
        }
        close_output = true;
    } else {
        out_file = stdout;  /* Output to stdout if no -o specified */
    }

    Code_Generator *cg = Code_Generator_New(out_file, sm);
    for (int i = 0; i < unit_count; i++) {
        Generate_Compilation_Unit(cg, units[i]);
    }

    /* Generate code for loaded package bodies (e.g., TEXT_IO) */
    for (int i = 0; i < Loaded_Body_Count; i++) {
        Generate_Compilation_Unit(cg, Loaded_Package_Bodies[i]);
    }

    /* Note: Derived type operations (RM 3.4) don't need wrapper functions.
     * Derived types have identical representation to parent types in Ada 83,
     * so calls to derived operations are emitted directly to the parent's
     * implementation (GNAT-style optimization). See call_target handling
     * in Generate_Apply(). */

    /* Emit address marker globals for 'ADDRESS attribute on packages/generics */
    for (uint32_t i = 0; i < cg->address_marker_count; i++) {
        Symbol *sym = cg->address_markers[i];
        Emit(cg, "@__addr.");
        Emit_Symbol_Name(cg, sym);
        Emit(cg, " = linkonce_odr constant i8 0\n");
    }

    /* ══════════════════════════════════════════════════════════════════════
     * Emit @main() with GNAT LLVM-style elaboration order (§15.7)
     *
     * Per Ada RM 10.2, library units must be elaborated in a safe order
     * before the main subprogram executes. The elaboration model (§15.7)
     * computes this order using dependency analysis and topological sort.
     *
     * The algorithm respects:
     *   • WITH clause dependencies
     *   • pragma Elaborate / Elaborate_All
     *   • Spec-before-body ordering
     *   • Preelaborate / Pure unit optimizations
     * ══════════════════════════════════════════════════════════════════════ */
    if (cg->main_candidate) {
        /* Compute elaboration order using the dependency graph algorithm */
        Elab_Order_Status elab_status = Elab_Compute_Order();

        if (elab_status == ELAB_ORDER_HAS_ELABORATE_ALL_CYCLE) {
            fprintf(stderr, "Error: circular pragma Elaborate_All dependency\n");
        } else if (elab_status == ELAB_ORDER_HAS_CYCLE) {
            fprintf(stderr, "Warning: elaboration cycle detected, using source order\n");
        }

        Emit(cg, "\n; C main entry point\n");
        Emit(cg, "; Elaboration order computed by GNAT LLVM-style algorithm (S15.7)\n");
        Emit(cg, "define i32 @main() {\n");

        /* Call elaboration functions in computed dependency order.
         * Prefer the graph-computed order; fall back to source order. */
        uint32_t elab_order_count = Elab_Get_Order_Count();
        if (elab_order_count > 0 and elab_status == ELAB_ORDER_OK) {
            for (uint32_t i = 0; i < elab_order_count; i++) {
                if (not Elab_Needs_Elab_Call(i)) continue;
                Symbol *sym = Elab_Get_Order_Symbol(i);
                if (not sym) continue;
                Emit(cg, "  call void @");
                Emit_Symbol_Name(cg, sym);
                Emit(cg, "___elab()\n");
            }
        } else {
            /* Fallback to source order (old behavior) */
            for (uint32_t i = 0; i < cg->elab_func_count; i++) {
                Emit(cg, "  call void @");
                Emit_Symbol_Name(cg, cg->elab_funcs[i]);
                Emit(cg, "___elab()\n");
            }
        }

        Emit(cg, "  call void @");
        Emit_Symbol_Name(cg, cg->main_candidate);
        Emit(cg, "()\n");
        Emit(cg, "  call void @exit(i32 0)\n");
        Emit(cg, "  ret i32 0\n");
        Emit(cg, "}\n");
    }

    /* Emit tracked exception globals that weren't defined in the header.
     * This handles instance-prefixed exceptions from generic instantiations
     * (e.g., @__exc.seq_io__status_error_s0 from SEQ_IO.STATUS_ERROR). */
    if (cg->exc_ref_count > 0) {
        for (uint32_t i = 0; i < cg->exc_ref_count; i++) {
            const char *name = cg->exc_refs[i];
            /* Check if already defined by Generate_Exception_Globals (in header).
             * Compare against each declared exception's mangled name. */
            bool already = false;
            for (uint32_t j = 0; j < Exception_Symbol_Count; j++) {
                FILE *real_out = cg->output;
                char buf[256];
                FILE *mem = fmemopen(buf, sizeof(buf) - 1, "w");
                cg->output = mem;
                Emit_Symbol_Name(cg, Exception_Symbols[j]);
                fflush(mem);
                long len = ftell(mem);
                fclose(mem);
                buf[len] = '\0';
                cg->output = real_out;
                if (strcmp(name, buf) == 0) { already = true; break; }
            }
            /* Also check standard exceptions */
            if (!already) {
                static const char *std_exc[] = {
                    "constraint_error", "numeric_error", "program_error",
                    "storage_error", "tasking_error", NULL
                };
                for (int j = 0; std_exc[j]; j++) {
                    if (strcmp(name, std_exc[j]) == 0) { already = true; break; }
                }
            }
            if (!already) {
                Emit(cg, "@__exc.%s = private constant i8 0\n", name);
            }
        }
    }

    if (close_output) {
        fclose(out_file);
        fprintf(stderr, "Compiled '%s' -> '%s'\n", input_path, output_path);

        /* Generate GNAT-compatible .ali file for dependency tracking */
        Generate_ALI_File(output_path, units, unit_count, source, source_size, sm);
    }
    free(source);
}

/* ─────────────────────────────────────────────────────────────────────────
 * Derive output .ll path from input path by replacing extension.
 * Writes into caller-supplied buffer.
 * ───────────────────────────────────────────────────────────────────────── */
static void Derive_Output_Path(const char *input, char *out, size_t out_size) {
    strncpy(out, input, out_size - 1);
    out[out_size - 1] = '\0';
    char *dot = strrchr(out, '.');
    char *slash = strrchr(out, '/');
    /* Only replace if the dot is after the last slash (i.e., part of filename) */
    if (dot and (not slash or dot > slash))
        strcpy(dot, ".ll");
    else
        strncat(out, ".ll", out_size - strlen(out) - 1);
}

/* ─────────────────────────────────────────────────────────────────────────
 * Parallel compilation — fork-based worker called from a pthread.
 *
 * Each thread forks a child process that compiles one file.  fork() gives
 * complete isolation of all global state (arena, error count, loaded
 * packages, etc.) without refactoring Compile_File.
 * ───────────────────────────────────────────────────────────────────────── */
typedef struct {
    const char *input_path;
    const char *output_path;  /* NULL > derive from input */
    int         exit_status;  /* 0 = success, 1 = failure */
} Compile_Job;

static void *Compile_Worker(void *arg) {
    Compile_Job *job = (Compile_Job *)arg;

    char derived[512];
    const char *out = job->output_path;
    if (not out) {
        Derive_Output_Path(job->input_path, derived, sizeof(derived));
        out = derived;
    }

    pid_t pid = fork();
    if (pid == 0) {
        /* Child — compile and exit */
        Compile_File(job->input_path, out);
        _exit(Error_Count > 0 ? 1 : 0);
    } else if (pid > 0) {
        int status;
        waitpid(pid, &status, 0);
        job->exit_status = WIFEXITED(status) ? WEXITSTATUS(status) : 1;
    } else {
        perror("fork");
        job->exit_status = 1;
    }
    return NULL;
}

int main(int argc, char *argv[]) {
    if (argc < 2) {
        fprintf(stderr,
            "Usage: %s [-I path] <input.ada ...> [-o output.ll]\n", argv[0]);
        return 1;
    }

    const char *inputs[256];
    int input_count = 0;
    const char *output = NULL;  /* NULL means derive from input name */

    /* Parse command-line arguments */
    for (int i = 1; i < argc; i++) {
        if (strcmp(argv[i], "-I") == 0 and i + 1 < argc) {
            if (Include_Path_Count < 32)
                Include_Paths[Include_Path_Count++] = argv[++i];
        } else if (strncmp(argv[i], "-I", 2) == 0) {
            if (Include_Path_Count < 32)
                Include_Paths[Include_Path_Count++] = argv[i] + 2;
        } else if (strcmp(argv[i], "-o") == 0 and i + 1 < argc) {
            output = argv[++i];
        } else if (argv[i][0] != '-') {
            if (input_count < 256)
                inputs[input_count++] = argv[i];
        }
    }

    if (input_count == 0) {
        fprintf(stderr, "Error: no input file specified\n");
        return 1;
    }

    if (output and input_count > 1) {
        fprintf(stderr, "Error: -o cannot be used with multiple input files\n");
        return 1;
    }

    /* ── Auto-discover rts path from executable location ──────────────── */
    {
        char exe_path[PATH_MAX];
        ssize_t len = readlink("/proc/self/exe", exe_path, sizeof(exe_path) - 1);
        if (len > 0) {
            exe_path[len] = '\0';
        } else {
            /* Fallback: use argv[0] */
            strncpy(exe_path, argv[0], sizeof(exe_path) - 1);
            exe_path[sizeof(exe_path) - 1] = '\0';
        }
        char *slash = strrchr(exe_path, '/');
        if (slash) {
            *slash = '\0';
            static char rts_path[PATH_MAX + 8];
            snprintf(rts_path, sizeof(rts_path), "%s/rts", exe_path);
            struct stat st;
            if (stat(rts_path, &st) == 0 and S_ISDIR(st.st_mode)) {
                if (Include_Path_Count < 32)
                    Include_Paths[Include_Path_Count++] = rts_path;
            }
        }
    }

    /* ── Auto-discover input file's directory as include path ─────────── */
    {
        const char *slash = strrchr(inputs[0], '/');
        if (slash) {
            static char input_dir[PATH_MAX];
            size_t dir_len = (size_t)(slash - inputs[0]);
            if (dir_len >= sizeof(input_dir)) dir_len = sizeof(input_dir) - 1;
            memcpy(input_dir, inputs[0], dir_len);
            input_dir[dir_len] = '\0';
            if (Include_Path_Count < 32)
                Include_Paths[Include_Path_Count++] = input_dir;
        }
    }

    /* Add current directory to include paths by default */
    if (Include_Path_Count < 32)
        Include_Paths[Include_Path_Count++] = ".";

    /* ── Compile ──────────────────────────────────────────────────────── */
    if (input_count == 1) {
        /* Single file — existing sequential behaviour */
        Compile_File(inputs[0], output);
        Arena_Free_All();
        return Error_Count > 0 ? 1 : 0;
    }

    /* Multiple files — parallel compilation using pthreads + fork */
    long nprocs = sysconf(_SC_NPROCESSORS_ONLN);
    if (nprocs < 1) nprocs = 1;
    int nthreads = (input_count < (int)nprocs) ? input_count : (int)nprocs;

    Compile_Job jobs[256];
    pthread_t threads[256];

    for (int base = 0; base < input_count; base += nthreads) {
        int batch = input_count - base;
        if (batch > nthreads) batch = nthreads;

        for (int i = 0; i < batch; i++) {
            jobs[base + i].input_path = inputs[base + i];
            jobs[base + i].output_path = NULL;  /* derive from input */
            jobs[base + i].exit_status = 0;
            pthread_create(&threads[i], NULL, Compile_Worker,
                           &jobs[base + i]);
        }
        for (int i = 0; i < batch; i++) {
            pthread_join(threads[i], NULL);
        }
    }

    int failed = 0;
    for (int i = 0; i < input_count; i++) {
        if (jobs[i].exit_status != 0) failed++;
    }

    if (failed > 0)
        fprintf(stderr, "%d of %d compilations failed\n", failed, input_count);

    return failed > 0 ? 1 : 0;
}

/* ═══════════════════════════════════════════════════════════════════════════
 * END OF Ada 83
 * ═══════════════════════════════════════════════════════════════════════════
 */
